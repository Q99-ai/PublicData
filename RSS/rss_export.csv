ID,title,link,description,authors,published
0,Multiverse Computing Raises €25 Million ($27M USD) in Oversubscribed Series A Funding Round,https://quantumcomputingreport.com/multiverse-computing-raises-e25-million-27m-usd-in-oversubscribed-series-a-funding-round/,"<p>Multiverse Computing, a leading European quantum software company, has successfully raised €25 million ($27M USD) in Series A funding. The investment round, oversubscribed, was led by Columbus Venture Partners and Quantonation Ventures, with contributions from various other investors including the European Innovation Council Fund and Redstone QAI Quantum Fund. This funding will be utilized to [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/multiverse-computing-raises-e25-million-27m-usd-in-oversubscribed-series-a-funding-round/\">Multiverse Computing Raises €25 Million ($27M USD) in Oversubscribed Series A Funding Round</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'Mohamed Abdel-Kareem'}],"Tue, 05 Mar 2024 18:55:19 +0000"
1,Maybell Quantum Secures $25M Series A Funding Led by Cerberus Ventures,https://quantumcomputingreport.com/maybell-quantum-secures-25m-series-a-funding-led-by-cerberus-ventures/,"<p>Maybell Quantum, a quantum infrastructure company, has secured $25M in Series A funding led by Cerberus Ventures. The funding will enable Maybell to scale manufacturing and open a new production facility in 2024. Maybell, founded in 2021, provides quantum infrastructure products such as their cryogenic platforms, the Fridge and the Big Fridge. In 2023, they [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/maybell-quantum-secures-25m-series-a-funding-led-by-cerberus-ventures/\">Maybell Quantum Secures $25M Series A Funding Led by Cerberus Ventures</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'Mohamed Abdel-Kareem'}],"Tue, 05 Mar 2024 05:51:45 +0000"
2,Quantum Computing Inc. Introduces Its Dirac-3 Entropy Quantum Computer for Optimization Applications,https://quantumcomputingreport.com/quantum-computing-inc-its-dirac-3-entropy-quantum-computer-for-optimization-applications/,"<p>Picture of the Direc-3 Entropy Quantum Computer. Credit: QCI Quantum Computing Inc. (QCi) has launched Dirac-3, a quantum optimization platform designed to solve complex problems using nonlinear quantum optics. The system encodes a problem into its photonic architecture and modulates the interaction between variables, ultimately finding an optimal solution. Unique to Dirac is its ability [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/quantum-computing-inc-its-dirac-3-entropy-quantum-computer-for-optimization-applications/\">Quantum Computing Inc. Introduces Its Dirac-3 Entropy Quantum Computer for Optimization Applications</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'dougfinke'}],"Sat, 02 Mar 2024 01:21:59 +0000"
3,SBQuantum and Silicon Microgravity Partner to Develop Drone-based Dual Sensor Systems for Mineral Exploration,https://quantumcomputingreport.com/sbquantum-and-silicon-microgravity-partner-to-develop-drone-based-dual-sensor-systems-for-mineral-exploration/,"<p>SBQuantum, a company developing diamond quantum magnetometers, and Silicon Microgravity, a company developing innovative inertial and gravity sensors, have partnered to accelerate mining exploration using quantum sensing. Their project, QUAMINEX (Quantum Accelerated Mining Exploration), involves the development of a drone-based system of sensors that combine magnetics and gravimetry. This system will improve the location and [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/sbquantum-and-silicon-microgravity-partner-to-develop-drone-based-dual-sensor-systems-for-mineral-exploration/\">SBQuantum and Silicon Microgravity Partner to Develop Drone-based Dual Sensor Systems for Mineral Exploration</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'dougfinke'}],"Sat, 02 Mar 2024 00:12:56 +0000"
4,Three Quantum Companies in Denmark Join BioInnovation Institute’s Venture Lab Program,https://quantumcomputingreport.com/three-quantum-companies-in-denmark-join-bioinnovation-institutes-venture-lab-program/,"<p>The BioInnovation Institute (BII), is an international non-profit foundation in Denmark that incubates and accelerates world-class life science research. They have just announced that twelve companies have been selected to join their 12 month Venture Lab acceleration program which supports startup companies with business acceleration, scientific, and team development. The program also provides each startup with [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/three-quantum-companies-in-denmark-join-bioinnovation-institutes-venture-lab-program/\">Three Quantum Companies in Denmark Join BioInnovation Institute&#8217;s Venture Lab Program</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'dougfinke'}],"Fri, 01 Mar 2024 21:05:43 +0000"
5,Rigetti Computing Secures Innovate UK Grant to Develop 24-qubit Quantum Computing System for National Quantum Computing Centre,https://quantumcomputingreport.com/rigetti-computing-secures-innovate-uk-grant-to-develop-24-qubit-quantum-computing-system-for-national-quantum-computing-centre/,"<p>Rigetti Computing's UK subsidiary has secured a Small Business Research Initiative (SBRI) grant from Innovate UK, in collaboration with the National Quantum Computing Centre (NQCC), to develop and deliver a 24-qubit quantum computing system. This system, based on Rigetti's fourth-generation Ankaa™-class architecture, will be deployed at NQCC's Harwell Campus. The proposed technology promises faster gate [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/rigetti-computing-secures-innovate-uk-grant-to-develop-24-qubit-quantum-computing-system-for-national-quantum-computing-centre/\">Rigetti Computing Secures Innovate UK Grant to Develop 24-qubit Quantum Computing System for National Quantum Computing Centre</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'Mohamed Abdel-Kareem'}],"Fri, 01 Mar 2024 20:28:05 +0000"
6,Zurich Instruments Launches SHF+ Line for High-Fidelity Qubit Control,https://quantumcomputingreport.com/zurich-instruments-launches-shf-line-for-high-fidelity-qubit-control/,"<p>Zurich Instruments introduces the SHF+ product line, comprising the SHFSG+ Signal Generator, SHFQC+ Qubit Controller, and SHFQA+ Quantum Analyzer, designed for high-fidelity qubit control and readout. With a 10 dB increase in signal-to-noise ratio (SNR), these products minimize thermal qubit excitation, enhancing algorithm fidelity and reducing phase errors. The SHF+ line offers noise-optimized signal chains [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/zurich-instruments-launches-shf-line-for-high-fidelity-qubit-control/\">Zurich Instruments Launches SHF+ Line for High-Fidelity Qubit Control</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'Mohamed Abdel-Kareem'}],"Fri, 01 Mar 2024 04:09:19 +0000"
7,QuantWare Unveils Next-Gen Quantum Processors: Contralto-D and Soprano-D,https://quantumcomputingreport.com/quantware-unveils-next-gen-quantum-processors-contralto-d-and-soprano-d/,"<p>QuantWare unveiled its latest offerings, Contralto-D and Soprano-D. These devices are intended for customers who want to build up their own systems and just want to purchase the individual qubit chips. Although going that route is much more complex than purchasing a fully complete system, doing so can potential save a significant amount of money. [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/quantware-unveils-next-gen-quantum-processors-contralto-d-and-soprano-d/\">QuantWare Unveils Next-Gen Quantum Processors: Contralto-D and Soprano-D</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'Mohamed Abdel-Kareem'}],"Fri, 01 Mar 2024 03:33:50 +0000"
8,IonQ Announces Q4 and Full Year 2023 Financial Results Showing Strong Growth,https://quantumcomputingreport.com/ionq-announces-q4-and-full-year-2023-financial-results-showing-strong-growth/,"<p>IonQ announced their Q4 and full year 2023 financial results showing strong growth from the previous year. For Q4'2023 they recorded revenue of $6.1 million versus $6.1 million in Q3'2023 and $3.8 million in Q4'2022. For the full year of 2023 they achieved revenue of $22 million almost double the full year 2022 amount of [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/ionq-announces-q4-and-full-year-2023-financial-results-showing-strong-growth/\">IonQ Announces Q4 and Full Year 2023 Financial Results Showing Strong Growth</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'dougfinke'}],"Thu, 29 Feb 2024 05:38:51 +0000"
9,Q-CTRL Forges Strategic Partnerships to Advance Quantum Computing Ecosystem,https://quantumcomputingreport.com/q-ctrl-forges-strategic-partnerships-to-advance-quantum-computing-ecosystem/,"<p>Q-CTRL, a leading provider of quantum infrastructure software, has announced strategic partnerships with Wolfram, Aqarios, qBraid, Qblox, Keysight, and QuantWare. These collaborations aim to enhance quantum research, commercialization, and adoption by integrating Q-CTRL's AI-driven performance-management software with diverse hardware and software platforms. For instance, Fire Opal, Q-CTRL's software, now integrates with Wolfram's Mathematica, enabling users [...]</p>
<p>The post <a href=\"https://quantumcomputingreport.com/q-ctrl-forges-strategic-partnerships-to-advance-quantum-computing-ecosystem/\">Q-CTRL Forges Strategic Partnerships to Advance Quantum Computing Ecosystem</a> appeared first on <a href=\"https://quantumcomputingreport.com\">Quantum Computing Report</a>.</p>",[{'name': 'Mohamed Abdel-Kareem'}],"Wed, 28 Feb 2024 20:19:23 +0000"
10,"Qblox, Maybell and Quantware Unite to Launch a Full-Stack Quantum System in Just 2 Days",https://thequantuminsider.com/2024/03/05/qblox-maybell-and-quantware-unite-to-launch-a-full-stack-quantum-system-in-just-2-days/,"<a href=\"https://thequantuminsider.com/2024/03/05/qblox-maybell-and-quantware-unite-to-launch-a-full-stack-quantum-system-in-just-2-days/\" rel=\"nofollow\" title=\"Qblox, Maybell and Quantware Unite to Launch a Full-Stack Quantum System in Just 2 Days\"><img alt=\"APS Meeting\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"1920\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/IMG-20240304-WA0020-scaled.jpg\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"2560\" /></a>Insider Brief Qblox, Maybell and QuantWare build a fully functional superconducting quantum computer on a conference floor. The system includes quantum devices, a 10mK cryostat, and the control electronics necessary to perform live qubit operations on the conference floor. The combination of advanced technologies features the Maybell Fridge, QuantWare Soprano chip, and Qblox Cluster control [&#8230;]",[{'name': 'Matt Swayne'}],"Tue, 05 Mar 2024 19:20:10 +0000"
11,Bluefors Launches New Gas Handling System Generation 2,https://thequantuminsider.com/2024/03/05/bluefors-launches-new-gas-handling-system-generation-2/,"<a href=\"https://thequantuminsider.com/2024/03/05/bluefors-launches-new-gas-handling-system-generation-2/\" rel=\"nofollow\" title=\"Bluefors Launches New Gas Handling System Generation 2\"><img alt=\"Bluefors\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"1080\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/Bluefors-Gas-Handling-System-Generation-2-units-1.jpg\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"1920\" /></a>Insider Brief Bluefors announced a next generation Gas Handling System. The team said the system reimagines the way scientists, researchers and companies working in quantum technology experience and control their cryogenic measurement systems. Gas Handling System Generation 2 introduces a modular design that brings more flexibility, usability, functionality, and safety. PRESS RELEASE &#8212; Bluefors announced [&#8230;]",[{'name': 'Matt Swayne'}],"Tue, 05 Mar 2024 16:56:35 +0000"
12,Zero Point Cryogenics Announces Funding for Quantum Sensing Technology Project From Canadian Government,https://thequantuminsider.com/2024/03/05/zero-point-cryogenics-announces-funding-for-quantum-sensing-technology-project-from-canadian-government/,"<a href=\"https://thequantuminsider.com/2024/03/05/zero-point-cryogenics-announces-funding-for-quantum-sensing-technology-project-from-canadian-government/\" rel=\"nofollow\" title=\"Zero Point Cryogenics Announces Funding for Quantum Sensing Technology Project From Canadian Government\"><img alt=\"black and silver dj controller\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"1067\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/ue766mrwnvi.jpg\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"1600\" /></a>Insider Brief Zero Point Cyrogenics (ZPC) is collaborating with the University of Waterloo and the Government of Canada as part of the Innovation for Defence Excellence and Security (IDEaS). The project is one of only six selected for the program. ZPC is participating in the University of Waterloo&#8217;s ambitious project, &#8216;Microwave Quantum Radar.’ PRESS RELEASE [&#8230;]",[{'name': 'Matt Swayne'}],"Tue, 05 Mar 2024 16:43:00 +0000"
13,Quantinuum Demonstrates Their Quantum Computers Will Scale with Major Hardware Innovation,https://thequantuminsider.com/2024/03/05/quantinuum-demonstrates-their-quantum-computers-will-scale-with-major-hardware-innovation/,<a href=\"https://thequantuminsider.com/2024/03/05/quantinuum-demonstrates-their-quantum-computers-will-scale-with-major-hardware-innovation/\" rel=\"nofollow\" title=\"Quantinuum Demonstrates Their Quantum Computers Will Scale with Major Hardware Innovation\"><img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"866\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/Screenshot-2024-03-04-at-12.14.42-PM.png\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"800\" /></a>Insider Brief Quantinuum have successfully demonstrated a novel approach that solves the &#8220;wiring problem&#8221; and the &#8220;sorting problem.&#8221; These are considered two major hurdles that limit the scalability and commercial viability of quantum computers. The approach is a combination of a fixed number of analog signals and a single digital input per qubit that significantly [&#8230;],[{'name': 'Matt Swayne'}],"Tue, 05 Mar 2024 15:59:35 +0000"
14,Multiverse Computing Raises Oversubscribed €25 million Series A Investment Round to Advance Quantum and Quantum-Inspired Computing Software,https://thequantuminsider.com/2024/03/05/multiverse-computing-raises-oversubscribed-e25-million-series-a-investment-round-to-advance-quantum-and-quantum-inspired-computing-software/,"<a href=\"https://thequantuminsider.com/2024/03/05/multiverse-computing-raises-oversubscribed-e25-million-series-a-investment-round-to-advance-quantum-and-quantum-inspired-computing-software/\" rel=\"nofollow\" title=\"Multiverse Computing Raises Oversubscribed €25 million Series A Investment Round to Advance Quantum and Quantum-Inspired Computing Software\"><img alt=\"Multiverse Computing\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"1991\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/multiverse-scaled-1.webp\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"2560\" /></a>Insider Brief The Series A round was led by Columbus Venture Partners and Quantonation. Funds will fuel the development of Singularity and CompactifAI, enabling quantum computing applications across industries Singularity enables professionals with no quantum background to use quantum and quantum-inspired computing for AI and optimization application. PRESS RELEASE &#8212; Multiverse Computing, a global leader in [&#8230;]",[{'name': 'Matt Swayne'}],"Tue, 05 Mar 2024 11:26:45 +0000"
15,Tomorrow’s Quantum Hotbeds? 7 U.S. Cities That Could Incubate The Next Great Quantum Technology Ecosystem,https://thequantuminsider.com/2024/03/04/tomorrows-quantum-hotbeds-7-u-s-cities-that-could-incubate-the-next-great-quantum-technology-ecosystem/,"<a href=\"https://thequantuminsider.com/2024/03/04/tomorrows-quantum-hotbeds-7-u-s-cities-that-could-incubate-the-next-great-quantum-technology-ecosystem/\" rel=\"nofollow\" title=\"Tomorrow&#8217;s Quantum Hotbeds? 7 U.S. Cities That Could Incubate The Next Great Quantum Technology Ecosystem\"><img alt=\"Quantum Ecosystems\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"1024\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/QuantumEcosystems.webp\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"1792\" /></a>Insider Brief The U.S. is a global powerhouse in quantum research and quantum entrepreneurship with quantum ecosystems emerging in several cities and regions. However, the country has the research acumen, the thirst for entrepreneurship and governments that encourage innovation to create even more quantum ecosystems. Quantum ecosystems tend to emerge from areas where there is [&#8230;]",[{'name': 'Matt Swayne'}],"Mon, 04 Mar 2024 20:36:29 +0000"
16,"Taiwan’s Five-Qubit Machine: “A Significant Milestone”, Academica Sinica Expert Says",https://thequantuminsider.com/2024/03/04/taiwans-five-qubit-machine-a-significant-milestone-academica-sinica-expert-says/,"<a href=\"https://thequantuminsider.com/2024/03/04/taiwans-five-qubit-machine-a-significant-milestone-academica-sinica-expert-says/\" rel=\"nofollow\" title=\"Taiwan’s Five-Qubit Machine: “A Significant Milestone”, Academica Sinica Expert Says\"><img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"557\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/Screenshot-1467.png\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"1135\" /></a>Taiwan has made significant strides in quantum computing, marking its entry into an exclusive group of nations capable of developing this cutting-edge technology. With the launch of its first five-qubit quantum computer, reported by The Quantum Insider in January, Taiwan has demonstrated its commitment to advancing scientific research and technological innovation. This development not only [&#8230;]",[{'name': 'James Dargan'}],"Mon, 04 Mar 2024 19:40:33 +0000"
17,"Quantum Advocate Charles Tahan Departs Government Roles, Says It Is ‘Now Time to Reauthorize The NQI Act’",https://thequantuminsider.com/2024/03/04/quantum-advocate-charles-tahan-departs-government-roles-says-it-is-now-time-to-reauthorize-the-nqi-act/,"<a href=\"https://thequantuminsider.com/2024/03/04/quantum-advocate-charles-tahan-departs-government-roles-says-it-is-now-time-to-reauthorize-the-nqi-act/\" rel=\"nofollow\" title=\"Quantum Advocate Charles Tahan Departs Government Roles, Says It Is &#8216;Now Time to Reauthorize The NQI Act&#8217;\"><img alt=\"National Quantum Initiative\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"656\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/Screenshot-2024-03-04-at-12.33.11-PM.png\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"712\" /></a>Editor&#8217;s Note: Charles Tahan, Director of the National Quantum Coordination Office and assistant for Quantum Information Science at the White House Office of Science and Technology Policy, has announced his departure from government roles after a 15-year tenure, including his recent four years at the White House. In his latest Director&#8217;s Letter, Tahan reflects on [&#8230;]",[{'name': 'Matt Swayne'}],"Mon, 04 Mar 2024 18:22:34 +0000"
18,Seeq Announces Generative AI Capabilities With Seeq AI Assistant,https://thequantuminsider.com/2024/03/04/seeq-announces-generative-ai-capabilities-with-seeq-ai-assistant/,"<a href=\"https://thequantuminsider.com/2024/03/04/seeq-announces-generative-ai-capabilities-with-seeq-ai-assistant/\" rel=\"nofollow\" title=\"Seeq Announces Generative AI Capabilities With Seeq AI Assistant\"><img alt=\"seeq\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"905\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/Seeq_Seeq_AI_Assistant_image.jpg\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"1915\" /></a>Insider Brief  Seeq introduced the Seeq AI Assistant, a generative AI (GenAI) resource embedded across its industrial analytics platform. The Seeq AI Assistant provides real-time assistance to users across the enterprise. GenAI is a type of artificial intelligence capable of generating new content, such as text, images, and code in response to prompts entered by a user. [&#8230;]",[{'name': 'Matt Swayne'}],"Mon, 04 Mar 2024 17:44:54 +0000"
19,Maybell Quantum Announces $25 Million Series A Funding Led by Cerberus,https://thequantuminsider.com/2024/03/04/maybell-quantum-announces-25-million-series-a-funding-led-by-cerberus/,"<a href=\"https://thequantuminsider.com/2024/03/04/maybell-quantum-announces-25-million-series-a-funding-led-by-cerberus/\" rel=\"nofollow\" title=\"Maybell Quantum Announces $25 Million Series A Funding Led by Cerberus\"><img alt=\"maybell\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"780\" src=\"https://thequantuminsider.com/wp-content/uploads/2024/03/Screenshot-2024-03-03-at-11.31.33-AM.png\" style=\"display: block; margin: auto; margin-bottom: 10px;\" width=\"1156\" /></a>Insider Brief Maybell Quantum closed a $25 million funding round led by an affiliate of Cerberus Capital Management, L.P. Maybell intends to use the funds to scale manufacturing and open a new production facility in 2024. The company is considered a global leader in quantum infrastructure performance and innovation. PRESS RELEASE &#8212; Maybell Quantum (“Maybell”), [&#8230;]",[{'name': 'Matt Swayne'}],"Mon, 04 Mar 2024 12:33:49 +0000"
20,Waist-to-height ratio detects fat obesity in children and adolescents significantly better than BMI,https://www.sciencedaily.com/releases/2024/03/240305134243.htm,An inexpensive measure of obesity in children and adolescents that could replace body mass index (BMI) has been identified in a new study as waist circumference-to-height ratio. This measure detected excess fat mass and distinguished fat mass from muscle mass in children and adolescents more accurately than BMI.,[],"Tue, 05 Mar 2024 13:42:43 EST"
21,Groundbreaking survey reveals secrets of planet birth around dozens of stars,https://www.sciencedaily.com/releases/2024/03/240305134240.htm,"A team of astronomers has shed new light on the fascinating and complex process of planet formation. The research brings together observations of more than 80 young stars that might have planets forming around them, providing astronomers with a wealth of data and unique insights into how planets arise in different regions of our galaxy.",[],"Tue, 05 Mar 2024 13:42:40 EST"
22,One way to improve a fusion reaction: Use weaknesses as strengths,https://www.sciencedaily.com/releases/2024/03/240305134238.htm,"Scientists are embracing imperfection, using less-than-ideal magnetic fields to make the plasma more manageable.",[],"Tue, 05 Mar 2024 13:42:38 EST"
23,Possible 'Trojan Horse' found for treating stubborn bacterial infections,https://www.sciencedaily.com/releases/2024/03/240305134236.htm,"Bacteria can be tricked into sending death signals to stop the growth of their slimy, protective homes that lead to deadly infections, a new study demonstrates. The discovery could someday be harnessed as an alternative to antibiotics for treating difficult infections. The researchers used the messengers, which they named death extracellular vesicles (D-EVs), to reduce growth of the bacterial communities by up to 99.99% in laboratory experiments.",[],"Tue, 05 Mar 2024 13:42:36 EST"
24,What makes black holes grow and new stars form? Machine learning helps solve the mystery,https://www.sciencedaily.com/releases/2024/03/240305134225.htm,It takes more than a galaxy merger to make a black hole grow and new stars form: machine learning shows cold gas is needed too to initiate rapid growth -- new research finds.,[],"Tue, 05 Mar 2024 13:42:25 EST"
25,"Juno spacecraft measures oxygen production on Jupiter's moon, Europa",https://www.sciencedaily.com/releases/2024/03/240305134217.htm,"NASA's Juno spacecraft has directly measured charged oxygen and hydrogen molecules from the atmosphere of one of Jupiter's largest moons, Europa. These observations provide key constraints on the potential oxygenation of its subsurface ocean.",[],"Tue, 05 Mar 2024 13:42:17 EST"
26,"After decades of Arctic sea ice getting faster and more hazardous for transport, models suggest a dramatic reversal is coming",https://www.sciencedaily.com/releases/2024/03/240305134215.htm,"Will ice floating in the Arctic Ocean move faster or slower over the coming decades? The answer to this question will tell us whether marine transportation can be expected to get more or less hazardous. It might also have important implications for the rate of ice cover loss, which is hugely consequential for Northern Indigenous communities, ecosystems, and the global climate system. While observational data suggest the trend has been towards faster sea ice speeds, climate models project that those speeds will slow down during the summer season. This contrast has led to some questions around the plausibility of the model projections.",[],"Tue, 05 Mar 2024 13:42:15 EST"
27,New cardiovascular imaging approach provides a better view of dangerous plaques,https://www.sciencedaily.com/releases/2024/03/240305134213.htm,"Researchers have developed a new catheter-based device that combines two powerful optical techniques to image the dangerous plaques that can build up inside the arteries that supply blood to the heart. By providing new details about plaque, the device could help clinicians and researchers improve treatments for preventing heart attacks and strokes.",[],"Tue, 05 Mar 2024 13:42:13 EST"
28,We know the Arctic is warming -- What will changing river flows do to its environment?,https://www.sciencedaily.com/releases/2024/03/240305134208.htm,"Scientists recently combined satellite data, field observations and sophisticated numerical modeling to paint a picture of how 22.45 million square kilometers of the Arctic will change over the next 80 years. As expected, the overall region will be warmer and wetter, but the details -- up to 25% more runoff, 30% more subsurface runoff and a progressively drier southern Arctic, provides one of the clearest views yet of how the landscape will respond to climate change.",[],"Tue, 05 Mar 2024 13:42:08 EST"
29,Fossil named 'Attenborough's strange bird' was the first in its kind without teeth,https://www.sciencedaily.com/releases/2024/03/240305134206.htm,"A new fossil, named 'Attenborough's strange bird' after naturalist and documentarian Sir David Attenborough, is the first of its kind to evolve a toothless beak. It's from a branch of the bird family tree that went extinct in the mass extinction 66 million years ago, and this strange bird is another puzzle piece that helps explain why some birds -- and their fellow dinosaurs -- went extinct, and others survived to today.",[],"Tue, 05 Mar 2024 13:42:06 EST"
30,Arctic could become 'ice-free' within a decade,https://www.sciencedaily.com/releases/2024/03/240305134203.htm,"While summer sea ice loss in the Arctic is inevitable, it can be reversed if the planet cools down, researchers say.",[],"Tue, 05 Mar 2024 13:42:03 EST"
31,8 in 10 lizards could be at risk due to deforestation,https://www.sciencedaily.com/releases/2024/03/240305133902.htm,"These reptiles move around tree trunks to seek warmth or shade. With trees disappearing, they would have trouble controlling their body temperature, a new study shows.",[],"Tue, 05 Mar 2024 13:39:02 EST"
32,"Plant Lavender, Marjoram and Ivy on your green wall to clean up the air",https://www.sciencedaily.com/releases/2024/03/240305133640.htm,"Green walls can strip pollution from the air -- and some plants do it better than others, according to new research. Researchers planted 10 species on a custom-built 1.4m green wall.",[],"Tue, 05 Mar 2024 13:36:40 EST"
33,"Coronary artery calcium score predictive of heart attacks, strokes",https://www.sciencedaily.com/releases/2024/03/240305133306.htm,Coronary artery calcium scoring with CT can identify symptomatic patients with a very low risk of heart attacks or strokes. Researchers said the findings may one day help some patients with stable chest pain avoid invasive coronary angiography.,[],"Tue, 05 Mar 2024 13:33:06 EST"
34,Researchers invent new triple-junction tandem solar cells with world-record efficiency,https://www.sciencedaily.com/releases/2024/03/240304221140.htm,"Scientists have developed a novel triple-junction perovskite/Si tandem solar cell that can achieve a certified world-record power conversion efficiency of 27.1 per cent across a solar energy absorption area of 1 sq cm, representing the best-performing triple-junction perovskite/Si tandem solar cell thus far. To achieve this, the team engineered a new cyanate-integrated perovskite solar cell that is stable and energy efficient.",[],"Mon, 04 Mar 2024 22:11:40 EST"
35,Protecting joints from bacteria with mussels,https://www.sciencedaily.com/releases/2024/03/240304195520.htm,A collaborative team of researchers developed an implant coating triggering antibiotic release in response to bacterial infection.,[],"Mon, 04 Mar 2024 19:55:20 EST"
36,Sleep apnea symptoms linked to memory and thinking problems,https://www.sciencedaily.com/releases/2024/03/240304195515.htm,"People who experience sleep apnea may be more likely to also have memory or thinking problems, according to a preliminary study. The study shows a positive association but did not determine whether sleep apnea causes cognitive decline.",[],"Mon, 04 Mar 2024 19:55:15 EST"
37,JWST captures the end of planet formation,https://www.sciencedaily.com/releases/2024/03/240304195509.htm,The James Webb Space Telescope is helping scientists uncover how planets form by advancing understanding of their birthplaces and the circumstellar disks surrounding young stars. Scientists have imaged winds from an old planet-forming disk (still very young relative to the Sun) which is actively dispersing its gas content. Knowing when the gas disperses is important as it constrains the time left for nascent planets to consume the gas from their surroundings.,[],"Mon, 04 Mar 2024 19:55:09 EST"
38,Scientists revolutionize wireless communication with three-dimensional processors,https://www.sciencedaily.com/releases/2024/03/240304195504.htm,Scientists have pioneered a method for using semiconductor technology to manufacture processors that significantly enhance the efficiency of transmitting vast amounts of data across the globe.,[],"Mon, 04 Mar 2024 19:55:04 EST"
39,Less ice in the Arctic Ocean has complex effects on marine ecosystems and ocean productivity,https://www.sciencedaily.com/releases/2024/03/240304195501.htm,"Most of the sunlight reaching the Arctic Ocean is reflected to space by sea ice, effectively shielding ocean ecosystems from sunlight. As the Arctic sea ice continues its downward trend, larger areas of the ocean become exposed to sunlight for longer periods, potentially allowing more primary production on the seafloor. However, according to a new study, this anticipated increase in primary production does not seem to be occurring uniformly across the Arctic Ocean.",[],"Mon, 04 Mar 2024 19:55:01 EST"
40,New research shows migrating animals learn by experience,https://www.sciencedaily.com/releases/2024/03/240304195455.htm,"Individual white storks incrementally straightened their migration routes to find more direct ways to move between destinations during the spring migration to summer breeding and nesting grounds, suggesting that experiential learning is an important part of successful migration.",[],"Mon, 04 Mar 2024 19:54:55 EST"
41,"Although trust in science remains high, public questions scientists' adherence to science's norms",https://www.sciencedaily.com/releases/2024/03/240304195451.htm,"In a new article, members of the Strategic Council of the National Academy of Sciences, Engineering, and Medicine examine what has happened to public confidence in science, why it has happened, and what can be done to elevate it. They say that while there is public agreement about the values that should underpin science, the public questions whether scientists actually live up to these values and whether they can overcome their individual biases.",[],"Mon, 04 Mar 2024 19:54:51 EST"
42,An inside look at Beech tree disease,https://www.sciencedaily.com/releases/2024/03/240304195446.htm,A new study found differences at the cellular level of leaves from infected Beech trees -- variations that may account for tree mortality.,[],"Mon, 04 Mar 2024 19:54:46 EST"
43,New AI model draws treasure maps to diagnose disease,https://www.sciencedaily.com/releases/2024/03/240304195443.htm,"Researchers have developed an artificial intelligence model that can accurately identify tumors and diseases in medical images. The tool draws a map to explain each diagnosis, helping doctors follow its line of reasoning, check for accuracy, and explain the results to patients.",[],"Mon, 04 Mar 2024 19:54:43 EST"
44,Breastfeeding after COVID-19 booster can give babies antibodies,https://www.sciencedaily.com/releases/2024/03/240304195439.htm,A recently published study that shows lactating mothers who get the COVID-19 booster pass along the antibodies to their children via their breast milk -- and potentially protect babies too young to receive the vaccine.,[],"Mon, 04 Mar 2024 19:54:39 EST"
45,Scientists put forth a smarter way to protect a smarter grid,https://www.sciencedaily.com/releases/2024/03/240304195348.htm,"Scientists have put forth a new approach to protect the electric grid, creating a tool that sorts and prioritizes cyber threats on the fly.",[],"Mon, 04 Mar 2024 19:53:48 EST"
46,Modeling the origins of life: New evidence for an 'RNA World',https://www.sciencedaily.com/releases/2024/03/240304195250.htm,"Scientists provide fresh insights on the origins of life, presenting compelling evidence supporting the 'RNA World' hypothesis. The study unveils an RNA enzyme that can make accurate copies of other functional RNA strands, while also allowing new variants of the molecule to emerge over time. These remarkable capabilities suggest the earliest forms of evolution may have occurred on a molecular scale in RNA, and also bring scientists one step closer to re-creating autonomous RNA-based life in the laboratory.",[],"Mon, 04 Mar 2024 19:52:50 EST"
47,An evolutionary mystery 125 million years in the making,https://www.sciencedaily.com/releases/2024/03/240304143643.htm,"Plant biologists have uncovered an evolutionary mystery over 100 million years in the making. It turns out that sometime during the last 125 million years, tomatoes and Arabidopsis thaliana plants experienced an extreme genetic makeover. Just what happened remains unclear. But the mystery surrounds CLV3, a gene key to healthy plant growth and development.",[],"Mon, 04 Mar 2024 14:36:43 EST"
48,3D-printed skin closes wounds and contains hair follicle precursors,https://www.sciencedaily.com/releases/2024/03/240304135920.htm,"Fat tissue holds the key to 3D printing layered living skin and potentially hair follicles, according to researchers who recently harnessed fat cells and supporting structures from clinically procured human tissue to precisely correct injuries in rats. The advancement could have implications for reconstructive facial surgery and even hair growth treatments for humans.",[],"Mon, 04 Mar 2024 13:59:20 EST"
49,Webb unlocks secrets of one of the most distant galaxies ever seen,https://www.sciencedaily.com/releases/2024/03/240304135917.htm,"Looking deeply into space and time, astronomers have studied the exceptionally luminous galaxy GN-z11, which existed when our 13.8 billion-year-old universe was only about 430 million years old.",[],"Mon, 04 Mar 2024 13:59:17 EST"
50,Advances in forensic science improve accuracy of 'time of death' estimates,https://www.sciencedaily.com/releases/2024/03/240304135902.htm,"Accurate 'time of death' estimates are a mainstay of murder mysteries and forensic programs, but such calculations in the real world are often complex and imprecise. In a first-of-its-kind study, researchers have discovered a group of common microbes that work together specifically to decompose flesh. These microorganisms serve as a biological clock and allow scientists to investigate the post-mortem breakdown of tissue with unprecedented precision.",[],"Mon, 04 Mar 2024 13:59:02 EST"
51,Spontaneous curvature the key to shape-shifting nanomaterials,https://www.sciencedaily.com/releases/2024/03/240304135857.htm,"Inspired by nature, nanotechnology researchers have identified 'spontaneous curvature' as the key factor determining how ultra-thin, artificial materials can transform into useful tubes, twists and helices.",[],"Mon, 04 Mar 2024 13:58:57 EST"
52,Studies on coffee consumption: New biomarker proposed,https://www.sciencedaily.com/releases/2024/03/240304135843.htm,"In order to record coffee consumption in nutrition and health studies, researchers usually rely on self-reporting by participants. However, this is not always reliable. It would therefore be desirable to conduct additional studies to objectively verify individual consumption using biomarkers. A research team has now validated the suitability of a specific roasted coffee compound and proposes it as a new, practical food biomarker.",[],"Mon, 04 Mar 2024 13:58:43 EST"
53,Humans have driven the Earth's freshwater cycle out of its stable state,https://www.sciencedaily.com/releases/2024/03/240304135840.htm,New analysis shows that the global freshwater cycle has shifted far beyond pre-industrial conditions.,[],"Mon, 04 Mar 2024 13:58:40 EST"
54,Exposure to different kinds of music influences how the brain interprets rhythm,https://www.sciencedaily.com/releases/2024/03/240304135838.htm,"The human brain appears biased toward hearing and producing rhythms with simple integer ratios, but the favored ratios can vary greatly between different societies, according to a 15-country study.",[],"Mon, 04 Mar 2024 13:58:38 EST"
55,A key to the future of robots could be hiding in liquid crystals,https://www.sciencedaily.com/releases/2024/03/240304135831.htm,"Robots and cameras of the future could be made of liquid crystals, thanks to a new discovery that significantly expands the potential of the chemicals already common in computer displays and digital watches. The findings are a simple and inexpensive way to manipulate the molecular properties of liquid crystals with light exposure.",[],"Mon, 04 Mar 2024 13:58:31 EST"
56,New dressing robot can 'mimic' the actions of care-workers,https://www.sciencedaily.com/releases/2024/03/240304135829.htm,Scientists have developed a new robot that can 'mimic' the two-handed movements of care-workers as they dress an individual.,[],"Mon, 04 Mar 2024 13:58:29 EST"
57,Photosynthetic secrets come to light,https://www.sciencedaily.com/releases/2024/03/240304135826.htm,"Secrets of photosynthesis have been discovered at atomic level, shedding important new light on this plant super-power that greened the earth more than a billion years ago.",[],"Mon, 04 Mar 2024 13:58:26 EST"
58,Network of quantum sensors boosts precision,https://www.sciencedaily.com/releases/2024/03/240304135823.htm,Quantum sensor technology promises even more precise measurements of physical quantities. A team has now compared the signals of up to 91 quantum sensors with each other and thus successfully eliminated the noise caused by interactions with the environment. Correlation spectroscopy can be used to increase the precision of sensor networks.,[],"Mon, 04 Mar 2024 13:58:23 EST"
59,Robotic hip exoskeleton shows promise for helping stroke patients regain their stride,https://www.sciencedaily.com/releases/2024/03/240304135821.htm,"More than 80% of stroke survivors experience walking difficulty, significantly impacting their daily lives, independence, and overall quality of life. Now, new research pushes forward the bounds of stroke recovery with a unique robotic hip exoskeleton, designed as a training tool to improve walking function. This invites the possibility of new therapies that are more accessible and easier to translate from practice to daily life compared to current rehabilitation methods.",[],"Mon, 04 Mar 2024 13:58:21 EST"
60,"Degree of cell crowding in the early human embryo influences cell identity decision, new culture system finds",https://www.sciencedaily.com/releases/2024/03/240304135818.htm,Collaborative work has developed a cell culture system that differentiates human pluripotent stem cells to amniotic ectoderm and surface ectoderm based on cell density.,[],"Mon, 04 Mar 2024 13:58:18 EST"
61,"It's not just you: Young people look, feel older when they're stressed",https://www.sciencedaily.com/releases/2024/03/240304135816.htm,A new study finds younger adults look and feel older on stressful days -- but only on days when they also feel they have relatively less control over their own lives.,[],"Mon, 04 Mar 2024 13:58:16 EST"
62,Your brain in the zone: A new neuroimaging study reveals how the brain achieves a creative flow state,https://www.sciencedaily.com/releases/2024/03/240304135813.htm,A new neuroimaging study reveals how the brain gets to the creative flow state.,[],"Mon, 04 Mar 2024 13:58:13 EST"
63,A model for the evolution of intelligence,https://www.sciencedaily.com/releases/2024/03/240304135811.htm,"When certain species of wild birds and primates discover new ways of finding food in the wild, it can serve to measure their flexibility and intelligence. In the largest experimental study ever conducted on this topic, researchers have shown that foraging problems requiring overcoming obstacles, such as removing the lid off a container of food, are the only predictors of brain size and innovative behavior in the wild.",[],"Mon, 04 Mar 2024 13:58:11 EST"
64,Cost of direct air carbon capture to remain higher than hoped,https://www.sciencedaily.com/releases/2024/03/240304135808.htm,"Researchers estimate the cost of removing 1 ton of CO2 from the air in the year 2050 to be between 230 and 540 US dollars to remove 1 ton. This is twice as high as previous estimates. The researchers compared the potential costs of three technologies that are already in use. From today's perspective, none of these technologies has clear advantages over the others in terms of potential costs. All three technologies should therefore be further developed, say the researchers.",[],"Mon, 04 Mar 2024 13:58:08 EST"
65,Researchers use liquid crystals to control polarization inside laser-written waveguides,https://www.sciencedaily.com/releases/2024/03/240304135803.htm,"Researchers have developed a new way to control and manipulate optical signals by embedding a liquid crystal layer into waveguides created with direct laser writing. The new devices enable electro-optical control of polarization, which could open new possibilities for chip-based devices and complex photonic circuits based on femtosecond-written waveguides.",[],"Mon, 04 Mar 2024 13:58:03 EST"
66,Unraveling the mystery of chiton visual systems,https://www.sciencedaily.com/releases/2024/03/240304135801.htm,"You'd probably walk past a chiton without even seeing it. These creatures often look like nothing more than another speck of seaweed on the crusty intertidal rocks. But it sees you. At least, if it's one of the species with eyes dotting its platemail shell.",[],"Mon, 04 Mar 2024 13:58:01 EST"
67,New method to test for oral cancer,https://www.sciencedaily.com/releases/2024/03/240304135753.htm,"A team of researchers has discovered a noninvasive, low-cost test to detect oral cancer, monitor precancerous lesions and determine when a biopsy is warranted.",[],"Mon, 04 Mar 2024 13:57:53 EST"
68,New AI smartphone tool accurately diagnoses ear infections,https://www.sciencedaily.com/releases/2024/03/240304135751.htm,"A new cell phone app developed by physician-scientists, which uses artificial intelligence (AI) to accurately diagnose ear infections, or acute otitis media (AOM), could help decrease unnecessary antibiotic use in young children, according to new research.",[],"Mon, 04 Mar 2024 13:57:51 EST"
69,Low-cost liquid tames tooth decay,https://www.sciencedaily.com/releases/2024/03/240304135748.htm,"An inexpensive, cavity-fighting liquid called silver diamine fluoride (SDF) works as well as dental sealants to keep tooth decay at bay in a school cavity prevention and treatment program, according to a new study. The study, which followed more than 4,000 elementary school students for four years, shows that SDF is an effective alternative to sealants, and can increase access to dental care while reducing costs.",[],"Mon, 04 Mar 2024 13:57:48 EST"
70,Study determines the original orientations of rocks drilled on Mars,https://www.sciencedaily.com/releases/2024/03/240304135739.htm,Geologists determined the original orientation of many of the Mars bedrock samples collected by the Perseverance rover. The findings can give scientists clues to the conditions in which the rocks originally formed.,[],"Mon, 04 Mar 2024 13:57:39 EST"
71,Tests show high-temperature superconducting magnets are ready for fusion,https://www.sciencedaily.com/releases/2024/03/240304135732.htm,"A comprehensive study of high-temperature superconducting magnets confirms they meet requirements for an economic, compact fusion power plant.",[],"Mon, 04 Mar 2024 13:57:32 EST"
72,"Zika vaccine safe, effective when administered during pregnancy",https://www.sciencedaily.com/releases/2024/03/240304135729.htm,"A vaccine against Zika virus is safe and effective when administered both before and during pregnancy, according to new research.",[],"Mon, 04 Mar 2024 13:57:29 EST"
73,"Firearm ownership is correlated with elevated lead levels in children, study finds",https://www.sciencedaily.com/releases/2024/03/240304135727.htm,"Childhood lead exposure, primarily from paint and water, is a significant health concern in the United States, but a new study has identified a surprising additional source of lead exposure that may disproportionately harm children: firearms. A team found an association between household firearm ownership and elevated lead levels in children's blood in 44 states, even when controlling for other major lead exposure sources.",[],"Mon, 04 Mar 2024 13:57:27 EST"
74,Geologists explore the hidden history of Colorado's Spanish Peaks,https://www.sciencedaily.com/releases/2024/03/240304135722.htm,"A team has collected dozens of samples from across southeastern Colorado, and their results could help to answer an enduring mystery: What made Colorado's High Plains so high?",[],"Mon, 04 Mar 2024 13:57:22 EST"
75,A better way to deliver fetal therapy for serious genetic disorders,https://www.sciencedaily.com/releases/2024/03/240304135015.htm,"In a discovery that opens the door to a less invasive way of treating some serious disorders before birth, UC San Francisco scientists have found that delivering medicine through amniotic fluid is as effective as delivering it to the fetal brain via cerebrospinal fluid. The experiment was done in mice with a genetic disorder called Angelman syndrome.",[],"Mon, 04 Mar 2024 13:50:15 EST"
76,Beyond the ink: Painting with physics,https://www.sciencedaily.com/releases/2024/03/240303125412.htm,"Falling from the tip of a brush suspended in mid-air, an ink droplet touches a painted surface and blossoms into a masterpiece of ever-changing beauty. It weaves a tapestry of intricate, evolving patterns. Some of them resemble branching snowflakes, thunderbolts or neurons, whispering the unique expression of the artist's vision.",[],"Sun, 03 Mar 2024 12:54:12 EST"
77,An overgrowth of nerve cells appears to cause lingering symptoms after recurrent UTIs,https://www.sciencedaily.com/releases/2024/03/240302171534.htm,"A perplexing problem for people with recurring urinary tract infections (UTIs) is persistent pain, even after antibiotics have successfully cleared the bacteria. Now researchers have identified the likely cause -- an overgrowth of nerve cells in the bladder.",[],"Sat, 02 Mar 2024 17:15:34 EST"
78,"In wake of powerful cyclone, remarkable recovery of Pacific island's forests",https://www.sciencedaily.com/releases/2024/03/240302171526.htm,"After one of the most intense cyclones in world history tore through the Pacific island of Tanna in Vanuatu, new research showed the resilience of the island's forests.",[],"Sat, 02 Mar 2024 17:15:26 EST"
79,2020 extreme weather event that brought fires and snow to western US,https://www.sciencedaily.com/releases/2024/03/240302171524.htm,"The same weather system that led to the spread of the devastating Labor Day wildfires in 2020 brought record-breaking cold and early-season snowfall to parts of the Rocky Mountains. Now, new research is shedding light on the meteorology behind what happened and the impacts of such an extreme weather event.",[],"Sat, 02 Mar 2024 17:15:24 EST"
80,Microsoft and 1910 Genetics partner to turbocharge R&D productivity for the pharmaceutical industry,https://cloudblogs.microsoft.com/quantum/2024/02/29/microsoft-and-1910-genetics-partner-to-turbocharge-rd-productivity-for-the-pharmaceutical-industry/,"<p>Unprecedented collaboration will build the most powerful, fully integrated, AI-driven drug discovery and development platform to dramatically improve pharmaceutical research and development (R&#38;D) productivity and bring novel therapeutics to patients faster and more cost-effectively than traditional approaches.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2024/02/29/microsoft-and-1910-genetics-partner-to-turbocharge-rd-productivity-for-the-pharmaceutical-industry/\">Microsoft and 1910 Genetics partner to turbocharge R&amp;D productivity for the pharmaceutical industry</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Zulfi Alam'}],"Thu, 29 Feb 2024 14:00:00 +0000"
81,DARPA selects Microsoft to continue the development of a utility-scale quantum computer,https://cloudblogs.microsoft.com/quantum/2024/02/08/darpa-selects-microsoft-to-continue-the-development-of-a-utility-scale-quantum-computer/,"<p>United States Government renews funding to Microsoft Azure Quantum based on recent results and detailed plans for building a quantum computer.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2024/02/08/darpa-selects-microsoft-to-continue-the-development-of-a-utility-scale-quantum-computer/\">DARPA selects Microsoft to continue the development of a utility-scale quantum computer </a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'David Bohn'}],"Thu, 08 Feb 2024 16:00:00 +0000"
82,Unlocking a new era for scientific discovery with AI: How Microsoft’s AI screened over 32 million candidates to find a better battery,https://cloudblogs.microsoft.com/quantum/2024/01/09/unlocking-a-new-era-for-scientific-discovery-with-ai-how-microsofts-ai-screened-over-32-million-candidates-to-find-a-better-battery/,"<p>Announcing the Microsoft Quantum team achieved a major milestone toward that vision, using advanced AI to screen over 32 million candidates to discover and synthesize a new material that holds the potential for better batteriesthe first real-life example of many that will be achieved in a new era of scientific discovery driven by AI.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2024/01/09/unlocking-a-new-era-for-scientific-discovery-with-ai-how-microsofts-ai-screened-over-32-million-candidates-to-find-a-better-battery/\">Unlocking a new era for scientific discovery with AI: How Microsoft’s AI screened over 32 million candidates to find a better battery</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Dr. Nathan Baker'}],"Tue, 09 Jan 2024 16:00:00 +0000"
83,Increasing research and development productivity with Copilot in Azure Quantum Elements,https://cloudblogs.microsoft.com/quantum/2023/12/12/increasing-research-and-development-productivity-with-copilot-in-azure-quantum-elements/,"<p>At Microsoft, we see opportunities to accelerate research and development productivity and usher in a new era of scientific discovery by harnessing the power of today's new generation of AI. </p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2023/12/12/increasing-research-and-development-productivity-with-copilot-in-azure-quantum-elements/\">Increasing research and development productivity with Copilot in Azure Quantum Elements</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Dr. Chi Chen and Yousif Almulla'}],"Tue, 12 Dec 2023 16:00:00 +0000"
84,Defining logical qubits: criteria for Resilient Quantum Computation,https://aka.ms/AQ/LogicalQubit/Blog,"<p>As an industry, we are all collectively committed to bringing scaled quantum computing to fruition. That's why in June 2023, we offered how quantum computing must graduate through three implementation levels to achieve utility scale: Level 1 Foundational, Level 2 Resilient, Level 3 Scale.</p>
<p>The post <a href=\"https://aka.ms/AQ/LogicalQubit/Blog\">Defining logical qubits: criteria for Resilient Quantum Computation</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Krysta Svore'}],"Tue, 28 Nov 2023 17:00:00 +0000"
85,Microsoft and Photonic join forces on the path to quantum at scale,https://cloudblogs.microsoft.com/quantum/2023/11/08/microsoft-and-photonic-join-forces-on-the-path-to-quantum-at-scale/,"<p>We are excited to announce a strategic co-innovation collaboration with Photonic Inc., a company focused on building scalable, fault tolerant, and distributed quantum technologies.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2023/11/08/microsoft-and-photonic-join-forces-on-the-path-to-quantum-at-scale/\">Microsoft and Photonic join forces on the path to quantum at scale</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Dennis Tom'}],"Wed, 08 Nov 2023 14:00:00 +0000"
86,Quantum networking: A roadmap to a quantum internet,https://cloudblogs.microsoft.com/quantum/2023/11/01/quantum-networking-a-roadmap-to-a-quantum-internet/,"<p>Quantum computing has the potential to tackle some of our most pressing global issues, from climate change to food security. We're dedicated to building a full-scale, fault-tolerant quantum computer that can help solve these challenges.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2023/11/01/quantum-networking-a-roadmap-to-a-quantum-internet/\">Quantum networking: A roadmap to a quantum internet</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Brad Lackey'}],"Wed, 01 Nov 2023 16:00:00 +0000"
87,Azure Quantum learning resources enable getting ready for a quantum supercomputer,https://cloudblogs.microsoft.com/quantum/2023/09/18/azure-quantum-learning-resources-enable-getting-ready-for-a-quantum-supercomputer/,"<p>As an industry, we are all collectively committed to bringing scaled quantum computing to fruition. However, it can get hard to separate the signal from the noise. To help, we have offered quantum computing implementation levels to the industry to help frame the roadmap towards achieving this shared goal.  </p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2023/09/18/azure-quantum-learning-resources-enable-getting-ready-for-a-quantum-supercomputer/\">Azure Quantum learning resources enable getting ready for a quantum supercomputer </a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Krysta Svore'}],"Mon, 18 Sep 2023 17:00:00 +0000"
88,Announcing season 2 of the Microsoft Quantum Innovator Series,https://cloudblogs.microsoft.com/quantum/2023/08/23/announcing-season-2-of-the-microsoft-quantum-innovator-series/,"<p>In this series, you will hear directly from the Microsoft Azure Quantum scientists and leaders about the path to quantum at scale and how you can get involved today.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2023/08/23/announcing-season-2-of-the-microsoft-quantum-innovator-series/\">Announcing season 2 of the Microsoft Quantum Innovator Series</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Microsoft Azure Quantum Team'}],"Wed, 23 Aug 2023 16:00:00 +0000"
89,Accelerating materials discovery with AI and Azure Quantum Elements,https://cloudblogs.microsoft.com/quantum/2023/08/09/accelerating-materials-discovery-with-ai-and-azure-quantum-elements/,"<p>At Microsoft, we see great potential to accelerate chemistry and materials advances by integrating Azure's scaled HPC solutions with AI models tuned for scientific research.</p>
<p>The post <a href=\"https://cloudblogs.microsoft.com/quantum/2023/08/09/accelerating-materials-discovery-with-ai-and-azure-quantum-elements/\">Accelerating materials discovery with AI and Azure Quantum Elements</a> appeared first on <a href=\"https://cloudblogs.microsoft.com/quantum\">Microsoft Azure Quantum Blog</a>.</p>",[{'name': 'Dr. Chi Chen and Dr. Nathan Baker'}],"Wed, 09 Aug 2023 16:00:00 +0000"
90,"Electrons become fractions of themselves in graphene, study finds",https://news.mit.edu/2024/electrons-become-fractions-graphene-study-finds-0221,An exotic electronic state observed by MIT physicists could enable more robust forms of quantum computing.,[{'name': 'Jennifer Chu | MIT News'}],"Wed, 21 Feb 2024 11:00:00 -0500"
91,Technique could improve the sensitivity of quantum sensing devices,https://news.mit.edu/2024/technique-could-improve-sensitivity-quantum-sensing-devices-0208,"The method lets researchers identify and control larger numbers of atomic-scale defects, to build a bigger system of qubits.",[{'name': 'Adam Zewe | MIT News'}],"Thu, 08 Feb 2024 00:00:00 -0500"
92,New MIT.nano equipment to accelerate innovation in “tough tech” sectors,https://news.mit.edu/2024/new-mit-nano-equipment-accelerate-innovation-0130,The advanced fabrication tools will enable the next generation of microelectronics and microsystems while bridging the gap from the lab to commercialization.,[{'name': 'Zach Winn | MIT News'}],"Tue, 30 Jan 2024 13:00:00 -0500"
93,"With a quantum “squeeze,” clocks could keep even more precise time, MIT researchers propose",https://news.mit.edu/2023/quantum-squeeze-clocks-more-precise-time-1130,"More stable clocks could measure quantum phenomena, including the presence of dark matter.",[{'name': 'Jennifer Chu | MIT News'}],"Thu, 30 Nov 2023 00:00:00 -0500"
94,Celebrating five years of MIT.nano,https://news.mit.edu/2023/celebrating-five-years-mit-nano-summit-1127,The Nano Summit highlights nanoscale research across multiple disciplines at MIT.,[{'name': 'Amanda Stoll DiCristofaro | MIT.nano'}],"Mon, 27 Nov 2023 15:15:00 -0500"
95,Physicists trap electrons in a 3D crystal for the first time,https://news.mit.edu/2023/physicists-trap-electrons-3d-crystal-first-time-1108,The results open the door to exploring superconductivity and other exotic electronic states in three-dimensional materials.,[{'name': 'Jennifer Chu | MIT News'}],"Wed, 08 Nov 2023 11:00:00 -0500"
96,MIT receives major National Science Foundation grant for quantum science,https://news.mit.edu/2023/mit-receives-major-nsf-grant-quantum-science-1018,Center for Ultracold Atoms gets funding boost to “punch through tough scientific barriers and see what's on the other side.”,[{'name': 'Sandi Miller | Department of Physics'}],"Wed, 18 Oct 2023 15:10:00 -0400"
97,"From a five-layer graphene sandwich, a rare electronic state emerges",https://news.mit.edu/2023/five-layer-graphene-sandwich-rare-electronic-behavior-1018,A newly discovered type of electronic behavior could help with packing more data into magnetic memory devices.,[{'name': 'Jennifer Chu | MIT News'}],"Wed, 18 Oct 2023 11:00:00 -0400"
98,Quantum repeaters use defects in diamond to interconnect quantum systems,https://news.mit.edu/2023/quantum-repeaters-use-defects-diamond-interconnect-quantum-systems-0927,This technology for storing and transmitting quantum information over lossy links could provide the foundation for scalable quantum networking.,[{'name': 'Ariana Tantillo | MIT Lincoln Laboratory'}],"Wed, 27 Sep 2023 16:35:00 -0400"
99,New qubit circuit enables quantum operations with higher accuracy,https://news.mit.edu/2023/new-qubit-circuit-enables-quantum-operations-higher-accuracy-0925,The advance brings quantum error correction a step closer to reality.,[{'name': 'Adam Zewe | MIT News'}],"Mon, 25 Sep 2023 11:00:00 -0400"
100,Four Lincoln Laboratory technologies win five 2023 R&D 100 awards,https://news.mit.edu/2023/lincoln-laboratory-technologies-win-rd-world-awards-0919,"Inventions in medical imaging, aircrew scheduling, data security, and quantum networking are named among the year’s most innovative new products.",[{'name': 'Kylie Foy | MIT Lincoln Laboratory'}],"Tue, 19 Sep 2023 16:35:34 -0400"
101,Canceling noise to improve quantum devices,https://news.mit.edu/2023/canceling-noise-improve-quantum-devices-0906,MIT researchers develop a protocol to extend the life of quantum coherence.,[{'name': 'Peter Reuell | Department of Nuclear Science and Engineering'}],"Wed, 06 Sep 2023 17:15:00 -0400"
102,"Simple superconducting device could dramatically cut energy use in computing, other applications",https://news.mit.edu/2023/simple-superconducting-device-could-dramatically-cut-energy-use-computing-other-important-0815,The ultrasmall “switch” could be easily scaled.,[{'name': 'Elizabeth Thomson | Materials Research Laboratory'}],"Tue, 15 Aug 2023 16:00:00 -0400"
103,Wolfgang Ketterle receives Vannevar Bush Faculty Fellowship,https://news.mit.edu/2023/wolfgang-ketterle-vannevar-bush-faculty-fellowship-0807,Professor of physics will use US Department of Defense fellowship to study quantum science with ultracold atoms.,[{'name': 'Sandi Miller | Department of Physics'}],"Mon, 07 Aug 2023 13:35:00 -0400"
104,Sensing and controlling microscopic spin density in materials,https://news.mit.edu/2023/sensing-microscopic-spin-density-materials-0802,"By fine-tuning the spin density in some materials, researchers may be able to develop new quantum sensors or quantum simulations.",[{'name': 'David L. Chandler | MIT News'}],"Wed, 02 Aug 2023 09:00:00 -0400"
105,Researchers grow precise arrays of nanoLEDs,https://news.mit.edu/2023/researchers-grow-precise-arrays-nanoleds-0706,"A new technique produces perovskite nanocrystals right where they’re needed, so the exceedingly delicate materials can be integrated into nanoscale devices.",[{'name': 'Adam Zewe | MIT News Office'}],"Thu, 06 Jul 2023 00:00:00 -0400"
106,Superconducting qubit foundry accelerates progress in quantum research,https://news.mit.edu/2023/superconducting-qubit-foundry-accelerates-progress-quantum-research-0705,The foundry gives the wider research community access to Lincoln Laboratory’s expertise in fabricating quantum circuits.,[{'name': 'Kylie Foy | Haley Wahl | MIT Lincoln Laboratory'}],"Wed, 05 Jul 2023 16:45:00 -0400"
107,A new mathematical “blueprint” is accelerating fusion device development,https://news.mit.edu/2023/mathematical-blueprint-accelerating-fusion-device-development-0622,New research explores how Dyson maps are putting quantum computers to work in designing fusion energy devices.,[{'name': 'Plasma Science and Fusion Center'}],"Thu, 22 Jun 2023 09:50:00 -0400"
108,Researchers develop a new source of quantum light,https://news.mit.edu/2023/researchers-develop-new-source-quantum-light-0622,The device emits a stream of single photons and could provide a basis for optical quantum computers.,[{'name': 'David L. Chandler | MIT News Office'}],"Thu, 22 Jun 2023 00:00:00 -0400"
109,Three Spanish MIT physics postdocs receive Botton Foundation fellowships,https://news.mit.edu/2023/botton-foundation-fellowships-spanish-mit-physics-postdocs-0609,"Recipients Luis Antonio Benítez, Carolina Cuesta-Lazaro, and Fernando Romero López receive support for their scientific research.",[{'name': 'Sandi Miller | Department of Physics'}],"Fri, 09 Jun 2023 17:00:00 -0400"
110,Life in a hologram,https://news.mit.edu/2023/daniel-harlow-life-hologram-0607,Physicist Daniel Harlow explores an alternate quantum reality in search of fundamental truths to our physical universe.,[{'name': 'Jennifer Chu | MIT News Office'}],"Wed, 07 Jun 2023 00:00:00 -0400"
111,Fueled by problem-solving,https://news.mit.edu/2023/fueled-by-problem-solving-thomas-bergamaschi-0530,Undergraduate research helped feed physics and EECS major Thomas Bergamaschi’s post-MIT interest in tackling challenges.,[{'name': 'Sandi Miller | Department of Physics'}],"Tue, 30 May 2023 14:20:00 -0400"
112,Success at the intersection of technology and finance,https://news.mit.edu/2023/success-intersection-technology-and-finance-0510,"Citadel founder and CEO Ken Griffin visits MIT, discusses how technology will continue to transform trading and investing.",[{'name': 'MIT Career Advising and Professional Development'}],"Wed, 10 May 2023 14:00:00 -0400"
113,MIT physicists predict exotic new phenomena and give “recipe” for realizing them,https://news.mit.edu/2023/mit-physicists-predict-exotic-new-phenomena-0317,Work with skyrmions could have applications in future computers and more.,[{'name': 'Elizabeth A. Thomson | Materials Research Laboratory'}],"Fri, 17 Mar 2023 16:10:00 -0400"
114,"It’s a weird, weird quantum world",https://news.mit.edu/2023/weird-weird-quantum-world-peter-shor-killian-lecture-0310,"In MIT’s 2023 Killian Lecture, Peter Shor shares a brief history of quantum computing from a personal viewpoint.",[{'name': 'Jennifer Chu | MIT News Office'}],"Fri, 10 Mar 2023 16:25:00 -0500"
115,QuARC 2023 explores the leading edge in quantum information and science,https://news.mit.edu/2023/quarc-2023-explores-leading-edge-quantum-information-and-science-0303,The second annual student-industry conference was held in-person for the first time.,[{'name': 'Center for Quantum Engineering'}],"Fri, 03 Mar 2023 12:30:00 -0500"
116,A new way for quantum computing systems to keep their cool,https://news.mit.edu/2023/new-way-quantum-computing-systems-keep-their-cool-0221,A wireless technique enables a super-cold quantum computer to send and receive data without generating too much error-causing heat.,[{'name': 'Adam Zewe | MIT News Office'}],"Tue, 21 Feb 2023 00:00:00 -0500"
117,Scientists boost quantum signals while reducing noise,https://news.mit.edu/2023/boost-quantum-signals-squeezing-noise-0209,“Squeezing” noise over a broad frequency bandwidth in a quantum system could lead to faster and more accurate quantum measurements.,[{'name': 'Adam Zewe | MIT News Office'}],"Thu, 09 Feb 2023 11:00:00 -0500"
118,Physicists observe rare resonance in molecules for the first time,https://news.mit.edu/2023/rare-resonance-ultracold-molecules-0201,The findings could provide a new way to control chemical reactions.,[{'name': 'Jennifer Chu | MIT News Office'}],"Wed, 01 Feb 2023 11:00:00 -0500"
119,Can you trust your quantum simulator?,https://news.mit.edu/2023/quantum-simulator-randomness-0118,A new technique helps verify the accuracy of experiments that probe the strange behavior of atomic-scale systems.,[{'name': 'Jennifer Chu | MIT News Office'}],"Wed, 18 Jan 2023 11:00:00 -0500"
120,New quantum computing architecture could be used to connect large-scale devices,https://news.mit.edu/2023/quantum-interconnects-photon-emission-0105,"Researchers have demonstrated directional photon emission, the first step toward extensible quantum interconnects.",[{'name': 'Adam Zewe | MIT News Office'}],"Thu, 05 Jan 2023 11:00:00 -0500"
121,MIT researchers use quantum computing to observe entanglement,https://news.mit.edu/2022/mit-researchers-use-quantum-computing-observe-entanglement-1201,Researchers at the Center for Theoretical Physics lead work on testing quantum gravity on a quantum processor.,[{'name': 'Julia C. Keller | School of Science'}],"Thu, 01 Dec 2022 07:45:00 -0500"
122,The task of magnetic classification suddenly looks easier,https://news.mit.edu/2022/task-magnetic-classification-suddenly-looks-easier-1128,"MIT undergraduate researchers Helena Merker, Harry Heiberger, and Linh Nguyen, and PhD student Tongtong Liu, exploit machine-learning techniques to determine the magnetic structure of materials.",[{'name': 'Steve Nadis | Department of Nuclear Science and Engineering'}],"Mon, 28 Nov 2022 15:25:00 -0500"
123,Liang Fu and Patrick Lee receive Larkin Awards in Theoretical Physics,https://news.mit.edu/2022/liang-fu-patrick-lee-receive-larkin-awards-theoretical-physics-1031,Inaugural award goes to MIT condensed matter theory professors of physics.,[{'name': 'Sandi Miller | Department of Physics'}],"Mon, 31 Oct 2022 16:45:00 -0400"
124,A faster experiment to find and study topological materials,https://news.mit.edu/2022/faster-topological-materials-quantum-1026,"Using machine learning and simple X-ray spectra, researchers can uncover compounds that might enable next-generation computer chips or quantum devices.",[{'name': 'David L. Chandler | MIT News Office'}],"Wed, 26 Oct 2022 09:00:00 -0400"
125,Making quantum computers more accurate,https://news.mit.edu/2022/alex-greene-quantum-computers-1013,PhD student Alex Greene studies superconducting quantum computing systems while rounding out their busy schedule with water sanitation projects.,[{'name': 'Rachel Yang | MIT News correspondent'}],"Thu, 13 Oct 2022 00:00:00 -0400"
126,Professor Danna Freedman receives 2022 MacArthur Fellowship,https://news.mit.edu/2022/danna-freedman-macarthur-fellowship-1012,"MIT chemist designs novel molecules that could be used for quantum sensing and communication; visiting scholar Moriba Jah is also awarded, for work on space sustainability.",[{'name': 'Anne Trafton | MIT News Office'}],"Wed, 12 Oct 2022 12:00:00 -0400"
127,Peter Shor wins Breakthrough Prize in Fundamental Physics,https://news.mit.edu/2022/shor-spielman-breakthrough-prize-0922,MIT professor to share $3 million prize with three others; Daniel Spielman PhD ’95 wins Breakthrough Prize in Mathematics.,[{'name': 'Jennifer Chu | MIT News Office'}],"Thu, 22 Sep 2022 09:00:00 -0400"
128,Between two universes,https://news.mit.edu/2022/between-two-universes-mohammad-javad-khojasteh-0920,"Mohammad Javad Khojasteh, a postdoc at MIT LIDS, uses both classical and quantum physics to improve state-of-the-art capabilities in communication, sensing, and computation.",[{'name': 'Raleigh McElvery | MIT Laboratory for Information and Decision Systems'}],"Tue, 20 Sep 2022 17:10:00 -0400"
129,"For Danna Freedman, an impasse is an invitation",https://news.mit.edu/2022/danna-freedman-chemistry-0731,The chemistry professor embraces the most challenging moments of her work to design molecules for quantum information science.,[{'name': 'Michaela Jarvis | MIT News correspondent'}],"Sun, 31 Jul 2022 00:00:00 -0400"
130,"Physicists discover a “family” of robust, superconducting graphene structures",https://news.mit.edu/2022/superconducting-graphene-family-0708,The findings could inform the design of practical superconducting devices.,[{'name': 'Jennifer Chu | MIT News Office'}],"Fri, 08 Jul 2022 00:00:00 -0400"
131,Quantum sensor can detect electromagnetic signals of any frequency,https://news.mit.edu/2022/quantum-sensor-frequency-0621,"MIT engineers expand the capabilities of these ultrasensitive nanoscale detectors, with potential uses for quantum computing and biological sensing.",[{'name': 'David L. Chandler | MIT News Office'}],"Tue, 21 Jun 2022 00:00:00 -0400"
132,Mining valuable insights from diamonds,https://news.mit.edu/2022/mining-valuable-insights-diamonds-changhao-li-0531,A drive to understand natural science phenomena ignited MIT graduate student Changhao Li’s love of quantum physics.,[{'name': 'Poornima Apte | Department of Nuclear Science and Engineering'}],"Tue, 31 May 2022 00:00:00 -0400"
133,Peter Shor receives 2022-2023 Killian Award,https://news.mit.edu/2022/peter-shor-receives-2022-2023-killian-award-0511,"The MIT professor is honored for extraordinary accomplishments in mathematics, computer science, and quantum physics.",[{'name': 'Jennifer Chu | MIT News Office'}],"Wed, 11 May 2022 16:00:00 -0400"
134,Bringing together the next generation of quantum coders,https://news.mit.edu/2022/bringing-together-next-generation-quantum-coders-0405,MIT iQuHACK gave teams from across the country time and experience on real quantum computers.,[{'name': 'Rachel Yang | Department of Electrical Engineering and Computer Science'}],"Tue, 05 Apr 2022 15:10:00 -0400"
135,School of Engineering welcomes Thomas Tull as visiting innovation scholar,https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404,"Primary focus will be to advance and promote technology, innovation, and entrepreneurship across the school.",[{'name': 'Lori LoTurco | School of Engineering'}],"Mon, 04 Apr 2022 15:40:00 -0400"
136,Seeing an elusive magnetic effect through the lens of machine learning,https://news.mit.edu/2022/seeing-elusive-magnetic-effect-through-lens-machine-learning-0324,An MIT team incorporates AI to facilitate the detection of an intriguing materials phenomenon that can lead to electronics without energy dissipation.,[{'name': 'Steve Nadis | Department of Nuclear Science and Engineering'}],"Thu, 24 Mar 2022 13:40:00 -0400"
137,Making quantum circuits more robust,https://news.mit.edu/2022/quantum-circuits-robust-noise-0321,"Researchers have developed a technique for making quantum computing more resilient to noise, which boosts performance.",[{'name': 'Adam Zewe | MIT News Office'}],"Mon, 21 Mar 2022 00:00:00 -0400"
138,MIT.nano receives grant to acquire focused ion beam scanning electron microscope,https://news.mit.edu/2022/mitnano-receives-grant-acquire-focused-ion-beam-scanning-electron-microscope-0209,National Science Foundation award will allow the VELION FIB-SEM to become a permanent instrument in MIT.nano’s characterization facility.,[{'name': 'MIT.nano'}],"Wed, 09 Feb 2022 16:20:00 -0500"
139,Tiny materials lead to a big advance in quantum computing,https://news.mit.edu/2022/tiny-materials-quibits-quantum-computing-0128,Using ultrathin materials to reduce the size of superconducting qubits may pave the way for personal-sized quantum devices.,[{'name': 'Adam Zewe | MIT News Office'}],"Thu, 27 Jan 2022 11:00:00 -0500"
140,Study determines the original orientations of rocks drilled on Mars,https://news.mit.edu/2024/study-determines-original-orientations-rocks-drilled-mars-0304,"The “oriented” samples, the first of their kind from any planet, could shed light on Mars’ ancient magnetic field.",[{'name': 'Jennifer Chu | MIT News'}],"Mon, 04 Mar 2024 00:00:00 -0500"
141,“We offer another place for knowledge”,https://news.mit.edu/2024/we-offer-another-place-knowledge-0226,"After acquiring data science and AI skills from MIT, Jospin Hassan shared them with his community in the Dzaleka Refugee Camp in Malawi and built pathways for talented learners.",[{'name': 'Katherine Ouellette | MIT Open Learning'}],"Mon, 26 Feb 2024 14:35:00 -0500"
142,Smart glove teaches new physical skills,https://news.mit.edu/2024/smart-glove-teaches-new-physical-skills-0220,"Adaptive smart glove from MIT CSAIL researchers can send tactile feedback to teach users new skills, guide robots with more precise manipulation, and help train surgeons and pilots.",[{'name': 'Alex Shipps | MIT CSAIL'}],"Tue, 20 Feb 2024 11:50:00 -0500"
143,Six MIT students selected as spring 2024 MIT-Pillar AI Collective Fellows,https://news.mit.edu/2024/mit-pillar-ai-collective-fellows-0206,"The graduate students will aim to commercialize innovations in AI, machine learning, and data science.",[{'name': 'School of Engineering'}],"Tue, 06 Feb 2024 16:50:00 -0500"
144,"Professor Emeritus Igor Paul, an expert in product design and safety, dies at 87",https://news.mit.edu/2024/professor-emeritus-igor-paul-dies-0131,"Longtime professor helped develop the Department of Mechanical Engineering’s design and manufacturing curriculum, contributed to artificial joints as well as NASA inertial guidance systems.",[{'name': 'Anne Wilson | Department of Mechanical Engineering'}],"Wed, 31 Jan 2024 16:35:00 -0500"
145,Baran Mensah: Savoring college life in a new country,https://news.mit.edu/2024/baran-mensah-savoring-college-life-new-country-0119,"From robotics to dance, the MIT senior has made it his mission to explore as many new experiences as possible at the Institute.",[{'name': 'Angelina Parrillo | MIT News correspondent'}],"Fri, 19 Jan 2024 00:00:00 -0500"
146,Reasoning and reliability in AI,https://news.mit.edu/2024/reasoning-and-reliability-in-ai-0118,PhD students interning with the MIT-IBM Watson AI Lab look to improve natural language usage.,[{'name': 'Lauren Hinkel | MIT-IBM Watson AI Lab'}],"Thu, 18 Jan 2024 13:00:00 -0500"
147,"Richard Wiesman, professor of the practice in mechanical engineering, dies at age 69",https://news.mit.edu/2024/meche-professor-practice-richard-wiesman-dies-0110,"A highly respected educator and mentor with a distinguished industry career, Wiesman inspired generations of mechanical engineering students.",[{'name': 'Department of Mechanical Engineering'}],"Wed, 10 Jan 2024 14:20:00 -0500"
148,Multiple AI models help robots execute complex plans more transparently,https://news.mit.edu/2024/multiple-ai-models-help-robots-execute-complex-plans-more-transparently-0108,"A multimodal system uses models trained on language, vision, and action data to help robots develop and execute plans for household, construction, and manufacturing tasks.",[{'name': 'Alex Shipps | MIT CSAIL'}],"Mon, 08 Jan 2024 15:15:00 -0500"
149,MIT Generative AI Week fosters dialogue across disciplines,https://news.mit.edu/2023/mit-generative-ai-week-fosters-dialogue-across-disciplines-1211,"During the last week of November, MIT hosted symposia and events aimed at examining the implications and possibilities of generative AI.",[{'name': 'Mary Beth Gallagher | School of Engineering'}],"Mon, 11 Dec 2023 16:25:00 -0500"
150,MIT engineers design a robotic replica of the heart’s right chamber,https://news.mit.edu/2023/mit-engineers-design-robotic-replica-hearts-right-chamber-1208,The realistic model could aid the development of better heart implants and shed light on understudied heart disorders.,[{'name': 'Jennifer Chu | MIT News'}],"Fri, 08 Dec 2023 05:00:00 -0500"
151,A new optimization framework for robot motion planning,https://news.mit.edu/2023/new-optimization-framework-robot-motion-planning-1130,"MIT CSAIL researchers established new connections between combinatorial and continuous optimization, which can find global solutions for complex motion-planning puzzles.",[{'name': 'Alex Shipps | MIT CSAIL'}],"Thu, 30 Nov 2023 09:00:00 -0500"
152,Using language to give robots a better grasp of an open-ended world,https://news.mit.edu/2023/using-language-give-robots-better-grasp-open-ended-world-1102,"By blending 2D images with foundation models to build 3D feature fields, a new MIT method helps robots understand and manipulate nearby objects with open-ended language prompts.",[{'name': 'Alex Shipps | MIT CSAIL'}],"Thu, 02 Nov 2023 16:25:00 -0400"
153,New technique helps robots pack objects into a tight space,https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017,Researchers coaxed a family of generative AI models to work together to solve multistep robot manipulation problems.,[{'name': 'Adam Zewe | MIT News'}],"Tue, 17 Oct 2023 00:00:00 -0400"
154,A method to interpret AI might not be so interpretable after all,https://news.mit.edu/2023/method-interpret-ai-might-not-be-so-interpretable-after-all-1016,Some researchers see formal specifications as a way for autonomous systems to \"explain themselves\" to humans. But a new study finds that we aren't understanding.,[{'name': 'Kylie Foy | MIT Lincoln Laboratory'}],"Mon, 16 Oct 2023 16:25:00 -0400"
155,Finger-shaped sensor enables more dexterous robots,https://news.mit.edu/2023/finger-shaped-sensor-enables-more-dexterous-robots-1004,"MIT engineers develop a long, curved touch sensor that could enable a robot to grasp and manipulate objects in multiple ways.",[{'name': 'Adam Zewe | MIT News'}],"Wed, 04 Oct 2023 00:00:00 -0400"
156,AI copilot enhances human precision for safer aviation,https://news.mit.edu/2023/ai-co-pilot-enhances-human-precision-safer-aviation-1003,"Designed to ensure safer skies, “Air-Guardian” blends human intuition with machine precision, creating a more symbiotic relationship between pilot and aircraft.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Tue, 03 Oct 2023 14:55:00 -0400"
157,2023-2024 Accenture Fellows advance technology at the crossroads of business and society,https://news.mit.edu/2023/accenture-fellows-advance-technology-crossroads-business-society-0919,The MIT and Accenture Convergence Initiative for Industry and Technology announces new graduate fellows.,[{'name': 'School of Engineering'}],"Tue, 19 Sep 2023 16:45:00 -0400"
158,Mechanical engineering with a twist: Pursuing a passion for robotics with customized major,https://news.mit.edu/2023/mechanical-engineering-twist-pursuing-passion-robotics-customized-major-0918,"Sharmi Shah ’23 pursued Course 2-A/6, a customizable degree path that combines mechanical engineering with computer science and electrical engineering.",[{'name': 'Department of Mechanical Engineering'}],"Mon, 18 Sep 2023 14:45:00 -0400"
159,A. Michael West: Advancing human-robot interactions in health care,https://news.mit.edu/2023/michael-west-advancing-human-robot-interactions-0913,"When he isn’t investigating human motor control, the graduate student gives back by volunteering with programs that helped him grow as a researcher.",[{'name': 'Michaela Jarvis | School of Engineering'}],"Wed, 13 Sep 2023 00:00:00 -0400"
160,Making life friendlier with personal robots,https://news.mit.edu/2023/making-life-friendlier-personal-robots-sharifa-alghowinem-0910,"Sharifa Alghowinem, a research scientist at the Media Lab, explores personal robot technology that explains emotions in English and Arabic.",[{'name': 'Dorothy Hanna | Department of Mechanical Engineering'}],"Sun, 10 Sep 2023 00:00:00 -0400"
161,AI helps robots manipulate objects with their whole bodies,https://news.mit.edu/2023/ai-technique-robots-manipulate-objects-whole-bodies-0824,"With a new technique, a robot can reason efficiently about moving objects using more than just its fingertips.",[{'name': 'Adam Zewe | MIT News'}],"Thu, 24 Aug 2023 00:00:00 -0400"
162,"SMART launches research group to advance AI, automation, and the future of work",https://news.mit.edu/2023/smart-launches-m3s-research-group-advance-ai-automation-future-work-0823,"Mens, Manus and Machina (M3S) will design technology, training programs, and institutions for successful human-machine collaboration.",[{'name': 'Singapore-MIT Alliance for Research and Technology'}],"Wed, 23 Aug 2023 14:00:00 -0400"
163,"MIT engineers use kirigami to make ultrastrong, lightweight structures",https://news.mit.edu/2023/using-kirigami-ultrastrong-lightweight-structures-0822,"Produced with techniques borrowed from Japanese paper-cutting, the strong metal lattices are lighter than cork and have customizable mechanical properties.",[{'name': 'Adam Zewe | MIT News'}],"Tue, 22 Aug 2023 00:00:00 -0400"
164,A simpler method for learning to control a robot,https://news.mit.edu/2023/simpler-method-learning-control-robot-0726,"Researchers develop a machine-learning technique that can efficiently learn to control a robot, leading to better performance with fewer data.",[{'name': 'Adam Zewe | MIT News Office'}],"Wed, 26 Jul 2023 00:00:00 -0400"
165,New quantum magnet unleashes electronics potential,https://news.mit.edu/2023/new-quantum-magnet-unleashes-electronics-potential-0725,"Researchers discover how to control the anomalous Hall effect and Berry curvature to create flexible quantum magnets for use in computers, robotics, and sensors.",[{'name': 'Julianna Mullen | Plasma Science and Fusion Center'}],"Tue, 25 Jul 2023 17:20:00 -0400"
166,A faster way to teach a robot,https://news.mit.edu/2023/faster-way-teach-robot-technique-0718,"A new technique helps a nontechnical user understand why a robot failed, and then fine-tune it with minimal effort to perform a task effectively.",[{'name': 'Adam Zewe | MIT News Office'}],"Tue, 18 Jul 2023 00:00:00 -0400"
167,AI helps household robots cut planning time in half,https://news.mit.edu/2023/ai-helps-household-robots-cut-planning-time-half-0714,"PIGINet leverages machine learning to streamline and enhance household robots' task and motion planning, by assessing and filtering feasible solutions in complex environments.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Fri, 14 Jul 2023 11:00:00 -0400"
168,3 Questions: Honing robot perception and mapping,https://news.mit.edu/2023/honing-robot-perception-mapping-0710,Luca Carlone and Jonathan How of MIT LIDS discuss how future robots might perceive and interact with their environment.,[{'name': 'Madeleine Turner | MIT Laboratory for Information and Decision Systems'}],"Mon, 10 Jul 2023 14:30:00 -0400"
169,"Magnetic robots walk, crawl, and swim",https://news.mit.edu/2023/magnetic-robots-walk-crawl-swim-0707,New soft-bodied robots that can be controlled by a simple magnetic field are well suited to work in confined spaces.,[{'name': 'Jennifer Michalowski | McGovern Institute for Brain Research'}],"Fri, 07 Jul 2023 14:20:00 -0400"
170,The chore of packing just got faster and easier,https://news.mit.edu/2023/chore-packing-just-got-faster-and-easier-0706,A new computational method facilitates the dense placement of objects inside a rigid container.<br />,[{'name': 'Steve Nadis | MIT CSAIL'}],"Thu, 06 Jul 2023 00:00:00 -0400"
171,Defining the public interest in new technologies,https://news.mit.edu/2023/defining-public-interest-new-technologies-0613,"New online journal seeks to bring together the MIT community to discuss the social responsibilities of individuals who design, implement, and evaluate technologies.",[{'name': 'Department of Urban Studies and Planning'}],"Tue, 13 Jun 2023 16:45:00 -0400"
172,A step toward safe and reliable autopilots for flying,https://news.mit.edu/2023/safe-and-reliable-autopilots-flying-0612,A new AI-based approach for controlling autonomous robots satisfies the often-conflicting goals of safety and stability.,[{'name': 'Adam Zewe | MIT News Office'}],"Mon, 12 Jun 2023 00:00:00 -0400"
173,Bioinspired robotics class offers intriguing surprises,https://news.mit.edu/2023/bioinspired-robotics-class-offers-intriguing-surprises-0609,"Students learn about the complexity behind simple, everyday movement before experimenting with mechanical models.",[{'name': 'Michaela Jarvis | Department of Mechanical Engineering'}],"Fri, 09 Jun 2023 00:00:00 -0400"
174,Helping robots handle fluids,https://news.mit.edu/2023/helping-robots-handle-fluids-0524,Researchers create a new simulation tool for robots to manipulate complex fluids in a step toward helping them more effortlessly assist with daily tasks.,[{'name': 'Rachel Gordon | MIT CSAIL'}],"Wed, 24 May 2023 10:00:00 -0400"
175,2.007 Forever!,https://news.mit.edu/2023/2007-forever-annual-robot-competition-0518,"With winches, spinners, and telescoping contraptions, bots go head to head in student robot competition inspired by “Black Panther: Wakanda Forever.”",[{'name': 'Jennifer Chu | MIT News Office'}],"Thu, 18 May 2023 13:00:00 -0400"
176,Four researchers with MIT ties earn 2023 Schmidt Science Fellowships,https://news.mit.edu/2023/four-researchers-mit-ties-earn-schmidt-science-fellowships-0512,The illustrious prize supports early-career scientists and engineers as they pursue interdisciplinary work.,[{'name': 'Danielle Randall Doughty | Department of Chemistry'}],"Fri, 12 May 2023 14:00:00 -0400"
177,Open-source platform simulates wildlife for soft robotics designers,https://news.mit.edu/2023/softzoo-simulates-wildlife-soft-robotics-for-designers-0502,SoftZoo is a soft robot co-design platform that can test optimal shapes and sizes for robotic performance in different environments.,[{'name': 'Alex Shipps | MIT CSAIL'}],"Tue, 02 May 2023 12:25:00 -0400"
178,Speedy robo-gripper reflexively organizes cluttered spaces,https://news.mit.edu/2023/speedy-robo-gripper-reflexively-organizes-spaces-0427,"Rather than start from scratch after a failed attempt, the pick-and-place robot adapts in the moment to get a better hold.",[{'name': 'Jennifer Chu | MIT News Office'}],"Thu, 27 Apr 2023 00:00:00 -0400"
179,Miniscule device could help preserve the battery life of tiny sensors,https://news.mit.edu/2023/miniscule-device-could-help-preserve-battery-life-0424,Researchers demonstrate a low-power “wake-up” receiver one-tenth the size of other devices.,[{'name': 'Adam Zewe | MIT News Office'}],"Mon, 24 Apr 2023 00:00:00 -0400"
180,Drones navigate unseen environments with liquid neural networks,https://news.mit.edu/2023/drones-navigate-unseen-environments-liquid-neural-networks-0419,"MIT researchers exhibit a new advancement in autonomous drone navigation, using brain-inspired liquid neural networks that excel in out-of-distribution scenarios.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Wed, 19 Apr 2023 14:15:00 -0400"
181,Robotic hand can identify objects with just one grasp,https://news.mit.edu/2023/robotic-hand-can-identify-objects-just-one-grasp-0403,The three-fingered robotic gripper can “feel” with great sensitivity along the full length of each finger – not just at the tips.,[{'name': 'Adam Zewe | MIT News Office'}],"Mon, 03 Apr 2023 00:00:00 -0400"
182,A four-legged robotic system for playing soccer on various terrains,https://news.mit.edu/2023/legged-robotic-system-playing-soccer-various-terrains-0403,"“DribbleBot” can maneuver a soccer ball on landscapes such as sand, gravel, mud, and snow, using reinforcement learning to adapt to varying ball dynamics.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Mon, 03 Apr 2023 00:00:00 -0400"
183,A portfolio that’s out of this world,https://news.mit.edu/2023/portfolio-out-of-this-world-ezinne-uzo-okoro-0327,"Following an influential career at NASA, Ezinne Uzo-Okoro SM ’20, PhD ’22 now shapes space policy as a top White House advisor.",[{'name': 'Leda Zimmerman | Department of Aeronautics and Astronautics'}],"Mon, 27 Mar 2023 16:45:00 -0400"
184,3 Questions: How automation and good jobs can co-exist,https://news.mit.edu/2023/3-questions-automation-and-good-jobs-can-co-exist-0317,Work of the Future Initiative co-directors Julie Shah and Ben Armstrong describe their vision of “positive-sum automation.”,[{'name': 'Peter Dizikes | MIT News Office'}],"Fri, 17 Mar 2023 00:00:00 -0400"
185,Resilient bug-sized robots keep flying even after wing damage,https://news.mit.edu/2023/resilient-bug-sized-robots-wing-damage-0315,New repair techniques enable microscale robots to recover flight performance after suffering severe damage to the artificial muscles that power their wings.,[{'name': 'Adam Zewe | MIT News Office'}],"Wed, 15 Mar 2023 14:00:00 -0400"
186,Mix-and-match kit could enable astronauts to build a menagerie of lunar exploration bots,https://news.mit.edu/2023/mixed-robot-kit-lunar-exploration-0314,Robotic parts could be assembled into nimble spider bots for exploring lava tubes or heavy-duty elephant bots for transporting solar panels.,[{'name': 'Jennifer Chu | MIT News Office'}],"Tue, 14 Mar 2023 00:00:00 -0400"
187,New “traffic cop” algorithm helps a drone swarm stay on task,https://news.mit.edu/2023/new-traffic-cop-algorithm-drone-swarm-wireless-0313,"By keeping data fresh, the system could help robots inspect buildings or search disaster zones.",[{'name': 'Jennifer Chu | MIT News Office'}],"Mon, 13 Mar 2023 00:00:00 -0400"
188,Learning to compute through art,https://news.mit.edu/2023/learning-compute-through-art-0306,"“Introduction to Physical Computing for Artists” at the MIT Student Art Association teaches students to use circuits, wiring, motors, sensors, and displays by developing their own kinetic artworks.",[{'name': 'Ken Shulman | Arts at MIT'}],"Mon, 06 Mar 2023 16:55:00 -0500"
189,"Custom, 3D-printed heart replicas look and pump just like the real thing",https://news.mit.edu/2023/custom-3d-printed-heart-replicas-patient-specific-0222,The soft robotic models are patient-specific and could help clinicians zero in on the best implant for an individual.,[{'name': 'Jennifer Chu | MIT News Office'}],"Wed, 22 Feb 2023 14:00:00 -0500"
190,Brain surgery training from an avatar,https://news.mit.edu/2024/brain-surgery-training-avatar-0229,MIT.nano Immersion Lab works with AR/VR startup to create transcontinental medical instruction.,[{'name': 'Becky Ham | MIT.nano'}],"Thu, 29 Feb 2024 16:30:00 -0500"
191,Study unlocks nanoscale secrets for designing next-generation solar cells,https://news.mit.edu/2024/study-unlocks-nanoscale-secrets-tuning-perovskites-0228,"The work will help researchers tune surface properties of perovskites, a promising alternative and supplement to silicon, for more efficient photovoltaics.",[{'name': 'David L. Chandler | MIT News'}],"Wed, 28 Feb 2024 05:00:00 -0500"
192,Researchers harness 2D magnetic materials for energy-efficient computing,https://news.mit.edu/2024/researchers-harness-2d-magnetic-materials-energy-efficient-computing-0222,"An MIT team precisely controlled an ultrathin magnet at room temperature, which could enable faster, more efficient processors and computer memories.",[{'name': 'Adam Zewe | MIT News'}],"Thu, 22 Feb 2024 00:00:00 -0500"
193,"Play it again, Spirio",https://news.mit.edu/2024/play-it-again-spirio-0221,A piano that captures the data of live performance offers the MIT community new possibilities for studying and experimenting with music.<br />,[{'name': 'Nicole Estvanik Taylor | Arts at MIT'}],"Wed, 21 Feb 2024 00:00:00 -0500"
194,Technique could improve the sensitivity of quantum sensing devices,https://news.mit.edu/2024/technique-could-improve-sensitivity-quantum-sensing-devices-0208,"The method lets researchers identify and control larger numbers of atomic-scale defects, to build a bigger system of qubits.",[{'name': 'Adam Zewe | MIT News'}],"Thu, 08 Feb 2024 00:00:00 -0500"
195,MIT-led team receives funding to pursue new treatments for metabolic disease,https://news.mit.edu/2024/mit-led-team-receives-funding-new-treatments-metabolic-disease-0205,"Awarded $65.67 million from ARPA-H, the researchers will work to develop ingestible capsules that deliver mRNA and electric stimuli to treat metabolic disorders such as diabetes.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 05 Feb 2024 15:30:00 -0500"
196,New MIT.nano equipment to accelerate innovation in “tough tech” sectors,https://news.mit.edu/2024/new-mit-nano-equipment-accelerate-innovation-0130,The advanced fabrication tools will enable the next generation of microelectronics and microsystems while bridging the gap from the lab to commercialization.,[{'name': 'Zach Winn | MIT News'}],"Tue, 30 Jan 2024 13:00:00 -0500"
197,"MIT, Applied Materials, and the Northeast Microelectronics Coalition Hub to bring 200mm advanced research capabilities to MIT.nano",https://news.mit.edu/2024/mit-applied-materials-nemc-hub-advanced-research-capabilities-mit-nano-0130,"State-of-the-art toolset will bridge academic innovations and industry pathways to scale for semiconductors, microelectronics, and other critical technologies.",[{'name': 'MIT.nano'}],"Tue, 30 Jan 2024 13:00:00 -0500"
198,DNA particles that mimic viruses hold promise as vaccines,https://news.mit.edu/2024/dna-particles-mimic-viruses-hold-promise-vaccines-0130,"Using a DNA-based scaffold carrying viral proteins, researchers created a vaccine that provokes a strong antibody response against SARS-CoV-2.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 30 Jan 2024 05:00:00 -0500"
199,"Middle-school students meet a beam of electrons, and excitement results",https://news.mit.edu/2024/middle-school-students-meet-beam-electrons-excitement-results-0129,EMERGE program ignites interest in science through hands-on electron microscopy.,[{'name': 'Lauren Paul | Department of Materials Science and Engineering'}],"Mon, 29 Jan 2024 17:00:00 -0500"
200,Benchtop test quickly identifies extremely impact-resistant materials,https://news.mit.edu/2024/benchtop-test-identifies-extremely-impact-resistant-materials-0129,"High-speed experiments can help identify lightweight, protective “metamaterials” for spacecraft, vehicles, helmets, or other objects.",[{'name': 'Jennifer Chu | MIT News'}],"Mon, 29 Jan 2024 15:00:00 -0500"
201,Capsid of HIV-1 behaves like cell’s cargo receptor to enter the nucleus,https://news.mit.edu/2024/capsid-hiv-1-behaves-like-cell-cargo-receptor-to-enter-nucleus-0124,Biologists demonstrate that HIV-1 capsid acts like a Trojan horse to pass viral cargo across the nuclear pore.,[{'name': 'Lillian Eden | Department of Biology'}],"Wed, 24 Jan 2024 13:45:00 -0500"
202,Researchers improve blood tests’ ability to detect and monitor cancer,https://news.mit.edu/2024/researchers-improve-blood-tests-ability-detect-monitor-cancer-0118,"The advance makes it easier to detect circulating tumor DNA in blood samples, which could enable earlier cancer diagnosis and help guide treatment.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 18 Jan 2024 14:00:00 -0500"
203,Shell joins MIT.nano Consortium,https://news.mit.edu/2024/shell-joins-mitnano-consortium-0109,International energy company becomes sustaining member of industry group.,[{'name': 'MIT.nano'}],"Tue, 09 Jan 2024 09:00:00 -0500"
204,MIT’s tiny technologies go to Washington,https://news.mit.edu/2023/mit-tiny-technologies-go-to-washington-1218,Cancer nanomedicine was on display at the 2023 White House Demo Day.,[{'name': 'Koch Institute'}],"Mon, 18 Dec 2023 12:45:00 -0500"
205,Nanoparticle-delivered RNA reduces neuroinflammation in lab tests,https://news.mit.edu/2023/nanoparticle-delivered-rna-reduces-neuroinflammation-lab-tests-1215,"MIT researchers find that in mice and human cell cultures, lipid nanoparticles can deliver a potential therapy for inflammation in the brain, a prominent symptom in Alzheimer’s.",[{'name': 'David Orenstein | Picower Institute'}],"Fri, 15 Dec 2023 15:45:00 -0500"
206,Angela Belcher delivers 2023 Dresselhaus Lecture on evolving organisms for new nanomaterials,https://news.mit.edu/2023/angela-belcher-delivers-dresselhaus-lecture-1213,"MIT professor combines nanoscience and viruses to develop solutions in energy, environment, and medicine.",[{'name': 'Amanda Stoll DiCristofaro | MIT.nano'}],"Wed, 13 Dec 2023 16:40:00 -0500"
207,Closing the design-to-manufacturing gap for optical devices,https://news.mit.edu/2023/closing-design-manufacturing-gap-optical-devices-1213,"A new method enables optical devices that more closely match their design specifications, boosting accuracy and efficiency.",[{'name': 'Adam Zewe | MIT News'}],"Wed, 13 Dec 2023 00:00:00 -0500"
208,3 Questions: Darrell Irvine on making HIV vaccines more powerful,https://news.mit.edu/2023/darrell-irvine-making-hiv-vaccines-more-powerful-1212,"Human volunteers will soon begin receiving an HIV vaccine that contains an adjuvant developed in Irvine’s lab, which helps to boost B cell responses to the vaccine.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 12 Dec 2023 00:00:00 -0500"
209,Scientists 3D print self-heating microfluidic devices,https://news.mit.edu/2023/scientists-3d-print-self-heating-microfluidic-devices-1211,The one-step fabrication process rapidly produces miniature chemical reactors that could be used to detect diseases or analyze substances.,[{'name': 'Adam Zewe | MIT News'}],"Mon, 11 Dec 2023 00:00:00 -0500"
210,Researchers safely integrate fragile 2D materials into devices,https://news.mit.edu/2023/researchers-safely-integrate-fragile-2d-materials-devices-1208,The advance opens a path to next-generation devices with unique optical and electronic properties.,[{'name': 'Adam Zewe | MIT News'}],"Fri, 08 Dec 2023 05:00:00 -0500"
211,"Remembering Professor Judy Hoyt, a pioneer in semiconductor research",https://news.mit.edu/2023/remembering-professor-judy-hoyt-1208,Her demonstration of incorporating lattice strain as a means to enhance performance in scaled silicon devices has informed virtually every high-performance chip manufactured today.,[{'name': 'Jane Halpern | Department of Electrical Engineering and Computer Science'}],"Thu, 07 Dec 2023 15:00:00 -0500"
212,A new way to deliver drugs more efficiently,https://news.mit.edu/2023/new-way-deliver-drugs-more-efficiently-1128,Core-shell structures made of hydrogel could enable more efficient uptake in the body.,[{'name': 'Department of Chemical Engineering'}],"Tue, 28 Nov 2023 11:00:00 -0500"
213,Celebrating five years of MIT.nano,https://news.mit.edu/2023/celebrating-five-years-mit-nano-summit-1127,The Nano Summit highlights nanoscale research across multiple disciplines at MIT.,[{'name': 'Amanda Stoll DiCristofaro | MIT.nano'}],"Mon, 27 Nov 2023 15:15:00 -0500"
214,Team engineers nanoparticles using ion irradiation to advance clean energy and fuel conversion,https://news.mit.edu/2023/team-engineers-nanoparticles-advance-clean-energy-fuel-conversion-1127,The work demonstrates control over key properties leading to better performance.,[{'name': 'Elizabeth Thomson | Materials Research Laboratory'}],"Mon, 27 Nov 2023 13:45:00 -0500"
215,New laser setup probes metamaterial structures with ultrafast pulses,https://news.mit.edu/2023/new-laser-setup-probes-metamaterial-structures-ultrafast-pulses-1115,"The LIRAS technique could speed up the development of acoustic lenses, impact-resistant films, and other futuristic materials.",[{'name': 'Jennifer Chu | MIT News'}],"Wed, 15 Nov 2023 11:00:00 -0500"
216,MIT physicists turn pencil lead into “gold”,https://news.mit.edu/2023/mit-physicists-turn-pencil-lead-into-gold-1114,Thin flakes of graphite can be tuned to exhibit three important properties.,[{'name': 'Elizabeth A. Thomson | Materials Research Laboratory'}],"Tue, 14 Nov 2023 15:10:00 -0500"
217,Using AI to optimize for rapid neural imaging,https://news.mit.edu/2023/using-ai-optimize-rapid-neural-imaging-1106,"MIT CSAIL researchers combine AI and electron microscopy to expedite detailed brain network mapping, aiming to enhance connectomics research and clinical pathology.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Mon, 06 Nov 2023 13:00:00 -0500"
218,"In a surprising finding, light can make water evaporate without heat",https://news.mit.edu/2023/surprising-finding-light-makes-water-evaporate-without-heat-1031,A newly identified process could explain a variety of natural phenomena and enable new approaches to desalination.,[{'name': 'David L. Chandler | MIT News'}],"Tue, 31 Oct 2023 15:20:00 -0400"
219,"From a five-layer graphene sandwich, a rare electronic state emerges",https://news.mit.edu/2023/five-layer-graphene-sandwich-rare-electronic-behavior-1018,A newly discovered type of electronic behavior could help with packing more data into magnetic memory devices.,[{'name': 'Jennifer Chu | MIT News'}],"Wed, 18 Oct 2023 11:00:00 -0400"
220,Photos: Moungi Bawendi’s first day as a Nobel laureate,https://news.mit.edu/2023/photos-moungi-bawendi-first-day-as-nobel-laureate-1004,A look at how the MIT professor spent his day after learning he had won the Nobel Prize in Chemistry.,[{'name': 'Maia Weinstock | MIT News'}],"Wed, 04 Oct 2023 18:40:00 -0400"
221,MIT Professor Moungi Bawendi shares Nobel Prize in Chemistry,https://news.mit.edu/2023/mit-chemist-moungi-bawendi-shares-nobel-prize-chemistry-1004,"For his work on techniques to generate quantum dots of uniform size and color, Bawendi is honored along with Louis Brus and Alexei Ekimov.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 04 Oct 2023 06:00:00 -0400"
222,Quantum repeaters use defects in diamond to interconnect quantum systems,https://news.mit.edu/2023/quantum-repeaters-use-defects-diamond-interconnect-quantum-systems-0927,This technology for storing and transmitting quantum information over lossy links could provide the foundation for scalable quantum networking.,[{'name': 'Ariana Tantillo | MIT Lincoln Laboratory'}],"Wed, 27 Sep 2023 16:35:00 -0400"
223,MIT.nano Family Day invites those at home to come to work,https://news.mit.edu/2023/mitnano-family-day-invites-those-home-come-work-0918,Staff share nano experience — and ice cream — with their families.,[{'name': 'MIT.nano'}],"Mon, 18 Sep 2023 14:00:00 -0400"
224,Pixel-by-pixel analysis yields insights into lithium-ion batteries,https://news.mit.edu/2023/pixel-analysis-yields-insights-lithium-ion-batteries-0913,"In a first, researchers have observed how lithium ions flow through a battery interface, which could help engineers optimize the material’s design.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 13 Sep 2023 11:00:00 -0400"
225,Internships fabricate a microelectronics future,https://news.mit.edu/2023/internships-fabricate-microelectronics-future-0911,"Lincoln Laboratory hosts students enrolled in the Massachusetts Microelectronics Internship Program, aimed at training a new generation of microelectronics leaders.",[{'name': 'Kylie Foy | MIT Lincoln Laboratory'}],"Mon, 11 Sep 2023 13:50:00 -0400"
226,MIT engineers design more powerful RNA vaccines,https://news.mit.edu/2023/mit-engineers-design-more-powerful-rna-vaccines-0907,The new approach could lead to intranasal vaccines for Covid-19 and other respiratory diseases.,[{'name': 'Anne Trafton | MIT News'}],"Thu, 07 Sep 2023 11:00:00 -0400"
227,How to prevent biofilms in space,https://news.mit.edu/2023/preventing-biofilms-space-0907,"Microbial or fungal biofilms on spacecraft can clog hoses and filters, or make astronauts sick. Space Station tests show that a surface treatment can help.",[{'name': 'David L. Chandler | MIT News'}],"Thu, 07 Sep 2023 00:00:00 -0400"
228,“This MIT Bootcamp shook everything upside down and has given me the spirit of innovation”,https://news.mit.edu/2024/mit-bootcamp-tackling-substance-use-disorder-biomedical-device-innovation-0305,New MIT offering brings a multidisciplinary approach to tackling substance use disorder through biomedical device innovation.,[{'name': 'Mariah Rawding | MIT Bootcamps'}],"Tue, 05 Mar 2024 16:15:00 -0500"
229,Brain surgery training from an avatar,https://news.mit.edu/2024/brain-surgery-training-avatar-0229,MIT.nano Immersion Lab works with AR/VR startup to create transcontinental medical instruction.,[{'name': 'Becky Ham | MIT.nano'}],"Thu, 29 Feb 2024 16:30:00 -0500"
230,What can super-healing species teach us about regeneration?,https://news.mit.edu/2024/what-can-super-healing-species-teach-us-about-regeneration-albert-almada-0221,"Albert Almada PhD ’13 studies the mechanics of how stem cells rebuild tissues. “Digging deep into the science is what MIT taught me,” he says.",[{'name': 'Lillian Eden | Department of Biology'}],"Wed, 21 Feb 2024 15:50:00 -0500"
231,MIT Solve announces 2024 Global Challenges and Indigenous Communities Fellowship,https://news.mit.edu/2024/mit-solve-announces-global-challenges-indigenous-communities-fellowship-0220,Over $1 million in prize funding available for tech-enabled solutions to the 2024 Global Challenges.,[{'name': 'Maya Bingman | MIT Solve'}],"Tue, 20 Feb 2024 12:30:00 -0500"
232,New model identifies drugs that shouldn’t be taken together,https://news.mit.edu/2024/new-model-identifies-drugs-shouldnt-be-taken-together-0220,"Using a machine-learning algorithm, researchers can predict interactions that could interfere with a drug’s effectiveness.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 20 Feb 2024 05:00:00 -0500"
233,"MIT course aids social connection, better relationships, and happiness",https://news.mit.edu/2024/mit-course-aids-social-connection-better-relationships-happiness-0215,"New PE.0539 course supports students who want to meet new people, strengthen friendships, build communities, and make MIT a more welcoming place.",[{'name': 'Sarah Foote | Division of Student Life'}],"Thu, 15 Feb 2024 16:55:00 -0500"
234,Hitchhiking cancer vaccine makes progress in the clinic,https://news.mit.edu/2024/hitchhiking-cancer-vaccine-makes-progress-in-clinic-0215,MIT spinout Elicio developed a vaccine based on a lymph node-targeting approach first developed at the Koch Institute. Phase 1 solid tumor clinical trial results are promising so far.,[{'name': 'Bendta Schroeder | Koch Institute'}],"Thu, 15 Feb 2024 15:30:00 -0500"
235,A new test could predict how heart attack patients will respond to mechanical pumps,https://news.mit.edu/2024/new-test-predict-heart-attack-patients-response-mechanical-pumps-0214,Performing this test could help doctors prevent dysfunction that can occur when the right and left ventricles of the heart become imbalanced.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 14 Feb 2024 14:00:00 -0500"
236,Annie Liau: Infinite caring for the MIT community,https://news.mit.edu/2024/annie-liau-infinite-caring-mit-community-0208,"A longtime physician reflects on her journey from Thailand to MIT, and her four decades of service at MIT Health.",[{'name': 'Maia Weinstock | MIT News'}],"Thu, 08 Feb 2024 15:00:00 -0500"
237,Scientists develop a low-cost device to make cell therapy safer,https://news.mit.edu/2024/scientists-develop-low-cost-device-safer-cell-therapy-0207,A plastic microfluidic chip can remove some risky cells that could potentially become tumors before they are implanted in a patient.,[{'name': 'Adam Zewe | MIT News'}],"Wed, 07 Feb 2024 00:00:00 -0500"
238,MIT-led team receives funding to pursue new treatments for metabolic disease,https://news.mit.edu/2024/mit-led-team-receives-funding-new-treatments-metabolic-disease-0205,"Awarded $65.67 million from ARPA-H, the researchers will work to develop ingestible capsules that deliver mRNA and electric stimuli to treat metabolic disorders such as diabetes.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 05 Feb 2024 15:30:00 -0500"
239,Doctors have more difficulty diagnosing disease when looking at images of darker skin,https://news.mit.edu/2024/doctors-more-difficulty-diagnosing-diseases-images-darker-skin-0205,"Dermatologists and general practitioners are somewhat less accurate in diagnosing disease in darker skin, a new study finds. Used correctly, AI may be able to help.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 05 Feb 2024 05:00:00 -0500"
240,Blood cell family trees trace how production changes with aging,https://news.mit.edu/2024/blood-cell-family-trees-trace-how-production-changes-aging-0131,"Jonathan Weissman and collaborators developed a tool to reconstruct human cell family trees, revealing how blood cell production changes in old age.",[{'name': 'Greta Friar | Whitehead Institute'}],"Wed, 31 Jan 2024 15:10:00 -0500"
241,School of Engineering fourth quarter 2023 awards,https://news.mit.edu/2024/school-engineering-fourth-quarter-awards-0126,"Faculty and researchers across MIT’s School of Engineering receive many awards in recognition of their scholarship, service, and overall excellence.",[{'name': 'School of Engineering'}],"Fri, 26 Jan 2024 14:20:00 -0500"
242,MIT Faculty Founder Initiative announces finalists for second competition,https://news.mit.edu/2024/mit-faculty-founder-initiative-announces-finalists-second-competition-0124,Twelve researchers selected as finalists for 2023-24 MIT-Royalty Pharma Prize Competition to support female entrepreneurs in biotech.,[{'name': 'Mary Beth Gallagher | School of Engineering'}],"Wed, 24 Jan 2024 16:15:00 -0500"
243,What to do about AI in health?,https://news.mit.edu/2024/what-to-do-about-ai-in-health-0123,"Although artificial intelligence in health has shown great promise, pressure is mounting for regulators around the world to act, as AI tools demonstrate potentially harmful outcomes.",[{'name': 'Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health'}],"Tue, 23 Jan 2024 16:25:00 -0500"
244,"Getfit, MIT Health’s winter exercise challenge, turns 20 in 2024",https://news.mit.edu/2024/getfit-winter-exercise-challenge-turns-20-0119,The program encourages everyone on campus to get moving during the cold months.,[{'name': 'Denise Brehm | Health and Safety Office'}],"Fri, 19 Jan 2024 13:15:00 -0500"
245,Researchers improve blood tests’ ability to detect and monitor cancer,https://news.mit.edu/2024/researchers-improve-blood-tests-ability-detect-monitor-cancer-0118,"The advance makes it easier to detect circulating tumor DNA in blood samples, which could enable earlier cancer diagnosis and help guide treatment.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 18 Jan 2024 14:00:00 -0500"
246,New hope for early pancreatic cancer intervention via AI-based risk prediction,https://news.mit.edu/2024/new-hope-early-pancreatic-cancer-intervention-ai-based-risk-prediction-0118,MIT CSAIL researchers develop advanced machine-learning models that outperform current methods in detecting pancreatic ductal adenocarcinoma.,[{'name': 'Rachel Gordon | MIT CSAIL'}],"Thu, 18 Jan 2024 14:00:00 -0500"
247,MedLinks volunteers aid students in residence halls with minor medical issues,https://news.mit.edu/2024/medlinks-volunteers-aid-students-minor-medical-issues-0118,Some 150 MIT students participate in the 30-year-old program.,[{'name': 'Sarah Foote | Division of Student Life'}],"Thu, 18 Jan 2024 12:00:00 -0500"
248,Stratospheric safety standards: How aviation could steer regulation of AI in health,https://news.mit.edu/2024/stratospheric-safety-standards-how-aviation-could-steer-ai-health-regulation-0117,An interdisciplinary team of researchers thinks health AI could benefit from some of the aviation industry’s long history of hard-won lessons that have created one of the safest activities today.,[{'name': 'Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health'}],"Wed, 17 Jan 2024 12:50:00 -0500"
249,K. Lisa Yang Global Engineering and Research Center will prioritize innovations for resource-constrained communities,https://news.mit.edu/2024/k-lisa-yang-global-engineering-research-gear-center-0117,"Collaborative hub founded by philanthropist Lisa Yang will catalyze academic innovation and result in real-world, global impact.",[{'name': 'Department of Mechanical Engineering'}],"Wed, 17 Jan 2024 09:00:00 -0500"
250,Turning history of science into a comic adventure,https://news.mit.edu/2024/turning-science-history-comic-adventure-0111,Associate Professor Lydia Bourouiba and artist Argha Manna take readers through a series of discoveries in infectious disease.,[{'name': 'Zach Winn | MIT News'}],"Thu, 11 Jan 2024 00:00:00 -0500"
251,Inhalable sensors could enable early lung cancer detection,https://news.mit.edu/2024/inhalable-sensors-early-lung-cancer-detection-0105,"The diagnostic, which requires only a simple urine test to read the results, could make lung cancer screening more accessible worldwide.",[{'name': 'Anne Trafton | MIT News'}],"Fri, 05 Jan 2024 14:00:00 -0500"
252,MIT community members elected to the National Academy of Inventors for 2023,https://news.mit.edu/2024/mit-community-members-elected-national-academy-inventors-0103,"MIT Koch Institute researchers Daniel Anderson and Ana Jaklenec, plus 11 MIT alumni, are honored for inventions that have made a tangible impact on society.",[{'name': 'Bendta Schroeder | Koch Institute'}],"Wed, 03 Jan 2024 15:30:00 -0500"
253,Does “food as medicine” make a big dent in diabetes?,https://news.mit.edu/2023/food-medicine-diabetes-study-1227,"Study of rigorous trial shows mixed results, suggests need to keep examining how nutrition can combat a pervasive disease.",[{'name': 'Peter Dizikes | MIT News'}],"Wed, 27 Dec 2023 00:00:00 -0500"
254,"Engineers develop a vibrating, ingestible capsule that might help treat obesity",https://news.mit.edu/2023/engineers-develop-vibrating-ingestible-capsule-1222,"Swallowing the device before a meal could create a sense of fullness, tricking the brain into thinking it’s time to stop eating.",[{'name': 'Anne Trafton | MIT News'}],"Fri, 22 Dec 2023 14:00:00 -0500"
255,MIT in the media: 2023 in review,https://news.mit.edu/2023/mit-media-year-in-review-1221,MIT community members made headlines with key research advances and their efforts to tackle pressing challenges.,[{'name': 'MIT News'}],"Thu, 21 Dec 2023 00:00:00 -0500"
256,"Using AI, MIT researchers identify a new class of antibiotic candidates",https://news.mit.edu/2023/using-ai-mit-researchers-identify-antibiotic-candidates-1220,"These compounds can kill methicillin-resistant Staphylococcus aureus (MRSA), a bacterium that causes deadly infections.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 20 Dec 2023 11:00:00 -0500"
257,Study: Colon cancer screenings are more effective than previously understood,https://news.mit.edu/2023/study-colon-cancer-screenings-are-more-effective-1219,"By reevaluating existing data, researchers find the procedure is even more valuable than consensus had indicated.",[{'name': 'Peter Dizikes | MIT News'}],"Tue, 19 Dec 2023 00:00:00 -0500"
258,Nanoparticle-delivered RNA reduces neuroinflammation in lab tests,https://news.mit.edu/2023/nanoparticle-delivered-rna-reduces-neuroinflammation-lab-tests-1215,"MIT researchers find that in mice and human cell cultures, lipid nanoparticles can deliver a potential therapy for inflammation in the brain, a prominent symptom in Alzheimer’s.",[{'name': 'David Orenstein | Picower Institute'}],"Fri, 15 Dec 2023 15:45:00 -0500"
259,3 Questions: Darrell Irvine on making HIV vaccines more powerful,https://news.mit.edu/2023/darrell-irvine-making-hiv-vaccines-more-powerful-1212,"Human volunteers will soon begin receiving an HIV vaccine that contains an adjuvant developed in Irvine’s lab, which helps to boost B cell responses to the vaccine.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 12 Dec 2023 00:00:00 -0500"
260,Scientists 3D print self-heating microfluidic devices,https://news.mit.edu/2023/scientists-3d-print-self-heating-microfluidic-devices-1211,The one-step fabrication process rapidly produces miniature chemical reactors that could be used to detect diseases or analyze substances.,[{'name': 'Adam Zewe | MIT News'}],"Mon, 11 Dec 2023 00:00:00 -0500"
261,School of Science announces 2024 Infinite Expansion Awards,https://news.mit.edu/2024/school-science-infinite-expansion-awards-0304,Nine postdocs and research scientists honored for contributions to the Institute.,[{'name': 'School of Science'}],"Mon, 04 Mar 2024 17:20:00 -0500"
262,Eight from MIT named 2024 Sloan Research Fellows,https://news.mit.edu/2024/sloan-research-fellows-0229,"Fellows honored for creativity, innovation, and research accomplishments.",[{'name': 'School of Science'}],"Thu, 29 Feb 2024 16:50:00 -0500"
263,Study unlocks nanoscale secrets for designing next-generation solar cells,https://news.mit.edu/2024/study-unlocks-nanoscale-secrets-tuning-perovskites-0228,"The work will help researchers tune surface properties of perovskites, a promising alternative and supplement to silicon, for more efficient photovoltaics.",[{'name': 'David L. Chandler | MIT News'}],"Wed, 28 Feb 2024 05:00:00 -0500"
264,"With just a little electricity, MIT researchers boost common catalytic reactions",https://news.mit.edu/2024/mit-researchers-boost-common-catalytic-reactions-with-electricity-0215,"Applying a small voltage to a catalyst can increase the rates of reactions used in petrochemical processing, pharmaceutical manufacture, and many other processes.",[{'name': 'David L. Chandler | MIT News'}],"Thu, 15 Feb 2024 14:00:00 -0500"
265,MIT community members honored with 2024 Franklin Institute Awards,https://news.mit.edu/2024/mit-community-members-honored-franklin-institute-awards-0209,"Two professors and three additional alumni recognized for “dreaming up solutions to global challenges — advancing health, sustainability, and human connection.”",[{'name': 'Department of Chemical Engineering'}],"Fri, 09 Feb 2024 16:30:00 -0500"
266,Researchers discover new channels to excite magnetic waves with terahertz light,https://news.mit.edu/2024/new-channels-excite-magnetic-waves-terahertz-light-0206,"The finding provides new insights into the ultrafast control of magnetic materials, with potential to enable next-generation information processing technologies.",[{'name': 'Department of Chemistry'}],"Tue, 06 Feb 2024 17:25:00 -0500"
267,"Middle-school students meet a beam of electrons, and excitement results",https://news.mit.edu/2024/middle-school-students-meet-beam-electrons-excitement-results-0129,EMERGE program ignites interest in science through hands-on electron microscopy.,[{'name': 'Lauren Paul | Department of Materials Science and Engineering'}],"Mon, 29 Jan 2024 17:00:00 -0500"
268,Susan Solomon wins VinFuture Award for Female Innovators,https://news.mit.edu/2024/susan-solomon-vinfuture-award-female-innovators-0126,The award recognizes Solomon’s contributions to understanding ozone depletion and the creation of the Montreal Protocol.,[{'name': 'Paige Colley | EAPS'}],"Fri, 26 Jan 2024 10:00:00 -0500"
269,Performance art and science collide as students experience “Blue Man Group”,https://news.mit.edu/2024/performance-art-science-collide-blue-man-group-0125,Students from Course 5.111 (Principles of Chemical Science) were treated to a performance that brought to life the chemical structures and crystal field theory concepts covered in class.,[{'name': 'Danielle Randall Doughty | Department of Chemistry'}],"Thu, 25 Jan 2024 13:10:00 -0500"
270,A new drug candidate can shrink kidney cysts,https://news.mit.edu/2024/new-drug-candidate-can-shrink-kidney-cysts-0122,"A compound originally developed to treat cancer could be repurposed to treat polycystic kidney disease, an inherited condition that can lead to kidney failure.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 22 Jan 2024 00:00:00 -0500"
271,Cobalt-free batteries could power cars of the future,https://news.mit.edu/2024/cobalt-free-batteries-could-power-future-cars-0118,"MIT chemists developed a battery cathode based on organic materials, which could reduce the EV industry’s reliance on scarce metals.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 18 Jan 2024 08:00:00 -0500"
272,Study reveals a reaction at the heart of many renewable energy technologies,https://news.mit.edu/2024/study-reveals-electrode-reaction-renewable-energy-technologies-0116,New insights into how proton-coupled electron transfers occur at an electrode could help researchers design more efficient fuel cells and electrolyzers.,[{'name': 'Anne Trafton | MIT News'}],"Tue, 16 Jan 2024 05:00:00 -0500"
273,MIT community members elected to the National Academy of Inventors for 2023,https://news.mit.edu/2024/mit-community-members-elected-national-academy-inventors-0103,"MIT Koch Institute researchers Daniel Anderson and Ana Jaklenec, plus 11 MIT alumni, are honored for inventions that have made a tangible impact on society.",[{'name': 'Bendta Schroeder | Koch Institute'}],"Wed, 03 Jan 2024 15:30:00 -0500"
274,Computational model captures the elusive transition states of chemical reactions,https://news.mit.edu/2023/computational-model-captures-elusive-transition-states-1215,"Using generative AI, MIT chemical engineers and chemists created a model that can predict the structures formed when a chemical reaction reaches its point of no return.",[{'name': 'Anne Trafton | MIT News'}],"Fri, 15 Dec 2023 05:00:00 -0500"
275,Moungi Bawendi honored during Nobel Week in Stockholm,https://news.mit.edu/2023/moungi-bawendi-honored-during-nobel-week-stockholm-1211,"The professor of chemistry participated in various festivities, culminating in the Nobel Prize ceremony on Dec. 10.",[{'name': 'MIT News'}],"Mon, 11 Dec 2023 16:03:00 -0500"
276,MIT engineers develop a way to determine how the surfaces of materials behave,https://news.mit.edu/2023/mit-engineers-how-surfaces-materials-behave-1207,"Using machine learning, the computational method can provide details of how materials work as catalysts, semiconductors, or battery components.",[{'name': 'David L. Chandler | MIT News'}],"Thu, 07 Dec 2023 05:00:00 -0500"
277,Chemists create organic molecules in a rainbow of colors,https://news.mit.edu/2023/chemists-create-organic-molecules-rainbow-colors-1205,"The molecules, known as acenes, could be useful as organic light-emitting diodes or solar cells, among other possible applications.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 05 Dec 2023 05:00:00 -0500"
278,Explained: The sugar coating of life,https://news.mit.edu/2023/explained-glycoscience-carbohydrates-1201,"Researchers are working to advance the field of glycoscience, illuminating the essential role of carbohydrates for human health and disease.",[{'name': 'Leah Campbell | School of Science'}],"Fri, 01 Dec 2023 11:00:00 -0500"
279,Celebrating five years of MIT.nano,https://news.mit.edu/2023/celebrating-five-years-mit-nano-summit-1127,The Nano Summit highlights nanoscale research across multiple disciplines at MIT.,[{'name': 'Amanda Stoll DiCristofaro | MIT.nano'}],"Mon, 27 Nov 2023 15:15:00 -0500"
280,GlycoMIT Symposium celebrates advancements in glycobiology,https://news.mit.edu/2023/glycomit-symposium-celebrates-advancements-glycobiology-1107,Glyco enthusiasts from MIT and beyond recently gathered in Bartos Theatre to enjoy presentations of the latest advancements in glycobiology research.,[{'name': 'Danielle Randall Doughty | Department of Chemistry'}],"Tue, 07 Nov 2023 17:00:00 -0500"
281,Bringing the environment to the forefront of engineering,https://news.mit.edu/2023/desiree-plata-sustainability-engineering-1024,Desirée Plata is on a lifelong mission to make sustainability a bigger factor in design decisions.,[{'name': 'Zach Winn | MIT News'}],"Tue, 24 Oct 2023 00:00:00 -0400"
282,Targeting a coronavirus ion channel could yield new Covid-19 drugs,https://news.mit.edu/2023/targeting-coronavirus-ion-channel-could-yield-new-covid-19-drugs-1013,"Chemists discover the structures of open and closed states of the channel, which could help the development of antiviral drugs to reduce inflammation.",[{'name': 'Anne Trafton | MIT News'}],"Fri, 13 Oct 2023 14:00:00 -0400"
283,Photos: Moungi Bawendi’s first day as a Nobel laureate,https://news.mit.edu/2023/photos-moungi-bawendi-first-day-as-nobel-laureate-1004,A look at how the MIT professor spent his day after learning he had won the Nobel Prize in Chemistry.,[{'name': 'Maia Weinstock | MIT News'}],"Wed, 04 Oct 2023 18:40:00 -0400"
284,MIT Professor Moungi Bawendi shares Nobel Prize in Chemistry,https://news.mit.edu/2023/mit-chemist-moungi-bawendi-shares-nobel-prize-chemistry-1004,"For his work on techniques to generate quantum dots of uniform size and color, Bawendi is honored along with Louis Brus and Alexei Ekimov.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 04 Oct 2023 06:00:00 -0400"
285,School of Science welcomes new faculty in 2023,https://news.mit.edu/2023/school-science-welcomes-new-faculty-0925,"Sixteen professors join the departments of Biology; Chemistry; Earth, Atmospheric and Planetary Sciences; Mathematics; and Physics.",[{'name': 'School of Science'}],"Mon, 25 Sep 2023 15:55:00 -0400"
286,Future science at the molecular level,https://news.mit.edu/2023/future-science-molecular-level-brad-pentelute-0915,Brad Pentelute and his lab compel the anthrax delivery system to deliver antibody and peptide variants into cells to treat cancer.,[{'name': 'Daniel de Wolff | MIT Industrial Liaison Program'}],"Fri, 15 Sep 2023 16:15:00 -0400"
287,Study suggests energy-efficient route to capturing and converting CO2,https://news.mit.edu/2023/study-suggests-energy-efficient-route-capturing-and-converting-co2-0906,"The findings, based on a single electrochemical process, could help cut emissions from the hardest-to-decarbonize industries, such as steel and cement.",[{'name': 'Jennifer Chu | MIT News'}],"Wed, 06 Sep 2023 14:15:00 -0400"
288,Arrays of quantum rods could enhance TVs or virtual reality devices,https://news.mit.edu/2023/arrays-quantum-rods-could-enhance-tv-virtual-reality-devices-0811,"MIT engineers developed a new way to create these arrays, by scaffolding quantum rods onto patterned DNA.",[{'name': 'Anne Trafton | MIT News'}],"Fri, 11 Aug 2023 14:00:00 -0400"
289,Fourteen MIT School of Science professors receive tenure for 2022 and 2023,https://news.mit.edu/2023/mit-school-science-professors-receive-tenure-0808,"Faculty members were recently granted tenure in the departments of Biology, Brain and Cognitive Sciences, Chemistry, EAPS, and Physics.",[{'name': 'School of Science'}],"Tue, 08 Aug 2023 17:00:00 -0400"
290,Helping to fill in gaps in urology research for female patients,https://news.mit.edu/2023/helping-fill-gaps-urology-research-female-patients-nicole-de-nisco-0802,"Biologist Nicole De Nisco ’07, PhD ’13 draws on her love of problem-solving and interdisciplinary skills honed as a student at MIT.",[{'name': 'Lillian Eden | Department of Biology'}],"Wed, 02 Aug 2023 13:20:00 -0400"
291,Probe expands understanding of oral cavity homeostasis,https://news.mit.edu/2023/probe-expands-understanding-oral-cavity-homeostasis-0718,A new approach opens the door to a greater understanding of protein-microbe interactions.,[{'name': 'Lillian Eden | Department of Biology'}],"Tue, 18 Jul 2023 16:15:00 -0400"
292,How Tau tangles form in the brain,https://news.mit.edu/2023/how-tau-tangles-form-brain-0714,A new study shows that truncated versions of the Tau protein are more likely to form the sticky filaments seen in the brains of people with Alzheimer’s disease.,[{'name': 'Anne Trafton | MIT News Office'}],"Fri, 14 Jul 2023 14:00:00 -0400"
293,Scientists pinpoint where thousands of individual proteins are made in intact tissue and single cells,https://news.mit.edu/2023/scientists-pinpoint-where-thousands-individual-proteins-are-made-0714,A new technology called RIBOmap can give researchers valuable insight into how protein production in animal and human tissue is altered in disease.,[{'name': 'Sarah C.P. Williams | Broad Institute'}],"Fri, 14 Jul 2023 10:00:00 -0400"
294,Learning the language of molecules to predict their properties,https://news.mit.edu/2023/learning-language-molecules-predict-properties-0707,"This AI system only needs a small amount of data to predict molecular properties, which could speed up drug discovery and material development.",[{'name': 'Adam Zewe | MIT News Office'}],"Fri, 07 Jul 2023 00:00:00 -0400"
295,Researchers grow precise arrays of nanoLEDs,https://news.mit.edu/2023/researchers-grow-precise-arrays-nanoleds-0706,"A new technique produces perovskite nanocrystals right where they’re needed, so the exceedingly delicate materials can be integrated into nanoscale devices.",[{'name': 'Adam Zewe | MIT News Office'}],"Thu, 06 Jul 2023 00:00:00 -0400"
296,Chemists discover why photosynthetic light-harvesting is so efficient,https://news.mit.edu/2023/chemists-discover-photosynthetic-light-harvesting-efficiency-0703,The disorganized arrangement of the proteins in light-harvesting complexes is the key to their extreme efficiency.,[{'name': 'Anne Trafton | MIT News Office'}],"Mon, 03 Jul 2023 15:00:00 -0400"
297,QS ranks MIT the world’s No. 1 university for 2023-24,https://news.mit.edu/2023/qs-ranks-mit-1-university-23-24-0627,"Ranking at the top for the 12th year in a row, the Institute also places first in 11 subject areas.",[{'name': 'MIT News Office'}],"Tue, 27 Jun 2023 16:00:00 -0400"
298,Surprise! Weaker bonds can make polymers stronger,https://news.mit.edu/2023/weaker-bonds-can-make-polymers-stronger-0622,"By adding weak linkers to a polymer network, chemists dramatically enhanced the material’s resistance to tearing.",[{'name': 'Anne Trafton | MIT News Office'}],"Thu, 22 Jun 2023 00:00:00 -0400"
299,Researchers develop a new source of quantum light,https://news.mit.edu/2023/researchers-develop-new-source-quantum-light-0622,The device emits a stream of single photons and could provide a basis for optical quantum computers.,[{'name': 'David L. Chandler | MIT News Office'}],"Thu, 22 Jun 2023 00:00:00 -0400"
300,Charlie Farquhar: Forger of chemical and social bonds,https://news.mit.edu/2023/charlie-farquhar-chemical-social-bonds-0621,"While developing targeted drug-delivery methods, the PhD student advocates for inclusion, belonging, and collaboration.",[{'name': 'Laura Rosado | MIT News correspondent'}],"Wed, 21 Jun 2023 00:00:00 -0400"
301,Tiny diamond rotor could improve protein studies,https://news.mit.edu/2023/tiny-diamond-rotor-could-improve-protein-studies-0524,A new way of machining microscale rotors from diamond crystal can enable ultrasensitive NMR devices for probing proteins and other materials.,[{'name': 'David L. Chandler | MIT News Office'}],"Wed, 24 May 2023 00:00:00 -0400"
302,J-WAFS announces 2023 seed grant recipients,https://news.mit.edu/2023/j-wafs-announces-seed-grant-recipients-0517,Fifteen principal investigators from across MIT will conduct early work to solve issues ranging from water contamination to aquaculture monitoring and management.,[{'name': 'Maria Paula Acosta Bello | Abdul Latif Jameel Water and Food Systems Lab'}],"Wed, 17 May 2023 14:45:00 -0400"
303,Four researchers with MIT ties earn 2023 Schmidt Science Fellowships,https://news.mit.edu/2023/four-researchers-mit-ties-earn-schmidt-science-fellowships-0512,The illustrious prize supports early-career scientists and engineers as they pursue interdisciplinary work.,[{'name': 'Danielle Randall Doughty | Department of Chemistry'}],"Fri, 12 May 2023 14:00:00 -0400"
304,Study reveals new ways for exotic quasiparticles to “relax”,https://news.mit.edu/2023/study-reveals-new-ways-exotic-quasiparticles-relax-0512,A perovskite-based device that combines aspects of electronics and photonics may open doors to new kinds of computer chips or quantum qubits.,[{'name': 'David L. Chandler | MIT News Office'}],"Fri, 12 May 2023 00:00:00 -0400"
305,Five MIT faculty elected to the National Academy of Sciences for 2023,https://news.mit.edu/2023/five-mit-elected-national-academy-sciences-2023-0511,"Joshua Angrist, Gang Chen, Catherine Drennan, Dina Katabi, Gregory Stephanopoulos, and seven additional alumni are recognized by their peers for their outstanding contributions to research.",[{'name': 'Mary Beth Gallagher | School of Engineering'}],"Thu, 11 May 2023 16:00:00 -0400"
306,Inaugural J-WAFS Grand Challenge aims to develop enhanced crop variants and move them from lab to land,https://news.mit.edu/2023/inaugural-j-wafs-grand-challenge-aims-develop-enhanced-crop-variants-0510,Matt Shoulders will lead an interdisciplinary team to improve RuBisCO — the photosynthesis enzyme thought to be the holy grail for improving agricultural yield.,[{'name': 'Carolyn Blais | Abdul Latif Jameel Water and Food Systems Lab'}],"Wed, 10 May 2023 13:00:00 -0400"
307,Chemists’ technique reveals whether antibodies neutralize SARS-CoV-2,https://news.mit.edu/2023/chemists-technique-neutralizing-antibodies-0510,The method could enable a rapid test to determine whether individuals are producing antibodies that help protect against Covid-19.,[{'name': 'Anne Trafton | MIT News Office'}],"Wed, 10 May 2023 09:00:00 -0400"
308,"MIT graduate engineering, business, science programs ranked highly by U.S. News for 2023-24",https://news.mit.edu/2023/mit-graduate-engineering-business-science-programs-rus-news-2023-24-0425,Graduate engineering program is No. 1 in the nation; MIT Sloan is No. 4.,[{'name': 'MIT News Office'}],"Tue, 25 Apr 2023 00:01:00 -0400"
309,Two-component system could offer a new way to halt internal bleeding,https://news.mit.edu/2023/two-component-system-halt-internal-bleeding-0425,"The technology, which mimics the body’s natural clotting process, could help keep severely injured people alive until they are treated at a hospital.",[{'name': 'Anne Trafton | MIT News Office'}],"Tue, 25 Apr 2023 00:00:00 -0400"
310,Nanoparticles provoke immune response against tumors but avoid side effects,https://news.mit.edu/2023/nanoparticles-provoke-immune-response-against-tumors-0419,"In a new study, immunostimulatory drugs slowed tumor growth without producing systemic inflammation.",[{'name': 'Anne Trafton | MIT News Office'}],"Wed, 19 Apr 2023 14:00:00 -0400"
311,School of Science announces 2024 Infinite Expansion Awards,https://news.mit.edu/2024/school-science-infinite-expansion-awards-0304,Nine postdocs and research scientists honored for contributions to the Institute.,[{'name': 'School of Science'}],"Mon, 04 Mar 2024 17:20:00 -0500"
312,Exposure to different kinds of music influences how the brain interprets rhythm,https://news.mit.edu/2024/exposure-different-kinds-music-influences-how-brain-interprets-rhythm-0304,"A study of people in 15 countries reveals that while everyone favors rhythms with simple integer ratios, biases can vary quite a bit across societies.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 04 Mar 2024 05:00:00 -0500"
313,How cognition changes before dementia hits,https://news.mit.edu/2024/how-cognition-changes-before-dementia-0229,Study finds language-processing difficulties are an indicator — in addition to memory loss — of amnestic mild cognitive impairment.,[{'name': 'Peter Dizikes | MIT News'}],"Thu, 29 Feb 2024 00:00:00 -0500"
314,Imaging method reveals new cells and structures in human brain tissue,https://news.mit.edu/2024/imaging-method-reveals-new-cells-structures-human-brain-tissue-0131,A new microscopy technique that enables high-resolution imaging could one day help doctors diagnose and treat brain tumors.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 31 Jan 2024 14:00:00 -0500"
315,"Simons Center’s collaborative approach propels autism research, at MIT and beyond",https://news.mit.edu/2024/simons-center-collaborative-approach-propels-autism-research-0130,"Team-based targeted projects, multi-mentor fellowships ensure that scientists studying social cognition, behavior, and autism integrate multiple perspectives and approaches to pressing questions.",[{'name': 'David Orenstein | Simons Center for the Social Brain'}],"Tue, 30 Jan 2024 16:35:00 -0500"
316,Creating new skills and new connections with MIT’s Quantitative Methods Workshop,https://news.mit.edu/2024/quantitative-methods-workshop-0130,More than 80 students and faculty from a dozen collaborating institutions became immersed at the intersection of computation and life sciences and forged new ties to MIT and each other.,[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Tue, 30 Jan 2024 15:45:00 -0500"
317,"Professor Emeritus Peter Schiller, a pioneer researcher of the visual system, dies at 92",https://news.mit.edu/2024/professor-emeritus-peter-schiller-dies-0123,His wide-ranging and influential career included fundamental discoveries about how visual scenes and stimuli are processed from the retina through the cortical visual system.,[{'name': 'Department of Brain and Cognitive Sciences'}],"Tue, 23 Jan 2024 15:45:00 -0500"
318,How the brain responds to reward is linked to socioeconomic background,https://news.mit.edu/2024/how-brain-responds-reward-socioeconomic-background-0122,An MIT study finds the brains of children who grow up in less affluent households are less responsive to rewarding experiences.,[{'name': 'Anne Trafton | MIT News'}],"Mon, 22 Jan 2024 13:00:00 -0500"
319,Evidence that gamma rhythm stimulation can treat neurological disorders is emerging,https://news.mit.edu/2024/evidence-gamma-rhythm-stimulation-can-treat-neurological-disorders-emerging-0118,"Researchers survey a broadening landscape of studies showing what’s known, and what remains to be found, about the therapeutic potential of noninvasive sensory, electrical, or magnetic stimulation of gamma brain rhythms.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Thu, 18 Jan 2024 12:50:00 -0500"
320,Study reveals a universal pattern of brain wave frequencies,https://news.mit.edu/2024/study-reveals-universal-pattern-brain-wave-frequencies-0118,"Across mammalian species, brain waves are slower in deep cortical layers, while superficial layers generate faster rhythms.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 18 Jan 2024 05:00:00 -0500"
321,Three honored with 2023 School of Science teaching prizes,https://news.mit.edu/2024/three-honored-school-science-teaching-prizes-0110,"Roger Levy, Pulin Li, and David McGee were nominated by peers and students for their exceptional instruction.",[{'name': 'School of Science'}],"Wed, 10 Jan 2024 15:55:00 -0500"
322,Juana De La O: Food for thought,https://news.mit.edu/2024/food-for-thought-juana-de-la-o-0110,This biology graduate student is building connections through her thesis work in mouse development and her passion for cooking and baking.,[{'name': 'Lillian Eden | Department of Biology'}],"Wed, 10 Jan 2024 15:00:00 -0500"
323,"Complex, unfamiliar sentences make the brain’s language network work harder",https://news.mit.edu/2024/complex-unfamiliar-sentences-brains-language-network-0103,"A new study finds that language regions in the left hemisphere light up when reading uncommon sentences, while straightforward sentences elicit little response.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 03 Jan 2024 05:00:00 -0500"
324,Nanoparticle-delivered RNA reduces neuroinflammation in lab tests,https://news.mit.edu/2023/nanoparticle-delivered-rna-reduces-neuroinflammation-lab-tests-1215,"MIT researchers find that in mice and human cell cultures, lipid nanoparticles can deliver a potential therapy for inflammation in the brain, a prominent symptom in Alzheimer’s.",[{'name': 'David Orenstein | Picower Institute'}],"Fri, 15 Dec 2023 15:45:00 -0500"
325,Deep neural networks show promise as models of human hearing,https://news.mit.edu/2023/deep-neural-nets-show-promise-models-of-human-hearing-1213,Study shows computational models trained to perform auditory tasks display an internal organization similar to that of the human auditory cortex.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 13 Dec 2023 14:00:00 -0500"
326,How a mutation in microglia elevates Alzheimer’s risk,https://news.mit.edu/2023/how-mutation-microglia-elevates-alzheimers-risk-1204,"A new study finds that microglia with mutant TREM2 protein reduce brain circuit connections, promote inflammation, and contribute to Alzheimer’s pathology in other ways.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Mon, 04 Dec 2023 16:00:00 -0500"
327,Elly Nedivi receives 2023 Kreig Cortical Kudos Discoverer Award,https://news.mit.edu/2023/award-honors-elly-nedivis-research-cortical-plasticity-1129,The neuroscientist is recognized for her ongoing work to understand molecular and cellular mechanisms that enable the brain to adapt to experience.,[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Wed, 29 Nov 2023 11:00:00 -0500"
328,A new way to see the activity inside a living cell,https://news.mit.edu/2023/new-method-fluorescent-labels-living-cell-1128,"Using fluorescent labels that switch on and off, MIT engineers can study how molecules in a cell interact to control the cell’s behavior.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 28 Nov 2023 11:00:00 -0500"
329,Search algorithm reveals nearly 200 new kinds of CRISPR systems,https://news.mit.edu/2023/search-algorithm-reveals-nearly-200-new-kinds-crispr-systems-1123,"By analyzing bacterial data, researchers have discovered thousands of rare new CRISPR systems that have a range of functions and could enable gene editing, diagnostics, and more.",[{'name': 'Allessandra DiCorato | Broad Institute'}],"Thu, 23 Nov 2023 14:00:00 -0500"
330,Three MIT affiliates receive Schmidt awards,https://news.mit.edu/2023/schmidt-awards-1120,"Jörn Dunkel and Surya Ganguli ’98, MNG ’98 receive Science Polymath awards; Josh Tenenbaum is named AI2050 Senior Fellow.",[{'name': 'Sandi Miller | Department of Mathematics'}],"Mon, 20 Nov 2023 13:40:00 -0500"
331,Mark Bear wins Society for Neuroscience Julius Axelrod Prize,https://news.mit.edu/2023/mark-bear-wins-julius-axelrod-prize-1117,"Award recognizes professor's synaptic plasticity research, its translation to potential amblyopia and autism treatments, and his career of mentorship.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Fri, 17 Nov 2023 13:20:00 -0500"
332,Rewarding excellence in open data,https://news.mit.edu/2023/rewarding-excellence-in-open-data-1116,MIT researchers who share their data recognized at second annual awards celebration.,[{'name': 'Brigham Fay | MIT Libraries'}],"Thu, 16 Nov 2023 16:30:00 -0500"
333,Aging Brain Initiative symposium showcases “cutting-edge” research across MIT,https://news.mit.edu/2023/aging-brain-initiative-symposium-1116,"Seed projects, posters represent a wide range of labs working on technologies, therapeutic strategies, and fundamental research to advance understanding of age-related neurodegenerative disease.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Thu, 16 Nov 2023 16:20:00 -0500"
334,A new wave of treatment for Alzheimer’s disease,https://news.mit.edu/2023/new-wave-treatment-alzheimers-disease-li-huei-tsai-1115,Professor Li-Huei Tsai studies how brain waves can be used to treat neurodegenerative diseases such as Alzheimer’s.,[{'name': 'Eric Bender | MIT Industrial Liaison Program'}],"Wed, 15 Nov 2023 12:55:00 -0500"
335,Anesthesia technology precisely controls unconsciousness in animal tests,https://news.mit.edu/2023/anesthesia-technology-precisely-controls-unconsciousness-animal-tests-1107,An advanced closed-loop anesthesia delivery system that monitors brain state to tailor propofol dose and achieve exactly the desired level of unconsciousness could reduce post-op side effects.,[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Tue, 07 Nov 2023 09:50:00 -0500"
336,Using AI to optimize for rapid neural imaging,https://news.mit.edu/2023/using-ai-optimize-rapid-neural-imaging-1106,"MIT CSAIL researchers combine AI and electron microscopy to expedite detailed brain network mapping, aiming to enhance connectomics research and clinical pathology.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Mon, 06 Nov 2023 13:00:00 -0500"
337,How “blue” and “green” appeared in a language that didn’t have words for them,https://news.mit.edu/2023/how-blue-and-green-appeared-language-1102,"People of a remote Amazonian society who learned Spanish as a second language began to interpret colors in a new way, an MIT study has found.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 02 Nov 2023 00:00:00 -0400"
338,The brain may learn about the world the same way some computational models do,https://news.mit.edu/2023/brain-self-supervised-computational-models-1030,"Two studies find “self-supervised” models, which learn about their environment from unlabeled data, can show activity patterns similar to those of the mammalian brain.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 30 Oct 2023 00:00:00 -0400"
339,How adults understand what kids are saying,https://news.mit.edu/2023/how-adults-understand-what-kids-are-saying-1026,"It’s not easy to parse young children’s words, but adults’ beliefs about what children want to communicate helps make it possible, a new study finds.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 26 Oct 2023 11:00:00 -0400"
340,New technique helps robots pack objects into a tight space,https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017,Researchers coaxed a family of generative AI models to work together to solve multistep robot manipulation problems.,[{'name': 'Adam Zewe | MIT News'}],"Tue, 17 Oct 2023 00:00:00 -0400"
341,Ariel Furst and Fan Wang receive 2023 National Institutes of Health awards,https://news.mit.edu/2023/mit-researchers-receive-nih-awards-1016,"The awards support creative, innovative research with a broad impact.",[{'name': 'Sophie Hartley | School of Science'}],"Mon, 16 Oct 2023 16:45:00 -0400"
342,Study: Deep neural networks don’t see the world the way we do,https://news.mit.edu/2023/study-deep-neural-networks-perception-1016,Images that humans perceive as completely unrelated can be classified as the same by computational models.,[{'name': 'Anne Trafton | MIT News'}],"Mon, 16 Oct 2023 11:00:00 -0400"
343,Practicing mindfulness with an app may improve children’s mental health,https://news.mit.edu/2023/practicing-mindfulness-may-improve-childrens-mental-health-1011,New research suggests daily mindfulness training at home helped reduce kids’ stress levels and negative emotions.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 11 Oct 2023 00:00:00 -0400"
344,Twelve with MIT ties elected to the National Academy of Medicine for 2023,https://news.mit.edu/2023/researchers-elected-national-academy-medicine-1010,"Five MIT faculty, along with seven additional affiliates, are honored for outstanding contributions to medical research.",[{'name': 'School of Science'}],"Tue, 10 Oct 2023 16:40:00 -0400"
345,Using generative AI to improve software testing,https://news.mit.edu/2024/using-generative-ai-improve-software-testing-datacebo-0305,MIT spinout DataCebo helps companies bolster their datasets by creating synthetic data that mimic the real thing.,[{'name': 'Zach Winn | MIT News'}],"Tue, 05 Mar 2024 00:00:00 -0500"
346,Startup accelerates progress toward light-speed computing,https://news.mit.edu/2024/startup-lightmatter-accelerates-progress-toward-light-speed-computing-0301,"Lightmatter, founded by three MIT alumni, is using photonic technologies to reinvent how chips communicate and calculate.",[{'name': 'Zach Winn | MIT News'}],"Fri, 01 Mar 2024 00:00:00 -0500"
347,Dealing with the limitations of our noisy world,https://news.mit.edu/2024/tamara-broderick-quantifying-uncertainty-0301,Tamara Broderick uses statistical approaches to understand and quantify the uncertainty that can affect study results.,[{'name': 'Adam Zewe | MIT News'}],"Fri, 01 Mar 2024 00:00:00 -0500"
348,Brain surgery training from an avatar,https://news.mit.edu/2024/brain-surgery-training-avatar-0229,MIT.nano Immersion Lab works with AR/VR startup to create transcontinental medical instruction.,[{'name': 'Becky Ham | MIT.nano'}],"Thu, 29 Feb 2024 16:30:00 -0500"
349,3 Questions: Shaping the future of work in an age of AI,https://news.mit.edu/2024/3-questions-shaping-future-work-age-of-ai-0228,"Daron Acemoglu, David Autor, and Simon Johnson, faculty co-directors of the new MIT Shaping the Future of Work Initiative, describe why the work matters and what they hope to achieve.",[{'name': 'Blueprint Labs'}],"Wed, 28 Feb 2024 16:40:00 -0500"
350,Sadhana Lolla named 2024 Gates Cambridge Scholar,https://news.mit.edu/2024/sadhana-lolla-gates-cambridge-scholar-0227,The MIT senior will pursue graduate studies in technology policy at Cambridge University.,[{'name': 'Julia Mongo | Office of Distinguished Fellowships'}],"Tue, 27 Feb 2024 16:10:00 -0500"
351,New AI model could streamline operations in a robotic warehouse,https://news.mit.edu/2024/new-ai-model-could-streamline-operations-robotic-warehouse-0227,"By breaking an intractable problem into smaller chunks, a deep-learning technique identifies the optimal areas for thinning out traffic in a warehouse.",[{'name': 'Adam Zewe | MIT News'}],"Tue, 27 Feb 2024 00:00:00 -0500"
352,“We offer another place for knowledge”,https://news.mit.edu/2024/we-offer-another-place-knowledge-0226,"After acquiring data science and AI skills from MIT, Jospin Hassan shared them with his community in the Dzaleka Refugee Camp in Malawi and built pathways for talented learners.",[{'name': 'Katherine Ouellette | MIT Open Learning'}],"Mon, 26 Feb 2024 14:35:00 -0500"
353,Generative AI for smart grid modeling,https://news.mit.edu/2024/generative-ai-smart-grid-modeling-0226,MIT LIDS awarded funding from the Appalachian Regional Commission as part of a multi-state collaborative project to model and test new smart grid technologies for use in rural areas.,[{'name': 'MIT Laboratory for Information and Decision Systems'}],"Mon, 26 Feb 2024 14:30:00 -0500"
354,Putting AI into the hands of people with problems to solve,https://news.mit.edu/2024/pienso-putting-user-friendly-ai-problem-solving-0226,Alumni-founded Pienso has developed a user-friendly AI builder so domain experts can build solutions without writing any code.,[{'name': 'Zach Winn | MIT News'}],"Mon, 26 Feb 2024 00:00:00 -0500"
355,New model identifies drugs that shouldn’t be taken together,https://news.mit.edu/2024/new-model-identifies-drugs-shouldnt-be-taken-together-0220,"Using a machine-learning algorithm, researchers can predict interactions that could interfere with a drug’s effectiveness.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 20 Feb 2024 05:00:00 -0500"
356,"This tiny, tamper-proof ID tag can authenticate almost anything",https://news.mit.edu/2024/tiny-tamper-proof-id-tag-can-authenticate-almost-anything-0218,MIT engineers developed a tag that can reveal with near-perfect accuracy whether an item is real or fake. The key is in the glue on the back of the tag.,[{'name': 'Adam Zewe | MIT News'}],"Sun, 18 Feb 2024 00:00:00 -0500"
357,Using AI to discover stiff and tough microstructures,https://news.mit.edu/2024/using-ai-discover-stiff-tough-microstructures-0214,Innovative AI system from MIT CSAIL melds simulations and physical testing to forge materials with newfound durability and flexibility for diverse engineering uses.,[{'name': 'Rachel Gordon | MIT CSAIL'}],"Wed, 14 Feb 2024 11:40:00 -0500"
358,A new way to let AI chatbots converse all day without crashing,https://news.mit.edu/2024/new-way-let-ai-chatbots-converse-all-day-without-crashing-0213,Researchers developed a simple yet effective solution for a puzzling problem that can worsen the performance of large language models such as ChatGPT.,[{'name': 'Adam Zewe | MIT News'}],"Tue, 13 Feb 2024 00:00:00 -0500"
359,Safer skies with self-flying helicopters,https://news.mit.edu/2024/safer-skies-self-flying-helicopters-rotor-technologies-0209,"Autonomous helicopters made by Rotor Technologies, a startup led by MIT alumni, take the human out of risky commercial missions.",[{'name': 'Zach Winn | MIT News'}],"Fri, 09 Feb 2024 00:00:00 -0500"
360,Six MIT students selected as spring 2024 MIT-Pillar AI Collective Fellows,https://news.mit.edu/2024/mit-pillar-ai-collective-fellows-0206,"The graduate students will aim to commercialize innovations in AI, machine learning, and data science.",[{'name': 'School of Engineering'}],"Tue, 06 Feb 2024 16:50:00 -0500"
361,How symmetry can come to the aid of machine learning,https://news.mit.edu/2024/how-symmetry-can-aid-machine-learning-0205,"Exploiting the symmetry within datasets, MIT researchers show, can decrease the amount of data needed for training neural networks.",[{'name': 'Steve Nadis | MIT CSAIL'}],"Mon, 05 Feb 2024 10:10:00 -0500"
362,Doctors have more difficulty diagnosing disease when looking at images of darker skin,https://news.mit.edu/2024/doctors-more-difficulty-diagnosing-diseases-images-darker-skin-0205,"Dermatologists and general practitioners are somewhat less accurate in diagnosing disease in darker skin, a new study finds. Used correctly, AI may be able to help.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 05 Feb 2024 05:00:00 -0500"
363,Generating the policy of tomorrow,https://news.mit.edu/2024/generating-policy-of-tomorrow-0124,"Hundreds of participants from around the world joined the sixth annual MIT Policy Hackathon to develop data-informed policy solutions to challenges in health, housing, and more.","[{'name': 'Kaitlin Provencher | Institute for Data, Systems, and Society'}]","Wed, 24 Jan 2024 15:25:00 -0500"
364,Q&A: A blueprint for sustainable innovation,https://news.mit.edu/2024/qa-atacama-biomaterials-blueprint-sustainable-innovation-0124,"Atacama Biomaterials, co-founded by Paloma Gonzalez-Rojas SM ’15, PhD ’21, combines architecture, machine learning, and chemical engineering to create eco-friendly materials.",[{'name': 'Adelaide Zollinger | MIT Morningside Academy for Design'}],"Wed, 24 Jan 2024 14:00:00 -0500"
365,What to do about AI in health?,https://news.mit.edu/2024/what-to-do-about-ai-in-health-0123,"Although artificial intelligence in health has shown great promise, pressure is mounting for regulators around the world to act, as AI tools demonstrate potentially harmful outcomes.",[{'name': 'Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health'}],"Tue, 23 Jan 2024 16:25:00 -0500"
366,New hope for early pancreatic cancer intervention via AI-based risk prediction,https://news.mit.edu/2024/new-hope-early-pancreatic-cancer-intervention-ai-based-risk-prediction-0118,MIT CSAIL researchers develop advanced machine-learning models that outperform current methods in detecting pancreatic ductal adenocarcinoma.,[{'name': 'Rachel Gordon | MIT CSAIL'}],"Thu, 18 Jan 2024 14:00:00 -0500"
367,Reasoning and reliability in AI,https://news.mit.edu/2024/reasoning-and-reliability-in-ai-0118,PhD students interning with the MIT-IBM Watson AI Lab look to improve natural language usage.,[{'name': 'Lauren Hinkel | MIT-IBM Watson AI Lab'}],"Thu, 18 Jan 2024 13:00:00 -0500"
368,Stratospheric safety standards: How aviation could steer regulation of AI in health,https://news.mit.edu/2024/stratospheric-safety-standards-how-aviation-could-steer-ai-health-regulation-0117,An interdisciplinary team of researchers thinks health AI could benefit from some of the aviation industry’s long history of hard-won lessons that have created one of the safest activities today.,[{'name': 'Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health'}],"Wed, 17 Jan 2024 12:50:00 -0500"
369,Multiple AI models help robots execute complex plans more transparently,https://news.mit.edu/2024/multiple-ai-models-help-robots-execute-complex-plans-more-transparently-0108,"A multimodal system uses models trained on language, vision, and action data to help robots develop and execute plans for household, construction, and manufacturing tasks.",[{'name': 'Alex Shipps | MIT CSAIL'}],"Mon, 08 Jan 2024 15:15:00 -0500"
370,Technique could efficiently solve partial differential equations for numerous applications,https://news.mit.edu/2024/peds-technique-could-efficiently-solve-partial-differential-equations-0108,"MIT researchers propose “PEDS” method for developing models of complex physical systems in mechanics, optics, thermal transport, fluid dynamics, physical chemistry, climate, and more.",[{'name': 'Sandi Miller | Department of Mathematics'}],"Mon, 08 Jan 2024 13:30:00 -0500"
371,AI agents help explain other AI systems,https://news.mit.edu/2024/ai-agents-help-explain-other-ai-systems-0103,MIT researchers introduce a method that uses artificial intelligence to automate the explanation of complex neural networks.,[{'name': 'Rachel Gordon | MIT CSAIL'}],"Wed, 03 Jan 2024 15:10:00 -0500"
372,"Complex, unfamiliar sentences make the brain’s language network work harder",https://news.mit.edu/2024/complex-unfamiliar-sentences-brains-language-network-0103,"A new study finds that language regions in the left hemisphere light up when reading uncommon sentences, while straightforward sentences elicit little response.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 03 Jan 2024 05:00:00 -0500"
373,The creative future of generative AI,https://news.mit.edu/2024/creative-future-generative-ai-0102,An MIT panel charts how artificial intelligence will impact art and design.,[{'name': 'Ken Shulman | Arts at MIT'}],"Tue, 02 Jan 2024 15:15:00 -0500"
374,Leveraging language to understand machines,https://news.mit.edu/2023/leveraging-language-understand-machines-1222,Master’s students Irene Terpstra ’23 and Rujul Gandhi ’22 use language to design new integrated circuits and make it understandable to robots.,[{'name': 'Lauren Hinkel | MIT-IBM Watson AI Lab'}],"Fri, 22 Dec 2023 12:45:00 -0500"
375,MIT in the media: 2023 in review,https://news.mit.edu/2023/mit-media-year-in-review-1221,MIT community members made headlines with key research advances and their efforts to tackle pressing challenges.,[{'name': 'MIT News'}],"Thu, 21 Dec 2023 00:00:00 -0500"
376,"Using AI, MIT researchers identify a new class of antibiotic candidates",https://news.mit.edu/2023/using-ai-mit-researchers-identify-antibiotic-candidates-1220,"These compounds can kill methicillin-resistant Staphylococcus aureus (MRSA), a bacterium that causes deadly infections.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 20 Dec 2023 11:00:00 -0500"
377,A flexible solution to help artists improve animation,https://news.mit.edu/2023/flexible-solution-help-artists-improve-animation-1220,This new method draws on 200-year-old geometric foundations to give artists control over the appearance of animated characters.,[{'name': 'Adam Zewe | MIT News'}],"Wed, 20 Dec 2023 00:00:00 -0500"
378,Image recognition accuracy: An unseen challenge confounding today’s AI,https://news.mit.edu/2023/image-recognition-accuracy-minimum-viewing-time-metric-1215,“Minimum viewing time” benchmark gauges image recognition complexity for AI systems by measuring the time needed for accurate human identification.,[{'name': 'Rachel Gordon | MIT CSAIL'}],"Fri, 15 Dec 2023 12:35:00 -0500"
379,Computational model captures the elusive transition states of chemical reactions,https://news.mit.edu/2023/computational-model-captures-elusive-transition-states-1215,"Using generative AI, MIT chemical engineers and chemists created a model that can predict the structures formed when a chemical reaction reaches its point of no return.",[{'name': 'Anne Trafton | MIT News'}],"Fri, 15 Dec 2023 05:00:00 -0500"
380,AI meets climate: MIT Energy and Climate Hack 2023,https://news.mit.edu/2023/ai-meets-climate-mit-energy-climate-hack-1214,The Energy and Climate Hack presented opportunities for students and companies to collaborate and develop innovative solutions.,[{'name': 'Johnathon Horn | Division of Student Life'}],"Thu, 14 Dec 2023 16:55:00 -0500"
381,Three MIT students selected as inaugural MIT-Pillar AI Collective Fellows,https://news.mit.edu/2023/inaugural-mit-pillar-ai-collective-fellows-1213,"The graduate students will aim to commercialize innovations in AI, machine learning, and data science.",[{'name': 'School of Engineering'}],"Wed, 13 Dec 2023 17:00:00 -0500"
382,Deep neural networks show promise as models of human hearing,https://news.mit.edu/2023/deep-neural-nets-show-promise-models-of-human-hearing-1213,Study shows computational models trained to perform auditory tasks display an internal organization similar to that of the human auditory cortex.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 13 Dec 2023 14:00:00 -0500"
383,Closing the design-to-manufacturing gap for optical devices,https://news.mit.edu/2023/closing-design-manufacturing-gap-optical-devices-1213,"A new method enables optical devices that more closely match their design specifications, boosting accuracy and efficiency.",[{'name': 'Adam Zewe | MIT News'}],"Wed, 13 Dec 2023 00:00:00 -0500"
384,A computer scientist pushes the boundaries of geometry,https://news.mit.edu/2023/justin-solomon-pushing-geometric-boundaries-1212,"Justin Solomon applies modern geometric techniques to solve problems in computer vision, machine learning, statistics, and beyond.",[{'name': 'Adam Zewe | MIT News'}],"Tue, 12 Dec 2023 14:05:00 -0500"
385,MIT Generative AI Week fosters dialogue across disciplines,https://news.mit.edu/2023/mit-generative-ai-week-fosters-dialogue-across-disciplines-1211,"During the last week of November, MIT hosted symposia and events aimed at examining the implications and possibilities of generative AI.",[{'name': 'Mary Beth Gallagher | School of Engineering'}],"Mon, 11 Dec 2023 16:25:00 -0500"
386,MIT group releases white papers on governance of AI,https://news.mit.edu/2023/mit-group-releases-white-papers-governance-ai-1211,The series aims to help policymakers create better oversight of AI in society.,[{'name': 'Peter Dizikes | MIT News'}],"Mon, 11 Dec 2023 00:00:00 -0500"
387,Automated system teaches users when to collaborate with an AI assistant,https://news.mit.edu/2023/automated-system-teaches-collaborate-ai-assistant-1208,MIT researchers develop a customized onboarding process that helps a human learn when a model’s advice is trustworthy.,[{'name': 'Adam Zewe | MIT News'}],"Fri, 08 Dec 2023 00:00:00 -0500"
388,MIT engineers develop a way to determine how the surfaces of materials behave,https://news.mit.edu/2023/mit-engineers-how-surfaces-materials-behave-1207,"Using machine learning, the computational method can provide details of how materials work as catalysts, semiconductors, or battery components.",[{'name': 'David L. Chandler | MIT News'}],"Thu, 07 Dec 2023 05:00:00 -0500"
389,Eric Evans to step down as director of MIT Lincoln Laboratory,https://news.mit.edu/2023/eric-evans-steps-down-director-lincoln-laboratory-1206,"During 18 years of leadership, Evans established new R&amp;D mission areas, strengthened ties to the MIT community, and increased inclusion and education efforts.",[{'name': 'Zach Winn | MIT News'}],"Wed, 06 Dec 2023 12:30:00 -0500"
390,AI accelerates problem-solving in complex scenarios,https://news.mit.edu/2023/ai-accelerates-problem-solving-complex-scenarios-1205,"A new, data-driven approach could lead to better solutions for tricky optimization problems like global package routing or power grid operation.",[{'name': 'Adam Zewe | MIT News'}],"Tue, 05 Dec 2023 00:00:00 -0500"
391,What does the future hold for generative AI?,https://news.mit.edu/2023/what-does-future-hold-generative-ai-1129,"Rodney Brooks, co-founder of iRobot, kicks off an MIT symposium on the promise and potential pitfalls of increasingly powerful AI tools like ChatGPT.",[{'name': 'Adam Zewe | MIT News'}],"Wed, 29 Nov 2023 16:00:00 -0500"
392,New method uses crowdsourced feedback to help train robots,https://news.mit.edu/2023/method-uses-crowdsourced-feedback-help-train-robots-1127,"Human Guided Exploration (HuGE) enables AI agents to learn quickly with some help from humans, even if the humans make mistakes.",[{'name': 'Adam Zewe | MIT News'}],"Mon, 27 Nov 2023 00:00:00 -0500"
393,Search algorithm reveals nearly 200 new kinds of CRISPR systems,https://news.mit.edu/2023/search-algorithm-reveals-nearly-200-new-kinds-crispr-systems-1123,"By analyzing bacterial data, researchers have discovered thousands of rare new CRISPR systems that have a range of functions and could enable gene editing, diagnostics, and more.",[{'name': 'Allessandra DiCorato | Broad Institute'}],"Thu, 23 Nov 2023 14:00:00 -0500"
394,Technique enables AI on edge devices to keep learning over time,https://news.mit.edu/2023/technique-enables-ai-edge-devices-keep-learning-over-time,"With the PockEngine training method, machine-learning models can efficiently and continuously learn from user data on edge devices like smartphones.",[{'name': 'Adam Zewe | MIT News'}],"Thu, 16 Nov 2023 00:00:00 -0500"
395,School of Science announces 2024 Infinite Expansion Awards,https://news.mit.edu/2024/school-science-infinite-expansion-awards-0304,Nine postdocs and research scientists honored for contributions to the Institute.,[{'name': 'School of Science'}],"Mon, 04 Mar 2024 17:20:00 -0500"
396,Exposure to different kinds of music influences how the brain interprets rhythm,https://news.mit.edu/2024/exposure-different-kinds-music-influences-how-brain-interprets-rhythm-0304,"A study of people in 15 countries reveals that while everyone favors rhythms with simple integer ratios, biases can vary quite a bit across societies.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 04 Mar 2024 05:00:00 -0500"
397,How cognition changes before dementia hits,https://news.mit.edu/2024/how-cognition-changes-before-dementia-0229,Study finds language-processing difficulties are an indicator — in addition to memory loss — of amnestic mild cognitive impairment.,[{'name': 'Peter Dizikes | MIT News'}],"Thu, 29 Feb 2024 00:00:00 -0500"
398,Imaging method reveals new cells and structures in human brain tissue,https://news.mit.edu/2024/imaging-method-reveals-new-cells-structures-human-brain-tissue-0131,A new microscopy technique that enables high-resolution imaging could one day help doctors diagnose and treat brain tumors.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 31 Jan 2024 14:00:00 -0500"
399,"Simons Center’s collaborative approach propels autism research, at MIT and beyond",https://news.mit.edu/2024/simons-center-collaborative-approach-propels-autism-research-0130,"Team-based targeted projects, multi-mentor fellowships ensure that scientists studying social cognition, behavior, and autism integrate multiple perspectives and approaches to pressing questions.",[{'name': 'David Orenstein | Simons Center for the Social Brain'}],"Tue, 30 Jan 2024 16:35:00 -0500"
400,Creating new skills and new connections with MIT’s Quantitative Methods Workshop,https://news.mit.edu/2024/quantitative-methods-workshop-0130,More than 80 students and faculty from a dozen collaborating institutions became immersed at the intersection of computation and life sciences and forged new ties to MIT and each other.,[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Tue, 30 Jan 2024 15:45:00 -0500"
401,"Professor Emeritus Peter Schiller, a pioneer researcher of the visual system, dies at 92",https://news.mit.edu/2024/professor-emeritus-peter-schiller-dies-0123,His wide-ranging and influential career included fundamental discoveries about how visual scenes and stimuli are processed from the retina through the cortical visual system.,[{'name': 'Department of Brain and Cognitive Sciences'}],"Tue, 23 Jan 2024 15:45:00 -0500"
402,How the brain responds to reward is linked to socioeconomic background,https://news.mit.edu/2024/how-brain-responds-reward-socioeconomic-background-0122,An MIT study finds the brains of children who grow up in less affluent households are less responsive to rewarding experiences.,[{'name': 'Anne Trafton | MIT News'}],"Mon, 22 Jan 2024 13:00:00 -0500"
403,Evidence that gamma rhythm stimulation can treat neurological disorders is emerging,https://news.mit.edu/2024/evidence-gamma-rhythm-stimulation-can-treat-neurological-disorders-emerging-0118,"Researchers survey a broadening landscape of studies showing what’s known, and what remains to be found, about the therapeutic potential of noninvasive sensory, electrical, or magnetic stimulation of gamma brain rhythms.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Thu, 18 Jan 2024 12:50:00 -0500"
404,Study reveals a universal pattern of brain wave frequencies,https://news.mit.edu/2024/study-reveals-universal-pattern-brain-wave-frequencies-0118,"Across mammalian species, brain waves are slower in deep cortical layers, while superficial layers generate faster rhythms.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 18 Jan 2024 05:00:00 -0500"
405,Three honored with 2023 School of Science teaching prizes,https://news.mit.edu/2024/three-honored-school-science-teaching-prizes-0110,"Roger Levy, Pulin Li, and David McGee were nominated by peers and students for their exceptional instruction.",[{'name': 'School of Science'}],"Wed, 10 Jan 2024 15:55:00 -0500"
406,Juana De La O: Food for thought,https://news.mit.edu/2024/food-for-thought-juana-de-la-o-0110,This biology graduate student is building connections through her thesis work in mouse development and her passion for cooking and baking.,[{'name': 'Lillian Eden | Department of Biology'}],"Wed, 10 Jan 2024 15:00:00 -0500"
407,"Complex, unfamiliar sentences make the brain’s language network work harder",https://news.mit.edu/2024/complex-unfamiliar-sentences-brains-language-network-0103,"A new study finds that language regions in the left hemisphere light up when reading uncommon sentences, while straightforward sentences elicit little response.",[{'name': 'Anne Trafton | MIT News'}],"Wed, 03 Jan 2024 05:00:00 -0500"
408,Nanoparticle-delivered RNA reduces neuroinflammation in lab tests,https://news.mit.edu/2023/nanoparticle-delivered-rna-reduces-neuroinflammation-lab-tests-1215,"MIT researchers find that in mice and human cell cultures, lipid nanoparticles can deliver a potential therapy for inflammation in the brain, a prominent symptom in Alzheimer’s.",[{'name': 'David Orenstein | Picower Institute'}],"Fri, 15 Dec 2023 15:45:00 -0500"
409,Deep neural networks show promise as models of human hearing,https://news.mit.edu/2023/deep-neural-nets-show-promise-models-of-human-hearing-1213,Study shows computational models trained to perform auditory tasks display an internal organization similar to that of the human auditory cortex.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 13 Dec 2023 14:00:00 -0500"
410,How a mutation in microglia elevates Alzheimer’s risk,https://news.mit.edu/2023/how-mutation-microglia-elevates-alzheimers-risk-1204,"A new study finds that microglia with mutant TREM2 protein reduce brain circuit connections, promote inflammation, and contribute to Alzheimer’s pathology in other ways.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Mon, 04 Dec 2023 16:00:00 -0500"
411,Elly Nedivi receives 2023 Kreig Cortical Kudos Discoverer Award,https://news.mit.edu/2023/award-honors-elly-nedivis-research-cortical-plasticity-1129,The neuroscientist is recognized for her ongoing work to understand molecular and cellular mechanisms that enable the brain to adapt to experience.,[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Wed, 29 Nov 2023 11:00:00 -0500"
412,A new way to see the activity inside a living cell,https://news.mit.edu/2023/new-method-fluorescent-labels-living-cell-1128,"Using fluorescent labels that switch on and off, MIT engineers can study how molecules in a cell interact to control the cell’s behavior.",[{'name': 'Anne Trafton | MIT News'}],"Tue, 28 Nov 2023 11:00:00 -0500"
413,Search algorithm reveals nearly 200 new kinds of CRISPR systems,https://news.mit.edu/2023/search-algorithm-reveals-nearly-200-new-kinds-crispr-systems-1123,"By analyzing bacterial data, researchers have discovered thousands of rare new CRISPR systems that have a range of functions and could enable gene editing, diagnostics, and more.",[{'name': 'Allessandra DiCorato | Broad Institute'}],"Thu, 23 Nov 2023 14:00:00 -0500"
414,Three MIT affiliates receive Schmidt awards,https://news.mit.edu/2023/schmidt-awards-1120,"Jörn Dunkel and Surya Ganguli ’98, MNG ’98 receive Science Polymath awards; Josh Tenenbaum is named AI2050 Senior Fellow.",[{'name': 'Sandi Miller | Department of Mathematics'}],"Mon, 20 Nov 2023 13:40:00 -0500"
415,Mark Bear wins Society for Neuroscience Julius Axelrod Prize,https://news.mit.edu/2023/mark-bear-wins-julius-axelrod-prize-1117,"Award recognizes professor's synaptic plasticity research, its translation to potential amblyopia and autism treatments, and his career of mentorship.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Fri, 17 Nov 2023 13:20:00 -0500"
416,Rewarding excellence in open data,https://news.mit.edu/2023/rewarding-excellence-in-open-data-1116,MIT researchers who share their data recognized at second annual awards celebration.,[{'name': 'Brigham Fay | MIT Libraries'}],"Thu, 16 Nov 2023 16:30:00 -0500"
417,Aging Brain Initiative symposium showcases “cutting-edge” research across MIT,https://news.mit.edu/2023/aging-brain-initiative-symposium-1116,"Seed projects, posters represent a wide range of labs working on technologies, therapeutic strategies, and fundamental research to advance understanding of age-related neurodegenerative disease.",[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Thu, 16 Nov 2023 16:20:00 -0500"
418,A new wave of treatment for Alzheimer’s disease,https://news.mit.edu/2023/new-wave-treatment-alzheimers-disease-li-huei-tsai-1115,Professor Li-Huei Tsai studies how brain waves can be used to treat neurodegenerative diseases such as Alzheimer’s.,[{'name': 'Eric Bender | MIT Industrial Liaison Program'}],"Wed, 15 Nov 2023 12:55:00 -0500"
419,Anesthesia technology precisely controls unconsciousness in animal tests,https://news.mit.edu/2023/anesthesia-technology-precisely-controls-unconsciousness-animal-tests-1107,An advanced closed-loop anesthesia delivery system that monitors brain state to tailor propofol dose and achieve exactly the desired level of unconsciousness could reduce post-op side effects.,[{'name': 'David Orenstein | The Picower Institute for Learning and Memory'}],"Tue, 07 Nov 2023 09:50:00 -0500"
420,Using AI to optimize for rapid neural imaging,https://news.mit.edu/2023/using-ai-optimize-rapid-neural-imaging-1106,"MIT CSAIL researchers combine AI and electron microscopy to expedite detailed brain network mapping, aiming to enhance connectomics research and clinical pathology.",[{'name': 'Rachel Gordon | MIT CSAIL'}],"Mon, 06 Nov 2023 13:00:00 -0500"
421,How “blue” and “green” appeared in a language that didn’t have words for them,https://news.mit.edu/2023/how-blue-and-green-appeared-language-1102,"People of a remote Amazonian society who learned Spanish as a second language began to interpret colors in a new way, an MIT study has found.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 02 Nov 2023 00:00:00 -0400"
422,The brain may learn about the world the same way some computational models do,https://news.mit.edu/2023/brain-self-supervised-computational-models-1030,"Two studies find “self-supervised” models, which learn about their environment from unlabeled data, can show activity patterns similar to those of the mammalian brain.",[{'name': 'Anne Trafton | MIT News'}],"Mon, 30 Oct 2023 00:00:00 -0400"
423,How adults understand what kids are saying,https://news.mit.edu/2023/how-adults-understand-what-kids-are-saying-1026,"It’s not easy to parse young children’s words, but adults’ beliefs about what children want to communicate helps make it possible, a new study finds.",[{'name': 'Anne Trafton | MIT News'}],"Thu, 26 Oct 2023 11:00:00 -0400"
424,New technique helps robots pack objects into a tight space,https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017,Researchers coaxed a family of generative AI models to work together to solve multistep robot manipulation problems.,[{'name': 'Adam Zewe | MIT News'}],"Tue, 17 Oct 2023 00:00:00 -0400"
425,Ariel Furst and Fan Wang receive 2023 National Institutes of Health awards,https://news.mit.edu/2023/mit-researchers-receive-nih-awards-1016,"The awards support creative, innovative research with a broad impact.",[{'name': 'Sophie Hartley | School of Science'}],"Mon, 16 Oct 2023 16:45:00 -0400"
426,Study: Deep neural networks don’t see the world the way we do,https://news.mit.edu/2023/study-deep-neural-networks-perception-1016,Images that humans perceive as completely unrelated can be classified as the same by computational models.,[{'name': 'Anne Trafton | MIT News'}],"Mon, 16 Oct 2023 11:00:00 -0400"
427,Practicing mindfulness with an app may improve children’s mental health,https://news.mit.edu/2023/practicing-mindfulness-may-improve-childrens-mental-health-1011,New research suggests daily mindfulness training at home helped reduce kids’ stress levels and negative emotions.,[{'name': 'Anne Trafton | MIT News'}],"Wed, 11 Oct 2023 00:00:00 -0400"
428,Twelve with MIT ties elected to the National Academy of Medicine for 2023,https://news.mit.edu/2023/researchers-elected-national-academy-medicine-1010,"Five MIT faculty, along with seven additional affiliates, are honored for outstanding contributions to medical research.",[{'name': 'School of Science'}],"Tue, 10 Oct 2023 16:40:00 -0400"
429,What Is Industrial Generative AI?,https://zapata.ai/what-is-industrial-generative-ai/,<p>The post <a href=\"https://zapata.ai/what-is-industrial-generative-ai/\" rel=\"nofollow\">What Is Industrial Generative AI?</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Fri, 15 Dec 2023 21:34:53 +0000"
430,"Introducing BenchQ, the Result of Our Work With DARPA",https://zapata.ai/darpa-quantum-benchmarking-phase-i-results/,"<p>The post <a href=\"https://zapata.ai/darpa-quantum-benchmarking-phase-i-results/\" rel=\"nofollow\">Introducing BenchQ, the Result of Our Work With DARPA</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>",[{'name': 'Rob Kerstens'}],"Mon, 11 Dec 2023 21:21:53 +0000"
431,How Quantum Science Enhances Generative AI,https://zapata.ai/how-quantum-science-enhances-generative-ai/,<p>The post <a href=\"https://zapata.ai/how-quantum-science-enhances-generative-ai/\" rel=\"nofollow\">How Quantum Science Enhances Generative AI</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Mon, 27 Nov 2023 17:22:31 +0000"
432,Podcast Recap: Zapata AI CEO Answers Potential Investor Questions on Industrial Generative AI,https://zapata.ai/podcast-recap-industrial-generative-ai/,<p>The post <a href=\"https://zapata.ai/podcast-recap-industrial-generative-ai/\" rel=\"nofollow\">Podcast Recap: Zapata AI CEO Answers Potential Investor Questions on Industrial Generative AI</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Fri, 27 Oct 2023 14:40:28 +0000"
433,ICYMI: Zapata’s Generative AI Keynote at Quantum.Tech Boston,https://zapata.ai/zapata-generative-ai-keynote/,<p>The post <a href=\"https://zapata.ai/zapata-generative-ai-keynote/\" rel=\"nofollow\">ICYMI: Zapata’s Generative AI Keynote at Quantum.Tech Boston</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Wed, 26 Jul 2023 13:33:25 +0000"
434,How Generative AI Is Impacting Analytics,https://zapata.ai/how-generative-ai-is-impacting-analytics/,<p>The post <a href=\"https://zapata.ai/how-generative-ai-is-impacting-analytics/\" rel=\"nofollow\">How Generative AI Is Impacting Analytics</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Thu, 29 Jun 2023 11:00:25 +0000"
435,How We Harness Industrial Generative AI for Optimization,https://zapata.ai/industrial-generative-ai-for-optimization/,<p>The post <a href=\"https://zapata.ai/industrial-generative-ai-for-optimization/\" rel=\"nofollow\">How We Harness Industrial Generative AI for Optimization</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Fri, 16 Jun 2023 14:42:10 +0000"
436,New Research Shows How Quantum Generative Models Can Outperform Classical Models,https://zapata.ai/new-research-shows-how-quantum-generative-models-can-outperform-classical-models/,<p>The post <a href=\"https://zapata.ai/new-research-shows-how-quantum-generative-models-can-outperform-classical-models/\" rel=\"nofollow\">New Research Shows How Quantum Generative Models Can Outperform Classical Models</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Tue, 25 Apr 2023 11:08:29 +0000"
437,Quantum Computing for Sustainability: A Practical Guide,https://zapata.ai/quantum-computing-for-sustainability-a-practical-guide/,<p>The post <a href=\"https://zapata.ai/quantum-computing-for-sustainability-a-practical-guide/\" rel=\"nofollow\">Quantum Computing for Sustainability: A Practical Guide</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Wed, 01 Mar 2023 12:47:03 +0000"
438,Can Quantum Computing Be Part of the Solution to Climate Change?,https://zapata.ai/sustainable-quantum-computing-applications-climate-change/,<p>The post <a href=\"https://zapata.ai/sustainable-quantum-computing-applications-climate-change/\" rel=\"nofollow\">Can Quantum Computing Be Part of the Solution to Climate Change?</a> appeared first on <a href=\"https://zapata.ai\" rel=\"nofollow\">Zapata AI</a>.</p>,[{'name': 'Rob Kerstens'}],"Mon, 27 Feb 2023 21:54:11 +0000"
439,Exascale’s New Software Frontier: ExaSGD,https://insidehpc.com/2024/03/exascales-new-software-frontier-exasgd/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"571\" src=\"https://insidehpc.com/wp-content/uploads/2024/02/OLCF-BANNER-AD.png\" style=\"float: right; margin-left: 5px;\" width=\"1500\" /><p>“Exascale’s New Frontier,” a project from the Oak Ridge Leadership Computing Facility, explores the new applications and software technology for driving scientific discoveries in the exascale era. The Scientific Challenge As more renewable sources of energy are added to the national power grid, it becomes more complex to manage. That’s because renewables such as wind [&#8230;]</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/exascales-new-software-frontier-exasgd/\">Exascale&#8217;s New Software Frontier: ExaSGD</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'Galen Fader'}],"Tue, 05 Mar 2024 21:06:49 +0000"
440,Exascale: E4S Software Deployments Boost Iindustry Acceptance of Accelerators,https://insidehpc.com/2024/03/exascale-e4s-software-deployments-boost-iindustry-acceptance-of-accelerators/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"92\" src=\"https://insidehpc.com/wp-content/uploads/2023/05/Exascale-Computing-Project-ECP-logo-0523-150x92.png\" style=\"float: right; margin-left: 5px;\" width=\"150\" /><p>Last November at SC23, industry leaders reflected on successful deployments of the Exascale Computing Project’s Extreme-Scale Scientific Software Stack (E4S). They highlighted how E4S at Pratt &#038; Whitney, ExxonMobil, TAE Technologies, and GE Aerospace....</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/exascale-e4s-software-deployments-boost-iindustry-acceptance-of-accelerators/\">Exascale: E4S Software Deployments Boost Iindustry Acceptance of Accelerators</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Tue, 05 Mar 2024 16:57:35 +0000"
441,LiquidStack Opens Manufacturing Facility and Global HQ in Texas,https://insidehpc.com/2024/03/93601/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"304\" src=\"https://insidehpc.com/wp-content/uploads/2024/03/LiquidStack-logo-0324.png\" style=\"float: right; margin-left: 5px;\" width=\"608\" /><p>CARROLLTON, TX–March 5, 2024– Data center liquid cooling company LiquidStack today announced its new U.S. manufacturing site and headquarters in Carrollton, Texas. The new facility supports LiquidStack’s mission to deliver liquid cooling solutions for high performance data center and edge computing applications. With an uptick in liquid cooling demand associated with Generative AI scaling, the [&#8230;]</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/93601/\">LiquidStack Opens Manufacturing Facility and Global HQ in Texas</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'Doug Black'}],"Tue, 05 Mar 2024 14:00:21 +0000"
442,AMD Hires Former Oak Ridge Director Thomas Zacharia,https://insidehpc.com/2024/03/amd-hires-former-oak-ridge-director-thomas-zacharia/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"351\" src=\"https://insidehpc.com/wp-content/uploads/2024/03/Thomas-Zacharia-2-1-0324.jpg\" style=\"float: right; margin-left: 5px;\" width=\"700\" /><p>AMD today announced that Thomas Zacharia, former director of Oak Ridge National Laborary, has joined AMD as senior vice president of strategic technology partnerships and public policy. Zacharia spent 35 years at Oak Ridge, leaving there after the organization developed and installed the AMD-powered Frontier supercomputer, the first supercomputer to break the exascale performance barrier.</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/amd-hires-former-oak-ridge-director-thomas-zacharia/\">AMD Hires Former Oak Ridge Director Thomas Zacharia</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Mon, 04 Mar 2024 23:19:13 +0000"
443,Women in HPC Launches Call for Submissions for 2nd Annual ISC Solution Forum Takeover,https://insidehpc.com/2024/03/women-in-hpc-launch-call-for-submissions-for-2nd-annual-isc-solution-forum-takeover/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"282\" src=\"https://insidehpc.com/wp-content/uploads/2024/03/WHPC-Isc-2024-call-for-participants-0324.png\" style=\"float: right; margin-left: 5px;\" width=\"574\" /><p>Now in its second year, Women in HPC will partner with ISC 2024 to present a diverse and inclusive event on the exhibition floor coinciding with the May 13th Exhibitor Gala in Hamburg, Germany. March 4, 2024 &#8211; Edinburgh, Scotland. The WHPC Volunteers for ISC 2024 have announced that the call for submissions for our [&#8230;]</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/women-in-hpc-launch-call-for-submissions-for-2nd-annual-isc-solution-forum-takeover/\">Women in HPC Launches Call for Submissions for 2nd Annual ISC Solution Forum Takeover</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Mon, 04 Mar 2024 20:59:47 +0000"
444,Groq Acquires Definitive Intelligence to Launch GroqCloud,https://insidehpc.com/2024/03/groq-acquires-definitive-intelligence-to-launch-groqcloud/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"550\" src=\"https://insidehpc.com/wp-content/uploads/2023/08/Groq.png\" style=\"float: right; margin-left: 5px;\" width=\"1100\" /><p>MOUNTAIN VIEW, Calif., March 1, 2024 &#8212; AI technology company Groq has acquired Definitive Intelligence to launch GroqCloud, &#8220;a new developer playground with fully integrated documentation, code samples, and self-serve access.&#8221; Definitive Intelligence Co-founder and CEO Sunny Madra will lead the new GroqCloud business unit with the goal of expanding access to the Groq LPU Inference [&#8230;]</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/groq-acquires-definitive-intelligence-to-launch-groqcloud/\">Groq Acquires Definitive Intelligence to Launch GroqCloud</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Mon, 04 Mar 2024 20:48:39 +0000"
445,"HPC News Bytes 20240304: GPU Scarcity, Global Fab Capacity Boost, AI Hurdles and Singapore’s AI Training Strategy (Including Mid-Careerists)",https://insidehpc.com/2024/03/hpc-news-bytes-20240304-gpu-scarcity-impacts-global-fab-capacity-boost-ai-hurdles-and-singapores-ai-training-strategy-including-mid-careerists/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"84\" src=\"https://insidehpc.com/wp-content/uploads/2022/02/@HPCpodcast-logo-w-Shahin-Doug-images-0122-150x84.png\" style=\"float: right; margin-left: 5px;\" width=\"150\" /><p>A good March morning to you! Forthwith is a fast (5:51) run-though of recent HPC-AI news, including: The GPU shortage; HPE, Dell financial results,  GPU allocations, new Intel fabs....</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/hpc-news-bytes-20240304-gpu-scarcity-impacts-global-fab-capacity-boost-ai-hurdles-and-singapores-ai-training-strategy-including-mid-careerists/\">HPC News Bytes 20240304: GPU Scarcity, Global Fab Capacity Boost, AI Hurdles and Singapore’s AI Training Strategy (Including Mid-Careerists)</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Mon, 04 Mar 2024 16:20:06 +0000"
446,Exascale’s New Software Frontier: Combustion-PELE,https://insidehpc.com/2024/03/exascales-new-software-frontier-combustion-pele/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"571\" src=\"https://insidehpc.com/wp-content/uploads/2024/02/OLCF-BANNER-AD.png\" style=\"float: right; margin-left: 5px;\" width=\"1500\" /><p>“Exascale’s New Frontier,” a project from the Oak Ridge Leadership Computing Facility, explores the new applications and software technology for driving scientific discoveries in the exascale era. The scientific challenge Diesel and gas-turbine engines drive the world’s trains, planes, and ships, but the fossil fuels that power these engines produce much of the carbon emissions [&#8230;]</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/exascales-new-software-frontier-combustion-pele/\">Exascale&#8217;s New Software Frontier: Combustion-PELE</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'Galen Fader'}],"Mon, 04 Mar 2024 15:50:10 +0000"
447,"NERSC Call for Proposals: Generative AI for Science, April 1 Deadline",https://insidehpc.com/2024/03/nersc-call-for-proposals-generative-ai-for-science-april-1-deadline/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"266\" src=\"https://insidehpc.com/wp-content/uploads/2024/02/NERSC-logo-2-1-0224.png\" style=\"float: right; margin-left: 5px;\" width=\"532\" /><p>NERSC is inviting proposals for projects that will leverage NERSC’s Perlmutter supercomputer to push the state of the art in Generative AI (GenAI) and deep learning for science and produce novel science outcomes.  We are specifically seeking teams with expertise using deep learning for science, a deep understanding of the scientific domain, and demonstrated proofs-of-concept. NERSC staff [&#8230;]</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/nersc-call-for-proposals-generative-ai-for-science-april-1-deadline/\">NERSC Call for Proposals: Generative AI for Science, April 1 Deadline</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Fri, 01 Mar 2024 21:37:32 +0000"
448,"AI Robotics Startup Attracting $675M from Nvidia, OpenAI, Microsoft, Bezos",https://insidehpc.com/2024/03/ai-robotics-startup-attracting-675m-from-nvidia-openai-microsoft-bezos/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"299\" src=\"https://insidehpc.com/wp-content/uploads/2024/03/Figure-robotic-image-2-1-0324.png\" style=\"float: right; margin-left: 5px;\" width=\"600\" /><p>Start up robotics company Figure, founded in 2022 and based in Sunnyvale, CA, is in the process of attracting $675 million in venture funding from the likes of Amazon founder Jeff Bezos, Microsoft, Intel, Samsung, OpenAI and Nvidia, along with a slew....</p>
<p>The post <a href=\"https://insidehpc.com/2024/03/ai-robotics-startup-attracting-675m-from-nvidia-openai-microsoft-bezos/\">AI Robotics Startup Attracting $675M from Nvidia, OpenAI, Microsoft, Bezos</a> appeared first on <a href=\"https://insidehpc.com\">High-Performance Computing News Analysis | insideHPC</a>.</p>",[{'name': 'staff'}],"Fri, 01 Mar 2024 20:57:17 +0000"
449,Get Ready for Gemma: The Game-Changing 2B 7B 6Trillion Token Platform,https://www.franksworld.com/2024/03/04/get-ready-for-gemma-the-game-changing-2b-7b-6trillion-token-platform/?utm_source=rss&utm_medium=rss&utm_campaign=get-ready-for-gemma-the-game-changing-2b-7b-6trillion-token-platform,This video is from Sam Witteveen.,[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:48:01 +0000"
450,Nintendo just picked a fight with open-source project Yuzu,https://www.franksworld.com/2024/03/04/nintendo-just-picked-a-fight-with-open-source-project-yuzu/?utm_source=rss&utm_medium=rss&utm_campaign=nintendo-just-picked-a-fight-with-open-source-project-yuzu,This video is from Fireship. Nintendo recently sued an open-source Nintendo Switch emulator called Yuzu. Let&#8217;s take a look at the hacking techniques used to exploit the Switch and find out what this lawsuit means for game developers.,[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:45:36 +0000"
451,The NSA has Picked these Programming Languages,https://www.franksworld.com/2024/03/04/the-nsa-has-picked-these-programming-languages/?utm_source=rss&utm_medium=rss&utm_campaign=the-nsa-has-picked-these-programming-languages,"The NSA has recommended a few programming languages, including Rust, C#, Java, Go and others. https://media.defense.gov/2022/Nov/10/2003112742/-1/-1/0/CSI_SOFTWARE_MEMORY_SAFETY.PDF This video is from Stefan Mischook.",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:43:59 +0000"
452,Unveiling Microsoft’s Revolutionary 1-bit LLMs in AI Research,https://www.franksworld.com/2024/03/04/unveiling-microsofts-revolutionary-1-bit-llms-in-ai-research/?utm_source=rss&utm_medium=rss&utm_campaign=unveiling-microsofts-revolutionary-1-bit-llms-in-ai-research,"In this video from AI Papers Academy.dive into a recent research paper by Microsoft: &#8220;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&#8221;. This paper introduce an interesting and exciting architecture for large language models, called BitNet b1.58, which significantly reduces LLMs memory consumption, and speeds-up LLMs inference latency. All of [&#8230;]",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:43:03 +0000"
453,40 APIs Every Developer Should Use (in 12 minutes),https://www.franksworld.com/2024/03/04/40-apis-every-developer-should-use-in-12-minutes/?utm_source=rss&utm_medium=rss&utm_campaign=40-apis-every-developer-should-use-in-12-minutes,"In this video, Coding with Lewis introduces you to 40 APIs that every developer should know and use. From social media to finance to weather, these APIs will help you create amazing applications. Most of these APIs are free without an API key, but might require some sort of sign up or a trial to [&#8230;]",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:41:03 +0000"
454,Do we create reality with our mind? A physicist’s reply.,https://www.franksworld.com/2024/03/04/do-we-create-reality-with-our-mind-a-physicists-reply/?utm_source=rss&utm_medium=rss&utm_campaign=do-we-create-reality-with-our-mind-a-physicists-reply,"This video is from Sabine Hossenfelder. Do we create reality with our minds? I got this question on twitter the other day and after rolling my eyes about it for some while, I decided it’s actually a good question. You might think the answer is obviously “no”. But it’s not that simple. Let me explain.",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:40:07 +0000"
455,How to Master Machine Learning: A Beginner’s Guide for 2024,https://www.franksworld.com/2024/03/04/how-to-master-machine-learning-a-beginners-guide-for-2024/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-master-machine-learning-a-beginners-guide-for-2024,"This video is from freeCodeCamp.org. This machine learning course is created for beginners who are learning in 2024. The course begins with a Machine Learning Roadmap for 2024, emphasizing career paths and beginner-friendly theory. Then it the course moves on to hands-on practical applications and a comprehensive end-to-end project using Python. ✏️ Course created by [&#8230;]",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:37:51 +0000"
456,Maximize Your Editing Efficiency: 7 Must-Have AI Tools in Premiere Pro,https://www.franksworld.com/2024/03/04/maximize-your-editing-efficiency-7-must-have-ai-tools-in-premiere-pro/?utm_source=rss&utm_medium=rss&utm_campaign=maximize-your-editing-efficiency-7-must-have-ai-tools-in-premiere-pro,This video from Lila takes you through the innovations in Adobe Premiere that take full advantage of AI.,[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:36:53 +0000"
457,How to Learn the Gemini API and Create a Multi-Turn Chat Bot (1 Hour Crash Course),https://www.franksworld.com/2024/03/04/how-to-learn-the-gemini-api-and-create-a-multi-turn-chat-bot-1-hour-crash-course/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-learn-the-gemini-api-and-create-a-multi-turn-chat-bot-1-hour-crash-course,This video is from Code with Ania Kubów. Get the video api code here: https://bit.ly/stream-code,[{'name': 'Frank'}],"Mon, 04 Mar 2024 15:26:57 +0000"
458,Combining Rust and Python: The Best of Both Worlds?,https://www.franksworld.com/2024/03/03/combining-rust-and-python-the-best-of-both-worlds/?utm_source=rss&utm_medium=rss&utm_campaign=combining-rust-and-python-the-best-of-both-worlds,"In this video, ArjanCodes shows you how to seamlessly integrate Rust with Python using Pyo3. This library allows you to write Python modules with Rust. This means that we get the speed and safety of Rust along with Python&#8217;s easy-to-use features!",[{'name': 'Frank'}],"Sun, 03 Mar 2024 13:53:09 +0000"
459,Breaking Down the Fastest AI Chip in the World: What You Need to Know,https://www.franksworld.com/2024/03/01/breaking-down-the-fastest-ai-chip-in-the-world-what-you-need-to-know/?utm_source=rss&utm_medium=rss&utm_campaign=breaking-down-the-fastest-ai-chip-in-the-world-what-you-need-to-know,"This video from Anastasi In Tech  discusses how it works, benchmarks, how it compares to other AI accelerators and the future outlook!",[{'name': 'Frank'}],"Fri, 01 Mar 2024 17:57:07 +0000"
460,Elevate Your AI Capabilities with Red Hat OpenShift AI: A Demo,https://www.franksworld.com/2024/03/01/elevate-your-ai-capabilities-with-red-hat-openshift-ai-a-demo/?utm_source=rss&utm_medium=rss&utm_campaign=elevate-your-ai-capabilities-with-red-hat-openshift-ai-a-demo,"In this video, Chris Chase demonstrates a typical workflow that includes creating a project, launching a Jupyter notebook with appropriate cluster resources and training a foundation model from Hugging Face with one’s own data. Once the model is fine-tuned, Chris automates the build using a data science pipeline and serves the model for use in [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:53:02 +0000"
461,Unveiling the Matrix: A Deep Dive into its Philosophical Themes,https://www.franksworld.com/2024/03/01/unveiling-the-matrix-a-deep-dive-into-its-philosophical-themes/?utm_source=rss&utm_medium=rss&utm_campaign=unveiling-the-matrix-a-deep-dive-into-its-philosophical-themes,"In this video from Einzelgänger take a deeper look into the Matrix. The Matrix, a science fiction film created by the Wachowskis, is probably one of the most influential movies ever made. The story starts when computer programmer Thomas Anderson, operating as a hacker under the alias “Neo,” discovers the truth about the world he’s [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:48:06 +0000"
462,Navigating the AI Landscape: Lessons from the Butlerian Jihad,https://www.franksworld.com/2024/03/01/navigating-the-ai-landscape-lessons-from-the-butlerian-jihad/?utm_source=rss&utm_medium=rss&utm_campaign=navigating-the-ai-landscape-lessons-from-the-butlerian-jihad,"The following was originally published as part of my LinkedIn newsletter: Frank Digs Data, with a special shout out to all the Dune fans out there. In the realm of popular science fiction, few narratives resonate as powerfully with contemporary technological and ethical debates as the Butlerian Jihad from Frank Herbert&#8217;s &#8220;Dune,&#8221; where robotics and [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:43:15 +0000"
463,Separating Fact from Fiction: Exploring AI Concerns with Dan Hendrycks on Win-Win,https://www.franksworld.com/2024/03/01/separating-fact-from-fiction-exploring-ai-concerns-with-dan-hendrycks-on-win-win/?utm_source=rss&utm_medium=rss&utm_campaign=separating-fact-from-fiction-exploring-ai-concerns-with-dan-hendrycks-on-win-win,"The rate of AI progress is accelerating, so how can we minimize the risks of this incredible technology, while maximizing the rewards?",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:38:52 +0000"
464,Data Engineering in the Age of AI: Data Intelligence Platforms,https://www.franksworld.com/2024/03/01/data-engineering-in-the-age-of-ai-data-intelligence-platforms/?utm_source=rss&utm_medium=rss&utm_campaign=data-engineering-in-the-age-of-ai-data-intelligence-platforms,"Learn about the Data Intelligence Platform and how Data Engineers benefit in their work from AI infused into every layer of the Databricks Lakehouse. This live demo walks you through the classic data engineering tasks, code generation, fixing, and documentation with the Databricks Assistant, automatic documentation with Unity Catalog, and making use of LLMs such [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:36:56 +0000"
465,How to Give a Great Data Presentation,https://www.franksworld.com/2024/03/01/how-to-give-a-great-data-presentation/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-give-a-great-data-presentation,This video is from DATAcated. Very excited to host Christopher Chin &#8211; to talk about How to Give a Great Data Presentation!!!,[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:35:40 +0000"
466,Uncovering the Fundamentals of SQL Server and Azure SQL DB Security | Data Exposed,https://www.franksworld.com/2024/03/01/uncovering-the-fundamentals-of-sql-server-and-azure-sql-db-security-data-exposed/?utm_source=rss&utm_medium=rss&utm_campaign=uncovering-the-fundamentals-of-sql-server-and-azure-sql-db-security-data-exposed,"In this video is from Microsoft Developer, learn about SQL Server and Azure SQL Database security fundamentals you won&#8217;t want to miss.",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:32:47 +0000"
467,Uncovering the Truth: The Alarming Rise of Fraud in the Scientific Community,https://www.franksworld.com/2024/03/01/uncovering-the-truth-the-alarming-rise-of-fraud-in-the-scientific-community/?utm_source=rss&utm_medium=rss&utm_campaign=uncovering-the-truth-the-alarming-rise-of-fraud-in-the-scientific-community,"This video is from Sabine Hossenfelder. Science has a big problem and it’s been getting rapidly worse in the past two years or so, to no small part because of recent advances in artificial intelligence. Fraudulent papers are getting published more than ever, and the fraudsters are getting increasingly aggressive. In this episode I want [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:31:54 +0000"
468,Unleashing Creativity: DeepMind’s New AI Generates Games From Scratch,https://www.franksworld.com/2024/03/01/unleashing-creativity-deepminds-new-ai-generates-games-from-scratch/?utm_source=rss&utm_medium=rss&utm_campaign=unleashing-creativity-deepminds-new-ai-generates-games-from-scratch,This video from Two Minute Papers covers the paper &#8220;Genie: Generative Interactive Environments.&#8221; See? Not all hope for Google is lost.,[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:30:17 +0000"
469,Drizzle ORM in 100 Seconds,https://www.franksworld.com/2024/03/01/drizzle-orm-in-100-seconds/?utm_source=rss&utm_medium=rss&utm_campaign=drizzle-orm-in-100-seconds,"Fireship explains Drizzle in 100 seconds. Drizzle is a serverless TypeScript ORM designed for PostgreSQL, MySQL and SQLite.",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:28:35 +0000"
470,The Rise of AGI: How to Prepare for the Next Technological Revolution,https://www.franksworld.com/2024/02/29/the-rise-of-agi-how-to-prepare-for-the-next-technological-revolution/?utm_source=rss&utm_medium=rss&utm_campaign=the-rise-of-agi-how-to-prepare-for-the-next-technological-revolution,"This video is from David Ondrej. Soon AGI will be created, yet most people are grossly unprepared. In this AI course I will show you exactly what you need to do to thrive in the post-AGI world.",[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:32:58 +0000"
471,Is it too late to invest in Nvidia?,https://www.franksworld.com/2024/02/29/is-it-too-late-to-invest-in-nvidia/?utm_source=rss&utm_medium=rss&utm_campaign=is-it-too-late-to-invest-in-nvidia,"On this edition of Quartz Smart Investing, is it too late to invest in Nvidia? Eric Beiley, executive managing director of The Beiley Group at Steward Partners, tells Quartz whether he thinks there&#8217;s still room to run for the AI chip stock.",[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:30:15 +0000"
472,OpenAI Sora: A Closer Look!,https://www.franksworld.com/2024/02/29/openai-sora-a-closer-look/?utm_source=rss&utm_medium=rss&utm_campaign=openai-sora-a-closer-look,This video is from Two Minute Papers. 📝 Sora: https://openai.com/research/video-generation-models-as-world-simulators,[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:29:04 +0000"
473,KubeCon EU 2024 Preview: Exploring the Clouds with Aparna Subramanian,https://www.franksworld.com/2024/02/29/kubecon-eu-2024-preview-exploring-the-clouds-with-aparna-subramanian/?utm_source=rss&utm_medium=rss&utm_campaign=kubecon-eu-2024-preview-exploring-the-clouds-with-aparna-subramanian,"With KubeCon EU in Paris around the corner (19th to 22nd March), what better way to get some insight on what is expected than by speaking to people directly involved in the event. Aparna Subramanian is a technologist and cloud-native enthusiast. She started her career as a Software Engineer and has spent most part of [&#8230;]",[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:27:22 +0000"
474,Waist-to-height ratio detects fat obesity in children and adolescents significantly better than BMI,https://www.sciencedaily.com/releases/2024/03/240305134243.htm,An inexpensive measure of obesity in children and adolescents that could replace body mass index (BMI) has been identified in a new study as waist circumference-to-height ratio. This measure detected excess fat mass and distinguished fat mass from muscle mass in children and adolescents more accurately than BMI.,[],"Tue, 05 Mar 2024 13:42:43 EST"
475,Groundbreaking survey reveals secrets of planet birth around dozens of stars,https://www.sciencedaily.com/releases/2024/03/240305134240.htm,"A team of astronomers has shed new light on the fascinating and complex process of planet formation. The research brings together observations of more than 80 young stars that might have planets forming around them, providing astronomers with a wealth of data and unique insights into how planets arise in different regions of our galaxy.",[],"Tue, 05 Mar 2024 13:42:40 EST"
476,One way to improve a fusion reaction: Use weaknesses as strengths,https://www.sciencedaily.com/releases/2024/03/240305134238.htm,"Scientists are embracing imperfection, using less-than-ideal magnetic fields to make the plasma more manageable.",[],"Tue, 05 Mar 2024 13:42:38 EST"
477,Possible 'Trojan Horse' found for treating stubborn bacterial infections,https://www.sciencedaily.com/releases/2024/03/240305134236.htm,"Bacteria can be tricked into sending death signals to stop the growth of their slimy, protective homes that lead to deadly infections, a new study demonstrates. The discovery could someday be harnessed as an alternative to antibiotics for treating difficult infections. The researchers used the messengers, which they named death extracellular vesicles (D-EVs), to reduce growth of the bacterial communities by up to 99.99% in laboratory experiments.",[],"Tue, 05 Mar 2024 13:42:36 EST"
478,What makes black holes grow and new stars form? Machine learning helps solve the mystery,https://www.sciencedaily.com/releases/2024/03/240305134225.htm,It takes more than a galaxy merger to make a black hole grow and new stars form: machine learning shows cold gas is needed too to initiate rapid growth -- new research finds.,[],"Tue, 05 Mar 2024 13:42:25 EST"
479,"Juno spacecraft measures oxygen production on Jupiter's moon, Europa",https://www.sciencedaily.com/releases/2024/03/240305134217.htm,"NASA's Juno spacecraft has directly measured charged oxygen and hydrogen molecules from the atmosphere of one of Jupiter's largest moons, Europa. These observations provide key constraints on the potential oxygenation of its subsurface ocean.",[],"Tue, 05 Mar 2024 13:42:17 EST"
480,"After decades of Arctic sea ice getting faster and more hazardous for transport, models suggest a dramatic reversal is coming",https://www.sciencedaily.com/releases/2024/03/240305134215.htm,"Will ice floating in the Arctic Ocean move faster or slower over the coming decades? The answer to this question will tell us whether marine transportation can be expected to get more or less hazardous. It might also have important implications for the rate of ice cover loss, which is hugely consequential for Northern Indigenous communities, ecosystems, and the global climate system. While observational data suggest the trend has been towards faster sea ice speeds, climate models project that those speeds will slow down during the summer season. This contrast has led to some questions around the plausibility of the model projections.",[],"Tue, 05 Mar 2024 13:42:15 EST"
481,New cardiovascular imaging approach provides a better view of dangerous plaques,https://www.sciencedaily.com/releases/2024/03/240305134213.htm,"Researchers have developed a new catheter-based device that combines two powerful optical techniques to image the dangerous plaques that can build up inside the arteries that supply blood to the heart. By providing new details about plaque, the device could help clinicians and researchers improve treatments for preventing heart attacks and strokes.",[],"Tue, 05 Mar 2024 13:42:13 EST"
482,We know the Arctic is warming -- What will changing river flows do to its environment?,https://www.sciencedaily.com/releases/2024/03/240305134208.htm,"Scientists recently combined satellite data, field observations and sophisticated numerical modeling to paint a picture of how 22.45 million square kilometers of the Arctic will change over the next 80 years. As expected, the overall region will be warmer and wetter, but the details -- up to 25% more runoff, 30% more subsurface runoff and a progressively drier southern Arctic, provides one of the clearest views yet of how the landscape will respond to climate change.",[],"Tue, 05 Mar 2024 13:42:08 EST"
483,Fossil named 'Attenborough's strange bird' was the first in its kind without teeth,https://www.sciencedaily.com/releases/2024/03/240305134206.htm,"A new fossil, named 'Attenborough's strange bird' after naturalist and documentarian Sir David Attenborough, is the first of its kind to evolve a toothless beak. It's from a branch of the bird family tree that went extinct in the mass extinction 66 million years ago, and this strange bird is another puzzle piece that helps explain why some birds -- and their fellow dinosaurs -- went extinct, and others survived to today.",[],"Tue, 05 Mar 2024 13:42:06 EST"
484,Arctic could become 'ice-free' within a decade,https://www.sciencedaily.com/releases/2024/03/240305134203.htm,"While summer sea ice loss in the Arctic is inevitable, it can be reversed if the planet cools down, researchers say.",[],"Tue, 05 Mar 2024 13:42:03 EST"
485,8 in 10 lizards could be at risk due to deforestation,https://www.sciencedaily.com/releases/2024/03/240305133902.htm,"These reptiles move around tree trunks to seek warmth or shade. With trees disappearing, they would have trouble controlling their body temperature, a new study shows.",[],"Tue, 05 Mar 2024 13:39:02 EST"
486,"Plant Lavender, Marjoram and Ivy on your green wall to clean up the air",https://www.sciencedaily.com/releases/2024/03/240305133640.htm,"Green walls can strip pollution from the air -- and some plants do it better than others, according to new research. Researchers planted 10 species on a custom-built 1.4m green wall.",[],"Tue, 05 Mar 2024 13:36:40 EST"
487,"Coronary artery calcium score predictive of heart attacks, strokes",https://www.sciencedaily.com/releases/2024/03/240305133306.htm,Coronary artery calcium scoring with CT can identify symptomatic patients with a very low risk of heart attacks or strokes. Researchers said the findings may one day help some patients with stable chest pain avoid invasive coronary angiography.,[],"Tue, 05 Mar 2024 13:33:06 EST"
488,Researchers invent new triple-junction tandem solar cells with world-record efficiency,https://www.sciencedaily.com/releases/2024/03/240304221140.htm,"Scientists have developed a novel triple-junction perovskite/Si tandem solar cell that can achieve a certified world-record power conversion efficiency of 27.1 per cent across a solar energy absorption area of 1 sq cm, representing the best-performing triple-junction perovskite/Si tandem solar cell thus far. To achieve this, the team engineered a new cyanate-integrated perovskite solar cell that is stable and energy efficient.",[],"Mon, 04 Mar 2024 22:11:40 EST"
489,Protecting joints from bacteria with mussels,https://www.sciencedaily.com/releases/2024/03/240304195520.htm,A collaborative team of researchers developed an implant coating triggering antibiotic release in response to bacterial infection.,[],"Mon, 04 Mar 2024 19:55:20 EST"
490,Sleep apnea symptoms linked to memory and thinking problems,https://www.sciencedaily.com/releases/2024/03/240304195515.htm,"People who experience sleep apnea may be more likely to also have memory or thinking problems, according to a preliminary study. The study shows a positive association but did not determine whether sleep apnea causes cognitive decline.",[],"Mon, 04 Mar 2024 19:55:15 EST"
491,JWST captures the end of planet formation,https://www.sciencedaily.com/releases/2024/03/240304195509.htm,The James Webb Space Telescope is helping scientists uncover how planets form by advancing understanding of their birthplaces and the circumstellar disks surrounding young stars. Scientists have imaged winds from an old planet-forming disk (still very young relative to the Sun) which is actively dispersing its gas content. Knowing when the gas disperses is important as it constrains the time left for nascent planets to consume the gas from their surroundings.,[],"Mon, 04 Mar 2024 19:55:09 EST"
492,Scientists revolutionize wireless communication with three-dimensional processors,https://www.sciencedaily.com/releases/2024/03/240304195504.htm,Scientists have pioneered a method for using semiconductor technology to manufacture processors that significantly enhance the efficiency of transmitting vast amounts of data across the globe.,[],"Mon, 04 Mar 2024 19:55:04 EST"
493,Less ice in the Arctic Ocean has complex effects on marine ecosystems and ocean productivity,https://www.sciencedaily.com/releases/2024/03/240304195501.htm,"Most of the sunlight reaching the Arctic Ocean is reflected to space by sea ice, effectively shielding ocean ecosystems from sunlight. As the Arctic sea ice continues its downward trend, larger areas of the ocean become exposed to sunlight for longer periods, potentially allowing more primary production on the seafloor. However, according to a new study, this anticipated increase in primary production does not seem to be occurring uniformly across the Arctic Ocean.",[],"Mon, 04 Mar 2024 19:55:01 EST"
494,New research shows migrating animals learn by experience,https://www.sciencedaily.com/releases/2024/03/240304195455.htm,"Individual white storks incrementally straightened their migration routes to find more direct ways to move between destinations during the spring migration to summer breeding and nesting grounds, suggesting that experiential learning is an important part of successful migration.",[],"Mon, 04 Mar 2024 19:54:55 EST"
495,"Although trust in science remains high, public questions scientists' adherence to science's norms",https://www.sciencedaily.com/releases/2024/03/240304195451.htm,"In a new article, members of the Strategic Council of the National Academy of Sciences, Engineering, and Medicine examine what has happened to public confidence in science, why it has happened, and what can be done to elevate it. They say that while there is public agreement about the values that should underpin science, the public questions whether scientists actually live up to these values and whether they can overcome their individual biases.",[],"Mon, 04 Mar 2024 19:54:51 EST"
496,An inside look at Beech tree disease,https://www.sciencedaily.com/releases/2024/03/240304195446.htm,A new study found differences at the cellular level of leaves from infected Beech trees -- variations that may account for tree mortality.,[],"Mon, 04 Mar 2024 19:54:46 EST"
497,New AI model draws treasure maps to diagnose disease,https://www.sciencedaily.com/releases/2024/03/240304195443.htm,"Researchers have developed an artificial intelligence model that can accurately identify tumors and diseases in medical images. The tool draws a map to explain each diagnosis, helping doctors follow its line of reasoning, check for accuracy, and explain the results to patients.",[],"Mon, 04 Mar 2024 19:54:43 EST"
498,Breastfeeding after COVID-19 booster can give babies antibodies,https://www.sciencedaily.com/releases/2024/03/240304195439.htm,A recently published study that shows lactating mothers who get the COVID-19 booster pass along the antibodies to their children via their breast milk -- and potentially protect babies too young to receive the vaccine.,[],"Mon, 04 Mar 2024 19:54:39 EST"
499,Scientists put forth a smarter way to protect a smarter grid,https://www.sciencedaily.com/releases/2024/03/240304195348.htm,"Scientists have put forth a new approach to protect the electric grid, creating a tool that sorts and prioritizes cyber threats on the fly.",[],"Mon, 04 Mar 2024 19:53:48 EST"
500,Modeling the origins of life: New evidence for an 'RNA World',https://www.sciencedaily.com/releases/2024/03/240304195250.htm,"Scientists provide fresh insights on the origins of life, presenting compelling evidence supporting the 'RNA World' hypothesis. The study unveils an RNA enzyme that can make accurate copies of other functional RNA strands, while also allowing new variants of the molecule to emerge over time. These remarkable capabilities suggest the earliest forms of evolution may have occurred on a molecular scale in RNA, and also bring scientists one step closer to re-creating autonomous RNA-based life in the laboratory.",[],"Mon, 04 Mar 2024 19:52:50 EST"
501,An evolutionary mystery 125 million years in the making,https://www.sciencedaily.com/releases/2024/03/240304143643.htm,"Plant biologists have uncovered an evolutionary mystery over 100 million years in the making. It turns out that sometime during the last 125 million years, tomatoes and Arabidopsis thaliana plants experienced an extreme genetic makeover. Just what happened remains unclear. But the mystery surrounds CLV3, a gene key to healthy plant growth and development.",[],"Mon, 04 Mar 2024 14:36:43 EST"
502,3D-printed skin closes wounds and contains hair follicle precursors,https://www.sciencedaily.com/releases/2024/03/240304135920.htm,"Fat tissue holds the key to 3D printing layered living skin and potentially hair follicles, according to researchers who recently harnessed fat cells and supporting structures from clinically procured human tissue to precisely correct injuries in rats. The advancement could have implications for reconstructive facial surgery and even hair growth treatments for humans.",[],"Mon, 04 Mar 2024 13:59:20 EST"
503,Webb unlocks secrets of one of the most distant galaxies ever seen,https://www.sciencedaily.com/releases/2024/03/240304135917.htm,"Looking deeply into space and time, astronomers have studied the exceptionally luminous galaxy GN-z11, which existed when our 13.8 billion-year-old universe was only about 430 million years old.",[],"Mon, 04 Mar 2024 13:59:17 EST"
504,Advances in forensic science improve accuracy of 'time of death' estimates,https://www.sciencedaily.com/releases/2024/03/240304135902.htm,"Accurate 'time of death' estimates are a mainstay of murder mysteries and forensic programs, but such calculations in the real world are often complex and imprecise. In a first-of-its-kind study, researchers have discovered a group of common microbes that work together specifically to decompose flesh. These microorganisms serve as a biological clock and allow scientists to investigate the post-mortem breakdown of tissue with unprecedented precision.",[],"Mon, 04 Mar 2024 13:59:02 EST"
505,Spontaneous curvature the key to shape-shifting nanomaterials,https://www.sciencedaily.com/releases/2024/03/240304135857.htm,"Inspired by nature, nanotechnology researchers have identified 'spontaneous curvature' as the key factor determining how ultra-thin, artificial materials can transform into useful tubes, twists and helices.",[],"Mon, 04 Mar 2024 13:58:57 EST"
506,Studies on coffee consumption: New biomarker proposed,https://www.sciencedaily.com/releases/2024/03/240304135843.htm,"In order to record coffee consumption in nutrition and health studies, researchers usually rely on self-reporting by participants. However, this is not always reliable. It would therefore be desirable to conduct additional studies to objectively verify individual consumption using biomarkers. A research team has now validated the suitability of a specific roasted coffee compound and proposes it as a new, practical food biomarker.",[],"Mon, 04 Mar 2024 13:58:43 EST"
507,Humans have driven the Earth's freshwater cycle out of its stable state,https://www.sciencedaily.com/releases/2024/03/240304135840.htm,New analysis shows that the global freshwater cycle has shifted far beyond pre-industrial conditions.,[],"Mon, 04 Mar 2024 13:58:40 EST"
508,Exposure to different kinds of music influences how the brain interprets rhythm,https://www.sciencedaily.com/releases/2024/03/240304135838.htm,"The human brain appears biased toward hearing and producing rhythms with simple integer ratios, but the favored ratios can vary greatly between different societies, according to a 15-country study.",[],"Mon, 04 Mar 2024 13:58:38 EST"
509,A key to the future of robots could be hiding in liquid crystals,https://www.sciencedaily.com/releases/2024/03/240304135831.htm,"Robots and cameras of the future could be made of liquid crystals, thanks to a new discovery that significantly expands the potential of the chemicals already common in computer displays and digital watches. The findings are a simple and inexpensive way to manipulate the molecular properties of liquid crystals with light exposure.",[],"Mon, 04 Mar 2024 13:58:31 EST"
510,New dressing robot can 'mimic' the actions of care-workers,https://www.sciencedaily.com/releases/2024/03/240304135829.htm,Scientists have developed a new robot that can 'mimic' the two-handed movements of care-workers as they dress an individual.,[],"Mon, 04 Mar 2024 13:58:29 EST"
511,Photosynthetic secrets come to light,https://www.sciencedaily.com/releases/2024/03/240304135826.htm,"Secrets of photosynthesis have been discovered at atomic level, shedding important new light on this plant super-power that greened the earth more than a billion years ago.",[],"Mon, 04 Mar 2024 13:58:26 EST"
512,Network of quantum sensors boosts precision,https://www.sciencedaily.com/releases/2024/03/240304135823.htm,Quantum sensor technology promises even more precise measurements of physical quantities. A team has now compared the signals of up to 91 quantum sensors with each other and thus successfully eliminated the noise caused by interactions with the environment. Correlation spectroscopy can be used to increase the precision of sensor networks.,[],"Mon, 04 Mar 2024 13:58:23 EST"
513,Robotic hip exoskeleton shows promise for helping stroke patients regain their stride,https://www.sciencedaily.com/releases/2024/03/240304135821.htm,"More than 80% of stroke survivors experience walking difficulty, significantly impacting their daily lives, independence, and overall quality of life. Now, new research pushes forward the bounds of stroke recovery with a unique robotic hip exoskeleton, designed as a training tool to improve walking function. This invites the possibility of new therapies that are more accessible and easier to translate from practice to daily life compared to current rehabilitation methods.",[],"Mon, 04 Mar 2024 13:58:21 EST"
514,"Degree of cell crowding in the early human embryo influences cell identity decision, new culture system finds",https://www.sciencedaily.com/releases/2024/03/240304135818.htm,Collaborative work has developed a cell culture system that differentiates human pluripotent stem cells to amniotic ectoderm and surface ectoderm based on cell density.,[],"Mon, 04 Mar 2024 13:58:18 EST"
515,"It's not just you: Young people look, feel older when they're stressed",https://www.sciencedaily.com/releases/2024/03/240304135816.htm,A new study finds younger adults look and feel older on stressful days -- but only on days when they also feel they have relatively less control over their own lives.,[],"Mon, 04 Mar 2024 13:58:16 EST"
516,Your brain in the zone: A new neuroimaging study reveals how the brain achieves a creative flow state,https://www.sciencedaily.com/releases/2024/03/240304135813.htm,A new neuroimaging study reveals how the brain gets to the creative flow state.,[],"Mon, 04 Mar 2024 13:58:13 EST"
517,A model for the evolution of intelligence,https://www.sciencedaily.com/releases/2024/03/240304135811.htm,"When certain species of wild birds and primates discover new ways of finding food in the wild, it can serve to measure their flexibility and intelligence. In the largest experimental study ever conducted on this topic, researchers have shown that foraging problems requiring overcoming obstacles, such as removing the lid off a container of food, are the only predictors of brain size and innovative behavior in the wild.",[],"Mon, 04 Mar 2024 13:58:11 EST"
518,Cost of direct air carbon capture to remain higher than hoped,https://www.sciencedaily.com/releases/2024/03/240304135808.htm,"Researchers estimate the cost of removing 1 ton of CO2 from the air in the year 2050 to be between 230 and 540 US dollars to remove 1 ton. This is twice as high as previous estimates. The researchers compared the potential costs of three technologies that are already in use. From today's perspective, none of these technologies has clear advantages over the others in terms of potential costs. All three technologies should therefore be further developed, say the researchers.",[],"Mon, 04 Mar 2024 13:58:08 EST"
519,Researchers use liquid crystals to control polarization inside laser-written waveguides,https://www.sciencedaily.com/releases/2024/03/240304135803.htm,"Researchers have developed a new way to control and manipulate optical signals by embedding a liquid crystal layer into waveguides created with direct laser writing. The new devices enable electro-optical control of polarization, which could open new possibilities for chip-based devices and complex photonic circuits based on femtosecond-written waveguides.",[],"Mon, 04 Mar 2024 13:58:03 EST"
520,Unraveling the mystery of chiton visual systems,https://www.sciencedaily.com/releases/2024/03/240304135801.htm,"You'd probably walk past a chiton without even seeing it. These creatures often look like nothing more than another speck of seaweed on the crusty intertidal rocks. But it sees you. At least, if it's one of the species with eyes dotting its platemail shell.",[],"Mon, 04 Mar 2024 13:58:01 EST"
521,New method to test for oral cancer,https://www.sciencedaily.com/releases/2024/03/240304135753.htm,"A team of researchers has discovered a noninvasive, low-cost test to detect oral cancer, monitor precancerous lesions and determine when a biopsy is warranted.",[],"Mon, 04 Mar 2024 13:57:53 EST"
522,New AI smartphone tool accurately diagnoses ear infections,https://www.sciencedaily.com/releases/2024/03/240304135751.htm,"A new cell phone app developed by physician-scientists, which uses artificial intelligence (AI) to accurately diagnose ear infections, or acute otitis media (AOM), could help decrease unnecessary antibiotic use in young children, according to new research.",[],"Mon, 04 Mar 2024 13:57:51 EST"
523,Low-cost liquid tames tooth decay,https://www.sciencedaily.com/releases/2024/03/240304135748.htm,"An inexpensive, cavity-fighting liquid called silver diamine fluoride (SDF) works as well as dental sealants to keep tooth decay at bay in a school cavity prevention and treatment program, according to a new study. The study, which followed more than 4,000 elementary school students for four years, shows that SDF is an effective alternative to sealants, and can increase access to dental care while reducing costs.",[],"Mon, 04 Mar 2024 13:57:48 EST"
524,Study determines the original orientations of rocks drilled on Mars,https://www.sciencedaily.com/releases/2024/03/240304135739.htm,Geologists determined the original orientation of many of the Mars bedrock samples collected by the Perseverance rover. The findings can give scientists clues to the conditions in which the rocks originally formed.,[],"Mon, 04 Mar 2024 13:57:39 EST"
525,Tests show high-temperature superconducting magnets are ready for fusion,https://www.sciencedaily.com/releases/2024/03/240304135732.htm,"A comprehensive study of high-temperature superconducting magnets confirms they meet requirements for an economic, compact fusion power plant.",[],"Mon, 04 Mar 2024 13:57:32 EST"
526,"Zika vaccine safe, effective when administered during pregnancy",https://www.sciencedaily.com/releases/2024/03/240304135729.htm,"A vaccine against Zika virus is safe and effective when administered both before and during pregnancy, according to new research.",[],"Mon, 04 Mar 2024 13:57:29 EST"
527,"Firearm ownership is correlated with elevated lead levels in children, study finds",https://www.sciencedaily.com/releases/2024/03/240304135727.htm,"Childhood lead exposure, primarily from paint and water, is a significant health concern in the United States, but a new study has identified a surprising additional source of lead exposure that may disproportionately harm children: firearms. A team found an association between household firearm ownership and elevated lead levels in children's blood in 44 states, even when controlling for other major lead exposure sources.",[],"Mon, 04 Mar 2024 13:57:27 EST"
528,Geologists explore the hidden history of Colorado's Spanish Peaks,https://www.sciencedaily.com/releases/2024/03/240304135722.htm,"A team has collected dozens of samples from across southeastern Colorado, and their results could help to answer an enduring mystery: What made Colorado's High Plains so high?",[],"Mon, 04 Mar 2024 13:57:22 EST"
529,A better way to deliver fetal therapy for serious genetic disorders,https://www.sciencedaily.com/releases/2024/03/240304135015.htm,"In a discovery that opens the door to a less invasive way of treating some serious disorders before birth, UC San Francisco scientists have found that delivering medicine through amniotic fluid is as effective as delivering it to the fetal brain via cerebrospinal fluid. The experiment was done in mice with a genetic disorder called Angelman syndrome.",[],"Mon, 04 Mar 2024 13:50:15 EST"
530,Beyond the ink: Painting with physics,https://www.sciencedaily.com/releases/2024/03/240303125412.htm,"Falling from the tip of a brush suspended in mid-air, an ink droplet touches a painted surface and blossoms into a masterpiece of ever-changing beauty. It weaves a tapestry of intricate, evolving patterns. Some of them resemble branching snowflakes, thunderbolts or neurons, whispering the unique expression of the artist's vision.",[],"Sun, 03 Mar 2024 12:54:12 EST"
531,An overgrowth of nerve cells appears to cause lingering symptoms after recurrent UTIs,https://www.sciencedaily.com/releases/2024/03/240302171534.htm,"A perplexing problem for people with recurring urinary tract infections (UTIs) is persistent pain, even after antibiotics have successfully cleared the bacteria. Now researchers have identified the likely cause -- an overgrowth of nerve cells in the bladder.",[],"Sat, 02 Mar 2024 17:15:34 EST"
532,"In wake of powerful cyclone, remarkable recovery of Pacific island's forests",https://www.sciencedaily.com/releases/2024/03/240302171526.htm,"After one of the most intense cyclones in world history tore through the Pacific island of Tanna in Vanuatu, new research showed the resilience of the island's forests.",[],"Sat, 02 Mar 2024 17:15:26 EST"
533,2020 extreme weather event that brought fires and snow to western US,https://www.sciencedaily.com/releases/2024/03/240302171524.htm,"The same weather system that led to the spread of the devastating Labor Day wildfires in 2020 brought record-breaking cold and early-season snowfall to parts of the Rocky Mountains. Now, new research is shedding light on the meteorology behind what happened and the impacts of such an extreme weather event.",[],"Sat, 02 Mar 2024 17:15:24 EST"
534,Groundbreaking survey reveals secrets of planet birth around dozens of stars,https://www.sciencedaily.com/releases/2024/03/240305134240.htm,"A team of astronomers has shed new light on the fascinating and complex process of planet formation. The research brings together observations of more than 80 young stars that might have planets forming around them, providing astronomers with a wealth of data and unique insights into how planets arise in different regions of our galaxy.",[],"Tue, 05 Mar 2024 13:42:40 EST"
535,What makes black holes grow and new stars form? Machine learning helps solve the mystery,https://www.sciencedaily.com/releases/2024/03/240305134225.htm,It takes more than a galaxy merger to make a black hole grow and new stars form: machine learning shows cold gas is needed too to initiate rapid growth -- new research finds.,[],"Tue, 05 Mar 2024 13:42:25 EST"
536,"Juno spacecraft measures oxygen production on Jupiter's moon, Europa",https://www.sciencedaily.com/releases/2024/03/240305134217.htm,"NASA's Juno spacecraft has directly measured charged oxygen and hydrogen molecules from the atmosphere of one of Jupiter's largest moons, Europa. These observations provide key constraints on the potential oxygenation of its subsurface ocean.",[],"Tue, 05 Mar 2024 13:42:17 EST"
537,Fossil named 'Attenborough's strange bird' was the first in its kind without teeth,https://www.sciencedaily.com/releases/2024/03/240305134206.htm,"A new fossil, named 'Attenborough's strange bird' after naturalist and documentarian Sir David Attenborough, is the first of its kind to evolve a toothless beak. It's from a branch of the bird family tree that went extinct in the mass extinction 66 million years ago, and this strange bird is another puzzle piece that helps explain why some birds -- and their fellow dinosaurs -- went extinct, and others survived to today.",[],"Tue, 05 Mar 2024 13:42:06 EST"
538,Arctic could become 'ice-free' within a decade,https://www.sciencedaily.com/releases/2024/03/240305134203.htm,"While summer sea ice loss in the Arctic is inevitable, it can be reversed if the planet cools down, researchers say.",[],"Tue, 05 Mar 2024 13:42:03 EST"
539,Researchers invent new triple-junction tandem solar cells with world-record efficiency,https://www.sciencedaily.com/releases/2024/03/240304221140.htm,"Scientists have developed a novel triple-junction perovskite/Si tandem solar cell that can achieve a certified world-record power conversion efficiency of 27.1 per cent across a solar energy absorption area of 1 sq cm, representing the best-performing triple-junction perovskite/Si tandem solar cell thus far. To achieve this, the team engineered a new cyanate-integrated perovskite solar cell that is stable and energy efficient.",[],"Mon, 04 Mar 2024 22:11:40 EST"
540,Webb unlocks secrets of one of the most distant galaxies ever seen,https://www.sciencedaily.com/releases/2024/03/240304135917.htm,"Looking deeply into space and time, astronomers have studied the exceptionally luminous galaxy GN-z11, which existed when our 13.8 billion-year-old universe was only about 430 million years old.",[],"Mon, 04 Mar 2024 13:59:17 EST"
541,Humans have driven the Earth's freshwater cycle out of its stable state,https://www.sciencedaily.com/releases/2024/03/240304135840.htm,New analysis shows that the global freshwater cycle has shifted far beyond pre-industrial conditions.,[],"Mon, 04 Mar 2024 13:58:40 EST"
542,Tests show high-temperature superconducting magnets are ready for fusion,https://www.sciencedaily.com/releases/2024/03/240304135732.htm,"A comprehensive study of high-temperature superconducting magnets confirms they meet requirements for an economic, compact fusion power plant.",[],"Mon, 04 Mar 2024 13:57:32 EST"
543,An overgrowth of nerve cells appears to cause lingering symptoms after recurrent UTIs,https://www.sciencedaily.com/releases/2024/03/240302171534.htm,"A perplexing problem for people with recurring urinary tract infections (UTIs) is persistent pain, even after antibiotics have successfully cleared the bacteria. Now researchers have identified the likely cause -- an overgrowth of nerve cells in the bladder.",[],"Sat, 02 Mar 2024 17:15:34 EST"
544,Orcas demonstrating they no longer need to hunt in packs to take down the great white shark,https://www.sciencedaily.com/releases/2024/03/240302171519.htm,"An orca (killer whale) has been observed, for the first-ever time, individually consuming a great white shark -- and within just two minutes.",[],"Sat, 02 Mar 2024 17:15:19 EST"
545,AI outperforms humans in standardized tests of creative potential,https://www.sciencedaily.com/releases/2024/03/240301134758.htm,"In a recent study, 151 human participants were pitted against ChatGPT-4 in three tests designed to measure divergent thinking, which is considered to be an indicator of creative thought.",[],"Fri, 01 Mar 2024 13:47:58 EST"
546,Ultraviolet radiation from massive stars shapes planetary systems,https://www.sciencedaily.com/releases/2024/03/240301134610.htm,"Up to a certain point, very luminous stars can have a positive effect on the formation of planets, but from that point on the radiation they emit can cause the material in protoplanetary discs to disperse.",[],"Fri, 01 Mar 2024 13:46:10 EST"
547,Ice shell thickness reveals water temperature on ocean worlds,https://www.sciencedaily.com/releases/2024/02/240229182929.htm,"Astrobiologists have devised a novel way to determine ocean temperatures of distant worlds based on the thickness of their ice shells, effectively conducting oceanography from space.",[],"Thu, 29 Feb 2024 18:29:29 EST"
548,Astronomers measure heaviest black hole pair ever found,https://www.sciencedaily.com/releases/2024/02/240229182830.htm,"Using archival data from the Gemini North telescope, a team of astronomers has measured the heaviest pair of supermassive black holes ever found. The merging of two supermassive black holes is a phenomenon that has long been predicted, though never observed. This massive pair gives clues as to why such an event seems so unlikely in the Universe.",[],"Thu, 29 Feb 2024 18:28:30 EST"
549,Building bionic jellyfish for ocean exploration,https://www.sciencedaily.com/releases/2024/02/240229124647.htm,Researchers show how biohybrid robots based on jellyfish could be used to gather climate science data from deep in the Earth's oceans.,[],"Thu, 29 Feb 2024 12:46:47 EST"
550,Could fiber optic cable help scientists probe the deep layers of the moon?,https://www.sciencedaily.com/releases/2024/02/240229124641.htm,"An increasing number of seismologists are using fiber optic cables to detect seismic waves on Earth -- but how would this technology fare on the Moon, and what would it tell us about the deep layers of our nearest neighbor in space?",[],"Thu, 29 Feb 2024 12:46:41 EST"
551,Astronomers reveal a new link between water and planet formation,https://www.sciencedaily.com/releases/2024/02/240229124620.htm,"Researchers have found water vapor in the disc around a young star exactly where planets may be forming. Water is a key ingredient for life on Earth, and is also thought to play a significant role in planet formation. Yet, until now, we had never been able to map how water is distributed in a stable, cool disc -- the type of disc that offers the most favorable conditions for planets to form around stars.",[],"Thu, 29 Feb 2024 12:46:20 EST"
552,Astronomers discover heavy elements after bright gamma-ray burst from neutron star merger,https://www.sciencedaily.com/releases/2024/02/240229124534.htm,An international team of astronomers obtained observational evidence for the creation of rare heavy elements in the aftermath of a cataclysmic explosion triggered by the merger of two neutron stars.,[],"Thu, 29 Feb 2024 12:45:34 EST"
553,"The Golgi organelle's ribbon structure is not exclusive to vertebrates, contrary to previous consensus",https://www.sciencedaily.com/releases/2024/02/240229124514.htm,"Researchers report that the Golgi ribbon, an organelle structure previously thought to be exclusive to vertebrates, is also present in animal taxa, including mollusks, earthworms, and sea urchins. The function of the Golgi ribbon is still enigmatic, but its presence in diverse animal lineages indicates that its function is not vertebrate specific, as previously thought. The team also showed Golgi ribbons form at a specific timepoint during embryogenesis, which suggests that they might play a role in cell differentiation.",[],"Thu, 29 Feb 2024 12:45:14 EST"
554,'Cosmic lighthouses' that cleared primordial fog identified with JWST,https://www.sciencedaily.com/releases/2024/02/240228132053.htm,"Scientists working with data from NASA's James Webb Space Telescope (JWST) have obtained the first full spectra of some of the earliest starlight in the universe. The images provide the clearest picture yet of very low-mass, newborn galaxies, created less than a billion years after the Big Bang, and suggest the tiny galaxies are central to the cosmic origin story.",[],"Wed, 28 Feb 2024 13:20:53 EST"
555,How molecular 'handedness' emerged in early biology,https://www.sciencedaily.com/releases/2024/02/240228115459.htm,Chemists fill a major gap in origin-of-life theories.,[],"Wed, 28 Feb 2024 11:54:59 EST"
556,Cannabis use linked to increase in heart attack and stroke risk,https://www.sciencedaily.com/releases/2024/02/240228115352.htm,"More frequent use of cannabis was associated with higher odds of adverse cardiovascular outcomes, finds new study.",[],"Wed, 28 Feb 2024 11:53:52 EST"
557,Double trouble at chromosome ends,https://www.sciencedaily.com/releases/2024/02/240228115250.htm,"New findings suggest the end-replication problem, an old standby of biology textbooks, is twice as intricate as once thought.",[],"Wed, 28 Feb 2024 11:52:50 EST"
558,How 40Hz sensory gamma rhythm stimulation clears amyloid in Alzheimer's mice,https://www.sciencedaily.com/releases/2024/02/240228114328.htm,"Stimulating a key brain rhythm with light and sound increases peptide release from interneurons, driving clearance of Alzheimer's protein via the brain's glymphatic system, new study suggests.",[],"Wed, 28 Feb 2024 11:43:28 EST"
559,Change in gene code may explain how human ancestors lost tails,https://www.sciencedaily.com/releases/2024/02/240228114226.htm,A genetic change in our ancient ancestors may partly explain why humans don't have tails like monkeys.,[],"Wed, 28 Feb 2024 11:42:26 EST"
560,New study links placental oxygen levels to fetal brain development,https://www.sciencedaily.com/releases/2024/02/240227172132.htm,"A new study shows oxygenation levels in the placenta, formed during the last three months of fetal development, are an important predictor of cortical growth (development of the outermost layer of the brain or cerebral cortex) and is likely a predictor of childhood cognition and behavior.",[],"Tue, 27 Feb 2024 17:21:32 EST"
561,Scientists use blue-green algae as a surrogate mother for 'meat-like' proteins,https://www.sciencedaily.com/releases/2024/02/240227130709.htm,Researchers have not only succeeded in using blue-green algae as a surrogate mother for a new protein -- they have even coaxed the microalgae to produce 'meat fiber-like' protein strands. The achievement may be the key to sustainable foods that have both the 'right' texture and require minimal processing.,[],"Tue, 27 Feb 2024 13:07:09 EST"
562,Significant glacial retreat in West Antarctica began in 1940s,https://www.sciencedaily.com/releases/2024/02/240226204614.htm,"Among the vast expanse of Antarctica lies the Thwaites Glacier, the world's widest glacier measuring about 80 miles on the western edge of the continent. Despite its size, the massive landform is losing about 50 billion tons of ice more than it is receiving in snowfall, which places it in a precarious position in respect to its stability. Accelerating ice loss has been observed since the 1970s, but it is unclear when this significant melting initiated -- until now. A new study suggests that the significant glacial retreat of two glaciers on the west coast of Antarctica began in the 1940's, likely spurred by climate change.",[],"Mon, 26 Feb 2024 20:46:14 EST"
563,New world record for CIGS solar cells,https://www.sciencedaily.com/releases/2024/02/240226114616.htm,A new record for electrical energy generation from CIGS solar cells has been reached. Scientists have achieved a 23.64 percent efficiency.,[],"Mon, 26 Feb 2024 11:46:16 EST"
564,A novel method for easy and quick fabrication of biomimetic robots with life-like movement,https://www.sciencedaily.com/releases/2024/02/240226114557.htm,"Ultraviolet-laser processing is a promising technique for developing intricate microstructures, enabling complex alignment of muscle cells, required for building life-like biohybrid actuators. Compared to traditional complex methods, this innovative technique enables easy and quick fabrication of microstructures with intricate patterns for achieving different muscle cell arrangements, paving the way for biohybrid actuators capable of complex, flexible movements.",[],"Mon, 26 Feb 2024 11:45:57 EST"
565,Predatory fish use rapid color changes to coordinate attacks,https://www.sciencedaily.com/releases/2024/02/240226114549.htm,"Striped marlin are some of the fastest animals on the planet and one of the ocean's top predators. When hunting in groups, individual marlin will take turns attacking schools of prey fish one at a time. Now a new study helps to explain how they might coordinate this turn-taking style of attack on their prey to avoid injuring each other. The key, according to the new work, is rapid color changes.",[],"Mon, 26 Feb 2024 11:45:49 EST"
566,Blindness from some inherited eye diseases may be caused by gut bacteria,https://www.sciencedaily.com/releases/2024/02/240226114543.htm,"Sight loss in certain inherited eye diseases may be caused by gut bacteria, and is potentially treatable by antimicrobials, finds a new study in mice.",[],"Mon, 26 Feb 2024 11:45:43 EST"
567,Metal scar found on cannibal star,https://www.sciencedaily.com/releases/2024/02/240226114047.htm,"When a star like our Sun reaches the end of its life, it can ingest the surrounding planets and asteroids that were born with it. Now, researchers have found a unique signature of this process for the first time -- a scar imprinted on the surface of a white dwarf star.",[],"Mon, 26 Feb 2024 11:40:47 EST"
568,"Drug limits dangerous reactions to allergy-triggering foods, Stanford Medicine-led study of kids finds",https://www.sciencedaily.com/releases/2024/02/240225212501.htm,"A drug that binds to allergy-causing antibodies can protect children from dangerous reactions to accidentally eating allergy-triggering foods, a new study found.",[],"Sun, 25 Feb 2024 21:25:01 EST"
569,Barriers against Antarctic ice melt disappearing at the double,https://www.sciencedaily.com/releases/2024/02/240223103904.htm,"Undersea anchors of ice that help prevent Antarctica's land ice from slipping into the ocean are shrinking at more than twice the rate compared with 50 years ago, research shows. More than a third of these frozen moorings, known as pinning points, have decreased in size since the turn of the century, experts say. Further deterioration of pinning points, which hold in place the floating ice sheets that fortify Antarctica's land ice, would accelerate the continent's contribution to rising sea levels, scientists warn.",[],"Fri, 23 Feb 2024 10:39:04 EST"
570,Compound vital for all life likely played a role in life's origin,https://www.sciencedaily.com/releases/2024/02/240222214056.htm,"A chemical compound essential to all living things has been synthesized in a lab in conditions that could have occurred on early Earth, suggesting it played a role at the outset of life.",[],"Thu, 22 Feb 2024 21:40:56 EST"
571,Side effects of wide scale forestation could reduce carbon removal benefits by up to a third,https://www.sciencedaily.com/releases/2024/02/240222214045.htm,"The side effects of large-scale forestation initiatives could reduce the CO2 removal benefits by up to a third, a pioneering study has found.",[],"Thu, 22 Feb 2024 21:40:45 EST"
572,Chemists synthesize unique anticancer molecules using novel approach,https://www.sciencedaily.com/releases/2024/02/240222214042.htm,"Nearly 30 years ago, scientists discovered a unique class of anticancer molecules in a family of bryozoans, a phylum of marine invertebrates found in tropical waters. The chemical structures of these molecules, which consist of a dense, highly complex knot of oxidized rings and nitrogen atoms, has attracted the interest of organic chemists worldwide, who aimed to recreate these structures from scratch in the laboratory. However, despite considerable effort, it has remained an elusive task. Until now, that is. A team of chemists has succeeded in synthesizing eight of the compounds for the first time using an approach that combines inventive chemical strategy with the latest technology in small molecule structure determination.",[],"Thu, 22 Feb 2024 21:40:42 EST"
573,Webb finds evidence for neutron star at heart of young supernova remnant,https://www.sciencedaily.com/releases/2024/02/240222214025.htm,"NASA's James Webb Space Telescope has found the best evidence yet for emission from a neutron star at the site of a recently observed supernova. The supernova, known as SN 1987A, was a core-collapse supernova, meaning the compacted remains at its core formed either a neutron star or a black hole. Evidence for such a compact object has long been sought, and while indirect evidence for the presence of a neutron star has previously been found, this is the first time that the effects of high-energy emission from the probable young neutron star have been detected.",[],"Thu, 22 Feb 2024 21:40:25 EST"
574,Combination of group competition and repeated interactions promotes cooperation,https://www.sciencedaily.com/releases/2024/02/240222132201.htm,"How did cooperative behavior prevail in human evolution? Researchers have challenged two prevailing explanations -- repeated interactions on the one hand or group competition on the other. Instead, both mechanisms synergistically contribute to fostering cooperation effectively.",[],"Thu, 22 Feb 2024 13:22:01 EST"
575,A new beginning: The search for more temperate Tatooines,https://www.sciencedaily.com/releases/2024/02/240222122425.htm,"Luke Skywalker's childhood might have been slightly less harsh if he'd grown up on a more temperate Tatooine -- like the ones identified in a new study. According to the study's authors, there are more climate-friendly planets in binary star systems -- in other words, those with two suns -- than previously known. And, they say, it may be a sign that, at least in some ways, the universe leans in the direction of orderly alignment rather than chaotic misalignment.",[],"Thu, 22 Feb 2024 12:24:25 EST"
576,Photon upconversion: Steering light with supercritical coupling,https://www.sciencedaily.com/releases/2024/02/240222122407.htm,"Researchers have unveiled a novel concept termed 'supercritical coupling' that enables several folds increase in photon upconversion efficiency. This discovery not only challenges existing paradigms, but also opens a new direction in the control of light emission.",[],"Thu, 22 Feb 2024 12:24:07 EST"
577,Underlying cause of 'brain fog' linked with long COVID discovered,https://www.sciencedaily.com/releases/2024/02/240222122347.htm,Scientists have announced a major discovery that has profound importance for our understanding of brain fog and cognitive decline seen in some patients with Long COVID. The findings showed that there was disruption to the integrity of the blood vessels in the brains of patients suffering from Long COVID and brain fog. This blood vessel 'leakiness' was able to objectively distinguish those patients with brain fog and cognitive decline compared to patients suffering from Long-COVID but not with brain fog.,[],"Thu, 22 Feb 2024 12:23:47 EST"
578,Treating newly-diagnosed Crohn's patients with advanced therapy leads to dramatic improvements in outcomes,https://www.sciencedaily.com/releases/2024/02/240222122339.htm,"A large-scale clinical trial of treatment strategies for Crohn's disease has shown that offering early advanced therapy to all patients straight after diagnosis can drastically improve outcomes, including by reducing the number of people requiring urgent abdominal surgery for treatment of their disease by ten-fold.",[],"Thu, 22 Feb 2024 12:23:39 EST"
579,Brightest and fastest-growing: Astronomers identify record-breaking quasar,https://www.sciencedaily.com/releases/2024/02/240222122324.htm,"Astronomers have characterized a bright quasar, finding it to be not only the brightest of its kind, but also the most luminous object ever observed. Quasars are the bright cores of distant galaxies and they are powered by supermassive black holes. The black hole in this record-breaking quasar is growing in mass by the equivalent of one Sun per day, making it the fastest-growing black hole to date.",[],"Thu, 22 Feb 2024 12:23:24 EST"
580,Real-time wearable human emotion recognition technology developed,https://www.sciencedaily.com/releases/2024/02/240222122318.htm,A research team has unveiled a groundbreaking technology that can recognize human emotions in real time.,[],"Thu, 22 Feb 2024 12:23:18 EST"
581,"Three years later, search for life on Mars continues",https://www.sciencedaily.com/releases/2024/02/240222122312.htm,"Scientists suspect Mars once had long-lived rivers, lakes and streams. Today, water on Mars is found in ice at the poles and trapped below the Martian surface. Researchers now reveal that Mars also may have had hydrothermal systems based on the hydrated magnesium sulfate the rover identified in the volcanic rocks.",[],"Thu, 22 Feb 2024 12:23:12 EST"
582,Biggest Holocene volcano eruption found by seabed survey,https://www.sciencedaily.com/releases/2024/02/240222004557.htm,"A detailed survey of the volcanic underwater deposits around the Kikai caldera in Japan clarified the deposition mechanisms as well as the event's magnitude. As a result, the research team found that the event 7,300 years ago was the largest volcanic eruption in the Holocene by far.",[],"Thu, 22 Feb 2024 00:45:57 EST"
583,New realistic computer model will help robots collect Moon dust,https://www.sciencedaily.com/releases/2024/02/240222004554.htm,A new computer model mimics Moon dust so well that it could lead to smoother and safer Lunar robot teleoperations.,[],"Thu, 22 Feb 2024 00:45:54 EST"
584,Method identified to double computer processing speeds,https://www.sciencedaily.com/releases/2024/02/240221213907.htm,"Scientists introduce what they call 'simultaneous and heterogeneous multithreading' or SHMT. This system doubles computer processing speeds with existing hardware by simultaneously using graphics processing units (GPUs), hardware accelerators for artificial intelligence (AI) and machine learning (ML), or digital signal processing units to process information.",[],"Wed, 21 Feb 2024 21:39:07 EST"
585,Researchers develop molecules for a new class of antibiotics that can overcome drug resistant bacteria,https://www.sciencedaily.com/releases/2024/02/240221213859.htm,"About a decade ago, researchers began to observe a recurring challenge in their research: Some of the compounds they were developing to harness energy from bacteria were instead killing the microbes. Not good if the objective of the project was to harness the metabolism of living bacteria to produce electricity.",[],"Wed, 21 Feb 2024 21:38:59 EST"
586,High resolution techniques reveal clues in 3.5 billion-year-old biomass,https://www.sciencedaily.com/releases/2024/02/240221213846.htm,"To learn about the first organisms on our planet, researchers have to analyze the rocks of the early Earth. These can only be found in a few places on the surface of the Earth. The Pilbara Craton in Western Australia is one of these rare sites: there are rocks there that are around 3.5 billion years old containing traces of the microorganisms that lived at that time. A research team has now found new clues about the formation and composition of this ancient biomass, providing insights into the earliest ecosystems on Earth.",[],"Wed, 21 Feb 2024 21:38:46 EST"
587,"Little groundwater recharge in ancient Mars aquifer, according to new models",https://www.sciencedaily.com/releases/2024/02/240221213829.htm,"Mars was once a wet world. The geological record of the Red Planet shows evidence for water flowing on the surface -- from river deltas to valleys carved by massive flash floods. But a new study shows that no matter how much rainfall fell on the surface of ancient Mars, very little of it seeped into an aquifer in the planet's southern highlands.",[],"Wed, 21 Feb 2024 21:38:29 EST"
588,Snaking toward a universal antivenom,https://www.sciencedaily.com/releases/2024/02/240221160542.htm,Scientists discovered antibodies that protect against a host of lethal snake venoms.,[],"Wed, 21 Feb 2024 16:05:42 EST"
589,Sleep improves ability to recall complex events,https://www.sciencedaily.com/releases/2024/02/240221160517.htm,"Sleep helps consolidate our memory of complex associations, thus supporting the ability to complete memories of whole events.",[],"Wed, 21 Feb 2024 16:05:17 EST"
590,Revealing what makes bacteria life-threatening,https://www.sciencedaily.com/releases/2024/02/240221160515.htm,"Researchers have discovered that a mutation in the cellulose making machinery of E. coli bacteria allows them to cause severe disease in people -- 'good' bacteria make cellulose and 'bad' bacteria can't. The mutations stopped the E. coli making the cell-surface carbohydrate cellulose and this led to increased inflammation in the intestinal tract of the host, resulting in a breakdown of the intestinal barrier, so the bacteria could spread through the body. Understanding how bacteria spread from intestinal reservoirs to the rest of the body is important in preventing infections and tackling antibiotic resistance.",[],"Wed, 21 Feb 2024 16:05:15 EST"
591,Butterfly and moth genomes mostly unchanged despite 250 million years of evolution,https://www.sciencedaily.com/releases/2024/02/240221160507.htm,"Comparison of over 200 high-quality butterfly and moth genomes reveals key insights into their biology, evolution and diversification over the last 250 million years, as well as clues for conservation.",[],"Wed, 21 Feb 2024 16:05:07 EST"
592,Cleaning or desalinating water quickly: Looking deep into smallest pores,https://www.sciencedaily.com/releases/2024/02/240221160501.htm,"Membranes of vertically aligned carbon nanotubes (VaCNT) can be used to clean or desalinate water at high flow rate and low pressure. Recently, researchers carried out steroid hormone adsorption experiments to study the interplay of forces in the small pores. They found that VaCNT of specific pore geometry and pore surface structure are suited for use as highly selective membranes.",[],"Wed, 21 Feb 2024 16:05:01 EST"
593,An awkward family reunion: Sea monsters are our cousins,https://www.sciencedaily.com/releases/2024/02/240221160425.htm,"The sea lamprey, a 500-million-year-old animal with a sharp-toothed suction cup for a mouth, is the thing of nightmares. A new study discovered that the hindbrain -- the part of the brain controlling vital functions like blood pressure and heart rate -- of both sea lampreys and humans is built using an extraordinarily similar molecular and genetic toolkit.",[],"Wed, 21 Feb 2024 16:04:25 EST"
594,Groundbreaking survey reveals secrets of planet birth around dozens of stars,https://www.sciencedaily.com/releases/2024/03/240305134240.htm,"A team of astronomers has shed new light on the fascinating and complex process of planet formation. The research brings together observations of more than 80 young stars that might have planets forming around them, providing astronomers with a wealth of data and unique insights into how planets arise in different regions of our galaxy.",[],"Tue, 05 Mar 2024 13:42:40 EST"
595,One way to improve a fusion reaction: Use weaknesses as strengths,https://www.sciencedaily.com/releases/2024/03/240305134238.htm,"Scientists are embracing imperfection, using less-than-ideal magnetic fields to make the plasma more manageable.",[],"Tue, 05 Mar 2024 13:42:38 EST"
596,What makes black holes grow and new stars form? Machine learning helps solve the mystery,https://www.sciencedaily.com/releases/2024/03/240305134225.htm,It takes more than a galaxy merger to make a black hole grow and new stars form: machine learning shows cold gas is needed too to initiate rapid growth -- new research finds.,[],"Tue, 05 Mar 2024 13:42:25 EST"
597,"Juno spacecraft measures oxygen production on Jupiter's moon, Europa",https://www.sciencedaily.com/releases/2024/03/240305134217.htm,"NASA's Juno spacecraft has directly measured charged oxygen and hydrogen molecules from the atmosphere of one of Jupiter's largest moons, Europa. These observations provide key constraints on the potential oxygenation of its subsurface ocean.",[],"Tue, 05 Mar 2024 13:42:17 EST"
598,"After decades of Arctic sea ice getting faster and more hazardous for transport, models suggest a dramatic reversal is coming",https://www.sciencedaily.com/releases/2024/03/240305134215.htm,"Will ice floating in the Arctic Ocean move faster or slower over the coming decades? The answer to this question will tell us whether marine transportation can be expected to get more or less hazardous. It might also have important implications for the rate of ice cover loss, which is hugely consequential for Northern Indigenous communities, ecosystems, and the global climate system. While observational data suggest the trend has been towards faster sea ice speeds, climate models project that those speeds will slow down during the summer season. This contrast has led to some questions around the plausibility of the model projections.",[],"Tue, 05 Mar 2024 13:42:15 EST"
599,New cardiovascular imaging approach provides a better view of dangerous plaques,https://www.sciencedaily.com/releases/2024/03/240305134213.htm,"Researchers have developed a new catheter-based device that combines two powerful optical techniques to image the dangerous plaques that can build up inside the arteries that supply blood to the heart. By providing new details about plaque, the device could help clinicians and researchers improve treatments for preventing heart attacks and strokes.",[],"Tue, 05 Mar 2024 13:42:13 EST"
600,Researchers invent new triple-junction tandem solar cells with world-record efficiency,https://www.sciencedaily.com/releases/2024/03/240304221140.htm,"Scientists have developed a novel triple-junction perovskite/Si tandem solar cell that can achieve a certified world-record power conversion efficiency of 27.1 per cent across a solar energy absorption area of 1 sq cm, representing the best-performing triple-junction perovskite/Si tandem solar cell thus far. To achieve this, the team engineered a new cyanate-integrated perovskite solar cell that is stable and energy efficient.",[],"Mon, 04 Mar 2024 22:11:40 EST"
601,JWST captures the end of planet formation,https://www.sciencedaily.com/releases/2024/03/240304195509.htm,The James Webb Space Telescope is helping scientists uncover how planets form by advancing understanding of their birthplaces and the circumstellar disks surrounding young stars. Scientists have imaged winds from an old planet-forming disk (still very young relative to the Sun) which is actively dispersing its gas content. Knowing when the gas disperses is important as it constrains the time left for nascent planets to consume the gas from their surroundings.,[],"Mon, 04 Mar 2024 19:55:09 EST"
602,Scientists revolutionize wireless communication with three-dimensional processors,https://www.sciencedaily.com/releases/2024/03/240304195504.htm,Scientists have pioneered a method for using semiconductor technology to manufacture processors that significantly enhance the efficiency of transmitting vast amounts of data across the globe.,[],"Mon, 04 Mar 2024 19:55:04 EST"
603,New AI model draws treasure maps to diagnose disease,https://www.sciencedaily.com/releases/2024/03/240304195443.htm,"Researchers have developed an artificial intelligence model that can accurately identify tumors and diseases in medical images. The tool draws a map to explain each diagnosis, helping doctors follow its line of reasoning, check for accuracy, and explain the results to patients.",[],"Mon, 04 Mar 2024 19:54:43 EST"
604,Scientists put forth a smarter way to protect a smarter grid,https://www.sciencedaily.com/releases/2024/03/240304195348.htm,"Scientists have put forth a new approach to protect the electric grid, creating a tool that sorts and prioritizes cyber threats on the fly.",[],"Mon, 04 Mar 2024 19:53:48 EST"
605,3D-printed skin closes wounds and contains hair follicle precursors,https://www.sciencedaily.com/releases/2024/03/240304135920.htm,"Fat tissue holds the key to 3D printing layered living skin and potentially hair follicles, according to researchers who recently harnessed fat cells and supporting structures from clinically procured human tissue to precisely correct injuries in rats. The advancement could have implications for reconstructive facial surgery and even hair growth treatments for humans.",[],"Mon, 04 Mar 2024 13:59:20 EST"
606,Webb unlocks secrets of one of the most distant galaxies ever seen,https://www.sciencedaily.com/releases/2024/03/240304135917.htm,"Looking deeply into space and time, astronomers have studied the exceptionally luminous galaxy GN-z11, which existed when our 13.8 billion-year-old universe was only about 430 million years old.",[],"Mon, 04 Mar 2024 13:59:17 EST"
607,Spontaneous curvature the key to shape-shifting nanomaterials,https://www.sciencedaily.com/releases/2024/03/240304135857.htm,"Inspired by nature, nanotechnology researchers have identified 'spontaneous curvature' as the key factor determining how ultra-thin, artificial materials can transform into useful tubes, twists and helices.",[],"Mon, 04 Mar 2024 13:58:57 EST"
608,A key to the future of robots could be hiding in liquid crystals,https://www.sciencedaily.com/releases/2024/03/240304135831.htm,"Robots and cameras of the future could be made of liquid crystals, thanks to a new discovery that significantly expands the potential of the chemicals already common in computer displays and digital watches. The findings are a simple and inexpensive way to manipulate the molecular properties of liquid crystals with light exposure.",[],"Mon, 04 Mar 2024 13:58:31 EST"
609,New dressing robot can 'mimic' the actions of care-workers,https://www.sciencedaily.com/releases/2024/03/240304135829.htm,Scientists have developed a new robot that can 'mimic' the two-handed movements of care-workers as they dress an individual.,[],"Mon, 04 Mar 2024 13:58:29 EST"
610,Network of quantum sensors boosts precision,https://www.sciencedaily.com/releases/2024/03/240304135823.htm,Quantum sensor technology promises even more precise measurements of physical quantities. A team has now compared the signals of up to 91 quantum sensors with each other and thus successfully eliminated the noise caused by interactions with the environment. Correlation spectroscopy can be used to increase the precision of sensor networks.,[],"Mon, 04 Mar 2024 13:58:23 EST"
611,Cost of direct air carbon capture to remain higher than hoped,https://www.sciencedaily.com/releases/2024/03/240304135808.htm,"Researchers estimate the cost of removing 1 ton of CO2 from the air in the year 2050 to be between 230 and 540 US dollars to remove 1 ton. This is twice as high as previous estimates. The researchers compared the potential costs of three technologies that are already in use. From today's perspective, none of these technologies has clear advantages over the others in terms of potential costs. All three technologies should therefore be further developed, say the researchers.",[],"Mon, 04 Mar 2024 13:58:08 EST"
612,Researchers use liquid crystals to control polarization inside laser-written waveguides,https://www.sciencedaily.com/releases/2024/03/240304135803.htm,"Researchers have developed a new way to control and manipulate optical signals by embedding a liquid crystal layer into waveguides created with direct laser writing. The new devices enable electro-optical control of polarization, which could open new possibilities for chip-based devices and complex photonic circuits based on femtosecond-written waveguides.",[],"Mon, 04 Mar 2024 13:58:03 EST"
613,New AI smartphone tool accurately diagnoses ear infections,https://www.sciencedaily.com/releases/2024/03/240304135751.htm,"A new cell phone app developed by physician-scientists, which uses artificial intelligence (AI) to accurately diagnose ear infections, or acute otitis media (AOM), could help decrease unnecessary antibiotic use in young children, according to new research.",[],"Mon, 04 Mar 2024 13:57:51 EST"
614,Study determines the original orientations of rocks drilled on Mars,https://www.sciencedaily.com/releases/2024/03/240304135739.htm,Geologists determined the original orientation of many of the Mars bedrock samples collected by the Perseverance rover. The findings can give scientists clues to the conditions in which the rocks originally formed.,[],"Mon, 04 Mar 2024 13:57:39 EST"
615,Tests show high-temperature superconducting magnets are ready for fusion,https://www.sciencedaily.com/releases/2024/03/240304135732.htm,"A comprehensive study of high-temperature superconducting magnets confirms they meet requirements for an economic, compact fusion power plant.",[],"Mon, 04 Mar 2024 13:57:32 EST"
616,Beyond the ink: Painting with physics,https://www.sciencedaily.com/releases/2024/03/240303125412.htm,"Falling from the tip of a brush suspended in mid-air, an ink droplet touches a painted surface and blossoms into a masterpiece of ever-changing beauty. It weaves a tapestry of intricate, evolving patterns. Some of them resemble branching snowflakes, thunderbolts or neurons, whispering the unique expression of the artist's vision.",[],"Sun, 03 Mar 2024 12:54:12 EST"
617,Evolution-capable AI promotes green hydrogen production using more abundant chemical elements,https://www.sciencedaily.com/releases/2024/03/240302171516.htm,"A research team has developed an AI technique capable of expediting the identification of materials with desirable characteristics. Using this technique, the team was able to discover high-performance water electrolyzer electrode materials free of platinum-group elements -- substances previously thought to be indispensable in water electrolysis. These materials may be used to reduce the cost of large-scale production of green hydrogen -- a next-generation energy source.",[],"Sat, 02 Mar 2024 17:15:16 EST"
618,Researchers create coating solution for safer food storage,https://www.sciencedaily.com/releases/2024/03/240301160123.htm,"Galvanized steel containers and surfaces are used for harvested produce because of their durability, strength and lower cost compared to stainless steel. However, bacteria residing in storage containers can cause corrosion. The new coating will reduce corrosion by at least 70 percent, researchers say.",[],"Fri, 01 Mar 2024 16:01:23 EST"
619,AI outperforms humans in standardized tests of creative potential,https://www.sciencedaily.com/releases/2024/03/240301134758.htm,"In a recent study, 151 human participants were pitted against ChatGPT-4 in three tests designed to measure divergent thinking, which is considered to be an indicator of creative thought.",[],"Fri, 01 Mar 2024 13:47:58 EST"
620,Researchers use GPS-tracked icebergs in novel study to improve climate models,https://www.sciencedaily.com/releases/2024/03/240301134753.htm,"Research unearthed new information to help scientists better understand circulation patterns of ocean water around glaciers. In the summers of 2014 and 2019, a group of pioneers in glacial research attached GPS devices to 13 icebergs and tracked hourly changes in their positions as they passed through Greenland's Ilulissat Icefjord toward the ocean. Study results showed circulation in the primary fjord is greatly affected by freshwater flow from connecting tributary fjords, which is critically important to consider in circulation models.",[],"Fri, 01 Mar 2024 13:47:53 EST"
621,Unlocking the potential of lithium-ion batteries with advanced binders,https://www.sciencedaily.com/releases/2024/03/240301134705.htm,"Lithium-ion batteries employ binders that encounter challenges such as poor conductivity and expansion during charging. In a recent study, scientists have developed a high-performing binder using poly(vinylphosphonic acid) for silicon oxide-based anodes in lithium-ion batteries. This binder offers enhanced performance as demonstrated by the superior durability, and discharging capacity of the anodes compared to conventional options. With patents filed internationally, this technology holds promise for broader applications in electric vehicles and beyond.",[],"Fri, 01 Mar 2024 13:47:05 EST"
622,AI-enabled atomic robotic probe to advance quantum material manufacturing,https://www.sciencedaily.com/releases/2024/03/240301134703.htm,"Scientists have pioneered a new methodology of fabricating carbon-based quantum materials at the atomic scale by integrating scanning probe microscopy techniques and deep neural networks. This breakthrough highlights the potential of implementing artificial intelligence at the sub-angstrom scale for enhanced control over atomic manufacturing, benefiting both fundamental research and future applications.",[],"Fri, 01 Mar 2024 13:47:03 EST"
623,New insights on how galaxies are formed,https://www.sciencedaily.com/releases/2024/03/240301134700.htm,Astronomers can use supercomputers to simulate the formation of galaxies from the Big Bang 13.8 billion years ago to the present day. But there are a number of sources of error. An international research team has spent a hundred million computer hours over eight years trying to correct these.,[],"Fri, 01 Mar 2024 13:47:00 EST"
624,Scientists make nanoparticles dance to unravel quantum limits,https://www.sciencedaily.com/releases/2024/03/240301134651.htm,"The question of where the boundary between classical and quantum physics lies is one of the longest-standing pursuits of modern scientific research and in new research, scientists demonstrate a novel platform that could help us find an answer.",[],"Fri, 01 Mar 2024 13:46:51 EST"
625,It's not only opposites that attract -- new study shows like-charged particles can come together,https://www.sciencedaily.com/releases/2024/03/240301134643.htm,"A study shows that similarly charged particles can sometimes attract, rather than repel. The team found that like-charged particles suspended in liquids can attract one another at long-range, depending on the solvent and the sign of the charge. The study has immediate implications for processes that involve interactions in solution across various length-scales, including self-assembly, crystallization, and phase separation.",[],"Fri, 01 Mar 2024 13:46:43 EST"
626,Software speeds up drug development,https://www.sciencedaily.com/releases/2024/03/240301134637.htm,"Sugars cover nearly all proteins present at the surface of the cells in our bodies, forming a shield around the proteins. Thus, these sugars influence how cells interact with their environment including pathogens, playing an important role in medical drug development. GlycoSHIELD, a new computational approach to study the sugar shields of proteins, is resource-reducing, time-efficient and user-friendly.",[],"Fri, 01 Mar 2024 13:46:37 EST"
627,Umbrella for atoms: The first protective layer for 2D quantum materials,https://www.sciencedaily.com/releases/2024/03/240301134631.htm,"As silicon-based computer chips approach their physical limitations in the quest for faster and smaller designs, the search for alternative materials that remain functional at atomic scales is one of science's biggest challenges. In a groundbreaking development, researchers have engineered a protective film that shields quantum semiconductor layers just one atom thick from environmental influences without compromising their revolutionary quantum properties. This puts the application of these delicate atomic layers in ultrathin electronic components within realistic reach.",[],"Fri, 01 Mar 2024 13:46:31 EST"
628,Lithium-ion batteries from drones might find second lives in less 'stressful' devices,https://www.sciencedaily.com/releases/2024/03/240301134616.htm,Taking flight can be stressful -- especially for a lithium-ion battery that powers a drone. Too much strain on these cells causes damage and shortens a device's overall lifespan. Research shows the potential to improve batteries in aerial electric vehicles that take off and land vertically. The team developed a new electrolyte to address these challenges and said the 'stressed out' batteries could also have second lives in less strenuous applications.,[],"Fri, 01 Mar 2024 13:46:16 EST"
629,Ultraviolet radiation from massive stars shapes planetary systems,https://www.sciencedaily.com/releases/2024/03/240301134610.htm,"Up to a certain point, very luminous stars can have a positive effect on the formation of planets, but from that point on the radiation they emit can cause the material in protoplanetary discs to disperse.",[],"Fri, 01 Mar 2024 13:46:10 EST"
630,Hurricanes and power grids: Eliminating large-scale outages with a new approach,https://www.sciencedaily.com/releases/2024/03/240301134253.htm,"Large scale-power outages caused by tropical cyclones can be prevented almost entirely if a small but critical set of power lines is protected against storm damages, a new study finds. Scientists developed a new method that can be used to identify those critical lines and increase the system's resilience.",[],"Fri, 01 Mar 2024 13:42:53 EST"
631,Ice shell thickness reveals water temperature on ocean worlds,https://www.sciencedaily.com/releases/2024/02/240229182929.htm,"Astrobiologists have devised a novel way to determine ocean temperatures of distant worlds based on the thickness of their ice shells, effectively conducting oceanography from space.",[],"Thu, 29 Feb 2024 18:29:29 EST"
632,Improving energy security with policies focused on demand-side solutions,https://www.sciencedaily.com/releases/2024/02/240229182848.htm,"Energy systems essential to supporting our everyday activities face increasing threats from wars, pandemics, climate change, and other unexpected events. An international team of researchers found that demand-oriented solutions have a significantly greater potential to reduce our vulnerability to energy crises compared to supply measures.",[],"Thu, 29 Feb 2024 18:28:48 EST"
633,Astronomers measure heaviest black hole pair ever found,https://www.sciencedaily.com/releases/2024/02/240229182830.htm,"Using archival data from the Gemini North telescope, a team of astronomers has measured the heaviest pair of supermassive black holes ever found. The merging of two supermassive black holes is a phenomenon that has long been predicted, though never observed. This massive pair gives clues as to why such an event seems so unlikely in the Universe.",[],"Thu, 29 Feb 2024 18:28:30 EST"
634,Study unlocks nanoscale secrets for designing next-generation solar cells,https://www.sciencedaily.com/releases/2024/02/240229124701.htm,"A team of researchers has revealed ways to optimize efficiency and better control degradation, by engineering the nanoscale structure of perovskite devices.",[],"Thu, 29 Feb 2024 12:47:01 EST"
635,"Researchers use AI, Google street view to predict household energy costs on large scale",https://www.sciencedaily.com/releases/2024/02/240229124655.htm,"An interdisciplinary team of experts has found a way to use artificial intelligence to analyze a household's passive design characteristics and predict its energy expenses with more than 74 percent accuracy. By combining their findings with demographic data including poverty levels, the researchers have created a comprehensive model for predicting energy burden across 1,402 census tracts and nearly 300,000 households in Chicago.",[],"Thu, 29 Feb 2024 12:46:55 EST"
636,"AI technique 'decodes' microscope images, overcoming fundamental limit",https://www.sciencedaily.com/releases/2024/02/240229124650.htm,"Researchers have developed a deep learning algorithm for removing systematic effects from atomic force microscopy images, enabling more precise profiles of material surfaces.",[],"Thu, 29 Feb 2024 12:46:50 EST"
637,Building bionic jellyfish for ocean exploration,https://www.sciencedaily.com/releases/2024/02/240229124647.htm,Researchers show how biohybrid robots based on jellyfish could be used to gather climate science data from deep in the Earth's oceans.,[],"Thu, 29 Feb 2024 12:46:47 EST"
638,Could fiber optic cable help scientists probe the deep layers of the moon?,https://www.sciencedaily.com/releases/2024/02/240229124641.htm,"An increasing number of seismologists are using fiber optic cables to detect seismic waves on Earth -- but how would this technology fare on the Moon, and what would it tell us about the deep layers of our nearest neighbor in space?",[],"Thu, 29 Feb 2024 12:46:41 EST"
639,Detailed study demonstrates how pulse oximeters significantly overestimate oxygen readings in people with darker skin tones,https://www.sciencedaily.com/releases/2024/02/240229124630.htm,"A systematic review draws together five decades of research -- including more than 730,000 individual measurements -- to assess how a person's skin tone can influence the readings provided by some of the most common monitoring devices used in global healthcare.",[],"Thu, 29 Feb 2024 12:46:30 EST"
640,Astronomers reveal a new link between water and planet formation,https://www.sciencedaily.com/releases/2024/02/240229124620.htm,"Researchers have found water vapor in the disc around a young star exactly where planets may be forming. Water is a key ingredient for life on Earth, and is also thought to play a significant role in planet formation. Yet, until now, we had never been able to map how water is distributed in a stable, cool disc -- the type of disc that offers the most favorable conditions for planets to form around stars.",[],"Thu, 29 Feb 2024 12:46:20 EST"
641,Turning waste into gold,https://www.sciencedaily.com/releases/2024/02/240229124612.htm,"Researchers have recovered gold from electronic waste. Their highly sustainable new method is based on a protein fibril sponge, which the scientists derive from whey, a food industry byproduct.",[],"Thu, 29 Feb 2024 12:46:12 EST"
642,Better neutron mirrors can reveal the inner secrets of matter,https://www.sciencedaily.com/releases/2024/02/240229124609.htm,Improved neutron mirrors can increase the efficiency of material analysis in neutron sources such as the ESS. The improved mirror has been developed by coating a silicon plate with extremely thin layers of iron and silicon mixed with boron carbide.,[],"Thu, 29 Feb 2024 12:46:09 EST"
643,"When the music changes, so does the dance: Controlling cooperative electronic states in Kagome metals",https://www.sciencedaily.com/releases/2024/02/240229124607.htm,"Playing a different sound track is, physically speaking, only a minute change of the vibration spectrum, yet its impact on a dance floor is dramatic. People long for this tiny trigger, and as a salsa changes to a tango completely different collective patterns emerge. For such a tiny stimulus to have an effect, the crowd needs to know more than just one dance. Electrons in metals tend to show only one behavior at zero temperature, when all kinetic energy is quenched.",[],"Thu, 29 Feb 2024 12:46:07 EST"
644,Researchers improve the stability of perovskite solar cells,https://www.sciencedaily.com/releases/2024/02/240229124602.htm,"Perovskite solar cells are considered the strongest contender to replace silicon solar cells. While they achieve high power conversion energy, they also suffer from lead leakage and perovskite degradation due to moisture. Now scientists leverage the technique of interfacial passivation, where lead ions are bound by crown ether B18C6, obtaining 21.7% power conversion energy. The crown ether also resists degradation due to moisture for 300 hours at room temperature and 85% humidity.",[],"Thu, 29 Feb 2024 12:46:02 EST"
645,Researchers create new compound to build space-age antennas,https://www.sciencedaily.com/releases/2024/02/240229124545.htm,"In a first-of-its-kind development, researchers have created a new compound that can be used to 3D print telecommunication antennas and other connectivity devices. These 3D printed products, created by combining a two-dimensional compound called MXenes with a polymer, can be used as an alternative for metallic counterparts and can make a vast improvement in communication technology including elements such as antennas, waveguides and filters.",[],"Thu, 29 Feb 2024 12:45:45 EST"
646,Astronomers discover heavy elements after bright gamma-ray burst from neutron star merger,https://www.sciencedaily.com/releases/2024/02/240229124534.htm,An international team of astronomers obtained observational evidence for the creation of rare heavy elements in the aftermath of a cataclysmic explosion triggered by the merger of two neutron stars.,[],"Thu, 29 Feb 2024 12:45:34 EST"
647,Scientists reveal how light behaves in formless solids,https://www.sciencedaily.com/releases/2024/02/240229124524.htm,"For a long time, it was thought that amorphous solids do not selectively absorb light because of their disordered atomic structure. A new study disproves this theory and shows that amorphous solids actually exhibit dichroism, meaning that they selectively absorb light of different polarizations.",[],"Thu, 29 Feb 2024 12:45:24 EST"
648,A bright idea for recycling rare-earth phosphors from used fluorescent bulbs,https://www.sciencedaily.com/releases/2024/02/240229124519.htm,"Recycling facilities collect glass and mercury from thrown away fluorescent bulbs, but discarded lighting could also supply rare-earth metals for reuse. The 17 metals referred to as rare earths aren't all widely available and aren't easily extracted with existing recycling methods. Now, researchers have found a simpler way to collect slightly magnetic particles that contain rare-earth metals from spent fluorescent bulbs.",[],"Thu, 29 Feb 2024 12:45:19 EST"
649,EU countries have seen a decade of progress towards their 2030 sustainable energy goal,https://www.sciencedaily.com/releases/2024/02/240228154703.htm,"Countries in the European Union (EU) have made progress over the past decade toward Sustainable Development Goal 7 (SDG 7), which calls for 'access to affordable, reliable, sustainable and modern energy for all' by 2030, according to a new study.",[],"Wed, 28 Feb 2024 15:47:03 EST"
650,'Cosmic lighthouses' that cleared primordial fog identified with JWST,https://www.sciencedaily.com/releases/2024/02/240228132053.htm,"Scientists working with data from NASA's James Webb Space Telescope (JWST) have obtained the first full spectra of some of the earliest starlight in the universe. The images provide the clearest picture yet of very low-mass, newborn galaxies, created less than a billion years after the Big Bang, and suggest the tiny galaxies are central to the cosmic origin story.",[],"Wed, 28 Feb 2024 13:20:53 EST"
651,How molecular 'handedness' emerged in early biology,https://www.sciencedaily.com/releases/2024/02/240228115459.htm,Chemists fill a major gap in origin-of-life theories.,[],"Wed, 28 Feb 2024 11:54:59 EST"
652,The West is best to spot UFOs,https://www.sciencedaily.com/releases/2024/02/240228115420.htm,"Researchers identified environmental factors that explain why reports of Unidentified Anomalous Phenomena (UAP) are more common in certain regions of the country. Most sightings occur in the American West where proximity to public lands, dark skies and military installations afford more opportunities to see strange objects in the air. Understanding the environmental context of these sightings will make it easier to find explanations for their occurrence and help identify truly anomalous objects that may be a legitimate threat.",[],"Wed, 28 Feb 2024 11:54:20 EST"
653,Biomolecules from formaldehyde on ancient Mars,https://www.sciencedaily.com/releases/2024/02/240228115359.htm,"Organic materials discovered on Mars may have originated from atmospheric formaldehyde, according to new research, marking a step forward in our understanding of the possibility of past life on the Red Planet.",[],"Wed, 28 Feb 2024 11:53:59 EST"
654,Get Ready for Gemma: The Game-Changing 2B 7B 6Trillion Token Platform,https://www.franksworld.com/2024/03/04/get-ready-for-gemma-the-game-changing-2b-7b-6trillion-token-platform/?utm_source=rss&utm_medium=rss&utm_campaign=get-ready-for-gemma-the-game-changing-2b-7b-6trillion-token-platform,This video is from Sam Witteveen.,[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:48:01 +0000"
655,Nintendo just picked a fight with open-source project Yuzu,https://www.franksworld.com/2024/03/04/nintendo-just-picked-a-fight-with-open-source-project-yuzu/?utm_source=rss&utm_medium=rss&utm_campaign=nintendo-just-picked-a-fight-with-open-source-project-yuzu,This video is from Fireship. Nintendo recently sued an open-source Nintendo Switch emulator called Yuzu. Let&#8217;s take a look at the hacking techniques used to exploit the Switch and find out what this lawsuit means for game developers.,[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:45:36 +0000"
656,The NSA has Picked these Programming Languages,https://www.franksworld.com/2024/03/04/the-nsa-has-picked-these-programming-languages/?utm_source=rss&utm_medium=rss&utm_campaign=the-nsa-has-picked-these-programming-languages,"The NSA has recommended a few programming languages, including Rust, C#, Java, Go and others. https://media.defense.gov/2022/Nov/10/2003112742/-1/-1/0/CSI_SOFTWARE_MEMORY_SAFETY.PDF This video is from Stefan Mischook.",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:43:59 +0000"
657,Unveiling Microsoft’s Revolutionary 1-bit LLMs in AI Research,https://www.franksworld.com/2024/03/04/unveiling-microsofts-revolutionary-1-bit-llms-in-ai-research/?utm_source=rss&utm_medium=rss&utm_campaign=unveiling-microsofts-revolutionary-1-bit-llms-in-ai-research,"In this video from AI Papers Academy.dive into a recent research paper by Microsoft: &#8220;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&#8221;. This paper introduce an interesting and exciting architecture for large language models, called BitNet b1.58, which significantly reduces LLMs memory consumption, and speeds-up LLMs inference latency. All of [&#8230;]",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:43:03 +0000"
658,40 APIs Every Developer Should Use (in 12 minutes),https://www.franksworld.com/2024/03/04/40-apis-every-developer-should-use-in-12-minutes/?utm_source=rss&utm_medium=rss&utm_campaign=40-apis-every-developer-should-use-in-12-minutes,"In this video, Coding with Lewis introduces you to 40 APIs that every developer should know and use. From social media to finance to weather, these APIs will help you create amazing applications. Most of these APIs are free without an API key, but might require some sort of sign up or a trial to [&#8230;]",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:41:03 +0000"
659,Do we create reality with our mind? A physicist’s reply.,https://www.franksworld.com/2024/03/04/do-we-create-reality-with-our-mind-a-physicists-reply/?utm_source=rss&utm_medium=rss&utm_campaign=do-we-create-reality-with-our-mind-a-physicists-reply,"This video is from Sabine Hossenfelder. Do we create reality with our minds? I got this question on twitter the other day and after rolling my eyes about it for some while, I decided it’s actually a good question. You might think the answer is obviously “no”. But it’s not that simple. Let me explain.",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:40:07 +0000"
660,How to Master Machine Learning: A Beginner’s Guide for 2024,https://www.franksworld.com/2024/03/04/how-to-master-machine-learning-a-beginners-guide-for-2024/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-master-machine-learning-a-beginners-guide-for-2024,"This video is from freeCodeCamp.org. This machine learning course is created for beginners who are learning in 2024. The course begins with a Machine Learning Roadmap for 2024, emphasizing career paths and beginner-friendly theory. Then it the course moves on to hands-on practical applications and a comprehensive end-to-end project using Python. ✏️ Course created by [&#8230;]",[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:37:51 +0000"
661,Maximize Your Editing Efficiency: 7 Must-Have AI Tools in Premiere Pro,https://www.franksworld.com/2024/03/04/maximize-your-editing-efficiency-7-must-have-ai-tools-in-premiere-pro/?utm_source=rss&utm_medium=rss&utm_campaign=maximize-your-editing-efficiency-7-must-have-ai-tools-in-premiere-pro,This video from Lila takes you through the innovations in Adobe Premiere that take full advantage of AI.,[{'name': 'Frank'}],"Mon, 04 Mar 2024 16:36:53 +0000"
662,How to Learn the Gemini API and Create a Multi-Turn Chat Bot (1 Hour Crash Course),https://www.franksworld.com/2024/03/04/how-to-learn-the-gemini-api-and-create-a-multi-turn-chat-bot-1-hour-crash-course/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-learn-the-gemini-api-and-create-a-multi-turn-chat-bot-1-hour-crash-course,This video is from Code with Ania Kubów. Get the video api code here: https://bit.ly/stream-code,[{'name': 'Frank'}],"Mon, 04 Mar 2024 15:26:57 +0000"
663,Combining Rust and Python: The Best of Both Worlds?,https://www.franksworld.com/2024/03/03/combining-rust-and-python-the-best-of-both-worlds/?utm_source=rss&utm_medium=rss&utm_campaign=combining-rust-and-python-the-best-of-both-worlds,"In this video, ArjanCodes shows you how to seamlessly integrate Rust with Python using Pyo3. This library allows you to write Python modules with Rust. This means that we get the speed and safety of Rust along with Python&#8217;s easy-to-use features!",[{'name': 'Frank'}],"Sun, 03 Mar 2024 13:53:09 +0000"
664,Breaking Down the Fastest AI Chip in the World: What You Need to Know,https://www.franksworld.com/2024/03/01/breaking-down-the-fastest-ai-chip-in-the-world-what-you-need-to-know/?utm_source=rss&utm_medium=rss&utm_campaign=breaking-down-the-fastest-ai-chip-in-the-world-what-you-need-to-know,"This video from Anastasi In Tech  discusses how it works, benchmarks, how it compares to other AI accelerators and the future outlook!",[{'name': 'Frank'}],"Fri, 01 Mar 2024 17:57:07 +0000"
665,Elevate Your AI Capabilities with Red Hat OpenShift AI: A Demo,https://www.franksworld.com/2024/03/01/elevate-your-ai-capabilities-with-red-hat-openshift-ai-a-demo/?utm_source=rss&utm_medium=rss&utm_campaign=elevate-your-ai-capabilities-with-red-hat-openshift-ai-a-demo,"In this video, Chris Chase demonstrates a typical workflow that includes creating a project, launching a Jupyter notebook with appropriate cluster resources and training a foundation model from Hugging Face with one’s own data. Once the model is fine-tuned, Chris automates the build using a data science pipeline and serves the model for use in [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:53:02 +0000"
666,Unveiling the Matrix: A Deep Dive into its Philosophical Themes,https://www.franksworld.com/2024/03/01/unveiling-the-matrix-a-deep-dive-into-its-philosophical-themes/?utm_source=rss&utm_medium=rss&utm_campaign=unveiling-the-matrix-a-deep-dive-into-its-philosophical-themes,"In this video from Einzelgänger take a deeper look into the Matrix. The Matrix, a science fiction film created by the Wachowskis, is probably one of the most influential movies ever made. The story starts when computer programmer Thomas Anderson, operating as a hacker under the alias “Neo,” discovers the truth about the world he’s [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:48:06 +0000"
667,Navigating the AI Landscape: Lessons from the Butlerian Jihad,https://www.franksworld.com/2024/03/01/navigating-the-ai-landscape-lessons-from-the-butlerian-jihad/?utm_source=rss&utm_medium=rss&utm_campaign=navigating-the-ai-landscape-lessons-from-the-butlerian-jihad,"The following was originally published as part of my LinkedIn newsletter: Frank Digs Data, with a special shout out to all the Dune fans out there. In the realm of popular science fiction, few narratives resonate as powerfully with contemporary technological and ethical debates as the Butlerian Jihad from Frank Herbert&#8217;s &#8220;Dune,&#8221; where robotics and [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:43:15 +0000"
668,Separating Fact from Fiction: Exploring AI Concerns with Dan Hendrycks on Win-Win,https://www.franksworld.com/2024/03/01/separating-fact-from-fiction-exploring-ai-concerns-with-dan-hendrycks-on-win-win/?utm_source=rss&utm_medium=rss&utm_campaign=separating-fact-from-fiction-exploring-ai-concerns-with-dan-hendrycks-on-win-win,"The rate of AI progress is accelerating, so how can we minimize the risks of this incredible technology, while maximizing the rewards?",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:38:52 +0000"
669,Data Engineering in the Age of AI: Data Intelligence Platforms,https://www.franksworld.com/2024/03/01/data-engineering-in-the-age-of-ai-data-intelligence-platforms/?utm_source=rss&utm_medium=rss&utm_campaign=data-engineering-in-the-age-of-ai-data-intelligence-platforms,"Learn about the Data Intelligence Platform and how Data Engineers benefit in their work from AI infused into every layer of the Databricks Lakehouse. This live demo walks you through the classic data engineering tasks, code generation, fixing, and documentation with the Databricks Assistant, automatic documentation with Unity Catalog, and making use of LLMs such [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:36:56 +0000"
670,How to Give a Great Data Presentation,https://www.franksworld.com/2024/03/01/how-to-give-a-great-data-presentation/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-give-a-great-data-presentation,This video is from DATAcated. Very excited to host Christopher Chin &#8211; to talk about How to Give a Great Data Presentation!!!,[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:35:40 +0000"
671,Uncovering the Fundamentals of SQL Server and Azure SQL DB Security | Data Exposed,https://www.franksworld.com/2024/03/01/uncovering-the-fundamentals-of-sql-server-and-azure-sql-db-security-data-exposed/?utm_source=rss&utm_medium=rss&utm_campaign=uncovering-the-fundamentals-of-sql-server-and-azure-sql-db-security-data-exposed,"In this video is from Microsoft Developer, learn about SQL Server and Azure SQL Database security fundamentals you won&#8217;t want to miss.",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:32:47 +0000"
672,Uncovering the Truth: The Alarming Rise of Fraud in the Scientific Community,https://www.franksworld.com/2024/03/01/uncovering-the-truth-the-alarming-rise-of-fraud-in-the-scientific-community/?utm_source=rss&utm_medium=rss&utm_campaign=uncovering-the-truth-the-alarming-rise-of-fraud-in-the-scientific-community,"This video is from Sabine Hossenfelder. Science has a big problem and it’s been getting rapidly worse in the past two years or so, to no small part because of recent advances in artificial intelligence. Fraudulent papers are getting published more than ever, and the fraudsters are getting increasingly aggressive. In this episode I want [&#8230;]",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:31:54 +0000"
673,Unleashing Creativity: DeepMind’s New AI Generates Games From Scratch,https://www.franksworld.com/2024/03/01/unleashing-creativity-deepminds-new-ai-generates-games-from-scratch/?utm_source=rss&utm_medium=rss&utm_campaign=unleashing-creativity-deepminds-new-ai-generates-games-from-scratch,This video from Two Minute Papers covers the paper &#8220;Genie: Generative Interactive Environments.&#8221; See? Not all hope for Google is lost.,[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:30:17 +0000"
674,Drizzle ORM in 100 Seconds,https://www.franksworld.com/2024/03/01/drizzle-orm-in-100-seconds/?utm_source=rss&utm_medium=rss&utm_campaign=drizzle-orm-in-100-seconds,"Fireship explains Drizzle in 100 seconds. Drizzle is a serverless TypeScript ORM designed for PostgreSQL, MySQL and SQLite.",[{'name': 'Frank'}],"Fri, 01 Mar 2024 16:28:35 +0000"
675,The Rise of AGI: How to Prepare for the Next Technological Revolution,https://www.franksworld.com/2024/02/29/the-rise-of-agi-how-to-prepare-for-the-next-technological-revolution/?utm_source=rss&utm_medium=rss&utm_campaign=the-rise-of-agi-how-to-prepare-for-the-next-technological-revolution,"This video is from David Ondrej. Soon AGI will be created, yet most people are grossly unprepared. In this AI course I will show you exactly what you need to do to thrive in the post-AGI world.",[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:32:58 +0000"
676,Is it too late to invest in Nvidia?,https://www.franksworld.com/2024/02/29/is-it-too-late-to-invest-in-nvidia/?utm_source=rss&utm_medium=rss&utm_campaign=is-it-too-late-to-invest-in-nvidia,"On this edition of Quartz Smart Investing, is it too late to invest in Nvidia? Eric Beiley, executive managing director of The Beiley Group at Steward Partners, tells Quartz whether he thinks there&#8217;s still room to run for the AI chip stock.",[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:30:15 +0000"
677,OpenAI Sora: A Closer Look!,https://www.franksworld.com/2024/02/29/openai-sora-a-closer-look/?utm_source=rss&utm_medium=rss&utm_campaign=openai-sora-a-closer-look,This video is from Two Minute Papers. 📝 Sora: https://openai.com/research/video-generation-models-as-world-simulators,[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:29:04 +0000"
678,KubeCon EU 2024 Preview: Exploring the Clouds with Aparna Subramanian,https://www.franksworld.com/2024/02/29/kubecon-eu-2024-preview-exploring-the-clouds-with-aparna-subramanian/?utm_source=rss&utm_medium=rss&utm_campaign=kubecon-eu-2024-preview-exploring-the-clouds-with-aparna-subramanian,"With KubeCon EU in Paris around the corner (19th to 22nd March), what better way to get some insight on what is expected than by speaking to people directly involved in the event. Aparna Subramanian is a technologist and cloud-native enthusiast. She started her career as a Software Engineer and has spent most part of [&#8230;]",[{'name': 'Frank'}],"Thu, 29 Feb 2024 18:27:22 +0000"
679,Ergodicity Breaking Under Confinement in Cold-Atom Quantum Simulators,https://quantum-journal.org/papers/q-2024-02-29-1274/,"<p>Quantum 8, 1274 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1274\">https://doi.org/10.22331/q-2024-02-29-1274</a><p class=\"abstract\">The quantum simulation of gauge theories on synthetic quantum matter devices has gained a lot of traction in the last decade, making possible the observation of a range of exotic quantum many-body phenomena. In this work, we consider the spin-$1/2$ quantum link formulation of $1+1$D quantum electrodynamics with a topological $\\theta$-angle, which can be used to tune a confinement-deconfinement transition. Exactly mapping this system onto a PXP model with mass and staggered magnetization terms, we show an intriguing interplay between confinement and the ergodicity-breaking paradigms of quantum many-body scarring and Hilbert-space fragmentation. We map out the rich dynamical phase diagram of this model, finding an ergodic phase at small values of the mass $\\mu$ and confining potential $\\chi$, an emergent integrable phase for large $\\mu$, and a fragmented phase for large values of both parameters. We also show that the latter hosts resonances that lead to a vast array of effective models. We propose experimental probes of our findings, which can be directly accessed in current cold-atom setups.</p>","[{'name': 'Jean-Yves Desaules, Guo-Xian Su, Ian P. McCulloch, Bing Yang, Zlatko Papić, and Jad C. Halimeh'}]","Thu, 29 Feb 2024 16:05:38 +0000"
680,Entanglement dynamics of photon pairs and quantum memories in the gravitational field of the earth,https://quantum-journal.org/papers/q-2024-02-29-1273/,"<p>Quantum 8, 1273 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1273\">https://doi.org/10.22331/q-2024-02-29-1273</a><p class=\"abstract\">We investigate the effect of entanglement dynamics due to gravity – the basis of a mechanism of universal decoherence – for photonic states and quantum memories in Mach-Zehnder and Hong-Ou-Mandel interferometry setups in the gravitational field of the earth. We show that chances are good to witness the effect with near-future technology in Hong-Ou-Mandel interferometry. This would represent an experimental test of theoretical modeling combining a multi-particle effect predicted by the quantum theory of light and an effect predicted by general relativity. Our article represents the first analysis of relativistic gravitational effects on space-based quantum memories which are expected to be an important ingredient for global quantum communication networks.</p>","[{'name': 'Roy Barzel, Mustafa Gündoğan, Markus Krutzik, Dennis Rätzel, and Claus Lämmerzahl'}]","Thu, 29 Feb 2024 15:38:15 +0000"
681,Entanglement-symmetries of covariant channels,https://quantum-journal.org/papers/q-2024-02-29-1272/,"<p>Quantum 8, 1272 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1272\">https://doi.org/10.22331/q-2024-02-29-1272</a><p class=\"abstract\">Let $G$ and $G&#039;$ be monoidally equivalent compact quantum groups, and let $H$ be a Hopf-Galois object realising a monoidal equivalence between these groups&#039; representation categories. This monoidal equivalence induces an equivalence Chan($G$) $\\rightarrow$ Chan($G&#039;$), where Chan($G$) is the category whose objects are finite-dimensional $C*$-algebras with an action of G and whose morphisms are covariant channels. We show that, if the Hopf-Galois object $H$ has a finite-dimensional *-representation, then channels related by this equivalence can simulate each other using a finite-dimensional entangled resource. We use this result to calculate the entanglement-assisted capacities of certain quantum channels.</p>",[{'name': 'Dominic Verdon'}],"Thu, 29 Feb 2024 15:28:17 +0000"
682,Dynamical quantum phase transitions from random matrix theory,https://quantum-journal.org/papers/q-2024-02-29-1271/,"<p>Quantum 8, 1271 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1271\">https://doi.org/10.22331/q-2024-02-29-1271</a><p class=\"abstract\">We uncover a novel dynamical quantum phase transition, using random matrix theory and its associated notion of planar limit. We study it for the isotropic XY Heisenberg spin chain. For this, we probe its real-time dynamics through the Loschmidt echo. This leads to the study of a random matrix ensemble with a complex weight, whose analysis requires novel technical considerations, that we develop. We obtain three main results: 1) There is a third order phase transition at a rescaled critical time, that we determine. 2) The third order phase transition persists away from the thermodynamic limit. 3) For times below the critical value, the difference between the thermodynamic limit and a finite chain decreases exponentially with the system size. All these results depend in a rich manner on the parity of the number of flipped spins of the quantum state conforming the fidelity.</p>","[{'name': 'David Pérez-García, Leonardo Santilli, and Miguel Tierz'}]","Thu, 29 Feb 2024 15:05:00 +0000"
683,Identifying families of multipartite states with non-trivial local entanglement transformations,https://quantum-journal.org/papers/q-2024-02-29-1270/,"<p>Quantum 8, 1270 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1270\">https://doi.org/10.22331/q-2024-02-29-1270</a><p class=\"abstract\">The study of state transformations by spatially separated parties with local operations assisted by classical communication (LOCC) plays a crucial role in entanglement theory and its applications in quantum information processing. Transformations of this type among pure bipartite states were characterized long ago and have a revealing theoretical structure. However, it turns out that generic fully entangled pure multipartite states cannot be obtained from nor transformed to any inequivalent fully entangled state under LOCC. States with this property are referred to as isolated. Nevertheless, multipartite states are classified into families, the so-called SLOCC classes, which possess very different properties. Thus, the above result does not forbid the existence of particular SLOCC classes that are free of isolation, and therefore, display a rich structure regarding LOCC convertibility. In fact, it is known that the celebrated $n$-qubit GHZ and W states give particular examples of such classes and in this work, we investigate this question in general. One of our main results is to show that the SLOCC class of the 3-qutrit totally antisymmetric state is isolation-free as well. Actually, all states in this class can be converted to inequivalent states by LOCC protocols with just one round of classical communication (as in the GHZ and W cases). Thus, we consider next whether there are other classes with this property and we find a large set of negative answers. Indeed, we prove weak isolation (i.e., states that cannot be obtained with finite-round LOCC nor transformed by one-round LOCC) for very general classes, including all SLOCC families with compact stabilizers and many with non-compact stabilizers, such as the classes corresponding to the $n$-qunit totally antisymmetric states for $n\\geq4$. Finally, given the pleasant feature found in the family corresponding to the 3-qutrit totally antisymmetric state, we explore in more detail the structure induced by LOCC and the entanglement properties within this class.</p>","[{'name': 'Nicky Kai Hong Li, Cornelia Spee, Martin Hebenstreit, Julio I. de Vicente, and Barbara Kraus'}]","Thu, 29 Feb 2024 14:27:42 +0000"
684,Discrimination and certification of unknown quantum measurements,https://quantum-journal.org/papers/q-2024-02-29-1269/,"<p>Quantum 8, 1269 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1269\">https://doi.org/10.22331/q-2024-02-29-1269</a><p class=\"abstract\">We study the discrimination of von Neumann measurements in the scenario when we are given a reference measurement and some other measurement. The aim of the discrimination is to determine whether the other measurement is the same as the first one. We consider the cases when the reference measurement is given without the classical description and when its classical description is known. Both cases are studied in the symmetric and asymmetric discrimination setups. Moreover, we provide optimal certification schemes enabling us to certify a known quantum measurement against the unknown one.</p>","[{'name': 'Aleksandra Krawiec, Łukasz Pawela, and Zbigniew Puchała'}]","Thu, 29 Feb 2024 13:43:58 +0000"
685,Bicolor loop models and their long range entanglement,https://quantum-journal.org/papers/q-2024-02-29-1268/,"<p>Quantum 8, 1268 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-29-1268\">https://doi.org/10.22331/q-2024-02-29-1268</a><p class=\"abstract\">Quantum loop models are well studied objects in the context of lattice gauge theories and topological quantum computing. They usually carry long range entanglement that is captured by the topological entanglement entropy. I consider generalization of the toric code model to bicolor loop models and show that the long range entanglement can be reflected in three different ways: a topologically invariant constant, a sub-leading logarithmic correction to the area law, or a modified bond dimension for the area-law term. The Hamiltonians are not exactly solvable for the whole spectra, but admit a tower of area-law exact excited states corresponding to the frustration free superposition of loop configurations with arbitrary pairs of localized vertex defects. The continuity of color along loops imposes kinetic constraints on the model and results in Hilbert space fragmentation, unless plaquette operators involving two neighboring faces are introduced to the Hamiltonian.</p>",[{'name': 'Zhao Zhang'}],"Thu, 29 Feb 2024 13:35:09 +0000"
686,Towards a measurement theory in QFT: “Impossible” quantum measurements are possible but not ideal,https://quantum-journal.org/papers/q-2024-02-27-1267/,"<p>Quantum 8, 1267 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-27-1267\">https://doi.org/10.22331/q-2024-02-27-1267</a><p class=\"abstract\">Naive attempts to put together relativity and quantum measurements lead to signaling between space-like separated regions. In QFT, these are known as $\\textit{impossible measurements}$. We show that the same problem arises in non-relativistic quantum physics, where joint nonlocal measurements (i.e., between systems kept spatially separated) in general lead to signaling, while one would expect no-signaling (based for instance on the $\\textit{principle of no-nonphysical communication}$). This raises the question: Which nonlocal quantum measurements are physically possible? We review and develop further a non-relativistic quantum information approach developed independently of the impossible measurements in QFT, and show that these two have been addressing virtually the same problem. The non-relativistic solution shows that all nonlocal measurements are $localizable$ (i.e., they can be carried out at a distance without violating no-signaling) but they (i) may require arbitrarily large entangled resources and (ii) cannot in general be $ideal$, i.e., are not immediately reproducible. These considerations could help guide the development of a complete theory of measurement in QFT.</p>",[{'name': 'Nicolas Gisin and Flavio Del Santo'}],"Tue, 27 Feb 2024 10:27:18 +0000"
687,Improved Accuracy for Trotter Simulations Using Chebyshev Interpolation,https://quantum-journal.org/papers/q-2024-02-26-1266/,"<p>Quantum 8, 1266 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-26-1266\">https://doi.org/10.22331/q-2024-02-26-1266</a><p class=\"abstract\">Quantum metrology allows for measuring properties of a quantum system at the optimal Heisenberg limit. However, when the relevant quantum states are prepared using digital Hamiltonian simulation, the accrued algorithmic errors will cause deviations from this fundamental limit. In this work, we show how algorithmic errors due to Trotterized time evolution can be mitigated through the use of standard polynomial interpolation techniques. Our approach is to extrapolate to zero Trotter step size, akin to zero-noise extrapolation techniques for mitigating hardware errors. We perform a rigorous error analysis of the interpolation approach for estimating eigenvalues and time-evolved expectation values, and show that the Heisenberg limit is achieved up to polylogarithmic factors in the error. Our work suggests that accuracies approaching those of state-of-the-art simulation algorithms may be achieved using Trotter and classical resources alone for a number of relevant algorithmic tasks.</p><p class=\"further-content\"></p>","[{'name': 'Gumaro Rendon, Jacob Watkins, and Nathan Wiebe'}]","Mon, 26 Feb 2024 14:34:15 +0000"
688,Quantum Vision Transformers,https://quantum-journal.org/papers/q-2024-02-22-1265/,"<p>Quantum 8, 1265 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-22-1265\">https://doi.org/10.22331/q-2024-02-22-1265</a><p class=\"abstract\">In this work, quantum transformers are designed and analysed in detail by extending the state-of-the-art classical transformer neural network architectures known to be very performant in natural language processing and image analysis. Building upon the previous work, which uses parametrised quantum circuits for data loading and orthogonal neural layers, we introduce three types of quantum transformers for training and inference, including a quantum transformer based on compound matrices, which guarantees a theoretical advantage of the quantum attention mechanism compared to their classical counterpart both in terms of asymptotic run time and the number of model parameters. These quantum architectures can be built using shallow quantum circuits and produce qualitatively different classification models. The three proposed quantum attention layers vary on the spectrum between closely following the classical transformers and exhibiting more quantum characteristics. As building blocks of the quantum transformer, we propose a novel method for loading a matrix as quantum states as well as two new trainable quantum orthogonal layers adaptable to different levels of connectivity and quality of quantum computers. We performed extensive simulations of the quantum transformers on standard medical image datasets that showed competitively, and at times better performance compared to the classical benchmarks, including the best-in-class classical vision transformers. The quantum transformers we trained on these small-scale datasets require fewer parameters compared to standard classical benchmarks. Finally, we implemented our quantum transformers on superconducting quantum computers and obtained encouraging results for up to six qubit experiments.</p>","[{'name': 'El Amine Cherrat, Iordanis Kerenidis, Natansh Mathur, Jonas Landman, Martin Strahm, and Yun Yvonna Li'}]","Thu, 22 Feb 2024 13:34:50 +0000"
689,Accelerating Quantum Algorithms with Precomputation,https://quantum-journal.org/papers/q-2024-02-22-1264/,"<p>Quantum 8, 1264 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-22-1264\">https://doi.org/10.22331/q-2024-02-22-1264</a><p class=\"abstract\">Real-world applications of computing can be extremely time-sensitive. It would be valuable if we could accelerate such tasks by performing some of the work ahead of time. Motivated by this, we propose a cost model for quantum algorithms that allows quantum precomputation; i.e., for a polynomial amount of ``free&#039;&#039; computation before the input to an algorithm is fully specified, and methods for taking advantage of it. We analyze two families of unitaries that are asymptotically more efficient to implement in this cost model than in the standard one. The first example of quantum precomputation, based on density matrix exponentiation, could offer an exponential advantage under certain conditions. The second example uses a variant of gate teleportation to achieve a quadratic advantage when compared with implementing the unitaries directly. These examples hint that quantum precomputation may offer a new arena in which to seek quantum advantage.</p>",[{'name': 'William J. Huggins and Jarrod R. McClean'}],"Thu, 22 Feb 2024 13:10:25 +0000"
690,Analogue Quantum Simulation with Fixed-Frequency Transmon Qubits,https://quantum-journal.org/papers/q-2024-02-22-1263/,"<p>Quantum 8, 1263 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-22-1263\">https://doi.org/10.22331/q-2024-02-22-1263</a><p class=\"abstract\">We experimentally assess the suitability of transmon qubits with fixed frequencies and fixed interactions for the realization of analogue quantum simulations of spin systems. We test a set of necessary criteria for this goal on a commercial quantum processor using full quantum process tomography and more efficient Hamiltonian tomography. Significant single qubit errors at low amplitudes are identified as a limiting factor preventing the realization of analogue simulations on currently available devices. We additionally find spurious dynamics in the absence of drive pulses, which we identify with coherent coupling between the qubit and a low dimensional environment. With moderate improvements, analogue simulation of a rich family of time-dependent many-body spin Hamiltonians may be possible.</p>","[{'name': 'Sean Greenaway, Adam Smith, Florian Mintert, and Daniel Malz'}]","Thu, 22 Feb 2024 13:02:06 +0000"
691,Taming the Rotating Wave Approximation,https://quantum-journal.org/papers/q-2024-02-21-1262/,"<p>Quantum 8, 1262 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-21-1262\">https://doi.org/10.22331/q-2024-02-21-1262</a><p class=\"abstract\">The interaction between light and matter is one of the oldest research areas of quantum mechanics, and a field that just keeps on delivering new insights and applications. With the arrival of cavity and circuit quantum electrodynamics we can now achieve strong light-matter couplings which form the basis of most implementations of quantum technology. But quantum information processing also has high demands requiring total error rates of fractions of percentage in order to be scalable (fault-tolerant) to useful applications. Since errors can also arise from modelling, this has brought into center stage one of the key approximations of quantum theory, the Rotating Wave Approximation (RWA) of the quantum Rabi model, leading to the Jaynes-Cummings Hamiltonian. While the RWA is often very good and incredibly useful to understand light-matter interactions, there is also growing experimental evidence of regimes where it is a bad approximation. Here, we ask and answer a harder question: for which experimental parameters is the RWA, although perhaps qualitatively adequate, already not good enough to match the demands of scalable quantum technology? For example, when is the error at least, and when at most, 1%? To answer this, we develop rigorous non-perturbative bounds taming the RWA.
We find that these bounds not only depend, as expected, on the ratio of the coupling strength and the oscillator frequency, but also on the average number of photons in the initial state. This confirms recent experiments on photon-dressed Bloch-Siegert shifts. We argue that with experiments reporting controllable cavity states with hundreds of photons and with quantum error correcting codes exploring more and more of Fock space, this state-dependency of the RWA is increasingly relevant for the field of quantum computation, and our results pave the way towards a better understanding of those experiments.</p><p class=\"further-content\"></p>","[{'name': 'Daniel Burgarth, Paolo Facchi, Robin Hillier, and Marilena Ligabò'}]","Wed, 21 Feb 2024 13:07:52 +0000"
692,Stabilizer Formalism for Operator Algebra Quantum Error Correction,https://quantum-journal.org/papers/q-2024-02-21-1261/,"<p>Quantum 8, 1261 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-21-1261\">https://doi.org/10.22331/q-2024-02-21-1261</a><p class=\"abstract\">We introduce a stabilizer formalism for the general quantum error correction framework called operator algebra quantum error correction (OAQEC), which generalizes Gottesman&#039;s formulation for traditional quantum error correcting codes (QEC) and Poulin&#039;s for operator quantum error correction and subsystem codes (OQEC). The construction generates hybrid classical-quantum stabilizer codes and we formulate a theorem that fully characterizes the Pauli errors that are correctable for a given code, generalizing the fundamental theorems for the QEC and OQEC stabilizer formalisms. We discover hybrid versions of the Bacon-Shor subsystem codes motivated by the formalism, and we apply the theorem to derive a result that gives the distance of such codes. We show how some recent hybrid subspace code constructions are captured by the formalism, and we also indicate how it extends to qudits.</p>","[{'name': 'Guillaume Dauphinais, David W. Kribs, and Michael Vasmer'}]","Wed, 21 Feb 2024 13:00:46 +0000"
693,Hierarchical generalization of dual unitarity,https://quantum-journal.org/papers/q-2024-02-20-1260/,"<p>Quantum 8, 1260 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-20-1260\">https://doi.org/10.22331/q-2024-02-20-1260</a><p class=\"abstract\">Quantum dynamics with local interactions in lattice models display rich physics, but is notoriously hard to study. Dual-unitary circuits allow for exact answers to interesting physical questions in clean or disordered one- and higher-dimensional quantum systems. However, this family of models shows some non-universal features, like vanishing correlations inside the light-cone and instantaneous thermalization of local observables. In this work we propose a generalization of dual-unitary circuits where the exactly calculable spatial-temporal correlation functions display richer behavior, and have non-trivial thermalization of local observables. This is achieved by generalizing the single-gate condition to a hierarchy of multi-gate conditions, where the first level recovers dual-unitary models, and the second level exhibits these new interesting features. We also extend the discussion and provide exact solutions to correlators with few-site observables and discuss higher-orders, including the ones after a quantum quench. In addition, we provide exhaustive parametrizations for qubit cases, and propose a new family of models for local dimensions larger than two, which also provides a new family of dual-unitary models.</p>","[{'name': 'Xie-Hang Yu, Zhiyuan Wang, and Pavel Kos'}]","Tue, 20 Feb 2024 14:43:10 +0000"
694,A hybrid quantum algorithm to detect conical intersections,https://quantum-journal.org/papers/q-2024-02-20-1259/,"<p>Quantum 8, 1259 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-20-1259\">https://doi.org/10.22331/q-2024-02-20-1259</a><p class=\"abstract\">Conical intersections are topologically protected crossings between the potential energy surfaces of a molecular Hamiltonian, known to play an important role in chemical processes such as photoisomerization and non-radiative relaxation. They are characterized by a non-zero Berry phase, which is a topological invariant defined on a closed path in atomic coordinate space, taking the value $\\pi$ when the path encircles the intersection manifold. In this work, we show that for real molecular Hamiltonians, the Berry phase can be obtained by tracing a local optimum of a variational ansatz along the chosen path and estimating the overlap between the initial and final state with a control-free Hadamard test. Moreover, by discretizing the path into $N$ points, we can use $N$ single Newton-Raphson steps to update our state non-variationally. Finally, since the Berry phase can only take two discrete values (0 or $\\pi$), our procedure succeeds even for a cumulative error bounded by a constant; this allows us to bound the total sampling cost and to readily verify the success of the procedure. We demonstrate numerically the application of our algorithm on small toy models of the formaldimine molecule (${H_2C=NH}$).</p>","[{'name': 'Emiel Koridon, Joana Fraxanet, Alexandre Dauphin, Lucas Visscher, Thomas E. O&#039;Brien, and Stefano Polla'}]","Tue, 20 Feb 2024 14:32:41 +0000"
695,Reqomp: Space-constrained Uncomputation for Quantum Circuits,https://quantum-journal.org/papers/q-2024-02-19-1258/,"<p>Quantum 8, 1258 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-19-1258\">https://doi.org/10.22331/q-2024-02-19-1258</a><p class=\"abstract\">Quantum circuits must run on quantum computers with tight limits on qubit and gate counts. To generate circuits respecting both limits, a promising opportunity is exploiting $uncomputation$ to trade qubits for gates. We present Reqomp, a method to automatically synthesize correct and efficient uncomputation of ancillae while respecting hardware constraints. For a given circuit, Reqomp can offer a wide range of trade-offs between tightly constraining qubit count or gate count. Our evaluation demonstrates that Reqomp can significantly reduce the number of required ancilla qubits by up to 96%. On 80% of our benchmarks, the ancilla qubits required can be reduced by at least 25% while never incurring a gate count increase beyond 28%.</p>","[{'name': 'Anouk Paradis, Benjamin Bichsel, and Martin Vechev'}]","Mon, 19 Feb 2024 10:26:13 +0000"
696,Spacetime-Efficient Low-Depth Quantum State Preparation with Applications,https://quantum-journal.org/papers/q-2024-02-15-1257/,"<p>Quantum 8, 1257 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-15-1257\">https://doi.org/10.22331/q-2024-02-15-1257</a><p class=\"abstract\">We propose a novel deterministic method for preparing arbitrary quantum states. When our protocol is compiled into CNOT and arbitrary single-qubit gates, it prepares an $N$-dimensional state in depth $O(\\log(N))$ and $\\textit{spacetime allocation}$ (a metric that accounts for the fact that oftentimes some ancilla qubits need not be active for the entire circuit) $O(N)$, which are both optimal. When compiled into the $\\{\\mathrm{H,S,T,CNOT}\\}$ gate set, we show that it requires asymptotically fewer quantum resources than previous methods. Specifically, it prepares an arbitrary state up to error $\\epsilon$ with optimal depth of $O(\\log(N) + \\log (1/\\epsilon))$ and spacetime allocation $O(N\\log(\\log(N)/\\epsilon))$, improving over $O(\\log(N)\\log(\\log (N)/\\epsilon))$ and $O(N\\log(N/\\epsilon))$, respectively. We illustrate how the reduced spacetime allocation of our protocol enables rapid preparation of many disjoint states with only constant-factor ancilla overhead – $O(N)$ ancilla qubits are reused efficiently to prepare a product state of $w$ $N$-dimensional states in depth $O(w + \\log(N))$ rather than $O(w\\log(N))$, achieving effectively constant depth per state. We highlight several applications where this ability would be useful, including quantum machine learning, Hamiltonian simulation, and solving linear systems of equations. We provide quantum circuit descriptions of our protocol, detailed pseudocode, and gate-level implementation examples using Braket.</p>","[{'name': 'Kaiwen Gui, Alexander M. Dalzell, Alessandro Achille, Martin Suchara, and Frederic T. Chong'}]","Thu, 15 Feb 2024 15:13:43 +0000"
697,Photonic entanglement during a zero-g flight,https://quantum-journal.org/papers/q-2024-02-15-1256/,"<p>Quantum 8, 1256 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-15-1256\">https://doi.org/10.22331/q-2024-02-15-1256</a><p class=\"abstract\">Quantum technologies have matured to the point that we can test fundamental quantum phenomena under extreme conditions. Specifically, entanglement, a cornerstone of modern quantum information theory, can be robustly produced and verified in various adverse environments. We take these tests further and implement a high-quality Bell experiment during a parabolic flight, transitioning from microgravity to hypergravity of 1.8 g while continuously observing Bell violation, with Bell-CHSH parameters between $S=-2.6202$ and $-2.7323$, an average of $\\overline{S} = -2.680$, and average standard deviation of $\\overline{\\Delta S} = 0.014$. This violation is unaffected both by uniform and non-uniform acceleration. This experiment demonstrates the stability of current quantum communication platforms for space-based applications and adds an important reference point for testing the interplay of non-inertial motion and quantum information.</p>","[{'name': 'Julius Arthur Bittermann, Lukas Bulla, Sebastian Ecker, Sebastian Philipp Neumann, Matthias Fink, Martin Bohmann, Nicolai Friis, Marcus Huber, and Rupert Ursin'}]","Thu, 15 Feb 2024 10:46:23 +0000"
698,Quantitative relations between different measurement contexts,https://quantum-journal.org/papers/q-2024-02-14-1255/,"<p>Quantum 8, 1255 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-14-1255\">https://doi.org/10.22331/q-2024-02-14-1255</a><p class=\"abstract\">In quantum theory, a measurement context is defined by an orthogonal basis in a Hilbert space, where each basis vector represents a specific measurement outcome. The precise quantitative relation between two different measurement contexts can thus be characterized by the inner products of nonorthogonal states in that Hilbert space. Here, we use measurement outcomes that are shared by different contexts to derive specific quantitative relations between the inner products of the Hilbert space vectors that represent the different contexts. It is shown that the probabilities that describe the paradoxes of quantum contextuality can be derived from a very small number of inner products, revealing details of the fundamental relations between measurement contexts that go beyond a basic violation of noncontextual limits. The application of our analysis to a product space of two systems reveals that the nonlocality of quantum entanglement can be traced back to a local inner product representing the relation between measurement contexts in only one system. Our results thus indicate that the essential nonclassical features of quantum mechanics can be traced back to the fundamental difference between quantum superpositions and classical alternatives.</p>",[{'name': 'Ming Ji and Holger F. Hofmann'}],"Wed, 14 Feb 2024 11:28:15 +0000"
699,Continuous-time quantum walks for MAX-CUT are hot,https://quantum-journal.org/papers/q-2024-02-13-1254/,"<p>Quantum 8, 1254 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-13-1254\">https://doi.org/10.22331/q-2024-02-13-1254</a><p class=\"abstract\">By exploiting the link between time-independent Hamiltonians and thermalisation, heuristic predictions on the performance of continuous-time quantum walks for MAX-CUT are made. The resulting predictions depend on the number of triangles in the underlying MAX-CUT graph. We extend these results to the time-dependent setting with multi-stage quantum walks and Floquet systems. The approach followed here provides a novel way of understanding the role of unitary dynamics in tackling combinatorial optimisation problems with continuous-time quantum algorithms.</p>","[{'name': 'Robert J. Banks, Ehsan Haque, Farah Nazef, Fatima Fethallah, Fatima Ruqaya, Hamza Ahsan, Het Vora, Hibah Tahir, Ibrahim Ahmad, Isaac Hewins, Ishaq Shah, Krish Baranwal, Mannan Arora, Mateen Asad, Mubasshirah Khan, Nabian Hasan, Nuh Azad, Salgai Fedaiee, Shakeel Majeed, Shayam Bhuyan, Tasfia Tarannum, Yahya Ali, Dan E. Browne, and P. A. Warburton'}]","Tue, 13 Feb 2024 13:56:51 +0000"
700,Rapid quantum approaches for combinatorial optimisation inspired by optimal state-transfer,https://quantum-journal.org/papers/q-2024-02-13-1253/,"<p>Quantum 8, 1253 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-13-1253\">https://doi.org/10.22331/q-2024-02-13-1253</a><p class=\"abstract\">We propose a new design heuristic to tackle combinatorial optimisation problems, inspired by Hamiltonians for optimal state-transfer. The result is a rapid approximate optimisation algorithm. We provide numerical evidence of the success of this new design heuristic. We find this approach results in a better approximation ratio than the Quantum Approximate Optimisation Algorithm at lowest depth for the majority of problem instances considered, while utilising comparable resources. This opens the door to investigating new approaches for tackling combinatorial optimisation problems, distinct from adiabatic-influenced approaches.</p>","[{'name': 'Robert J. Banks, Dan E. Browne, and P.A. Warburton'}]","Tue, 13 Feb 2024 12:59:17 +0000"
701,Adaptive variational simulation for open quantum systems,https://quantum-journal.org/papers/q-2024-02-13-1252/,"<p>Quantum 8, 1252 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-13-1252\">https://doi.org/10.22331/q-2024-02-13-1252</a><p class=\"abstract\">Emerging quantum hardware provides new possibilities for quantum simulation. While much of the research has focused on simulating closed quantum systems, the real-world quantum systems are mostly open. Therefore, it is essential to develop quantum algorithms that can effectively simulate open quantum systems. Here we present an adaptive variational quantum algorithm for simulating open quantum system dynamics described by the Lindblad equation. The algorithm is designed to build resource-efficient ansatze through the dynamical addition of operators by maintaining the simulation accuracy. We validate the effectiveness of our algorithm on both noiseless simulators and IBM quantum processors and observe good quantitative and qualitative agreement with the exact solution. We also investigate the scaling of the required resources with system size and accuracy and find polynomial behavior. Our results demonstrate that near-future quantum processors are capable of simulating open quantum systems.</p>","[{'name': 'Huo Chen, Niladri Gomes, Siyuan Niu, and Wibe Albert de Jong'}]","Tue, 13 Feb 2024 10:17:44 +0000"
702,Fast simulation of planar Clifford circuits,https://quantum-journal.org/papers/q-2024-02-12-1251/,"<p>Quantum 8, 1251 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-12-1251\">https://doi.org/10.22331/q-2024-02-12-1251</a><p class=\"abstract\">A general quantum circuit can be simulated classically in exponential time. If it has a planar layout, then a tensor-network contraction algorithm due to Markov and Shi has a runtime exponential in the square root of its size, or more generally exponential in the treewidth of the underlying graph. Separately, Gottesman and Knill showed that if all gates are restricted to be Clifford, then there is a polynomial time simulation. We combine these two ideas and show that treewidth and planarity can be exploited to improve Clifford circuit simulation. Our main result is a classical algorithm with runtime scaling asymptotically as $ n^{\\omega/2}$ $\\lt$ $n^{1.19}$ which samples from the output distribution obtained by measuring all $n$ qubits of a planar graph state in given Pauli bases. Here $\\omega$ is the matrix multiplication exponent. We also provide a classical algorithm with the same asymptotic runtime which samples from the output distribution of any constant-depth Clifford circuit in a planar geometry. Our work improves known classical algorithms with cubic runtime.

A key ingredient is a mapping which, given a tree decomposition of some graph $G$, produces a Clifford circuit with a structure that mirrors the tree decomposition and which emulates measurement of the corresponding graph state. We provide a classical simulation of this circuit with the runtime stated above for planar graphs and otherwise $nt^{\\omega-1}$ where $t$ is the width of the tree decomposition. Our algorithm incorporates two subroutines which may be of independent interest. The first is a matrix-multiplication-time version of the Gottesman-Knill simulation of multi-qubit measurement on stabilizer states. The second is a new classical algorithm for solving symmetric linear systems over $\\mathbb{F}_2$ in a planar geometry, extending previous works which only applied to non-singular linear systems in the analogous setting.</p><p class=\"further-content\"></p>","[{'name': 'David Gosset, Daniel Grier, Alex Kerzner, and Luke Schaeffer'}]","Mon, 12 Feb 2024 15:28:25 +0000"
703,Efficient learning of $t$-doped stabilizer states with single-copy measurements,https://quantum-journal.org/papers/q-2024-02-12-1250/,"<p>Quantum 8, 1250 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-12-1250\">https://doi.org/10.22331/q-2024-02-12-1250</a><p class=\"abstract\">One of the primary objectives in the field of quantum state learning is to develop algorithms that are time-efficient for learning states generated from quantum circuits. Earlier investigations have demonstrated time-efficient algorithms for states generated from Clifford circuits with at most $\\log(n)$ non-Clifford gates. However, these algorithms necessitate multi-copy measurements, posing implementation challenges in the near term due to the requisite quantum memory. On the contrary, using solely single-qubit measurements in the computational basis is insufficient in learning even the output distribution of a Clifford circuit with one additional $T$ gate under reasonable post-quantum cryptographic assumptions. In this work, we introduce an efficient quantum algorithm that employs only nonadaptive single-copy measurement to learn states produced by Clifford circuits with a maximum of $O(\\log n)$ non-Clifford gates, filling a gap between the previous positive and negative results.</p>","[{'name': 'Nai-Hui Chia, Ching-Yi Lai, and Han-Hsuan Lin'}]","Mon, 12 Feb 2024 15:20:13 +0000"
704,Stabilizer Codes with Exotic Local-dimensions,https://quantum-journal.org/papers/q-2024-02-12-1249/,"<p>Quantum 8, 1249 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-12-1249\">https://doi.org/10.22331/q-2024-02-12-1249</a><p class=\"abstract\">Traditional stabilizer codes operate over prime power local-dimensions. In this work we extend the stabilizer formalism using the local-dimension-invariant setting to import stabilizer codes from these standard local-dimensions to other cases. In particular, we show that any traditional stabilizer code can be used for analog continuous-variable codes, and consider restrictions in phase space and discretized phase space. This puts this framework on an equivalent footing as traditional stabilizer codes. Following this, using extensions of prior ideas, we show that a stabilizer code originally designed with a finite field local-dimension can be transformed into a code with the same $n$, $k$, and $d$ parameters for any integral domain. This is of theoretical interest and can be of use for systems whose local-dimension is better described by mathematical rings, which permits the use of traditional stabilizer codes for protecting their information as well.</p>",[{'name': 'Lane G. Gunderman'}],"Mon, 12 Feb 2024 14:18:38 +0000"
705,Gravitational quantum switch on a superposition of spherical shells,https://quantum-journal.org/papers/q-2024-02-12-1248/,"<p>Quantum 8, 1248 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-12-1248\">https://doi.org/10.22331/q-2024-02-12-1248</a><p class=\"abstract\">In the absence of a complete theory of quantum gravity, phenomenological models built upon minimal assumptions have been explored for the analysis of possible quantum effects in gravitational systems. Implications of a superposition of geometries have been considered in such models, including the occurrence of processes with indefinite order. In a gravitational quantum switch, in particular, the order of operations applied by two agents on a target system is entangled with the state of the geometry. We consider a model describing the superposition of geometries produced by distinct arrangements of spherical mass shells, and show that a protocol for the implementation of a gravitational quantum switch can be formulated in such a system. The geometries in superposition are identical in an exterior region outside a given radius, and differ within such a radius. The exterior region provides a classical frame from which the superposition of geometries in the interior region can be probed. One of the agents crosses the interior region and becomes entangled with the geometry, which is explored as a resource for the implementation of the quantum switch. Novel features of the protocol include the superposition of nonisometric geometries, the existence of a region with a definite geometry, and the fact that the agent that experiences the superposition of geometries is in free fall, preventing information on the global geometry to be obtained from within its laboratory.</p><p class=\"further-content\">Presentation at Perimeter Institute \"<a href=\"https://pirsa.org/24010078?__hstc=261081490.d970f744ba129097d273c94d9522ba42.1691152397211.1707222076809.1707264080021.47&#38;__hssc=261081490.3.1707264080021&#38;__hsfp=2499221673\">Indefinite temporal order on a superposition of spherical shells</a>\" by  Natália Salomé Móller <span class=\"institution field field--name-field-sp-institution-name field--type-string field--label-hidden field__items\">Slovak Academy of Sciences - Institute of Physics</span></p>","[{'name': 'Natália S. Móller, Bruna Sahdo, and Nelson Yokomizo'}]","Mon, 12 Feb 2024 14:10:00 +0000"
706,Qibolab: an open-source hybrid quantum operating system,https://quantum-journal.org/papers/q-2024-02-12-1247/,"<p>Quantum 8, 1247 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-12-1247\">https://doi.org/10.22331/q-2024-02-12-1247</a><p class=\"abstract\">We present $\\texttt{Qibolab}$, an open-source software library for quantum hardware control integrated with the $\\texttt{Qibo}$ quantum computing middleware framework. $\\texttt{Qibolab}$ provides the software layer required to automatically execute circuit-based algorithms on custom self-hosted quantum hardware platforms. We introduce a set of objects designed to provide programmatic access to quantum control through pulses-oriented drivers for instruments, transpilers and optimization algorithms. $\\texttt{Qibolab}$ enables experimentalists and developers to delegate all complex aspects of hardware implementation to the library so they can standardize the deployment of quantum computing algorithms in a extensible hardware-agnostic way, using superconducting qubits as the first officially supported quantum technology. We first describe the status of all components of the library, then we show examples of control setup for superconducting qubits platforms. Finally, we present successful application results related to circuit-based algorithms.</p>","[{'name': 'Stavros Efthymiou, Alvaro Orgaz-Fuertes, Rodolfo Carobene, Juan Cereijo, Andrea Pasquale, Sergi Ramos-Calderer, Simone Bordoni, David Fuentes-Ruiz, Alessandro Candido, Edoardo Pedicillo, Matteo Robbiati, Yuanzheng Paul Tan, Jadwiga Wilkens, Ingo Roth, José Ignacio Latorre, and Stefano Carrazza'}]","Mon, 12 Feb 2024 13:56:02 +0000"
707,Incompatibility of quantum instruments,https://quantum-journal.org/papers/q-2024-02-12-1246/,"<p>Quantum 8, 1246 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-12-1246\">https://doi.org/10.22331/q-2024-02-12-1246</a><p class=\"abstract\">Quantum instruments describe outcome probability as well as state change induced by measurement of a quantum system. Incompatibility of two instruments, i. e. the impossibility to realize them simultaneously on a given quantum system, generalizes incompatibility of channels and incompatibility of positive operator-valued measures (POVMs). We derive implications of instrument compatibility for the induced POVMs and channels. We also study relation of instrument compatibility to the concept of non-disturbance. Finally, we prove equivalence between instrument compatibility and postprocessing of certain instruments, which we term complementary instruments. We illustrate our findings on examples of various classes of instruments.</p>",[{'name': 'Leevi Leppäjärvi and Michal Sedlák'}],"Mon, 12 Feb 2024 13:43:17 +0000"
708,Impact of conditional modelling for a universal autoregressive quantum state,https://quantum-journal.org/papers/q-2024-02-08-1245/,"<p>Quantum 8, 1245 (2024).</p><a href=\"https://doi.org/10.22331/q-2024-02-08-1245\">https://doi.org/10.22331/q-2024-02-08-1245</a><p class=\"abstract\">We present a generalized framework to adapt universal quantum state approximators, enabling them to satisfy rigorous normalization and autoregressive properties. We also introduce filters as analogues to convolutional layers in neural networks to incorporate translationally symmetrized correlations in arbitrary quantum states. By applying this framework to the Gaussian process state, we enforce autoregressive and/or filter properties, analyzing the impact of the resulting inductive biases on variational flexibility, symmetries, and conserved quantities. In doing so we bring together different autoregressive states under a unified framework for machine learning-inspired ansätze. Our results provide insights into how the autoregressive construction influences the ability of a variational model to describe correlations in spin and fermionic lattice models, as well as ab $initio$ electronic structure problems where the choice of representation affects accuracy. We conclude that, while enabling efficient and direct sampling, thus avoiding autocorrelation and loss of ergodicity issues in Metropolis sampling, the autoregressive construction materially constrains the expressivity of the model in many systems.</p>","[{'name': 'Massimo Bortone, Yannic Rath, and George H. Booth'}]","Thu, 08 Feb 2024 12:49:05 +0000"
709,Reflecting on National Cybersecurity Awareness Month!,https://wp.quantumcomputinginc.com/blog/reflecting-on-national-cybersecurity-awareness-month/,"<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/11/IMG_1003-1-150x150.jpg\" width=\"150\" />As a first-to-market nanophotonic-based quantum technology company, Quantum Computing Inc. publishes a monthly newsletter to share the latest announcements and news involving quantum technologies.&#160;looks back on National Cybersecurity Awareness Month and delves into QCi&#8217;s cybersecurity product offerings, as well as the efforts the company is taking to define its presence in the cybersecurity sector. It&#8217;s ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/reflecting-on-national-cybersecurity-awareness-month/\">Read Article</a></div>",[{'name': 'QCi'}],"Thu, 02 Nov 2023 02:18:13 +0000"
710,September’s Cyber Defense: Introducing QCi’s Cyber Solutions,https://wp.quantumcomputinginc.com/blog/septembers-cyber-defense-introducing-qcis-cyber-solutions/,"<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/10/1695248209708-150x150.jpeg\" width=\"150\" />As a first-to-market nanophotonic-based quantum technology company, Quantum Computing Inc. publishes a monthly newsletter to share the latest announcements and news involving quantum technologies.&#160;This month&#8217;s issue focuses on QCi&#8217;s cybersecurity solutions, partnerships, and participation in cyber conferences in the United States and overseas. World Says Cybersecurity, We Say Solutions Our QCi Team, including&#160;Robert Liscouski, CEO;&#160;Dr. ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/septembers-cyber-defense-introducing-qcis-cyber-solutions/\">Read Article</a></div>",[{'name': 'QCi'}],"Thu, 05 Oct 2023 11:39:03 +0000"
711,Quantum Leaps Ahead – QCi’s R&D Surge!,https://wp.quantumcomputinginc.com/blog/quantum-leaps-ahead-qcis-rd-surge/,"<img alt=\"QCi scientists in the lab\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/08/Untitled-design-29-150x150.png\" width=\"150\" />As a first-to-market nanophotonic-based quantum technology company, Quantum Computing Inc. publishes a monthly newsletter to share the latest announcements and news involving quantum technologies. This month's issue highlights QCi's research and development projects, covering what our team has been working on, our newest products, and upcoming events.",[{'name': 'Quantum Computing Inc.'}],"Wed, 30 Aug 2023 13:33:22 +0000"
712,Flying Cars Meet Quantum Computing,https://wp.quantumcomputinginc.com/blog/flying-cars-meet-quantum-computing/,<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/08/Untitled-design-42-150x150.png\" width=\"150\" />Experience the not-so-distant future at the crossroads of flying cars and quantum computing. Aerial vehicles are poised to take to the sky and Quantum Computing Inc.’s technology is paving the way. Read our CTO’s insights on the trajectory of quantum technology and its revolutionary impact on the future of mobility.,[{'name': 'QCi'}],"Fri, 25 Aug 2023 16:10:44 +0000"
713,Navigating the Landscape of Licenses for Cybersecurity and US Patents,https://wp.quantumcomputinginc.com/blog/navigating-the-landscape-of-licenses-for-cybersecurity-and-us-patents/,"<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/08/1FB3AB5C-8AEC-436E-B629-045A591FDA08-150x150.png\" width=\"150\" />In today&#8217;s fast-changing digital era, where cyber threats are an increasing concern, defending new cybersecurity solutions has become necessary. As technology continues to influence our society, cybersecurity licenses and US patents have grown in relevance. But what are the complexities? How do you obtain such a license? In this article, we&#8217;ll look into the intricacies ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/navigating-the-landscape-of-licenses-for-cybersecurity-and-us-patents/\">Read Article</a></div>",[{'name': 'QCi'}],"Tue, 15 Aug 2023 14:41:02 +0000"
714,QCi & Quantum in the News,https://wp.quantumcomputinginc.com/blog/qci-quantum-in-the-news/,"<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/07/53002877954_439bd21781_o-150x150.jpg\" width=\"150\" />As a first-to-market nanophotonic-based quantum technology company, Quantum Computing Inc. publishes a monthly newsletter to share the latest announcements and news involving quantum technologies. This month features QCi&#8217;s new products and subcontract awards with NASA. Quantum Computing Inc. Full Stack Quantum Solutions &#124; Value for Customers Today The Future of Quantum, Today Robert Liscouski, QCi ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/qci-quantum-in-the-news/\">Read Article</a></div>",[{'name': 'Quantum Computing Inc.'}],"Tue, 25 Jul 2023 14:56:20 +0000"
715,Intro to Quantum Random Number Generators,https://wp.quantumcomputinginc.com/blog/intro-to-quantum-random-number-generators/,"<img alt=\"Intro to Quantum Random Number Generators\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/05/Intro-to-Quantum-Random-Number-Generators-150x150.jpg\" width=\"150\" />This is part three of a three-part series on quantum security – how it works, the implications for society and business, and what it will mean for leaders of organizations that process sensitive data and rely on keeping that data secure. Part one looked at the basics of quantum computing and cryptography. Part two talked ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/intro-to-quantum-random-number-generators/\">Read Article</a></div>",[{'name': 'David Bean'}],"Tue, 09 May 2023 13:51:39 +0000"
716,Why QCi uniform Quantum Random Number Generator?,https://wp.quantumcomputinginc.com/blog/why-qci-uniform-quantum-random-number-generator/,"<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/04/qrng-blog-post-2-150x150.jpg\" width=\"150\" />From the dawn of time, humans have survived because of their ability to find and identify patterns. For example, patterns helped us distinguish edible berries from poisonous ones, related agricultural activities to seasons, and navigate the world using the stars. These days data mining, machine learning, neural networks, time series analysis, and regression analysis are ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/why-qci-uniform-quantum-random-number-generator/\">Read Article</a></div>","[{'name': 'Malvika Garikapati, Quantum Physicist'}]","Wed, 12 Apr 2023 20:39:37 +0000"
717,What does “steal now decrypt later” mean for cybersecurity?,https://wp.quantumcomputinginc.com/blog/what-does-steal-now-decrypt-later-mean-for-cybersecurity/,"<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://wp.quantumcomputinginc.com/wp-content/uploads/2023/04/What-does-steal-now-decrypt-later-mean-for-cybersecurity-scaled-1-150x150.jpg\" width=\"150\" />This is part two of a three-part series on quantum security – how it works, the implications for society and business, and what it will mean for leaders of organizations that process sensitive data and rely on keeping that data secure. Part one looked at the basics of quantum computing and cryptography. Part two focuses ... <div class=\"read-more-link\"><a class=\"more-link\" href=\"https://wp.quantumcomputinginc.com/blog/what-does-steal-now-decrypt-later-mean-for-cybersecurity/\">Read Article</a></div>",[{'name': 'QCi'}],"Tue, 11 Apr 2023 20:27:40 +0000"
718,Phase Genomics gets $1.5M grant from Gates Foundation to fight cow burp methane,https://www.geekwire.com/2024/phase-genomics-gets-1-5m-grant-from-gates-foundation-to-fight-cow-burp-methane/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"533\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/51037438917_d9691b4d1d_c1-1.jpg\" width=\"799\" /><br />Seattle biotech startup Phase Genomics is receiving $1.5 million from the Bill &#38; Melinda Gates Foundation to fund research into two important areas: killing drug-resistant bacteria and battling methane-producing microorganisms that live in the guts of cows and other ruminants. The new grant will support a year-long project to create an antimicrobial discovery platform to tackle these challenges. The focus is on Campylobacter infections, which are among the most common human infections and can cause severe diarrhea. Methane released in cow burps are the No. 1 source of greenhouse gases for the agricultural sector. The startup&#8217;s work is centered on&#8230; <a href=\"https://www.geekwire.com/2024/phase-genomics-gets-1-5m-grant-from-gates-foundation-to-fight-cow-burp-methane/\">Read More</a>",[{'name': 'Lisa Stiffler'}],"Tue, 05 Mar 2024 18:33:50 +0000"
719,"Glowforge releases Spark, another low-priced 3D laser engraver to attract more home crafters",https://www.geekwire.com/2024/glowforge-releases-spark-another-low-priced-3d-laser-engraver-to-attract-more-home-crafters/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"780\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/Spark-Head-On-Shadow-1-1260x780.png\" width=\"1260\" /><br />Seattle-based 3D laser engraver maker Glowforge is making another pitch to home crafters with another lower-priced machine, the company announced Tuesday. Less than a year after the release of the $1,200 Aura — designed to attract a wider audience of consumers —&#160;Glowforge is releasing the new Spark, which will sell for $699. Glowforge&#8217;s two higher-end machines include the Glowforge Plus ($4,995) and Glowforge Pro ($6,995). The Spark is a little smaller than the Aura, but is built around the same laser technology, capable of cutting materials ranging from paper to leather to wood. The bed size of the Spark is&#8230; <a href=\"https://www.geekwire.com/2024/glowforge-releases-spark-another-low-priced-3d-laser-engraver-to-attract-more-home-crafters/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Tue, 05 Mar 2024 17:00:00 +0000"
720,Jeff Bezos bumps Elon Musk from billionaires top spot with net worth of $200.3B,https://www.geekwire.com/2024/jeff-bezos-bumps-elon-musk-from-billionaires-top-spot-with-net-worth-of-200-3b/,"<img alt=\"Musk and Bezos\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"542\" src=\"https://cdn.geekwire.com/wp-content/uploads/2019/04/190410-musk-bezos.jpg\" width=\"933\" /><br />Jeff Bezos is back on top of the Bloomberg Billionaires Index for the first time since 2021, overtaking Elon Musk as the richest person in the world with a net worth of $200.3 billion. Bloomberg reported that Musk lost his top ranking on Monday after Tesla shares tumbled 7.2%, leaving the automaker&#8217;s CEO with a net worth of $197.7 billion. The stock fell after February vehicle shipments fell in China, the company&#8217;s largest market. Bezos&#8217; wealth has been on an upward trajectory thanks to the same trend for Amazon shares, which have more than doubled since late 2022. Tesla, meanwhile,&#8230; <a href=\"https://www.geekwire.com/2024/jeff-bezos-bumps-elon-musk-from-billionaires-top-spot-with-net-worth-of-200-3b/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Tue, 05 Mar 2024 16:25:49 +0000"
721,"Enzzo, a PSL spinout led by Seattle startup vet, raises $3M to use AI for hardware development",https://www.geekwire.com/2024/enzzo-a-psl-spinout-led-by-seattle-startup-vet-raises-3m-to-use-ai-for-hardware-development/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"840\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/enzzo-team-1260x840.jpg\" width=\"1260\" /><br />Building hardware is hard. It can be especially challenging in the early part of product creation, when designers need to set parameters and requirements, also known as the &#8220;definition phase.&#8221; Can AI help speed up that process? That&#8217;s what a group of longtime investors are betting on with a $3 million seed investment in Enzzo, a new Seattle startup that spun out of Pioneer Square Labs and aims to accelerate hardware development. The 4-person startup is led by veteran entrepreneur and tech leader Ford Davidson, who most recently spent time at Meta and Amazon in product leadership roles. He previously&#8230; <a href=\"https://www.geekwire.com/2024/enzzo-a-psl-spinout-led-by-seattle-startup-vet-raises-3m-to-use-ai-for-hardware-development/\">Read More</a>",[{'name': 'Taylor Soper'}],"Tue, 05 Mar 2024 16:24:29 +0000"
722,Will AI change how we shop? What it’s like to use Amazon’s new Rufus assistant,https://www.geekwire.com/2024/will-ai-change-how-we-shop-what-its-like-to-use-amazons-new-rufus-assistant/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"841\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/rufus2-1260x841.jpg\" width=\"1260\" /><br />Searching on Amazon for a trainer to convert my road bike into a stationary cycle, I knew the make and model of my bike, but had no clue about its wheel size, or whether it would be compatible with the products I was considering. So I pulled up from the bottom of my screen in the Amazon app, and called on Rufus for help: &#8220;Can you recommend a trainer for my bike, which is a Raleigh cadent 2?&#8221; Rufus responded, &#8220;The Raleigh Cadent 2 is a versatile hybrid bike that can handle both road and light off-road riding. When choosing&#8230; <a href=\"https://www.geekwire.com/2024/will-ai-change-how-we-shop-what-its-like-to-use-amazons-new-rufus-assistant/\">Read More</a>",[{'name': 'Todd Bishop'}],"Tue, 05 Mar 2024 10:00:00 +0000"
723,"Agility Robotics names new CEO: Peggy Johnson, former Magic Leap CEO and Microsoft exec",https://www.geekwire.com/2024/agility-robotic/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"495\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/peggy-final.jpg\" width=\"373\" /><br />Peggy Johnson, the former Microsoft executive who stepped down as Magic Leap CEO last fall, is the new CEO of Agility Robotics, the Corvalis, Ore.-based company known for the Digit bipedal humanoid warehouse robot. Announcing the news this morning, Agility said Johnson will lead its &#8220;next phase of growth, focusing on sales, strategic industry partnerships, future fundraising, and delivering robots at scale to meet overwhelming demand.&#8221; Damion Shelton, the company&#8217;s CEO since its inception in 2015, will now serve as Agility&#8217;s president as part of Johnson&#8217;s leadership team. Johnson will be based in California in the new role. Agility has&#8230; <a href=\"https://www.geekwire.com/2024/agility-robotic/\">Read More</a>",[{'name': 'Todd Bishop'}],"Mon, 04 Mar 2024 21:18:39 +0000"
724,"Peer-to-peer laundry startup Loopie acquires Bidbud, a gig economy job-bidding platform",https://www.geekwire.com/2024/peer-to-peer-laundry-startup-loopie-acquires-bidbud-a-gig-economy-job-bidding-platform/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"584\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/loopiebidbud-1260x584.jpeg\" width=\"1260\" /><br />Loopie, the Seattle peer-to-peer laundry service, announced the acquisition Monday of Bidbud, a gig economy platform that allows clients to post job opportunities that can be bid on by freelancers and service providers. In a news release, Loopie called the move a strategic way to revolutionize its mobile app marketplace. Launched in July 2018, Loopie is led by co-founder and CEO John Vincent Lee. The mobile app laundromat, connects people who don’t have the time or desire to deal with their own dirty laundry with people who can wash and dry on their own and earn money doing it. Lee&#8230; <a href=\"https://www.geekwire.com/2024/peer-to-peer-laundry-startup-loopie-acquires-bidbud-a-gig-economy-job-bidding-platform/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Mon, 04 Mar 2024 19:31:11 +0000"
725,"Blue Origin targets 2025 for cargo lander’s inaugural moon trip, with humans to follow",https://www.geekwire.com/2024/blue-origin-2025-moon-lander/,"<img alt=\"Blue Moon MK1 lander\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"744\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/240304-bluemoon2-1260x744.jpg\" width=\"1260\" /><br />Jeff Bezos&#8217; Blue Origin space venture is aiming to send an uncrewed lander to the surface of the moon in the next 12 to 16 months, according to the executive in charge of the development program. John Couluris, senior vice president for lunar permanence at Blue Origin, provided an update on the company&#8217;s moon lander program on CBS&#8217; &#8220;60 Minutes&#8221; news program on Sunday. &#8220;We&#8217;re expecting to land on the moon between 12 and 16 months from today,&#8221; Couluris said. &#8220;I understand I&#8217;m saying that publicly, but that&#8217;s what our team is aiming towards.&#8221; Couluris was referring to a pathfinder&#8230; <a href=\"https://www.geekwire.com/2024/blue-origin-2025-moon-lander/\">Read More</a>",[{'name': 'Alan Boyle'}],"Mon, 04 Mar 2024 18:59:41 +0000"
726,"Data from Seattle food delivery drivers shows higher hourly earnings, but less customer demand",https://www.geekwire.com/2024/data-from-seattle-food-delivery-drivers-shows-higher-hourly-earnings-but-less-customer-demand/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"840\" src=\"https://cdn.geekwire.com/wp-content/uploads/2019/06/UberEats_Photo_Home_Delivery_Handoff-1-1260x840.jpg\" width=\"1260\" /><br />Seattle-area gig workers are making higher hourly wages while they&#8217;re delivering food for platforms such as Uber Eats and DoorDash following the implementation of a new minimum wage law. But they&#8217;re also getting fewer tips, and consumer demand has likely fallen. Those are some takeaways from data provided to GeekWire from Solo, a Seattle-based software startup that helps more than 250,000 independent contractors manage their earnings. The controversial law went into effect in January and set a minimum per-minute and per-mile amount for app-based workers delivering for tech platforms. The companies responded by adding substantial new fees for consumers — $5 for each order — and&#8230; <a href=\"https://www.geekwire.com/2024/data-from-seattle-food-delivery-drivers-shows-higher-hourly-earnings-but-less-customer-demand/\">Read More</a>",[{'name': 'Taylor Soper'}],"Mon, 04 Mar 2024 17:09:17 +0000"
727,Why India’s thriving software talent base is important for the Seattle innovation ecosystem,https://www.geekwire.com/2024/why-indias-thriving-software-talent-base-is-important-for-the-seattle-innovation-ecosystem/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"840\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/7k5a3657-1260x840.jpg\" width=\"1260\" /><br />Editor&#8217;s note: This guest post was written by Kellan Carter, founding partner at Bellevue, Wash.-based venture capital firm FUSE. On a recent trip to India, something caught my attention inside a tech company office. Bunk beds. The Chennai-based team working for Zuper turned their conference room into a sleeping area for employees who were staying late at the office working to improve the company’s software platform. This was just one example highlighting the unmatched determination of founders and teams in India — which has become a critical part of the innovation ecosystem in Seattle despite being halfway across the world.&#8230; <a href=\"https://www.geekwire.com/2024/why-indias-thriving-software-talent-base-is-important-for-the-seattle-innovation-ecosystem/\">Read More</a>",[{'name': 'Kellan Carter'}],"Mon, 04 Mar 2024 16:00:00 +0000"
728,Protein design pioneer David Baker on why sharing code is key to building biotech startups,https://www.geekwire.com/2024/protein-design-pioneer-david-baker-on-why-sharing-code-is-important-for-biotech-startups/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"932\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/Jenny-Cronin-and-David-Baker-5-1260x932.jpg\" width=\"1260\" /><br />The Institute for Protein Design at the University of Washington is a startup factory, spinning out companies developing new protein-based therapeutics, industrial enzymes, materials, biosensors and more. A key to the institute&#8217;s entrepreneurial success is a mindset of open inquiry and collaboration &#8212; and an emphasis on making the code for its protein-design tools readily available. “I really believed from the beginning that we should share everything that we did,” said IPD director and UW professor David Baker, speaking at an event on campus in Seattle last week. More than two decades ago, Baker and his colleagues developed an early&#8230; <a href=\"https://www.geekwire.com/2024/protein-design-pioneer-david-baker-on-why-sharing-code-is-important-for-biotech-startups/\">Read More</a>",[{'name': 'Charlotte Schubert'}],"Mon, 04 Mar 2024 15:53:45 +0000"
729,"Week in Review: Most popular stories on GeekWire for the week of Feb. 25, 2024",https://www.geekwire.com/2024/geekwire-weekly-roundup-2024-02-25/,"<img alt=\"GeekWire Week in Review\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"630\" src=\"https://cdn.geekwire.com/wp-content/uploads/2015/11/geekwire-week-in-review1.png\" width=\"1200\" /><br />See the technology stories that people were reading on GeekWire for the week of Feb. 25, 2024.&#8230; <a href=\"https://www.geekwire.com/2024/geekwire-weekly-roundup-2024-02-25/\">Read More</a>",[{'name': 'GeekWire'}],"Sun, 03 Mar 2024 16:00:06 +0000"
730,Pfizer to close Seagen manufacturing plant in Seattle area following $43B acquisition,https://www.geekwire.com/2024/pfizer-to-close-seagen-manufacturing-plant-in-seattle-area-following-43b-acquisition/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"840\" src=\"https://cdn.geekwire.com/wp-content/uploads/2023/03/Seagen-Building-10-Lobby-1-1260x840.jpeg\" width=\"1260\" /><br />Pharma giant Pfizer, fresh off its $43 billion acquisition of Seagen, said it will shut down construction on a new 270,000 square-foot manufacturing facility Seagen was building north of Seattle near its headquarters. Previously: How Pfizer’s $43B acquisition of Seagen may impact Seattle and broader biotech market",[{'name': 'Taylor Soper'}],"Sat, 02 Mar 2024 16:19:40 +0000"
731,"Seattle vanlife gurus see tech and AI’s potential as a copilot, to boost human connections on road trips",https://www.geekwire.com/2024/seattle-vanlife-gurus-see-tech-and-ais-potential-as-a-copilot-to-boost-human-connections-on-road-trips/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"921\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/peacevans1-1260x921.jpeg\" width=\"1260\" /><br />With all the makings of a buddy road trip adventure, two longtime Seattle friends and tech veterans have teamed up to breathe new life into a popular travel app under the umbrella of a thriving business built around a love for &#8220;vanlife.&#8221; Jordan Schwartz, the software entrepreneur who previously founded and led Seattle startup Pathable, is the new chief product officer at Sēkr, an app to help travelers plan trips, find campsites and more. Founded in 2018 and originally based in San Diego, Sēkr was acquired last year by Peace Vans and owner Harley Sitner, whose nationally known business south&#8230; <a href=\"https://www.geekwire.com/2024/seattle-vanlife-gurus-see-tech-and-ais-potential-as-a-copilot-to-boost-human-connections-on-road-trips/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Sat, 02 Mar 2024 16:00:00 +0000"
732,"How Microsoft, T-Mobile, and Amazon use big bets to build durable businesses in turbulent times",https://www.geekwire.com/2024/how-microsoft-t-mobile-and-amazon-use-big-bets-to-build-durable-businesses-in-turbulent-times/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"813\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/106-crop-1260x813.jpg\" width=\"1260\" /><br />At the outset of their new book, &#8220;Big Bet Leadership,&#8221; authors John Rossman and Kevin McCaffrey identify three &#8220;mega forces&#8221; that they believe could define the years ahead for businesses and the economy: They write in the book, &#8220;These mega forces will feed into each other like a vortex, building an overriding theme for business and society—that of a chaotic environment of dramatic change with successful business operators realizing productivity and cost model advantages that separate them from their competition.&#8221; Their thesis: companies that thrive in this chaos will be the ones that master the art of &#8220;big bets,&#8221; transformative&#8230; <a href=\"https://www.geekwire.com/2024/how-microsoft-t-mobile-and-amazon-use-big-bets-to-build-durable-businesses-in-turbulent-times/\">Read More</a>",[{'name': 'Todd Bishop'}],"Sat, 02 Mar 2024 15:48:11 +0000"
733,Transplant organ freezing and rewarming technique wins U. of Washington health innovation challenge,https://www.geekwire.com/2024/transplant-organ-freezing-and-rewarming-technique-wins-u-of-washington-health-innovation-challenge/,"<img alt=\"BioLegacy\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"600\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/2024-HIC_Grand-Prize_BioLegacy_800x600.jpeg\" width=\"800\" /><br />A team working on prolonging the lifespan of transplant organs took home the top prize in the 9th annual Hollomon Health Innovation Challenge at the University of Washington. BioLegacy, made up of Seattle University students (mechanical engineering, chemistry, and finance) and University of Washington students (mechanical engineering) was awarded the $15,000 WRF Capital Grand Prize for its organ cryopreservation and rewarming innovation. The team was one of 22 that competed in this year&#8217;s final round of competition at the UW Foster School’s Buerk Center for Entrepreneurship. The challenge attracted a record-breaking 53 applicants from student teams across the Pacific Northwest and British Columbia.&#8230; <a href=\"https://www.geekwire.com/2024/transplant-organ-freezing-and-rewarming-technique-wins-u-of-washington-health-innovation-challenge/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Fri, 01 Mar 2024 20:46:34 +0000"
734,"5 days in the office? Some tech startups are bringing workers together all week, every week",https://www.geekwire.com/2024/5-days-in-the-office-these-tech-startups-are-bringing-workers-together-all-week-every-week/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"762\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/20240212_141204-EDIT-1260x762.jpg\" width=\"1260\" /><br />BELLEVUE, Wash. — At precisely 2 p.m. Pacific time on a recent Monday afternoon, employees of the technology startup Statsig were alerted to their regular standup meeting not by a notification on their screens, or a buzzing of their devices, but by the sound of engineering lead Marcos Arribas tapping the taut surface of one of several musical instruments specially designated for the purpose. This is the drumbeat of daily work in a place where workers are in the office every day. The fact that it&#8217;s a novelty shows just how much our world has changed. At a time when&#8230; <a href=\"https://www.geekwire.com/2024/5-days-in-the-office-these-tech-startups-are-bringing-workers-together-all-week-every-week/\">Read More</a>",[{'name': 'Todd Bishop'}],"Fri, 01 Mar 2024 16:38:04 +0000"
735,Tech Moves: AWS vet lands at health startup; Lumen hires longtime Microsoft GM; ex-Qualtrics exec joins Typeform board,https://www.geekwire.com/2024/tech-moves-aws-vet-lands-at-health-startup-ex-qualtrics-exec-joins-typeform-board/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"800\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/03/1632520923858.jpeg\" width=\"800\" /><br />— Harshit Shah, a former head of engineering at Amazon Web Services, is now chief technology officer at Boston, Mass-based healthcare software company Kyruus Health. Shah, based in the Seattle region, most recently held the same position at Spring Health, a mental health company. He also previously spent a decade at Microsoft in various managerial roles. Founded in 2010, Kyruus describes itself as a &#8220;care access platform&#8221; that develops various software products for health systems, hospitals, medical groups, and health plans. The company raised a $42 million round in 2020. It has offices in the Portland, Ore., area and has&#8230; <a href=\"https://www.geekwire.com/2024/tech-moves-aws-vet-lands-at-health-startup-ex-qualtrics-exec-joins-typeform-board/\">Read More</a>",[{'name': 'Taylor Soper'}],"Fri, 01 Mar 2024 16:34:26 +0000"
736,"Univ. of Washington’s famed cherry blossoms have some bright, tech-infused competition on campus",https://www.geekwire.com/2024/univ-of-washingtons-famed-cherry-blossoms-have-some-bright-tech-infused-competition-on-campus/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"945\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/UWtree1-1260x945.jpeg\" width=\"1260\" /><br />The cherry blossoms at the University of Washington offer a spectacular welcome to spring every year on the school&#8217;s Seattle campus. Thursday night, a brightly shining, tech-infused tree in front of the Husky Union Building got a jump on nature. BECU, in partnership with the UW, unveiled the 12-foot-tall work of art in a promotion aimed at symbolizing the credit union&#8217;s &#8220;commitment to supporting the UW community&#8217;s financial well-being.&#8221; The colorful specimen features 550 3D-printed blossoms with LED lights and about 1,200 laser-cut mirrored mylar leaves that flutter and reflect the illumination source. It was created by Intention Space, a&#8230; <a href=\"https://www.geekwire.com/2024/univ-of-washingtons-famed-cherry-blossoms-have-some-bright-tech-infused-competition-on-campus/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Fri, 01 Mar 2024 15:45:34 +0000"
737,Clean energy and power grid projects in Washington land federal and state funding,https://www.geekwire.com/2024/clean-energy-and-power-grid-projects-in-washington-land-federal-and-state-funding/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"839\" src=\"https://cdn.geekwire.com/wp-content/uploads/2021/08/american-public-power-association-XGAZzyLzn18-unsplash-1260x839.jpg\" width=\"1260\" /><br />Clean energy projects for Washington groups including public utilities, the Yakama Nation, and others will receive funding from grants announced this week by the U.S. Department of Energy and the state&#8217;s Department of Commerce. The Yakama Nation will receive up to $32 million from DOE to accelerate a project to create a &#8220;cutting-edge system&#8221; that will transform open-water irrigation canals into an in-ground pipeline system that will generate micro-hydropower and solar energy. The upgrade will conserve water and save residents money on their utility bills, according to DOE. The project includes additional plans to install solar panels on the Yakama&#8230; <a href=\"https://www.geekwire.com/2024/clean-energy-and-power-grid-projects-in-washington-land-federal-and-state-funding/\">Read More</a>",[{'name': 'Lisa Stiffler'}],"Fri, 01 Mar 2024 00:36:33 +0000"
738,"With $1.2B in assets, the Paul Allen Family Foundation evolves — and stays true to PNW roots",https://www.geekwire.com/2024/with-1-2b-in-assets-the-paul-allen-family-foundation-evolves-and-stays-true-to-its-pnw-roots/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"942\" src=\"https://cdn.geekwire.com/wp-content/uploads/2023/09/troll1-1260x942.jpeg\" width=\"1260\" /><br />Paul Allen is synonymous with philanthropic giving in the Pacific Northwest. Thirty-six years ago, the late Microsoft co-founder and his sister Jody Allen created their family foundation, which grants more than $55 million annually in charitable funding. Then in 2018, Paul died suddenly at the age of 65, triggering a reorganization of the effort. It has been five years now since the philanthropy created a board of directors and brought &#8220;more structure and formality&#8221; to the organization, said Lara Littlefield, the foundation&#8217;s executive director of partnerships and programs. The foundation&#8217;s oversight is still lean &#8212; namely Jody and a two-person&#8230; <a href=\"https://www.geekwire.com/2024/with-1-2b-in-assets-the-paul-allen-family-foundation-evolves-and-stays-true-to-its-pnw-roots/\">Read More</a>",[{'name': 'Lisa Stiffler'}],"Thu, 29 Feb 2024 21:38:50 +0000"
739,"Seattle studio Ridgeline Games, led by ‘Halo’ co-creator, closes as part of EA cuts",https://www.geekwire.com/2024/seattle-studio-ridgeline-games-led-by-halo-co-creator-closes-as-part-of-ea-cuts/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"709\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/Battlefield-2042-1260x709.jpg\" width=\"1260\" /><br />A new wave of layoffs at video game mega-studio Electronic Arts has multiple impacts on the Pacific Northwest gaming industry, including the end of development on a Star Wars video game and the effective closure of a developer based in Seattle. Electronic Arts (EA), based in Redwood City, Calif., is one of the largest independent game publishers in the modern industry, owing to the strength of franchises like Battlefield, Apex Legends, last year’s Dead Space remake, and its annually-released football simulator Madden. In addition to affiliates around the world, EA started new investments in the Seattle area in the last&#8230; <a href=\"https://www.geekwire.com/2024/seattle-studio-ridgeline-games-led-by-halo-co-creator-closes-as-part-of-ea-cuts/\">Read More</a>",[{'name': 'Thomas Wilde'}],"Thu, 29 Feb 2024 20:21:34 +0000"
740,"Seattle biotech company Kineta lays off majority of staff, including its CEO",https://www.geekwire.com/2024/seattle-biotech-company-kineta-lays-off-majority-of-staff-including-its-ceo/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"450\" src=\"https://cdn.geekwire.com/wp-content/uploads/2022/06/Shawn_Iadonato.jpeg\" width=\"300\" /><br />Kineta announced Thursday that it is laying off 64% of its workforce, or seven employees — including its CEO Shawn Iadonato — as it undergoes a restructuring process.",[{'name': 'Taylor Soper'}],"Thu, 29 Feb 2024 18:48:36 +0000"
741,"2024 GeekWire Awards nominations close today, so act fast to honor the best in Pacific NW tech",https://www.geekwire.com/2024/2024-geekwire-awards-nominations-close-today-so-act-fast-to-honor-the-best-in-pacific-nw-tech/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"840\" src=\"https://cdn.geekwire.com/wp-content/uploads/2023/05/20230518_GeekWire_Awards_1150-1260x840.jpg\" width=\"1260\" /><br />You&#8217;ve probably met plenty of deadlines for code releases, product launches and anything else tech related that makes sense, so here&#8217;s another timely item to take care of: get your nominations in now for the 2024 GeekWire Awards! Today is the last day for the community to nominate amazing entrepreneurs, innovators, deal makers and non-profit leaders that we&#8217;ll honor across more than a dozen categories at our annual event, May 9 in Seattle. Are you currently working in what feels like the Workplace of the Year? Nominate that place! Did you just close out of an app or website with&#8230; <a href=\"https://www.geekwire.com/2024/2024-geekwire-awards-nominations-close-today-so-act-fast-to-honor-the-best-in-pacific-nw-tech/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Thu, 29 Feb 2024 16:51:00 +0000"
742,Oceanography professors transform a research tool into a startup that’s sucking CO2 from seawater,https://www.geekwire.com/2024/oceanography-professors-transform-a-research-tool-into-a-startup-thats-sucking-co2-from-seawater/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"945\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/PXL_20240221_003043310-1260x945.jpg\" width=\"1260\" /><br />A decade ago, University of Washington oceanographers Julian Sachs and Alex Gagnon were working in a tropical paradise, studying the impacts of climate change on coral reefs surrounding remote islands in French Polynesia. They were focused on ocean acidification, which is happening as seawater soaks up much of the excess carbon dioxide produced by burning fossil fuels. The scientists were researching the effect of ocean conditions predicted for the end of the century. They devised a system for pulling carbon dioxide out of seawater from deep in the ocean and using it to create more acidic conditions at their experimental&#8230; <a href=\"https://www.geekwire.com/2024/oceanography-professors-transform-a-research-tool-into-a-startup-thats-sucking-co2-from-seawater/\">Read More</a>",[{'name': 'Lisa Stiffler'}],"Thu, 29 Feb 2024 16:43:07 +0000"
743,Former AWS engineers raise $3M to take on tech giants with ‘world’s fastest spreadsheet’,https://www.geekwire.com/2024/former-aws-engineers-raise-3m-to-take-on-tech-giants-with-worlds-fastest-spreadsheet/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"838\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/rowzerofounders-1260x838.jpg\" width=\"1260\" /><br />When a spreadsheet gets big, your computer can get slow. Row Zero wants to help. The Seattle startup that describes its product as the &#8220;world&#8217;s fastest spreadsheet&#8221; just raised $3 million to take on the likes of Microsoft and Google with a spreadsheet tool designed for complex analysis or big datasets. Founded in 2021 by former engineers at Amazon Web Services, the company is targeting a wide range of customers that use Row Zero for business intelligence, finance, operations, marketing, and more. It&#8217;s aiming to fill a gap between pricey spreadsheet tools and software that requires programming skills. &#8220;Our biggest&#8230; <a href=\"https://www.geekwire.com/2024/former-aws-engineers-raise-3m-to-take-on-tech-giants-with-worlds-fastest-spreadsheet/\">Read More</a>",[{'name': 'Taylor Soper'}],"Thu, 29 Feb 2024 16:42:30 +0000"
744,Global health nonprofit PATH moving to new HQ space in Seattle that was once home to Tableau,https://www.geekwire.com/2024/global-health-nonprofit-path-moving-to-new-hq-space-in-seattle-that-was-once-home-to-tableau/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"500\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/westdock1.jpeg\" width=\"750\" /><br />PATH, the global health nonprofit, is moving to a new headquarters space in Seattle&#8217;s Fremont neighborhood after 15 years in South Lake Union. PATH announced a lease agreement Thursday with real estate development group Hess Callahan Grey Group to take over the entire 52,000-square-foot space in the West Dock building at 437 N. 34th St. in 2025. Located on the Burke-Gilman Trail with views of the Lake Washington Ship Canal, and next to offices for Google and Adobe, West Dock was once home to Sound Mind &#38; Body Gym. But the building was purchased and renovated in 2014 and turned&#8230; <a href=\"https://www.geekwire.com/2024/global-health-nonprofit-path-moving-to-new-hq-space-in-seattle-that-was-once-home-to-tableau/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Thu, 29 Feb 2024 08:01:00 +0000"
745,Computer scientist Cecilia Aragon traces her trajectory from stunt flying to a startup,https://www.geekwire.com/2024/computer-scientist-cecilia-aragon-aerobatic-startup/,"<img alt=\"Cecilia Aragon at Women&#039;s Leadership Conference in Bellevue, Wash.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"972\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/aragon01-0886-1260x972.jpg\" width=\"1260\" /><br />BELLEVUE, Wash. &#8212; Three decades ago, Cecilia Aragon made aviation history as the first Latina to earn a place on the U.S. Unlimited Aerobatic Team. She went on to write a book about it, titled &#8220;Flying Free.&#8221; Today, she&#8217;s still flying free, as a professor and data scientist in the University of Washington &#8212; and as the co-founder of a Seattle startup that aims to commercialize her research. Aragon recounted her personal journey today during a talk at the Women&#8217;s Leadership Conference, presented by the Bellevue Chamber. The conference brought nearly 400 attendees to Bellevue&#8217;s Meydenbauer Center to hear about&#8230; <a href=\"https://www.geekwire.com/2024/computer-scientist-cecilia-aragon-aerobatic-startup/\">Read More</a>",[{'name': 'Alan Boyle'}],"Thu, 29 Feb 2024 06:08:53 +0000"
746,Uber and Lyft drivers will get expanded death benefits thanks to new Washington state law,https://www.geekwire.com/2024/uber-and-lyft-drivers-will-get-expanded-death-benefits-thanks-to-new-washington-state-law/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"600\" src=\"https://cdn.geekwire.com/wp-content/uploads/2020/01/bigstock-Chicago-Circa-June-Ube-308733928.jpg\" width=\"900\" /><br />The families of drivers in Washington state working for transportation network companies such as Uber and Lyft will receive enhanced survivor death benefits under a new bill passed by state lawmakers. The bill, HB 2382, provides death benefits under the state workers&#8217; compensation system for drivers and their families regardless of whether they have a passenger or are waiting to receive a trip. The existing law does not provide drivers with survivor death benefits if a driver is killed while logged into one of the platforms but not driving a customer. Five rideshare drivers have been murdered in Washington state&#8230; <a href=\"https://www.geekwire.com/2024/uber-and-lyft-drivers-will-get-expanded-death-benefits-thanks-to-new-washington-state-law/\">Read More</a>",[{'name': 'Taylor Soper'}],"Wed, 28 Feb 2024 20:20:35 +0000"
747,Glowforge gets in legal tangle with tech ‘activist’ who questions safety of startup’s laser engravers,https://www.geekwire.com/2024/glowforge-gets-in-legal-tangle-with-tech-activist-who-questions-safety-of-startups-laser-engravers/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"916\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/PRO_OPEN_MEDIA_SIDE-1260x916.jpg\" width=\"1260\" /><br />Glowforge, the Seattle-based maker of 3D laser engravers, has been tangled in a legal dispute with a Las Vegas man who claimed online for years that the startup is selling defective and dangerous machines. In a filing in King County Superior Court dated Oct. 31, 2023 (see the full suit below), Glowforge accused Jonathan Gleich, a tech enthusiast and self-professed activist, of making false and defamatory allegations about the company and its products on social media. Contending that Gleich&#8217;s alleged conduct was causing harm to Glowforge&#8217;s reputation among customers and in the 3D laser printer business community, Glowforge was seeking&#8230; <a href=\"https://www.geekwire.com/2024/glowforge-gets-in-legal-tangle-with-tech-activist-who-questions-safety-of-startups-laser-engravers/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Wed, 28 Feb 2024 17:13:31 +0000"
748,Former Textio CEO Kieran Snyder dives into new research on how AI is impacting the workplace,https://www.geekwire.com/2024/former-textio-ceo-kieran-snyder-dives-into-new-research-on-how-ai-is-impacting-the-workplace/,"<img alt=\"Kieran Snyder\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"608\" src=\"https://cdn.geekwire.com/wp-content/uploads/2016/08/kieransnyder-e1470948553979.jpg\" width=\"778\" /><br />Kieran Snyder, the co-founder and former CEO of Seattle-based Textio, has launched her next project, less than two months after stepping back from the augmented writing startup. In an email announcement on Wednesday, Snyder shared her new website, Nerd Processor, and said she plans to explore &#8220;the impact that AI is having on workplace communication, leadership, and team dynamics.&#8221; Snyder, who has a PhD in linguistics, founded Textio in 2014 with her husband, Jensen Harris, who took over as CEO in January. The startup uses artificial intelligence and machine learning to help remove bias from workplace language — in job postings&#8230; <a href=\"https://www.geekwire.com/2024/former-textio-ceo-kieran-snyder-dives-into-new-research-on-how-ai-is-impacting-the-workplace/\">Read More</a>",[{'name': 'Kurt Schlosser'}],"Wed, 28 Feb 2024 16:34:40 +0000"
749,"SpaceX and Microsoft vets raise $5.4M for Gradial, a Seattle startup using generative AI for marketing",https://www.geekwire.com/2024/spacex-and-microsoft-vets-raise-5-4m-for-gradial-a-seattle-startup-using-generative-ai-for-marketing/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"920\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/IMG_8729-1.jpeg\" width=\"1232\" /><br />Gradial, a new Seattle startup using generative AI to help marketing operations teams increase productivity, raised $5.4 million in a seed investment round led by Madrona. Founded last year by former managers at SpaceX and Microsoft, the company&#8217;s software allows brands to build websites, campaigns, and other marketing-related experiences by simply typing written sentences. It also helps streamline related workflows to speed up how content is edited and updated —&#160;for example, taking a design from Canva or Figma and implementing it across a company&#8217;s website and apps. Gradial is one of many up-and-coming startups taking advantage of new large language&#8230; <a href=\"https://www.geekwire.com/2024/spacex-and-microsoft-vets-raise-5-4m-for-gradial-a-seattle-startup-using-generative-ai-for-marketing/\">Read More</a>",[{'name': 'Taylor Soper'}],"Wed, 28 Feb 2024 16:09:09 +0000"
750,"Seattle after Techstars: Former managing director reflects on accelerator’s impact, looks ahead",https://www.geekwire.com/2024/seattle-after-techstars-former-managing-director-reflects-on-accelerators-impact-looks-ahead/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"945\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/techstars-1260x945.jpg\" width=\"1260\" /><br />Entrepreneur and investor Chris DeVore had an inside view of Techstars Seattle as one of the original leaders of the local startup accelerator in 2010, before serving as its managing director from 2014 to 2019. His Feb. 21 post &#8220;What went wrong at Techstars,&#8221; looked closely at the broader organization&#8217;s evolution — including its increased focus on corporate sponsorships and shift to centralized fundraising — as the backdrop for the news last week that Techstars is closing its Seattle accelerator as part of a larger reset also impacting the original Techstars accelerator in Boulder, Colo. So where should Seattle go&#8230; <a href=\"https://www.geekwire.com/2024/seattle-after-techstars-former-managing-director-reflects-on-accelerators-impact-looks-ahead/\">Read More</a>",[{'name': 'Todd Bishop'}],"Wed, 28 Feb 2024 14:39:28 +0000"
751,Tech Moves: Instacart COO lands at Microsoft in AI product role; ZoomInfo accounting chief departs,https://www.geekwire.com/2024/tech-moves-instacart-coo-lands-at-microsoft-in-ai-product-role-zoominfo-accounting-chief-departs/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"1260\" src=\"https://cdn.geekwire.com/wp-content/uploads/2024/02/081722_Instacart_2217_Asha-Sharma-1008x1260.jpg\" width=\"1008\" /><br />Asha Sharma is headed back to Seattle full-time for a new role leading product for Microsoft&#8217;s AI platform. Sharma was most recently at Instacart, where she was chief operating officer since 2021. Sharma was previously a vice president of product at Meta and COO at Seattle-based home services company Porch Group. In a LinkedIn post, Sharma said AI-powered advances will be &#8220;exponential, sparking the most important product making era yet, with significant gains in how billions of people program, work and live.&#8221; &#8220;I’m ecstatic to be joining Microsoft, the leader in this transformation, to help define and build this future,&#8221;&#8230; <a href=\"https://www.geekwire.com/2024/tech-moves-instacart-coo-lands-at-microsoft-in-ai-product-role-zoominfo-accounting-chief-departs/\">Read More</a>",[{'name': 'Taylor Soper'}],"Wed, 28 Feb 2024 05:24:13 +0000"
752,Redfin trims losses in Q4 as it navigates ‘dreadful’ housing market,https://www.geekwire.com/2024/redfin-trims-losses-in-q4-as-it-navigates-dreadful-housing-market/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"473\" src=\"https://cdn.geekwire.com/wp-content/uploads/2020/06/redfinhouse.jpg\" width=\"630\" /><br />Redfin shares were down more than 2% in after-hours trading after the company reported its fourth quarter earnings. Related: Redfin targeted in new commissions suit blasting buyer agents via RealEstateNews.com.,[{'name': 'Taylor Soper'}],"Tue, 27 Feb 2024 21:12:18 +0000"
753,The Magic Behind the Screen: Celebrating the 96th Academy Awards Nominees for Best Visual Effects,https://blogs.nvidia.com/blog/academy-awards-vfx-openusd/,"The 96th Academy Awards nominees for Best Visual Effects are a testament to the incredible technological advancements pushing the boundaries of what’s possible in film. Whether showcasing colossal destruction scenes, heart-pumping action sequences or interstellar adventures, each nominee demonstrates unique contributions in visual effects, or VFX — and they all used cutting-edge NVIDIA technologies in		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/academy-awards-vfx-openusd/\">
			Read Article			<span></span>
		</a>",[{'name': 'Rick Champagne'}],"Tue, 05 Mar 2024 17:00:50 +0000"
754,Robo Rendezvous: Robotics Innovators and AI Leaders to Converge at NVIDIA GTC,https://blogs.nvidia.com/blog/robotics-innovators-ai-gtc-2024/,"Bringing together pioneers in robotics and AI, NVIDIA GTC will be a state-of-the-art showcase of applied AI for autonomous machines. The conference, running March 18-21 at the San Jose Convention Center and online, boasts a star-studded lineup. This includes a fireside chat with Marc Raibert, executive director of The AI Institute, and Dieter Fox, senior		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/robotics-innovators-ai-gtc-2024/\">
			Read Article			<span></span>
		</a>",[{'name': 'Jason Black'}],"Mon, 04 Mar 2024 18:55:55 +0000"
755,Automakers Electrify Geneva International Motor Show,https://blogs.nvidia.com/blog/automakers-geneva-motor-show/,"The Geneva International Motor Show, one of the most important and long-standing global auto exhibitions, opened this week, with the spotlight on several China and U.S. EV makers building on NVIDIA DRIVE that are expanding their presence in Europe. BYD One of the key reveals is BYD’s Yangweng U8 plug-in hybrid large SUV, built on		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/automakers-geneva-motor-show/\">
			Read Article			<span></span>
		</a>",[{'name': 'Danny Shapiro'}],"Fri, 01 Mar 2024 19:13:33 +0000"
756,No Noobs Here: Top Pro Gamers Bolster Software Quality Assurance Testing,https://blogs.nvidia.com/blog/nvidia-life-pro-gamers/,"For some NVIDIANs, it’s always game day. Our Santa Clara-based software quality assurance team boasts some of the world’s top gamers, whose search for bugs and errors is as strategic as their battle plans for toppling top-tier opponents in video games. Two team members of the QA team — friendly colleagues in the office but		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/nvidia-life-pro-gamers/\">
			Read Article			<span></span>
		</a>",[{'name': 'Samantha Zee'}],"Fri, 01 Mar 2024 17:14:58 +0000"
757,What Is Trustworthy AI?,https://blogs.nvidia.com/blog/what-is-trustworthy-ai/,"Artificial intelligence, like any transformative technology, is a work in progress — continually growing in its capabilities and its societal impact. Trustworthy AI initiatives recognize the real-world effects that AI can have on people and society, and aim to channel that power responsibly for positive change. What Is Trustworthy AI? Trustworthy AI is an approach		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/what-is-trustworthy-ai/\">
			Read Article			<span></span>
		</a>",[{'name': 'Nikki Pope'}],"Fri, 01 Mar 2024 17:00:24 +0000"
758,Live at GTC: Hear From Industry Leaders Using AI to Drive Innovation and Agility,https://blogs.nvidia.com/blog/industry-leaders-ai-innovation-gtc-2024/,Enterprise execs across broad sectors to share their AI strategies and success stories.,[{'name': 'Ben Oliveri'}],"Fri, 01 Mar 2024 16:00:28 +0000"
759,Battle.net Leaps Into the Cloud With GeForce NOW,https://blogs.nvidia.com/blog/geforce-now-thursday-battlenet-march-games-list/,"GFN Thursday celebrates this leap day with the addition of a popular game store to the cloud. Stream the first titles from Blizzard Entertainment’s Battle.net, including Diablo IV, Overwatch 2, Call of Duty HQ and Hearthstone, now playable across more devices than ever. They’re all part of the 30 new games coming to GeForce NOW		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/geforce-now-thursday-battlenet-march-games-list/\">
			Read Article			<span></span>
		</a>",[{'name': 'GeForce NOW Community'}],"Thu, 29 Feb 2024 14:00:55 +0000"
760,What Is Sovereign AI?,https://blogs.nvidia.com/blog/what-is-sovereign-ai/,"Nations have long invested in domestic infrastructure to advance their economies, control their own data and take advantage of technology opportunities in areas such as transportation, communications, commerce, entertainment and healthcare. AI, the most important technology of our time, is turbocharging innovation across every facet of society. It’s expected to generate trillions of dollars in		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/what-is-sovereign-ai/\">
			Read Article			<span></span>
		</a>",[{'name': 'Keith Strier'}],"Wed, 28 Feb 2024 20:31:53 +0000"
761,And … Action! Cuebric CEO Provides Insights Into Filmmaking Using AI,https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/,"These days, just about everyone is a content creator. But can generative AI help make people create high-quality films and other content affordably? Find out from Pinar Seyhan Demirdag, cofounder and CEO of Cuebric, during his conversation with NVIDIA AI Podcast host Noah Kravitz. Cuebric is on a mission to offer new solutions in filmmaking		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/\">
			Read Article			<span></span>
		</a>",[{'name': 'Brian Caulfield'}],"Wed, 28 Feb 2024 14:00:55 +0000"
762,Time to Skill Up: Game Reviewer Ralph Panebianco Wields NVIDIA RTX for the Win,https://blogs.nvidia.com/blog/skillup-adobe-premiere-pro-photoshop/,"YouTube content creator Ralph Panebianco really, really loves video games.",[{'name': 'Gerardo Delgado'}],"Wed, 28 Feb 2024 14:00:13 +0000"
763,Rack ‘n’ Roll: NVIDIA Grace Hopper Systems Gather at GTC,https://blogs.nvidia.com/blog/mgx-accelerated-systems-gtc/,"The spirit of software legend Grace Hopper will live on at NVIDIA GTC. Accelerated systems using powerful processors — named in honor of the pioneer of programming — will be on display at the global AI conference running March 18-21, ready to take computing to the next level. System makers will show more than 500		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/mgx-accelerated-systems-gtc/\">
			Read Article			<span></span>
		</a>",[{'name': 'Ivan Goldwasser'}],"Tue, 27 Feb 2024 16:00:36 +0000"
764,Meet the Omnivore: Mode Maison Harnesses OpenUSD to Drive Innovations in Retail With High-Fidelity Digital Twins,https://blogs.nvidia.com/blog/mode-maison-openusd-omniverse/,"Editor’s note: This post is a part of our Meet the Omnivore series, which features individual creators and developers who use OpenUSD to build tools, applications and services for 3D workflows and physically accurate virtual worlds. A failed furniture-shopping trip turned into a business idea for Steven Gay, cofounder and CEO of company Mode Maison.		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/mode-maison-openusd-omniverse/\">
			Read Article			<span></span>
		</a>",[{'name': 'Nicole Castro'}],"Tue, 27 Feb 2024 16:00:34 +0000"
765,NVIDIA RTX 500 and 1000 Professional Ada Generation Laptop GPUs Drive AI-Enhanced Workflows From Anywhere,https://blogs.nvidia.com/blog/rtx-ada-ai-workflows/,"With generative AI and hybrid work environments becoming the new standard, nearly every professional, whether a content creator, researcher or engineer, needs a powerful, AI-accelerated laptop to help users tackle their industry’s toughest challenges — even on the go. The new NVIDIA RTX 500 and 1000 Ada Generation Laptop GPUs will be available in new,		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/rtx-ada-ai-workflows/\">
			Read Article			<span></span>
		</a>",[{'name': 'John Della Bona'}],"Mon, 26 Feb 2024 08:00:23 +0000"
766,Add It to the Toolkit: February Studio Driver and NVIDIA App Beta Now Available,https://blogs.nvidia.com/blog/studio-driver-app-rtx-ai-adobe-premiere-pro/,"The February NVIDIA Studio Driver, designed specifically to optimize creative apps, is now available for download.",[{'name': 'Gerardo Delgado'}],"Thu, 22 Feb 2024 14:00:51 +0000"
767,Into the Omniverse: Rhino 3D Launches OpenUSD Features to Enhance 3D Modeling and Development,https://blogs.nvidia.com/blog/rhino-launches-openusd-features/,"Editor’s note: This post is part of Into the Omniverse, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in OpenUSD and NVIDIA Omniverse. The combination of powerful 3D tools and groundbreaking technologies can transform the way designers bring their visions to life — and Universal Scene		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/rhino-launches-openusd-features/\">
			Read Article			<span></span>
		</a>",[{'name': 'George Matos'}],"Thu, 22 Feb 2024 14:00:51 +0000"
768,"Time to Play: GeForce NOW Now Offers 1,800 Games to Stream",https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-nightingale-bandai-namco/,"Top-tier games from publishing partners Bandai Namco Entertainment and Inflexion Games are joining GeForce NOW this week as the cloud streaming service’s fourth-anniversary celebrations continue. Eleven new titles join the over 1,800 supported games in the GeForce NOW library, including Nightingale from Inflexion Games and Bandai Namco Entertainment’s Tales of Arise, Katamari Damacy REROLL and		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-nightingale-bandai-namco/\">
			Read Article			<span></span>
		</a>",[{'name': 'GeForce NOW Community'}],"Thu, 22 Feb 2024 14:00:13 +0000"
769,FOMO Alert: Discover 7 Unmissable Reasons to Attend GTC 2024,https://blogs.nvidia.com/blog/do-not-miss-gtc-2024/,"“I just got back from GTC and ….” In four weeks, those will be among the most powerful words in your industry. But you won’t be able to use them if you haven’t been here. NVIDIA’s GTC 2024 transforms the San Jose Convention Center into a crucible of innovation, learning and community from March 18-21,		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/do-not-miss-gtc-2024/\">
			Read Article			<span></span>
		</a>",[{'name': 'Claudia Cook'}],"Thu, 22 Feb 2024 14:00:07 +0000"
770,Shining Brighter Together: Google’s Gemma Optimized to Run on NVIDIA GPUs,https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/,"NVIDIA, in collaboration with Google, today launched optimizations across all NVIDIA AI platforms for Gemma — Google’s state-of-the-art new lightweight 2 billion&#8211; and 7 billion-parameter open language models that can be run anywhere, reducing costs and speeding innovative work for domain-specific use cases. Teams from the companies worked closely together to accelerate the performance of		<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/\">
			Read Article			<span></span>
		</a>",[{'name': 'Ankit Patel'}],"Wed, 21 Feb 2024 13:00:31 +0000"
771,Best Free Resources to Learn Data Analysis and Data Science,https://www.kdnuggets.com/2024/03/365datascience-best-free-resources-learn-data-analysis-data-science?utm_source=rss&utm_medium=rss&utm_campaign=best-free-resources-to-learn-data-analysis-and-data-science,"This article introduces six top-notch, free data science resources ideal for aspiring data analysts, data scientists, or anyone aiming to enhance their analytical skills.",[{'name': 'KDnuggets'}],"Tue, 05 Mar 2024 18:00:53 +0000"
772,Extractive Summarization with LLM using BERT,https://www.kdnuggets.com/extractive-summarization-with-llm-using-bert?utm_source=rss&utm_medium=rss&utm_campaign=extractive-summarization-with-llm-using-bert,"An in-depth overview of extractive text summarization, how state-of-the-art NLP models like BERT can enhance it, and a coding tutorial for using BERT to generate extractive summaries.",[{'name': 'Kevin Vu'}],"Tue, 05 Mar 2024 17:00:01 +0000"
773,5 Data Science Communities to Advance Your Career,https://www.kdnuggets.com/5-data-science-communities-to-advance-your-career?utm_source=rss&utm_medium=rss&utm_campaign=5-data-science-communities-to-advance-your-career,The best way to improve our knowledge is by learning together with communities.,[{'name': 'Cornellius Yudha Wijaya'}],"Tue, 05 Mar 2024 15:00:02 +0000"
774,5 Free University Courses to Learn Databases and SQL,https://www.kdnuggets.com/5-free-university-courses-to-learn-databases-and-sql?utm_source=rss&utm_medium=rss&utm_campaign=5-free-university-courses-to-learn-databases-and-sql,"Looking to learn SQL and databases to level up your data science skills? Learn SQL, database internals, and much more with these free university courses.",[{'name': 'Bala Priya C'}],"Tue, 05 Mar 2024 13:00:03 +0000"
775,Data Science and the Go Programming Language,https://www.kdnuggets.com/2024/03/nwu-data-science-go-programming-language?utm_source=rss&utm_medium=rss&utm_campaign=data-science-and-the-go-programming-language,Northwestern’s School of Professional Studies uses Go in Its Master of Science in Data Science Program.,[{'name': 'KDnuggets'}],"Mon, 04 Mar 2024 18:00:02 +0000"
776,Unlock the Secrets of LLMs in 60-Minute with Andrej Karpathy,https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy?utm_source=rss&utm_medium=rss&utm_campaign=unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy,"Karpathy's talk provides a comprehensive yet accessible introduction to large language models, explaining their capabilities, future potential, and associated security risks in an engaging manner.",[{'name': 'Kanwal Mehreen'}],"Mon, 04 Mar 2024 17:00:50 +0000"
777,5 Courses to Master LLMs,https://www.kdnuggets.com/5-courses-to-master-llms?utm_source=rss&utm_medium=rss&utm_campaign=5-courses-to-master-llms,"The future world is full of LLM, and you don’t want to miss this most sought skill.",[{'name': 'Cornellius Yudha Wijaya'}],"Mon, 04 Mar 2024 15:00:41 +0000"
778,2024 Reading List: 5 Essential Reads on Artificial Intelligence,https://www.kdnuggets.com/2024-reading-list-5-essential-reads-on-artificial-intelligence?utm_source=rss&utm_medium=rss&utm_campaign=2024-reading-list-5-essential-reads-on-artificial-intelligence,Transform your understanding of current and future tech with these top 5 AI reads to explore the minds shaping our future.,[{'name': 'Nisha Arya'}],"Mon, 04 Mar 2024 13:00:55 +0000"
779,Top 5 Linux Distro for Data Science,https://www.kdnuggets.com/top-5-linux-distro-for-data-science?utm_source=rss&utm_medium=rss&utm_campaign=top-5-linux-distro-for-data-science,"If you are considering transitioning from Microsoft Windows to another operating system that suits your needs, check out these five Linux distributions for data science and machine learning.",[{'name': 'Abid Ali Awan'}],"Fri, 01 Mar 2024 15:00:03 +0000"
780,Top 6 YouTube Series for Data Science Beginners,https://www.kdnuggets.com/top-6-youtube-series-for-data-science-beginners?utm_source=rss&utm_medium=rss&utm_campaign=top-6-youtube-series-for-data-science-beginners,"Want to start your data science journey from home, for free, and work at your own pace? Have a dive into this data science roadmap using the YouTube series.",[{'name': 'Nisha Arya'}],"Fri, 01 Mar 2024 13:00:46 +0000"
781,Free Site Reliability Engineering Course From Google + Uplimit,https://www.kdnuggets.com/2024/02/uplimit-free-site-reliability-engineering-course-from-google?utm_source=rss&utm_medium=rss&utm_campaign=free-site-reliability-engineering-course-from-google-uplimit,Claim your spot for the free Google Site Reliability Engineering in partnership with Uplimit right now! Starts March 11.,[{'name': 'KDnuggets'}],"Thu, 29 Feb 2024 18:00:25 +0000"
782,5 Podcasts Every Machine Learning Enthusiast Should Follow,https://www.kdnuggets.com/5-podcasts-every-machine-learning-enthusiast-should-follow?utm_source=rss&utm_medium=rss&utm_campaign=5-podcasts-every-machine-learning-enthusiast-should-follow,The podcasts that would improve your ML knowledge.,[{'name': 'Cornellius Yudha Wijaya'}],"Thu, 29 Feb 2024 15:00:23 +0000"
783,5 Free Courses to Master Statistics for Data Science,https://www.kdnuggets.com/5-free-courses-to-master-statistics-for-data-science?utm_source=rss&utm_medium=rss&utm_campaign=5-free-courses-to-master-statistics-for-data-science,Want to learn statistics for data science? Check out these free courses to learn essential statistics concepts.,[{'name': 'Bala Priya C'}],"Thu, 29 Feb 2024 13:00:26 +0000"
784,AI Con USA: Navigate the Future of AI,https://www.kdnuggets.com/2024/02/techwell-ai-con-usa-navigate-the-future-of-ai?utm_source=rss&utm_medium=rss&utm_campaign=ai-con-usa-navigate-the-future-of-ai,"AI Con USA is scheduled for June 2-7 in Las Vegas, and it's bringing together some of the brightest minds in the realm of artificial intelligence and machine learning.",[{'name': 'KDnuggets'}],"Wed, 28 Feb 2024 18:00:50 +0000"
785,"Collection of Free Courses to Learn Data Science, Data Engineering, Machine Learning, MLOps, and LLMOps",https://www.kdnuggets.com/collection-of-free-courses-to-learn-data-science-data-engineering-machine-learning-mlops-and-llmops?utm_source=rss&utm_medium=rss&utm_campaign=collection-of-free-courses-to-learn-data-science-data-engineering-machine-learning-mlops-and-llmops,Begin your data professional journey from the basics of statistics to building a production-grade AI application.,[{'name': 'Abid Ali Awan'}],"Wed, 28 Feb 2024 15:00:15 +0000"
786,"Vector Database for LLMs, Generative AI, and Deep Learning",https://www.kdnuggets.com/vector-database-for-llms-generative-ai-and-deep-learning?utm_source=rss&utm_medium=rss&utm_campaign=vector-database-for-llms-generative-ai-and-deep-learning,Exploring the limitless possibilities of AI and making it context-aware.,[{'name': 'Kevin Vu'}],"Wed, 28 Feb 2024 13:00:30 +0000"
787,How to Learn Python Basics With ChatGPT,https://www.kdnuggets.com/how-to-learn-python-basics-with-chatgpt?utm_source=rss&utm_medium=rss&utm_campaign=how-to-learn-python-basics-with-chatgpt,Your Ultimate Learning Companion.,[{'name': 'Nate Rosidi'}],"Tue, 27 Feb 2024 15:00:06 +0000"
788,Free Data Analyst Bootcamp for Beginners,https://www.kdnuggets.com/free-data-analyst-bootcamp-for-beginners?utm_source=rss&utm_medium=rss&utm_campaign=free-data-analyst-bootcamp-for-beginners,Want to become a data analyst? This free beginner-friendly data analyst bootcamp is all you need.,[{'name': 'Bala Priya C'}],"Tue, 27 Feb 2024 13:00:41 +0000"
789,8 Built-in Python Decorators to Write Elegant Code,https://www.kdnuggets.com/8-built-in-python-decorators-to-write-elegant-code?utm_source=rss&utm_medium=rss&utm_campaign=8-built-in-python-decorators-to-write-elegant-code,"Developers can modify a function's behavior using decorators, without changing its source code. This provides a concise and flexible way to enhance and extend the functionality of functions.",[{'name': 'Kanwal Mehreen'}],"Mon, 26 Feb 2024 15:00:31 +0000"
790,7 Free Harvard University Courses to Advance Your Skills,https://www.kdnuggets.com/7-free-harvard-university-courses-to-advance-your-skills?utm_source=rss&utm_medium=rss&utm_campaign=7-free-harvard-university-courses-to-advance-your-skills,Transform your tech career with one of the best universities in the world!,[{'name': 'Nisha Arya'}],"Mon, 26 Feb 2024 13:00:19 +0000"
791,Everything You Need to Know About MLOps: A KDnuggets Tech Brief,https://www.kdnuggets.com/tech-brief-everything-you-need-to-know-about-mlops?utm_source=rss&utm_medium=rss&utm_campaign=everything-you-need-to-know-about-mlops-a-kdnuggets-tech-brief,"KDnuggets' first Tech Brief is now available, and it outlines everything you need to know about MLOps.",[{'name': 'KDnuggets'}],"Fri, 23 Feb 2024 15:25:10 +0000"
792,Free Mastery Course: Become a Large Language Model Expert,https://www.kdnuggets.com/ree-mastery-course-become-a-large-language-model-expert?utm_source=rss&utm_medium=rss&utm_campaign=free-mastery-course-become-a-large-language-model-expert,It is a self-paced course that covers fundamental and advanced concepts of LLMs and teaches how to deploy them in production.,[{'name': 'Abid Ali Awan'}],"Fri, 23 Feb 2024 15:00:19 +0000"
793,3 Inspirational Stories of Leaders in AI,https://www.kdnuggets.com/3-inspirational-stories-of-leaders-in-ai?utm_source=rss&utm_medium=rss&utm_campaign=3-inspirational-stories-of-leaders-in-ai,"Every leader has their origin story, and here are some that might inspire you.",[{'name': 'Cornellius Yudha Wijaya'}],"Fri, 23 Feb 2024 13:00:57 +0000"
794,5 Airflow Alternatives for Data Orchestration,https://www.kdnuggets.com/5-airflow-alternatives-for-data-orchestration?utm_source=rss&utm_medium=rss&utm_campaign=5-airflow-alternatives-for-data-orchestration,Top list of open-source tools for building and managing workflows.,[{'name': 'Abid Ali Awan'}],"Thu, 22 Feb 2024 15:00:05 +0000"
795,7 Free Kaggle Micro-Courses for Data Science Beginners,https://www.kdnuggets.com/7-free-kaggle-micro-courses-for-data-science-beginners?utm_source=rss&utm_medium=rss&utm_campaign=7-free-kaggle-micro-courses-for-data-science-beginners,Interested in learning data science? Check out these free micro-courses from Kaggle to learn essential data science skills.,[{'name': 'Bala Priya C'}],"Thu, 22 Feb 2024 13:00:29 +0000"
796,The Right Way to Access Dictionaries in Python,https://www.kdnuggets.com/the-right-way-to-access-dictionaries-in-python?utm_source=rss&utm_medium=rss&utm_campaign=the-right-way-to-access-dictionaries-in-python,Effectively accessing dictionaries data with Python’s get() and setdefault().,[{'name': 'Josep Ferrer'}],"Wed, 21 Feb 2024 15:00:17 +0000"
797,Free Amazon Courses to Learn Generative AI: For All Levels,https://www.kdnuggets.com/free-amazon-courses-to-learn-generative-ai-for-all-levels?utm_source=rss&utm_medium=rss&utm_campaign=free-amazon-courses-to-learn-generative-ai-for-all-levels,"Upskill with these free courses to master generative AI, regardless of your job title.",[{'name': 'Nisha Arya'}],"Wed, 21 Feb 2024 13:00:56 +0000"
798,Python in Finance: Real Time Data Streaming within Jupyter Notebook,https://www.kdnuggets.com/python-in-finance-real-time-data-streaming-within-jupyter-notebook?utm_source=rss&utm_medium=rss&utm_campaign=python-in-finance-real-time-data-streaming-within-jupyter-notebook,"Learn a modern approach to stream real-time data in Jupyter Notebook. This guide covers dynamic visualizations, a Python for quant finance use case, and Bollinger Bands analysis with live data.",[{'name': 'Mudit Srivastava'}],"Tue, 20 Feb 2024 17:00:53 +0000"
799,Navigating the Data Revolution: Exploring the Booming Trends in Data Science and Machine Learning,https://www.kdnuggets.com/navigating-the-data-revolution-exploring-the-booming-trends-in-data-science-and-machine-learning?utm_source=rss&utm_medium=rss&utm_campaign=navigating-the-data-revolution-exploring-the-booming-trends-in-data-science-and-machine-learning,"Dive into transformative trends in data science, encompassing AI-powered automation, NLP, ethical considerations, decentralized computing, and interdisciplinary collaboration.",[{'name': 'Aryan Garg'}],"Tue, 20 Feb 2024 15:00:08 +0000"
800,6 YouTube Channels to Learn about AI,https://www.kdnuggets.com/6-youtube-channels-to-learn-about-ai?utm_source=rss&utm_medium=rss&utm_campaign=6-youtube-channels-to-learn-about-ai,Are you looking into learning about AI? YouTube is your first stop.,[{'name': 'Nisha Arya'}],"Tue, 20 Feb 2024 13:00:07 +0000"
801,Prompt Engineering: An Integrated Dream,https://www.kdnuggets.com/prompt-engineering-an-integrated-dream?utm_source=rss&utm_medium=rss&utm_campaign=prompt-engineering-an-integrated-dream,"Clickbait headlines like \"AI's Hottest Job\" have promised a career that anyone who knows how to chat with AI could pay a six-figure salary with no computer background. But is this reality, or just another internet pipe dream? Let's ditch the sensationalism and delve into the actual job market data to find out.",[{'name': 'Mahdi Ahmadi'}],"Mon, 19 Feb 2024 17:00:41 +0000"
802,Introduction to Memory Profiling in Python,https://www.kdnuggets.com/introduction-to-memory-profiling-in-python?utm_source=rss&utm_medium=rss&utm_campaign=introduction-to-memory-profiling-in-python,"So where did all the memory go? To figure out, learn how to profile your Python code for memory usage using the memory-profiler package.",[{'name': 'Bala Priya C'}],"Mon, 19 Feb 2024 15:00:12 +0000"
803,A Roadmap For Your Data Career,https://www.kdnuggets.com/a-roadmap-for-your-data-career?utm_source=rss&utm_medium=rss&utm_campaign=a-roadmap-for-your-data-career,"As you design your career in data, you’ve got to avoid getting stuck in your comfort zone or allowing your manager or current situation to determine your path.",[{'name': 'Stan Pugsley'}],"Mon, 19 Feb 2024 13:00:56 +0000"
804,Master The Art Of Command Line With This GitHub Repository,https://www.kdnuggets.com/master-the-art-of-command-line-with-this-github-repository?utm_source=rss&utm_medium=rss&utm_campaign=master-the-art-of-command-line-with-this-github-repository,"Whether you are a beginner or an experienced user, this guide is perfect for familiarizing yourself with basic and advanced command line tools.",[{'name': 'Abid Ali Awan'}],"Fri, 16 Feb 2024 15:00:51 +0000"
805,7 Steps to Mastering Exploratory Data Analysis,https://www.kdnuggets.com/7-steps-to-mastering-exploratory-data-analysis?utm_source=rss&utm_medium=rss&utm_campaign=7-steps-to-mastering-exploratory-data-analysis,"A Step-by-Step Approach to Unearthing Trends, Outliers, and Insights in your Data.",[{'name': 'Josep Ferrer'}],"Fri, 16 Feb 2024 13:00:50 +0000"
806,Jupyter Notebook Magic Methods Cheat Sheet,https://www.kdnuggets.com/jupyter-notebook-magic-methods-cheat-sheet?utm_source=rss&utm_medium=rss&utm_campaign=jupyter-notebook-magic-methods-cheat-sheet,KDnuggets' latest original cheat sheet covers Jupyter Notebook magic methods. Check it out now and become a notebook magician.,[{'name': 'KDnuggets'}],"Thu, 15 Feb 2024 17:00:54 +0000"
807,Large Language Models Explained in 3 Levels of Difficulty,https://www.kdnuggets.com/large-language-models-explained-in-3-levels-of-difficulty?utm_source=rss&utm_medium=rss&utm_campaign=large-language-models-explained-in-3-levels-of-difficulty,"Simple explanations, no matter what your level is right now.",[{'name': 'Cornellius Yudha Wijaya'}],"Thu, 15 Feb 2024 15:00:44 +0000"
808,Semantic Layers are the Missing Piece for AI-Enabled Analytics,https://www.kdnuggets.com/2024/02/cube-semantic-layers-missing-piece-ai-enabled-analytics?utm_source=rss&utm_medium=rss&utm_campaign=semantic-layers-are-the-missing-piece-for-ai-enabled-analytics,"Integrating a semantic layer with Language Learning Models (LLMs) presents a clean solution to this, particularly in the realm of AI chatbots. This combination empowers businesses to generate fast responses and reports based on their data. Leveraging AI and semantic layers is advancing business intelligence, making it easier than ever for people to interact with data.",[{'name': 'KDnuggets'}],"Wed, 14 Feb 2024 18:00:10 +0000"
809,Top 5 DataCamp Courses for Mastering Generative AI,https://www.kdnuggets.com/top-5-datacamp-courses-for-mastering-generative-ai?utm_source=rss&utm_medium=rss&utm_campaign=top-5-datacamp-courses-for-mastering-generative-ai,"Learn the skills you require to kickstart your Generative AI journey with DataCamp - beginner, intermediate, and expert!",[{'name': 'Nisha Arya'}],"Wed, 14 Feb 2024 15:00:36 +0000"
810,"What Is Data Lineage, And Why Does It Matter?",https://www.kdnuggets.com/what-is-data-lineage-and-why-does-it-matter?utm_source=rss&utm_medium=rss&utm_campaign=what-is-data-lineage-and-why-does-it-matter,"If you’ve ever had conversations with data professionals, you’ve probably heard “data lineage” pop up quite a few times. So what is data lineage all about, and why is it important?",[{'name': 'Bala Priya C'}],"Wed, 14 Feb 2024 13:00:23 +0000"
811,"Generative AI Playground: Text-to-Image Stable Diffusion with Stability AI, Stable Diffusion XL, and CompVis on the Latest Intel® GPU",https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-text-to-image-stable-diffusion?utm_source=rss&utm_medium=rss&utm_campaign=generative-ai-playground-text-to-image-stable-diffusion-with-stability-ai-stable-diffusion-xl-and-compvis-on-the-latest-intel-gpu,"Stable Diffusion models are revolutionizing digital artistry, transforming mere text into stunning, lifelike images. Explore further here.",[{'name': 'KDnuggets'}],"Tue, 13 Feb 2024 18:00:30 +0000"
812,3 Research-Driven Advanced Prompting Techniques for LLM Efficiency and Speed Optimization,https://www.kdnuggets.com/3-research-driven-advanced-prompting-techniques-for-llm-efficiency-and-speed-optimization?utm_source=rss&utm_medium=rss&utm_campaign=3-research-driven-advanced-prompting-techniques-for-llm-efficiency-and-speed-optimization,This article has explored three promising prompting techniques that have been developed to reduce the occurrence of hallucinations in large language models.,[{'name': 'Abid Ali Awan'}],"Tue, 13 Feb 2024 17:00:06 +0000"
813,2024 Tech Trends: AI Breakthroughs & Development Insights from O’Reilly’s Free Report,https://www.kdnuggets.com/2024-tech-trends-ai-breakthroughs-development-insights-oreilly-free-report?utm_source=rss&utm_medium=rss&utm_campaign=2024-tech-trends-ai-breakthroughs-development-insights-from-oreillys-free-report,Want to prepare your tech career for 2024 and onwards? Have a look at O’Reilly’s FREE technology trends report.,[{'name': 'Nisha Arya'}],"Tue, 13 Feb 2024 15:00:51 +0000"
814,How To Comment Your Python Code as a Data Scientist,https://www.kdnuggets.com/how-to-comment-your-python-code-as-a-data-scientist?utm_source=rss&utm_medium=rss&utm_campaign=how-to-comment-your-python-code-as-a-data-scientist,Don’t overlook these essential aspects of programming activity.,[{'name': 'Cornellius Yudha Wijaya'}],"Tue, 13 Feb 2024 13:00:18 +0000"
815,Synthetic Data for Machine Learning,https://www.kdnuggets.com/synthetic-data-for-machine-learning?utm_source=rss&utm_medium=rss&utm_campaign=synthetic-data-for-machine-learning,You don't always have high-quality labeled datasets for supervised machine learning. Learn about why you should augment your real data with synthetic data as well as the ways to generate it.,[{'name': 'Michael Galarnyk'}],"Mon, 12 Feb 2024 17:00:56 +0000"
816,Free Data Engineering Course for Beginners,https://www.kdnuggets.com/free-data-engineering-course-for-beginners?utm_source=rss&utm_medium=rss&utm_campaign=free-data-engineering-course-for-beginners,Interested in data engineering but don't know where to start? Get up to speed in data engineering fundamentals with this free course.,[{'name': 'Bala Priya C'}],"Mon, 12 Feb 2024 15:00:58 +0000"
817,Learn Data Science on a Budget,https://www.kdnuggets.com/learn-data-science-on-a-budget?utm_source=rss&utm_medium=rss&utm_campaign=learn-data-science-on-a-budget,This blog will go through platforms and courses you can take that will get you from 0-100 on your data science knowledge.,[{'name': 'Nisha Arya'}],"Mon, 12 Feb 2024 13:00:56 +0000"
818,University of Cincinnati MS Business Analytics Summer 2024 Information Session,https://www.kdnuggets.com/2024/02/uc-business-analytics-summer-2024-information-session?utm_source=rss&utm_medium=rss&utm_campaign=university-of-cincinnati-ms-business-analytics-summer-2024-information-session,Don't miss this chance to chart your course toward a successful career in business analytics. Reserve your spot now and embark on a journey of knowledge and growth!,[{'name': 'KDnuggets'}],"Fri, 09 Feb 2024 18:10:21 +0000"
819,The Only Free Course You Need To Become a MLOps Engineer,https://www.kdnuggets.com/the-only-free-course-you-need-to-become-a-mlops-engineer?utm_source=rss&utm_medium=rss&utm_campaign=the-only-free-course-you-need-to-become-a-mlops-engineer,"Unlock the secrets to building, deploying, and monitoring models like a pro.",[{'name': 'Abid Ali Awan'}],"Fri, 09 Feb 2024 15:00:58 +0000"
820,5 Cheap Books to Master Machine Learning,https://www.kdnuggets.com/5-cheap-books-to-master-machine-learning?utm_source=rss&utm_medium=rss&utm_campaign=5-cheap-books-to-master-machine-learning,"Machine Learning is a skill that everyone should have, and these cheap books would facilitate that learning process.",[{'name': 'Cornellius Yudha Wijaya'}],"Fri, 09 Feb 2024 13:00:00 +0000"
821,Navigating Today’s Data and AI Market Uncertainty,https://www.kdnuggets.com/2024/02/altair-navigating-todays-data-ai-market-uncertainty?utm_source=rss&utm_medium=rss&utm_campaign=navigating-todays-data-and-ai-market-uncertainty,It’s more important than ever to think long-term about the analytics partnerships you forge. Are you choosing technologies that will stand the test of time? Are you choosing companies with proven track records?,[{'name': 'KDnuggets'}],"Thu, 08 Feb 2024 18:00:47 +0000"
822,Top 5 AI Coding Assistants You Must Try,https://www.kdnuggets.com/top-5-ai-coding-assistants-you-must-try?utm_source=rss&utm_medium=rss&utm_campaign=top-5-ai-coding-assistants-you-must-try,"Discover the top AI coding assistants that can 10X your productivity overnight - #5 has the best autocomplete feature, and #1 is the most advanced code assistant tool ever seen!",[{'name': 'Abid Ali Awan'}],"Thu, 08 Feb 2024 15:00:31 +0000"
823,Free Data Science Interview Book to Land Your Dream Job,https://www.kdnuggets.com/free-data-science-interview-book-to-land-your-dream-job?utm_source=rss&utm_medium=rss&utm_campaign=free-data-science-interview-book-to-land-your-dream-job,Are you preparing for your dream data science job but feeling overwhelmed by the vast amount of online resources? Look no further than this free and easily accessible web-based book to help you brush up on your skills and feel confident for your upcoming interview.,[{'name': 'Kanwal Mehreen'}],"Thu, 08 Feb 2024 13:00:45 +0000"
824,Generative AI Playground: LLMs with Camel-5b and Open LLaMA 3B on the Latest Intel® GPU,https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-llms-with-camel-5b-and-open-llama-3b?utm_source=rss&utm_medium=rss&utm_campaign=generative-ai-playground-llms-with-camel-5b-and-open-llama-3b-on-the-latest-intel-gpu,"Intel offers a thrilling glimpse into the next generation of AI, showcasing the power of Camel-5b and Open LLaMA 3B LLMs.",[{'name': 'KDnuggets'}],"Wed, 07 Feb 2024 18:00:37 +0000"
825,Sentiment Analysis in Python: Going Beyond Bag of Words,https://www.kdnuggets.com/sentiment-analysis-in-python-going-beyond-bag-of-words?utm_source=rss&utm_medium=rss&utm_campaign=sentiment-analysis-in-python-going-beyond-bag-of-words,"This code based tutorial provides a brief introduction to Sentiment Analysis, a method used to predict emotions, similar to a digital psychologist.",[{'name': 'Nate Rosidi'}],"Wed, 07 Feb 2024 15:00:57 +0000"
826,5 Free Courses to Master Python for Data Science,https://www.kdnuggets.com/5-free-courses-to-master-python-for-data-science?utm_source=rss&utm_medium=rss&utm_campaign=5-free-courses-to-master-python-for-data-science,Want to learn Python to kickstart your career in data? Here are five free courses to help you master Python for data science.,[{'name': 'Bala Priya C'}],"Wed, 07 Feb 2024 13:00:52 +0000"
827,Breaking Down DENSE_RANK(): A Step-by-Step Guide for SQL Enthusiasts,https://www.kdnuggets.com/breaking-down-denserank-a-step-by-step-guide-for-sql-enthusiasts?utm_source=rss&utm_medium=rss&utm_campaign=breaking-down-dense_rank-a-step-by-step-guide-for-sql-enthusiasts,"This article introduced you to the world of ranking functions in SQL. We will cover the basics of how they work, how they're used, and how to avoid common pitfalls.",[{'name': 'John Hughes'}],"Tue, 06 Feb 2024 17:00:33 +0000"
828,5 FREE Courses on AI and ChatGPT to Take You From 0-100,https://www.kdnuggets.com/5-free-courses-on-ai-and-chatgpt-to-take-you-from-0-100?utm_source=rss&utm_medium=rss&utm_campaign=5-free-courses-on-ai-and-chatgpt-to-take-you-from-0-100,Want to learn more about AI and ChatGPT in 2024 for FREE? Keep reading.,[{'name': 'Nisha Arya'}],"Tue, 06 Feb 2024 15:00:50 +0000"
829,The Essential Guide to SQL’s Execution Order,https://www.kdnuggets.com/the-essential-guide-to-sql-execution-order?utm_source=rss&utm_medium=rss&utm_campaign=the-essential-guide-to-sqls-execution-order,Discovering the Hidden Logic Behind SQL's Command Order.,[{'name': 'Josep Ferrer'}],"Tue, 06 Feb 2024 13:00:05 +0000"
830,"Books, Courses, and Live Events to Learn Generative AI with O’Reilly",https://www.kdnuggets.com/books-courses-and-live-events-to-learn-generative-ai-with-oreilly?utm_source=rss&utm_medium=rss&utm_campaign=books-courses-and-live-events-to-learn-generative-ai-with-oreilly,"If you are new to generative AI or an expert who wants to learn more, O’Reilly offers a range of resources to kickstart your generative AI journey.",[{'name': 'Nisha Arya'}],"Mon, 05 Feb 2024 18:00:20 +0000"
831,"Research Papers in February 2024: A LoRA Successor, Small Finetuned LLMs Vs Generalist LLMs, and Transparent LLM Research",https://magazine.sebastianraschka.com/p/research-papers-in-february-2024,"Once again, this has been an exciting month in AI research. This month, I'm covering two new openly available LLMs, insights into small finetuned LLMs, and a new parameter-efficient LLM finetuning technique. The two LLMs mentioned above stand out for several reasons. One LLM (OLMo) is completely open source, meaning that everything from the training code to the dataset to the log files is openly shared.","[{'name': 'Sebastian Raschka, PhD'}]","Sun, 03 Mar 2024 11:53:57 GMT"
832,Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch,https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch,"Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model (for example, an LLM or vision transformer) to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters.","[{'name': 'Sebastian Raschka, PhD'}]","Sun, 18 Feb 2024 18:35:24 GMT"
833,"Research Papers in Jan 2024: Model Merging, Mixtures of Experts, and Towards Smaller LLMs",https://magazine.sebastianraschka.com/p/research-papers-in-january-2024,"Model Merging, Mixtures of Experts, and Towards Smaller LLMs","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 03 Feb 2024 11:55:32 GMT"
834,"Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attention, and Causal-Attention in LLMs",https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention,"This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama. Self-attention and related mechanisms are core components of LLMs, making them a useful topic to understand when working with these models.",[],"Sun, 14 Jan 2024 11:55:06 GMT"
835,Ten Noteworthy AI Research Papers of 2023,https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023,"This year has felt distinctly different. I've been working in, on, and with machine learning and AI for over a decade, yet I can't recall a time when these fields were as popular and rapidly evolving as they have been this year. To conclude an eventful 2023 in machine learning and AI research, I'm excited to share 10 noteworthy papers I've read this year. My personal focus has been more on large language models, so you'll find a heavier emphasis on large language model (LLM) papers than computer vision papers this year.","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 30 Dec 2023 12:20:19 GMT"
836,"Research Papers in Nov 2023: Tackling Hallucinations, Boosting Reasoning Abilities, and New Insights into the Transformer Architecture",https://magazine.sebastianraschka.com/p/research-papers-in-november-2023,"This month, I want to focus on three papers that address three distinct problem categories of Large Language Models (LLMs): Reducing hallucinations. Enhancing the reasoning capabilities of small, openly available models. Deepening our understanding of, and potentially simplifying, the transformer architecture.","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 09 Dec 2023 11:56:15 GMT"
837,Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation),https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms,Things I Learned From Hundreds of Experiments,"[{'name': 'Sebastian Raschka, PhD'}]","Sun, 19 Nov 2023 12:11:26 GMT"
838,Research Papers in Oct 2023: A Potential Successor to RLHF for Efficient LLM Alignment and the Resurgence of CNNs,https://magazine.sebastianraschka.com/p/research-papers-october-2023,"From Vision Transformers to innovative large language model finetuning techniques, the AI community has been very active with lots of interesting research this past month. Here's a snapshot of the highlights I am covering in this article: In the paper","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 04 Nov 2023 10:51:40 GMT"
839,AI and Open Source in 2023,https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023,The Highs and Lows: A Year in Review,"[{'name': 'Sebastian Raschka, PhD'}]","Mon, 23 Oct 2023 10:53:13 GMT"
840,"LLM Business and Busyness: Recent Company Investments and AI Adoption, New Small Openly Available LLMs, and LoRA Research",https://magazine.sebastianraschka.com/p/ahead-of-ai-12-llm-businesses,"Discussing Recent Company Investments and AI Adoption, New Small Openly Available LLMs, and LoRA Research","[{'name': 'Sebastian Raschka, PhD'}]","Sun, 08 Oct 2023 10:55:14 GMT"
841,Research Papers Aug-Sep 2023: From Self-Alignment to LongLoRA,https://magazine.sebastianraschka.com/p/research-highlights-in-three-sentences-3d5,"Another month, another round of interesting research papers ranging from large language modeling to computer vision. One recent focus is on refining Large Language Models (LLMs). For instance, introducing models like Platypus and the Reinforced Self-Training (ReST) method are the latest attempts to improve alignment with human preferences.","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 23 Sep 2023 11:12:03 GMT"
842,LLM Training: RLHF and Its Alternatives,https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives,"I frequently reference a process called Reinforcement Learning with Human Feedback (RLHF) when discussing LLMs, whether in the research news or tutorials. RLHF is an integral part of the modern LLM training pipeline due to its ability to incorporate human preferences into the optimization landscape, which can improve the model's helpfulness and safety.","[{'name': 'Sebastian Raschka, PhD'}]","Sun, 10 Sep 2023 11:33:03 GMT"
843,The Missing Bits: Llama 2 Weights Have Changed,https://magazine.sebastianraschka.com/p/the-missing-bits-llama-2-weights,"Due to the extensive length of the regular Ahead of AI #11: New Foundation Models article, I removed some interesting tidbits around the Llama 2 weights from the main newsletter. However, it might be nice to include those as a small bonus for the supporters of Ahead of AI. Thanks again for the kind support!","[{'name': 'Sebastian Raschka, PhD'}]","Sun, 27 Aug 2023 14:38:46 GMT"
844,New Foundation Models: CodeLlama and other highlights in Open-Source AI,https://magazine.sebastianraschka.com/p/ahead-of-ai-11-new-foundation-models,"In this edition of the newsletter, we direct our attention to one of the most prominent highlights of the summer: the release of the Llama 2 base and chat models, as well as CodeLlama, the latest highlights in the open-source AI large language model (LLM) landscape.","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 26 Aug 2023 11:34:03 GMT"
845,"Research Highlights Jul-Aug 2023: Llama 2, Flash-Attention 2, and More",https://magazine.sebastianraschka.com/p/research-highlights-in-three-sentences,"Every month is a busy month for LLM research. However, this month has been particularly interesting due to the release of new state-of-the-art base models, such as Meta's Llama 2 model suite. Double kudos: this new iteration of Llama models comes without any major restrictions and a very detailed 77-page report on arXiv!","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 12 Aug 2023 16:41:26 GMT"
846,Large Language Models and Nearest Neighbors,https://magazine.sebastianraschka.com/p/large-language-models-and-nearest,"Instead of jumping on the latest trend of the week, I wanted to dive into a recent, fascinating application of nearest-neighbor methods in the context of large language models (LLMs) that made big waves in July. You may know that I like simple yet elegant and baselines, but I also found this method quite refreshing given that most of the current research is about scaling already massive LLMs. While they may not scale to all kinds of problems where LLMs currently excel, seemingly simple methods such as nearest neighbor algorithms have a certain beauty to them. It also shows that there are still many opportunities to innovate and make significant contributions based on foundational or \"classic\" techniques.","[{'name': 'Sebastian Raschka, PhD'}]","Sun, 30 Jul 2023 12:03:29 GMT"
847,"AI Research Highlights June-July 2023: Long Contexts and Scaling Transformers to 1,000,000,000 Tokens",https://magazine.sebastianraschka.com/p/ai-research-highlights-in-3-sentences-738,"In this article, I compiled and annotated 24 AI research highlights form June to July 2023. A lot of exciting developments are currently happening, once again, in the fields of natural language processing and computer vision! In addition, if you are curious about last month's highlights, you can find them here:","[{'name': 'Sebastian Raschka, PhD'}]","Sat, 15 Jul 2023 12:50:53 GMT"
848,State of Computer Vision 2023: From Vision Transformers to Neural Radiance Fields,https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer,"Large language model development (LLM) development is still happening at a rapid pace. At the same time, leaving AI regulation debates aside, LLM news seem to be arriving at a just slightly slower rate than usual. This is a good opportunity to give the spotlight to computer vision once in a while, discussing the current state of research and development in this field. And this theme also goes nicely with a recap of CVPR 2023 in Vancouver, which was a wonderful conference at probably the nicest conference venue I have attended so far.","[{'name': 'Sebastian Raschka, PhD'}]","Thu, 06 Jul 2023 12:48:11 GMT"
849,Accelerating PyTorch Model Training,https://magazine.sebastianraschka.com/p/accelerating-pytorch-model-training,Using Mixed-Precision and Fully Sharded Data Parallelism,"[{'name': 'Sebastian Raschka, PhD'}]","Mon, 26 Jun 2023 11:47:03 GMT"
850,Understanding Encoder And Decoder LLMs,https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder,Several people asked me to dive a bit deeper into large language model (LLM) jargon and explain some of the more technical terms we nowadays take for granted. This includes references to \"encoder-style\" and \"decoder-style\" LLMs. What do these terms mean?,"[{'name': 'Sebastian Raschka, PhD'}]","Sat, 17 Jun 2023 12:45:03 GMT"
851,AMD hires Thomas Zacharia to expand strategic AI relationships,https://ai-techpark.com/amd-hires-thomas-zacharia-to-expand-strategic-ai-relationships/,"<p>Former head of Oak Ridge National Laboratory to accelerate adoption of AMD technologies for sovereign AI deployments benefiting citizens around the world Today AMD (NASDAQ: AMD) announced that Thomas Zacharia has joined AMD as senior vice president of strategic technology partnerships and public policy. Zacharia will lead the global expansion of AMD...</p>
<p>The post <a href=\"https://ai-techpark.com/amd-hires-thomas-zacharia-to-expand-strategic-ai-relationships/\">AMD hires Thomas Zacharia to expand strategic AI relationships</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'Globe Newswire'}],"Tue, 05 Mar 2024 10:49:14 +0000"
852,Jeff Vogt joins Alaska Communications as Chief Operating Officer,https://ai-techpark.com/jeff-vogt-joins-alaska-communications-as-chief-operating-officer/,"<p>Alaska Communications, a leading connectivity solutions provider to the Alaska consumer and business markets, is pleased to welcome industry leader Jeff Vogt as chief operating officer. Vogt will report to President and CEO Matt McConnell and will be responsible for the company’s cross-functional operations, strategic direction, and transformation initiatives, with...</p>
<p>The post <a href=\"https://ai-techpark.com/jeff-vogt-joins-alaska-communications-as-chief-operating-officer/\">Jeff Vogt joins Alaska Communications as Chief Operating Officer</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'Business Wire'}],"Tue, 05 Mar 2024 07:30:00 +0000"
853,Coalition for Health AI (CHAI) names Board of Directors and CEO,https://ai-techpark.com/coalition-for-health-ai-chai-names-board-of-directors-and-ceo/,"<p>CHAI General Membership, Advisory Boards and Working Groups Target Broad Participation Across U.S. Healthcare System and Communities Today CHAI, the Coalition for Health AI, announced Dr.&#160;Brian S. Anderson, a CHAI co-founder and chief digital health physician at MITRE, to be its first CEO. It also named members of CHAI&#8217;s inaugural...</p>
<p>The post <a href=\"https://ai-techpark.com/coalition-for-health-ai-chai-names-board-of-directors-and-ceo/\">Coalition for Health AI (CHAI) names Board of Directors and CEO</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'PR Newswire'}],"Mon, 04 Mar 2024 15:00:00 +0000"
854,Agility Robotics appoints Peggy Johnson as Chief Executive Officer,https://ai-techpark.com/agility-robotics-appoints-peggy-johnson-as-chief-executive-officer/,"<p>Veteran technology leader to spur broad commercial adoption as company prepares to deploy Digit robot at scale Agility Robotics, creator of the market-leading bipedal Mobile Manipulation Robot (MMR) called Digit, announced the appointment of veteran technology leader Peggy Johnson as Chief Executive Officer, effective today. Johnson will draw on her...</p>
<p>The post <a href=\"https://ai-techpark.com/agility-robotics-appoints-peggy-johnson-as-chief-executive-officer/\">Agility Robotics appoints Peggy Johnson as Chief Executive Officer</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'Business Wire'}],"Mon, 04 Mar 2024 14:30:00 +0000"
855,H2O.ai releases new language model H2O-Danube-1.8B for mobile,https://ai-techpark.com/h2o-ai-releases-new-language-model-h2o-danube-1-8b-for-mobile/,"<p>H2O-Danube-1.8B super tiny LLM model designed to run on smartphones, laptops, desktops and IoT devices, spurring growth in natural language applications and further democratizing AI H2O.ai, the open source leader in Generative AI and machine learning and maker behind Enterprise h2oGPTe, is announcing the release of H2O-Danube-1.8B &#8211; an open source natural language...</p>
<p>The post <a href=\"https://ai-techpark.com/h2o-ai-releases-new-language-model-h2o-danube-1-8b-for-mobile/\">H2O.ai releases new language model H2O-Danube-1.8B for mobile</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'Business Wire'}],"Mon, 04 Mar 2024 10:00:00 +0000"
856,Groq® acquires Definitive Intelligence to launch GroqCloud,https://ai-techpark.com/groq-acquires-definitive-intelligence-to-launch-groqcloud/,"<p>Definitive Intelligence Co-founder and CEO&#160;Sunny Madra&#160;to Lead New GroqCloud Business Unit and Launch New Developer Playground Groq®, a generative AI solutions company, has acquired Definitive Intelligence, a company redefining how businesses utilize data and empowering organizations to unlock actionable insights – all powered by AI. Definitive Intelligence Co-founder and CEO Sunny Madra will...</p>
<p>The post <a href=\"https://ai-techpark.com/groq-acquires-definitive-intelligence-to-launch-groqcloud/\">Groq® acquires Definitive Intelligence to launch GroqCloud</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'PR Newswire'}],"Mon, 04 Mar 2024 07:30:00 +0000"
857,"DreamSmart Group unveils Meizu 21 Pro, fully embracing AI",https://ai-techpark.com/dreamsmart-group-unveils-meizu-21-pro-fully-embracing-ai/,"<p>On February 29, 2024, DreamSmart Group hosted a special event, announcing its &#8216;All in AI&#8217; new strategy to embrace the promising future of AI technologies. Other new products, such as the Open AI Terminal Meizu 21 PRO and a new color variant of coronet blue of MYVU smart AR glasses, were...</p>
<p>The post <a href=\"https://ai-techpark.com/dreamsmart-group-unveils-meizu-21-pro-fully-embracing-ai/\">DreamSmart Group unveils Meizu 21 Pro, fully embracing AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'PR Newswire'}],"Fri, 01 Mar 2024 14:30:00 +0000"
858,Renesas unveils powerful Single-Chip RZ/V2H MPU,https://ai-techpark.com/renesas-unveils-powerful-single-chip-rz-v2h-mpu/,"<p>New Generation AI Accelerator with 10 TOPS/W Power Efficiency Delivers AI Inference Performance of up to 80 TOPS Without Cooling Fan Renesas Electronics Corporation (TSE:6723), a premier supplier of advanced semiconductor solutions, has expanded its popular RZ Family of microprocessors (MPUs) with a new device targeting high-performance robotics applications. Offering...</p>
<p>The post <a href=\"https://ai-techpark.com/renesas-unveils-powerful-single-chip-rz-v2h-mpu/\">Renesas unveils powerful Single-Chip RZ/V2H MPU</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'Neha Jagtap'}],"Fri, 01 Mar 2024 11:45:00 +0000"
859,TD SYNNEX increases AI offerings with expanded NVIDIA collaboration,https://ai-techpark.com/td-synnex-increases-ai-offerings-with-expanded-nvidia-collaboration/,"<p>TD SYNNEX (NYSE: SNX), a leading global distributor and solutions aggregator for the IT ecosystem, announced today further expansion of its AI offerings through an expanded collaboration with NVIDIA in North America. The expansion builds on a collaboration that spans more than a decade, with TD SYNNEX offering a host...</p>
<p>The post <a href=\"https://ai-techpark.com/td-synnex-increases-ai-offerings-with-expanded-nvidia-collaboration/\">TD SYNNEX increases AI offerings with expanded NVIDIA collaboration</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'Business Wire'}],"Fri, 01 Mar 2024 10:30:00 +0000"
860,Apple’s shift from EVs to AI sparks influencers diverse reactions,https://ai-techpark.com/apples-shift-from-evs-to-ai-sparks-influencers-diverse-reactions/,"<p>With reports emerging on Apple’s plans to shelve its electric vehicle (EV) project, a subsequent rise in discussions related to “Apple” among the influencers on “X” platform has been witnessed in the last week of February, according to the Social Media Analytics Platform of GlobalData, a leading data and analytics...</p>
<p>The post <a href=\"https://ai-techpark.com/apples-shift-from-evs-to-ai-sparks-influencers-diverse-reactions/\">Apple’s shift from EVs to AI sparks influencers diverse reactions</a> first appeared on <a href=\"https://ai-techpark.com\">AI-TechPark</a>.</p>",[{'name': 'GlobalData'}],"Fri, 01 Mar 2024 09:37:39 +0000"
861,Transforming Enterprise Capabilities with GenAI: Best Practices for Integrating GenAI at Scale,https://aibusiness.com/responsible-ai/transforming-enterprise-capabilities-with-genai-best-practices-for-integrating-genai-at-scale,"<p>A compelling case study from technical and product leadership at Clarivate, AI21 Labs, and NorthBay Solutions, who will illustrate how clients can work with AI model providers and solutions partners to optimize strategies for integrating GenAI into your enterprise.</p>
<p>You’ll learn how Clarivate, a global leader in trusted intelligence research services, solved a key challenge around the information retrieval experience for researchers by introducing an innovative, faster way to access academic literature. Search engines fell short when it came to user experience, and most AI solutions offered questionable integrity in the results they offered - making their answers problematic and unreliable for academic use.</p>
<p>Join us to discover how Clarivate succeeded with AI21’s Task-Specific AI models.</p>",[{'name': 'Susie Harrison'}],"Tue, 19 Mar 2024 17:00:00 GMT"
862,Hugging Face Launches New StarCoder Code Generation Models,https://aibusiness.com/ml/hugging-face-launches-new-starcoder-code-generation-models,Nvidia was brought in to help train these compact yet powerful new coding models,[{'name': 'Ben Wodecki'}],"Tue, 05 Mar 2024 17:45:50 GMT"
863,"Elon Musk on the Future of AI, Self-Driving Cars at Bosch Connected World",https://aibusiness.com/verticals/elon-musk-on-the-future-of-ai-self-driving-cars-at-bosch-connected-world,"In a video Q&amp;A, Musk spoke about the need to ramp up sustainable power generation to meet the rising demands of AI and autonomous vehicles",[{'name': 'Scarlett Evans'}],"Tue, 05 Mar 2024 16:46:12 GMT"
864,This Virus Steals Your Data from Generative AI Tools,https://aibusiness.com/nlp/this-virus-steals-your-data-from-generative-ai-tools,Morris II covertly extracts data from AI tools - malware for generative AI,[{'name': 'Ben Wodecki'}],"Tue, 05 Mar 2024 16:32:46 GMT"
865,AI Startup Roundup: The Startup that Blew Away OpenAI,https://aibusiness.com/verticals/ai-startup-roundup-the-startup-backed-by-openai-jeff-bezos-microsoft,Also - An enterprise AI assistant startup and Israeli company using AI for underground mapping,[{'name': 'Deborah Yao'}],"Mon, 04 Mar 2024 21:52:19 GMT"
866,Anthropic Unveils Business Friendly Claude 3 AI Models,https://aibusiness.com/nlp/anthropic-s-claude-3-models-focus-on-enterprise-needs,"The OpenAI rival's Claude 3 multimodal models are more capable, accurate and offer competitive pricing",[{'name': 'Deborah Yao'}],"Mon, 04 Mar 2024 19:49:51 GMT"
867,Connected Tech Woos Crowds at Mobile World Congress,https://aibusiness.com/verticals/connected-tech-woos-crowds-at-mobile-world-congress,"What the mobile ecosystem predicts consumers will wear, carry and ride in 2024 and beyond",[{'name': 'Berenice Baker'}],"Mon, 04 Mar 2024 17:11:18 GMT"
868,Human-in-the-Loop: Mission Critical for AI Usage and Evaluation,https://aibusiness.com/ml/human-in-the-loop-mission-critical-for-ai-usage-and-evaluation,An opinion piece by the vice president of advanced analytics at SAS,[{'name': 'Udo Sglavo'}],"Fri, 01 Mar 2024 22:45:21 GMT"
869,AI News Roundup: SEC Probing OpenAI Over CEO Firing,https://aibusiness.com/nlp/ai-news-roundup-sec-probing-openai-over-ceo-firing,Also - Stack Overflow is getting an integration with Google Gemini,[{'name': 'Ben Wodecki'}],"Fri, 01 Mar 2024 21:26:58 GMT"
870,Elon Musk Sues OpenAI to Save Humanity,https://aibusiness.com/responsible-ai/elon-musk-sues-openai-to-save-humanity,"It is a peculiar lawsuit in which the beneficiary is all of society, not Musk himself","[{'name': 'Ben Wodecki, Deborah Yao'}]","Fri, 01 Mar 2024 20:19:26 GMT"
871,Unlocking the Power of Large Graphical Models (LGMs) for Forecasting Excellence,https://aibusiness.com/responsible-ai/solving-the-enterprise-generative-ai-data-problem,"<p>According to IBM, at least 2.5 quintillion bytes of data are generated every single day, representing an explosion of real-time data generation. In this environment, organizations that can put Generative AI to work at scale will emerge as leaders. While there are a host of text- and voice-based AI applications focused on business processes like customer support and service, LLMs are not sufficient for making sense of transactional time-series data for forecasting and resource optimization.</p>
<p>Join Ikigai Labs for an exclusive webinar where we'll delve into the transformative potential of Large Graphical Models (LGMs) for consolidating enterprise time-series data, providing predictive insights, and planning at any scale or frequency. Kamal Ahluwalia, President of Ikigai Labs, and co-author of &quot;What's Next for You&quot; and &quot;Deep Talent,&quot; will share his extensive experience in leading hyper-growth organizations and scaling businesses with AI, and AI-first strategies for success.</p>",[{}],"Fri, 01 Mar 2024 19:00:00 GMT"
872,"This Week's Most Read: Gemini's Image Flaws, Protecting Your Job from AI",https://aibusiness.com/nlp/this-week-s-most-read-gemini-s-image-flaws-protecting-your-job-from-ai,"Also, updates from Mobile World Congress 2024 including Lenovo’s transparent display laptop",[{'name': 'Ben Wodecki'}],"Thu, 29 Feb 2024 23:40:04 GMT"
873,Google DeepMind's Genie Makes Super Mario-like Games from Images,https://aibusiness.com/nlp/google-deepmind-s-genie-making-video-games-from-images,Genie transforms images into interactive Super Mario-like games. The science behind it could be a stepping stone to AGI.,[{}],"Thu, 29 Feb 2024 23:00:00 GMT"
874,Inside Sora: OpenAI’s Amazing Video Generation Model,https://aibusiness.com/nlp/inside-sora-openai-s-jaw-dropping-video-generation-model,How is Sora able to produce cinematic-quality videos? Here is how it works,[{'name': 'Ben Wodecki'}],"Thu, 29 Feb 2024 22:36:56 GMT"
875,Google CEO: Gemini’s Racial Gaff is ‘Completely Unacceptable’,https://aibusiness.com/responsible-ai/google-ceo-gemini-s-racial-gaff-is-completely-unacceptable-,Google also explains exactly what went wrong with Gemini,[{'name': 'Ben Wodecki'}],"Thu, 29 Feb 2024 19:04:59 GMT"
876,Disrupting Ethically With AI: EY Thought Leadership - MWC 2024,https://aibusiness.com/responsible-ai/disrupting-ethically-with-ai-ey-thought-leadership-mwc-2024,"Unlike prior technologies, which are process-driven, AI is objective-driven, making ethical considerations paramount",[{'name': 'Berenice Baker'}],"Thu, 29 Feb 2024 18:01:57 GMT"
877,"Bosch, Microsoft to Use Generative AI to Make Roads Safer, Bosch Connected World 2024",https://aibusiness.com/verticals/bosch-microsoft-to-use-generative-ai-to-make-roads-safer-bosch-connected-world-2024,The collaboration aims to improve automated driving functions using generative AI,[{'name': 'Liz Hughes'}],"Thu, 29 Feb 2024 17:28:41 GMT"
878,CDW UK’s Chief Technologist on Emerging Themes in Gen AI,https://aibusiness.com/nlp/cdw-uk-s-chief-technologist-on-emerging-themes-in-gen-ai,"Tim Russell joins the AI Business Podcast to discuss generative AI security, FOMO and confusion around the tech",[{'name': 'Tom Taulli'}],"Wed, 28 Feb 2024 22:45:00 GMT"
879,Apple Puts Brakes on EV Plans to Focus on Gen AI,https://aibusiness.com/nlp/apple-puts-brakes-on-ev-plans-to-focus-on-gen-ai,"Apple is pivoting to generative AI from electric vehicles, closing down one of the company's most ambitious projects",[{'name': 'Deborah Yao'}],"Wed, 28 Feb 2024 22:09:45 GMT"
880,Microsoft Vows Fair AI Practices Amid Antitrust Scrutiny – MWC 2024,https://aibusiness.com/responsible-ai/microsoft-vows-fair-ai-practices-amid-antitrust-scrutiny-mwc-2024,Microsoft unveils its 'AI Access Principles' to show it is playing fair in the AI market. A key pledge: making it easy to switch cloud providers,[{'name': 'Ben Wodecki'}],"Wed, 28 Feb 2024 20:53:41 GMT"
881,Generative AI Journeys with CDW UK's Chief Technologist,https://aibusiness.com/nlp/generative-ai-journeys-with-cdw-uk-s-chief-technologist,,[{}],"Wed, 28 Feb 2024 19:52:41 GMT"
882,This AI Tool Aids Enterprise Workflows by Analyzing Images,https://aibusiness.com/nlp/this-ai-tool-streamlines-workflows-by-analyzing-images-for-enterprises,"Palmyra-Vision from AI startup Writer can check an ad to see if it is compliant with regulations, among other use cases",[{'name': 'Ben Wodecki'}],"Wed, 28 Feb 2024 17:34:26 GMT"
883,OpenAI: NY Times 'Hacked' ChatGPT So It Could Sue Us,https://aibusiness.com/responsible-ai/openai-ny-times-hacked-chatgpt-for-its-copyright-lawsuit,OpenAI accuses The New York Times of manipulating ChatGPT to fabricate lawsuit evidence. The paper is suing for alleged copyright infringement.,[{'name': 'Ben Wodecki'}],"Wed, 28 Feb 2024 16:51:18 GMT"
884,Lenovo's Transparent Display Laptop and AI PCs – MWC 2024,https://aibusiness.com/verticals/lenovo-debuts-transparent-display-laptop-mwc-2024,The PC giant showcased its AI-infused products at Mobile World Congress 2024,[{'name': 'Deborah Yao'}],"Tue, 27 Feb 2024 22:53:45 GMT"
885,"HPE, Juniper to Deliver Modern AI Architecture – MWC 2024",https://aibusiness.com/ml/hpe-juniper-m-a-to-deliver-modern-ai-architecture-mwc-2024,The AI-driven architecture would encompass the cloud all the way to the edge,[{'name': 'Ben Wodecki'}],"Tue, 27 Feb 2024 21:11:47 GMT"
886,Telco Giants Embrace AI to Power New Revenue Streams – MWC 2024,https://aibusiness.com/ml/telco-giants-embrace-ai-to-power-new-revenue-streams-mwc-2024,Telco leaders explore AI's impact: from monetizing networks to improving service reliability,[{'name': 'Ben Wodecki'}],"Tue, 27 Feb 2024 20:03:04 GMT"
887,Huawei Builds an AI Model for Telcos – MWC 2024,https://aibusiness.com/verticals/huawei-builds-an-ai-model-for-telcos-mwc-2024,The Telecom Foundation Model will power sector-specific applications,[{'name': 'Ben Wodecki'}],"Tue, 27 Feb 2024 19:33:02 GMT"
888,Experts Spotlight Industrial Metaverse Use Cases - MWC 2024,https://aibusiness.com/verticals/experts-spotlight-industrial-metaverse-use-cases-mwc-2024,Impacting real-world outcomes through virtual representation requires a full-stack approach,[{'name': 'Berenice Baker'}],"Tue, 27 Feb 2024 18:57:25 GMT"
889,"Mistral Goes Large: Microsoft Deal, New Flagship Model",https://aibusiness.com/nlp/mistral-unveils-its-most-advanced-llm-and-chatgpt-rival,"Mistral also unveiled an AI chatbot called 'Le Chat,' meaning cat in French and a play on the English word 'chat'",[{'name': 'Ben Wodecki'}],"Tue, 27 Feb 2024 18:30:15 GMT"
890,AI Startup Roundup: Chinese LLM Startup Raises Over $1 Billion,https://aibusiness.com/nlp/ai-startup-roundup-chinese-llm-startup-raises-1-billion,Also - Capital raise for the startup behind Langchain,"[{'name': 'Ben Wodecki, Deborah Yao'}]","Mon, 26 Feb 2024 22:03:34 GMT"
891,"Google DeepMind CEO on AGI, OpenAI and Beyond – MWC 2024",https://aibusiness.com/nlp/google-deepmind-ceo-on-agi-openai-and-beyond-mwc-2024,Google DeepMind CEO Demis Hassabis also gave a glimpse into how Google lost ground to OpenAI in the AI race,"[{'name': 'Ben Wodecki, Deborah Yao'}]","Mon, 26 Feb 2024 20:56:07 GMT"
892,AI-powered Technique Could Help Quantum Computers Scale,https://aibusiness.com/verticals/ai-powered-technique-could-help-quantum-computers-scale,A collaboration between DeepMind and Quantinuum leads to a quantum computing optimization breakthrough,[{'name': 'Ben Wodecki'}],"Mon, 26 Feb 2024 18:56:00 GMT"
893,How Telcos are Using Generative AI - MWC 2024,https://aibusiness.com/nlp/how-telcos-are-using-generative-ai,Verizon and Telia executives discuss how they incorporate Gen AI into their businesses,[{'name': 'Ben Wodecki'}],"Mon, 26 Feb 2024 17:54:44 GMT"
894,Google DeepMind CEO Defends Gemini's Image Flaws - MWC 2024,https://aibusiness.com/responsible-ai/google-deepmind-ceo-defends-gemini-s-well-intended-image-flaws,DeepMind CEO Demis Hassabis said the problem should be fixed in the next couple of weeks,[{'name': 'Ben Wodecki'}],"Mon, 26 Feb 2024 17:23:42 GMT"
895,Deloitte: How to Prevent AI from Taking Your Job,https://aibusiness.com/responsible-ai/deloitte-how-to-prevent-ai-from-taking-your-job,"An interview with David Mallon, managing director of Deloitte Consulting",[{'name': 'Deborah Yao'}],"Mon, 26 Feb 2024 13:00:00 GMT"
896,Google to Train AI Models on Reddit Posts. What Could Go Wrong?,https://aibusiness.com/nlp/your-reddit-posts-could-be-used-to-train-google-s-ai-models,Posts are infamously candid and can be offensive. Redditors think Google will have to train its models more carefully,[{'name': 'Ben Wodecki'}],"Fri, 23 Feb 2024 20:47:40 GMT"
897,AI News Roundup: Mistral’s Open Source AI Models Heading to AWS,https://aibusiness.com/nlp/ai-news-roundup-mistral-s-open-source-ai-models-heading-to-aws,Also – Adobe unveils AI assistant and Stability AI sells Clipdrop to Jasper,"[{'name': 'Ben Wodecki, Deborah Yao'}]","Fri, 23 Feb 2024 20:05:21 GMT"
898,AI in Crime-Fighting: DOJ Launches Justice AI,https://aibusiness.com/responsible-ai/ai-in-crime-fighting-doj-launches-justice-ai,"The U.S. Department of Justice's new initiative, Justice AI, aims to modernize crime-fighting while adhering to ethical standards.",[{'name': 'Ben Wodecki'}],"Fri, 23 Feb 2024 18:55:26 GMT"
899,Microsoft's Free AI Security Tester for Gen AI Models,https://aibusiness.com/nlp/microsoft-offers-free-use-of-ai-security-tool-for-language-models,"Microsoft's PyRIT generates malicious prompts to stress-test models, reducing testing time from weeks to hours",[{'name': 'Ben Wodecki'}],"Fri, 23 Feb 2024 18:01:39 GMT"
900,"Stable Diffusion 3: More Realistic, Better Speller",https://aibusiness.com/nlp/stable-diffusion-3-more-realistic-better-speller,"The latest version of the popular text-to-image model uses a new architecture, leading to improved performance",[{'name': 'Ben Wodecki'}],"Fri, 23 Feb 2024 17:07:48 GMT"
901,This Week's Most Read: Can Quantum Help AI Understand?,https://aibusiness.com/nlp/this-week-s-most-read-can-quantum-help-ai-understand-,"Also, Air Canada pays up for its chatbot’s mistake and Hugging Face’s new AI assistant builder",[{'name': 'Ben Wodecki'}],"Thu, 22 Feb 2024 23:46:06 GMT"
902,The Rising Importance of Orchestration in Gen AI Development,https://aibusiness.com/nlp/the-rising-importance-of-orchestration-in-generative-ai-development,"As generative AI applications get more complex, there is a need for tools to help with orchestration",[{'name': 'Tom Taulli'}],"Thu, 22 Feb 2024 23:00:00 GMT"
903,Geoff Hinton: Russia and US Under Trump Can Let AI ‘Go Too Far’,https://aibusiness.com/responsible-ai/geoff-hinton-china-russia-and-us-could-let-ai-go-too-far-,One of the godfathers of AI fears world leaders could use AI to manipulate elections and wage war,[{'name': 'Ben Wodecki'}],"Thu, 22 Feb 2024 21:02:12 GMT"
904,Google’s Gemini Has Trouble Drawing White People,https://aibusiness.com/responsible-ai/google-s-gemini-has-trouble-drawing-white-people,Google halted Gemini's image generation of people after it drew images of people of color holding positions historically held by whites,[{'name': 'Ben Wodecki'}],"Thu, 22 Feb 2024 19:51:22 GMT"
905,"A Bold Call from OpenAI, Safety Crusaders: Limit Compute",https://aibusiness.com/responsible-ai/a-bold-call-from-openai-other-safety-crusaders-limit-compute,"Turing awardee Yoshua Bengio and top universities join call for regulators to focus on hardware, not software, for AI safety",[{'name': 'Ben Wodecki'}],"Thu, 22 Feb 2024 18:00:32 GMT"
906,Quantum-Enhanced Gen AI Creates Viable Cancer Drug Candidates,https://aibusiness.com/verticals/quantum-enhanced-generative-ai-creates-viable-cancer-drug-candidates,Zapata AI study outperformed classical methods to deliver drug candidates in a world-first,[{'name': 'Berenice Baker'}],"Thu, 22 Feb 2024 17:23:00 GMT"
907,Nvidia CEO: AI Activity has 'Accelerated Significantly',https://aibusiness.com/nlp/nvidia-s-record-revenue-points-to-strong-ai-demand,"After reporting blow-out earnings, CEO Jensen Huang added $9.6 billion to his fortune in one day, making him the 21st richest person in the world.",[{'name': 'Deborah Yao'}],"Wed, 21 Feb 2024 22:00:00 GMT"
908,"Google Unveils Open Source Models to Rival Meta, Mistral",https://aibusiness.com/nlp/google-unveils-open-source-models-to-compete-against-meta,"Google released the Gemma line of open source models, which it says outperforms rival models from Meta and Mistral.",[{'name': 'Deborah Yao'}],"Wed, 21 Feb 2024 19:58:33 GMT"
909,Build Multilingual AI Solutions with Cohere’s New Aya Model,https://aibusiness.com/nlp/build-multilingual-ai-solutions-with-cohere-s-new-aya-model,Cohere for AI's new open source project lets developers build AI applications that span over 100 languages,[{'name': 'Ben Wodecki'}],"Wed, 21 Feb 2024 18:15:56 GMT"
910,Mobile World Congress Barcelona 2024 Preview,https://aibusiness.com/verticals/mwc-barcelona-2024-preview-industry-rubs-shoulders-with-consumer-tech,"The news to watch in AI, IoT, quantum and beyond as the connectivity event reconvenes on February 26 to 29",[{'name': 'Berenice Baker'}],"Wed, 21 Feb 2024 17:15:02 GMT"
911,Anthropic’s latest AI model beats rivals and achieves industry first,https://www.artificialintelligence-news.com/2024/03/05/anthropic-latest-ai-model-beats-rivals-achieves-industry-first/,"<p>Anthropic’s latest cutting-edge language model, Claude 3, has surged ahead of competitors like ChatGPT and Google&#8217;s Gemini to set new industry standards in performance and capability. According to Anthropic, Claude 3 has not only surpassed its predecessors but has also achieved &#8220;near-human&#8221; proficiency in various tasks. The company attributes this success to rigorous testing and<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/03/05/anthropic-latest-ai-model-beats-rivals-achieves-industry-first/\" title=\"ReadAnthropic&#8217;s latest AI model beats rivals and achieves industry first\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/03/05/anthropic-latest-ai-model-beats-rivals-achieves-industry-first/\">Anthropic&#8217;s latest AI model beats rivals and achieves industry first</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Tue, 05 Mar 2024 11:52:32 +0000"
912,AIs in India will need government permission before launching,https://www.artificialintelligence-news.com/2024/03/04/ai-india-need-government-permission-before-launching/,"<p>In an advisory issued by India’s Ministry of Electronics and Information Technology (MeitY) last Friday, it was declared that any AI technology still in development must acquire explicit government permission before being released to the public. Developers will also only be able to deploy these technologies after labelling the potential fallibility or unreliability of the<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/03/04/ai-india-need-government-permission-before-launching/\" title=\"ReadAIs in India will need government permission before launching\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/03/04/ai-india-need-government-permission-before-launching/\">AIs in India will need government permission before launching</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Mon, 04 Mar 2024 17:03:13 +0000"
913,Elon Musk sues OpenAI over alleged breach of nonprofit agreement,https://www.artificialintelligence-news.com/2024/03/01/elon-musk-sues-openai-alleged-breach-nonprofit-agreement/,"<p>Elon Musk has filed a lawsuit against OpenAI and its CEO, Sam Altman, citing a violation of their nonprofit agreement. The legal battle, unfolding in the Superior Court of California for the County of San Francisco, revolves around OpenAI&#8217;s departure from its foundational mission of advancing open-source artificial general intelligence (AGI) for the betterment of<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/03/01/elon-musk-sues-openai-alleged-breach-nonprofit-agreement/\" title=\"ReadElon Musk sues OpenAI over alleged breach of nonprofit agreement\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/03/01/elon-musk-sues-openai-alleged-breach-nonprofit-agreement/\">Elon Musk sues OpenAI over alleged breach of nonprofit agreement</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Fri, 01 Mar 2024 13:09:25 +0000"
914,UK and France to collaborate on AI following Horizon membership,https://www.artificialintelligence-news.com/2024/02/29/uk-and-france-collaborate-ai-following-horizon-membership/,"<p>The UK and France have announced new funding initiatives and partnerships aimed at advancing global AI safety. The developments come in the wake of the UK&#8217;s association with Horizon Europe, a move that was broadly seen as putting the divisions of Brexit in the past and the repairing of relations for the good of the<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/29/uk-and-france-collaborate-ai-following-horizon-membership/\" title=\"ReadUK and France to collaborate on AI following Horizon membership\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/29/uk-and-france-collaborate-ai-following-horizon-membership/\">UK and France to collaborate on AI following Horizon membership</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Thu, 29 Feb 2024 10:07:19 +0000"
915,Mistral AI unveils LLM rivalling major players,https://www.artificialintelligence-news.com/2024/02/27/mistral-ai-unveils-llm-rivalling-major-players/,"<p>Mistral AI, a France-based startup, has introduced a new large language model (LLM) called Mistral Large that it claims can compete with several top AI systems on the market.   Mistral AI stated that Mistral Large outscored most major LLMs except for OpenAI&#8217;s recently launched GPT-4 in tests of language understanding. It also performed strongly in<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/27/mistral-ai-unveils-llm-rivalling-major-players/\" title=\"ReadMistral AI unveils LLM rivalling major players\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/27/mistral-ai-unveils-llm-rivalling-major-players/\">Mistral AI unveils LLM rivalling major players</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Tue, 27 Feb 2024 12:59:49 +0000"
916,UK Home Secretary sounds alarm over deepfakes ahead of elections,https://www.artificialintelligence-news.com/2024/02/26/uk-home-secretary-alarm-deepfakes-ahead-elections/,"<p>Criminals and hostile state actors could hijack Britain&#8217;s democratic process by deploying AI-generated &#8220;deepfakes&#8221; to mislead voters, UK Home Secretary James Cleverly cautioned in remarks ahead of meetings with major tech companies.  Speaking to The Times, Cleverly emphasised the rapid advancement of AI technology and its potential to undermine elections not just in the UK<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/26/uk-home-secretary-alarm-deepfakes-ahead-elections/\" title=\"ReadUK Home Secretary sounds alarm over deepfakes ahead of elections\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/26/uk-home-secretary-alarm-deepfakes-ahead-elections/\">UK Home Secretary sounds alarm over deepfakes ahead of elections</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Mon, 26 Feb 2024 16:46:48 +0000"
917,Stability AI previews Stable Diffusion 3 text-to-image model,https://www.artificialintelligence-news.com/2024/02/23/stability-ai-previews-stable-diffusion-3-text-to-image-model/,"<p>London-based AI lab Stability AI has announced an early preview of its new text-to-image model, Stable Diffusion 3. The advanced generative AI model aims to create high-quality images from text prompts with improved performance across several key areas. The announcement comes just days after Stability AI’s largest rival, OpenAI, unveiled Sora—a brand new AI model<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/23/stability-ai-previews-stable-diffusion-3-text-to-image-model/\" title=\"ReadStability AI previews Stable Diffusion 3 text-to-image model\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/23/stability-ai-previews-stable-diffusion-3-text-to-image-model/\">Stability AI previews Stable Diffusion 3 text-to-image model</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Fri, 23 Feb 2024 16:49:01 +0000"
918,Google pledges to fix Gemini’s inaccurate and biased image generation,https://www.artificialintelligence-news.com/2024/02/22/google-pledges-fix-gemini-inaccurate-biased-image-generation/,"<p>Google&#8217;s Gemini model has come under fire for its production of historically-inaccurate and racially-skewed images, reigniting concerns about bias in AI systems. The controversy arose as users on social media platforms flooded feeds with examples of Gemini generating pictures depicting racially-diverse Nazis, black medieval English kings, and other improbable scenarios. Google Gemini Image generation model<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/22/google-pledges-fix-gemini-inaccurate-biased-image-generation/\" title=\"ReadGoogle pledges to fix Gemini’s inaccurate and biased image generation\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/22/google-pledges-fix-gemini-inaccurate-biased-image-generation/\">Google pledges to fix Gemini’s inaccurate and biased image generation</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Thu, 22 Feb 2024 15:11:11 +0000"
919,Microsoft is quadrupling its AI and cloud investment in Spain,https://www.artificialintelligence-news.com/2024/02/21/microsoft-quadrupling-ai-cloud-investment-spain/,"<p>Microsoft has announced plans to significantly boost its investment in AI and cloud infrastructure in Spain, with a commitment to quadruple its spending during 2024-2025 to reach $2.1 billion. This substantial increase marks the largest investment by Microsoft in Spain since its establishment in the country 37 years ago. The tech giant is set to<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/21/microsoft-quadrupling-ai-cloud-investment-spain/\" title=\"ReadMicrosoft is quadrupling its AI and cloud investment in Spain\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/21/microsoft-quadrupling-ai-cloud-investment-spain/\">Microsoft is quadrupling its AI and cloud investment in Spain</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Wed, 21 Feb 2024 15:53:40 +0000"
920,Wipro and IBM collaborate to propel enterprise AI,https://www.artificialintelligence-news.com/2024/02/20/wipro-and-ibm-collaborate-propel-enterprise-ai/,"<p>In a bid to accelerate the adoption of AI in the enterprise sector, Wipro has unveiled its latest offering that leverages the capabilities of IBM’s watsonx AI and data platform. The extended partnership between Wipro and IBM combines the former’s extensive industry expertise with IBM&#8217;s leading AI innovations. The collaboration seeks to develop joint solutions<a class=\"excerpt-read-more\" href=\"https://www.artificialintelligence-news.com/2024/02/20/wipro-and-ibm-collaborate-propel-enterprise-ai/\" title=\"ReadWipro and IBM collaborate to propel enterprise AI\">... Read more &#187;</a></p>
<p>The post <a href=\"https://www.artificialintelligence-news.com/2024/02/20/wipro-and-ibm-collaborate-propel-enterprise-ai/\">Wipro and IBM collaborate to propel enterprise AI</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>",[{'name': 'Ryan Daws'}],"Tue, 20 Feb 2024 16:31:33 +0000"
921,Google Is Finally Trying to Kill AI Clickbait,https://www.wired.com/story/google-search-artificial-intelligence-clickbait-spam-crackdown/,"On Tuesday, Google announced changes to combat AI spam in search. An SEO expert says these new rules could “change everything.”",[{'name': 'Kate Knibbs'}],"Tue, 05 Mar 2024 21:16:52 +0000"
922,Robert F. Kennedy Jr.’s Microsoft-Powered Chatbot Is Back Online,https://www.wired.com/story/robert-f-kennedy-jr-chatbot-microsoft-openai-disappeared/,"The RFK Jr. campaign’s chatbot had previously affirmed Kennedy’s promotion of conspiracy theories, and appeared to circumvent OpenAI’s ban on political use.",[{'name': 'Makena Kelly'}],"Sun, 03 Mar 2024 23:23:40 +0000"
923,What Is OpenAI’s ChatGPT Plus? Here’s What You Should Know,https://www.wired.com/story/what-is-chatgpt-plus-gpt4-openai/,OpenAI’s subscription-only service costs $20 a month and includes access to the GPT-4 model. We signed up and tried it out.,[{'name': 'Reece Rogers'}],"Sun, 03 Mar 2024 12:00:00 +0000"
924,The Wild Claim at the Heart of Elon Musk’s OpenAI Lawsuit,https://www.wired.com/story/wild-claim-at-the-heart-of-elon-musks-openai-lawsuit/,Elon Musk’s lawsuit against OpenAI hinges on a dubious claim that the company has already developed ‘artificial general intelligence’—and handed it over to Microsoft.,[{'name': 'Will Knight'}],"Fri, 01 Mar 2024 22:50:40 +0000"
925,The Mind-Blowing Experience of a Chatbot That Answers Instantly,https://www.wired.com/story/plaintext-groq-mindblowing-chatbot-answers-instantly/,AI chips from startup Groq allow chatbots to answer queries almost instantly. That could open up whole new use cases for generative AI helpers.,[{'name': 'Steven Levy'}],"Fri, 01 Mar 2024 14:00:00 +0000"
926,Elon Musk Sues OpenAI and Sam Altman for ‘Flagrant Breaches’ of Contract,https://www.wired.com/story/elon-musk-sues-sam-altman-openai/,"In the lawsuit, Musk claims OpenAI has abandoned its mission to develop AI for the benefit of humanity.",[{'name': 'Morgan Meaker'}],"Fri, 01 Mar 2024 13:54:14 +0000"
927,Here Come the AI Worms,https://www.wired.com/story/here-come-the-ai-worms/,Security researchers created an AI worm in a test environment that can automatically spread between generative AI agents—potentially stealing data and sending spam emails along the way.,[{'name': 'Matt Burgess'}],"Fri, 01 Mar 2024 09:00:00 +0000"
928,Google’s Deal With Stack Overflow Is the Latest Proof That AI Giants Will Pay for Data,https://www.wired.com/story/google-deal-stackoverflow-ai-giants-pay-for-data/,Stack Overflow’s programming community will power a version of Google’s Gemini chatbot. It’s part of a new breed of AI data licensing deals with websites seeking a cut of the generative AI boom.,[{'name': 'Paresh Dave'}],"Thu, 29 Feb 2024 22:07:43 +0000"
929,The AI Culture Wars Are Just Getting Started,https://www.wired.com/story/fast-forward-ai-culture-wars-just-getting-started/,Google apologized after its Gemini model caused offense by being too “woke.” Expect political fights over AI’s values to worsen as the technology becomes more capable.,[{'name': 'Will Knight'}],"Thu, 29 Feb 2024 17:00:00 +0000"
930,How Nvidia Came to Rule AI,https://www.wired.com/story/gadget-lab-podcast-634/,"This week we chart the rise of Nvidia, the company whose chips, servers, and data centers have fueled the growth of artificial intelligence.","[{'name': 'Lauren Goode, Michael Calore, Will Knight'}]","Thu, 29 Feb 2024 13:00:00 +0000"
931,New dressing robot can 'mimic' the actions of care-workers,https://www.sciencedaily.com/releases/2024/03/240304135829.htm,Scientists have developed a new robot that can 'mimic' the two-handed movements of care-workers as they dress an individual.,[],"Mon, 04 Mar 2024 13:58:29 EST"
932,A novel method for easy and quick fabrication of biomimetic robots with life-like movement,https://www.sciencedaily.com/releases/2024/02/240226114557.htm,"Ultraviolet-laser processing is a promising technique for developing intricate microstructures, enabling complex alignment of muscle cells, required for building life-like biohybrid actuators. Compared to traditional complex methods, this innovative technique enables easy and quick fabrication of microstructures with intricate patterns for achieving different muscle cell arrangements, paving the way for biohybrid actuators capable of complex, flexible movements.",[],"Mon, 26 Feb 2024 11:45:57 EST"
933,Method identified to double computer processing speeds,https://www.sciencedaily.com/releases/2024/02/240221213907.htm,"Scientists introduce what they call 'simultaneous and heterogeneous multithreading' or SHMT. This system doubles computer processing speeds with existing hardware by simultaneously using graphics processing units (GPUs), hardware accelerators for artificial intelligence (AI) and machine learning (ML), or digital signal processing units to process information.",[],"Wed, 21 Feb 2024 21:39:07 EST"
934,How ancient sea creatures can inform soft robotics,https://www.sciencedaily.com/releases/2024/02/240212153511.htm,"Fossils of a marine animal that lived 500 million years ago, combined with computer simulations, informed the design of a new soft robot.",[],"Mon, 12 Feb 2024 15:35:11 EST"
935,Why insects navigate more efficiently than robots,https://www.sciencedaily.com/releases/2024/02/240212133153.htm,"Engineers have studied how insects navigate, for the purpose of developing energy-efficient robots.",[],"Mon, 12 Feb 2024 13:31:53 EST"
936,Innovations in depth from focus/defocus pave the way to more capable computer vision systems,https://www.sciencedaily.com/releases/2024/02/240209134440.htm,"In an image, estimating the distance between objects and the camera by using the blur in the images as clue, also known as depth from focus/defocus, is essential in computer vision. However, model-based methods fail when texture-less surfaces are present, and learning-based methods require the same camera settings during training and testing. Now, researchers have come up with an innovative strategy for depth estimation that combines the best of both the worlds to solve these limitations, extending the applicability of depth from focus/defocus.",[],"Fri, 09 Feb 2024 13:44:40 EST"
937,A sleeker facial recognition technology tested on Michelangelo's David,https://www.sciencedaily.com/releases/2024/02/240202132613.htm,"Many people are familiar with facial recognition systems that unlock smartphones and game systems or allow access to our bank accounts online. But the current technology can require boxy projectors and lenses. Now, researchers report on a sleeker 3D surface imaging system with flatter, simplified optics. In proof-of-concept demonstrations, the new system recognized the face of Michelangelo's David just as well as an existing smartphone system.",[],"Fri, 02 Feb 2024 13:26:13 EST"
938,Robot trained to read braille at twice the speed of humans,https://www.sciencedaily.com/releases/2024/01/240129122413.htm,Researchers have developed a robotic sensor that incorporates artificial intelligence techniques to read braille at speeds roughly double that of most human readers.,[],"Mon, 29 Jan 2024 12:24:13 EST"
939,Utilizing active microparticles for artificial intelligence,https://www.sciencedaily.com/releases/2024/01/240129122349.htm,Artificial intelligence using neural networks performs calculations digitally with the help of microelectronic chips. Physicists have now created a type of neural network that works not with electricity but with so-called active colloidal particles.The researchers describe how these microparticles can be used as a physical system for artificial intelligence and the prediction of time series.,[],"Mon, 29 Jan 2024 12:23:49 EST"
940,Scientists design a two-legged robot powered by muscle tissue,https://www.sciencedaily.com/releases/2024/01/240126140516.htm,"Compared to robots, human bodies are flexible, capable of fine movements, and can convert energy efficiently into movement. Drawing inspiration from human gait, researchers from Japan crafted a two-legged biohybrid robot by combining muscle tissues and artificial materials. This method allows the robot to walk and pivot.",[],"Fri, 26 Jan 2024 14:05:16 EST"
941,"Chats with AI shift attitudes on climate change, Black Lives Matter",https://www.sciencedaily.com/releases/2024/01/240126001915.htm,People who were more skeptical of human-caused climate change or the Black Lives Matter movement who took part in conversation with a popular AI chatbot were disappointed with the experience but left the conversation more supportive of the scientific consensus on climate change or BLM. This is according to researchers studying how these chatbots handle interactions from people with different cultural backgrounds.,[],"Fri, 26 Jan 2024 00:19:15 EST"
942,Autonomous synthesis robot uses AI to speed up chemical discovery,https://www.sciencedaily.com/releases/2024/01/240125145938.htm,"Chemists have developed an autonomous chemical synthesis robot with an integrated AI-driven machine learning unit. Dubbed 'RoboChem', the benchtop device can outperform a human chemist in terms of speed and accuracy while also displaying a high level of ingenuity. As the first of its kind, it could significantly accelerate chemical discovery of molecules for pharmaceutical and many other applications.",[],"Thu, 25 Jan 2024 14:59:38 EST"
943,"Mini-robots modeled on insects may be smallest, lightest, fastest ever developed",https://www.sciencedaily.com/releases/2024/01/240118122235.htm,"Two insect-like robots, a mini-bug and a water strider may be the smallest, lightest and fastest fully functional micro-robots ever known to be created. Such miniature robots could someday be used for work in areas such as artificial pollination, search and rescue, environmental monitoring, micro-fabrication or robotic-assisted surgery. Reporting on their work in the proceedings of the IEEE Robotics and Automation Society's International Conference on Intelligent Robots and Systems, the mini-bug weighs in at eight milligrams while the water strider weighs 55 milligrams. Both can move at about six millimeters a second.",[],"Thu, 18 Jan 2024 12:22:35 EST"
944,Study identifies new findings on implant positioning and stability during robotic-assisted knee revision surgery,https://www.sciencedaily.com/releases/2024/01/240117183753.htm,"An innovative study explores the use of robotic-assisted joint replacement in revision knee scenarios, comparing the pre- and post-revision implant positions in a series of revision total knee arthroplasties (TKA) using a state-of-the-art robotic arm system.",[],"Wed, 17 Jan 2024 18:37:53 EST"
945,'Smart glove' can boost hand mobility of stroke patients,https://www.sciencedaily.com/releases/2024/01/240116131818.htm,"This month, a group of stroke survivors in British Columbia will test a new technology designed to aid their recovery, and ultimately restore use of their limbs and hands. Participants will wear a new groundbreaking 'smart glove' capable of tracking their hand and finger movements during rehabilitation exercises.",[],"Tue, 16 Jan 2024 13:18:18 EST"
946,Artificial muscle device produces force 34 times its weight,https://www.sciencedaily.com/releases/2024/01/240111113200.htm,"Scientists developed a soft fluidic switch using an ionic polymer artificial muscle that runs with ultra-low power to lift objects 34 times greater than its weight. Its light weight and small size make it applicable to various industrial fields such as soft electronics, smart textiles, and biomedical devices by controlling fluid flow with high precision, even in narrow spaces.",[],"Thu, 11 Jan 2024 11:32:00 EST"
947,Researchers developing AI to make the internet more accessible,https://www.sciencedaily.com/releases/2024/01/240109170521.htm,"In an effort to make the internet more accessible for people with disabilities, researchers have begun developing an artificial intelligence agent that could complete complex tasks on any website using simple language commands.",[],"Tue, 09 Jan 2024 17:05:21 EST"
948,"New soft robots roll like tires, spin like tops and orbit like moons",https://www.sciencedaily.com/releases/2024/01/240108153135.htm,"Researchers have developed a new soft robot design that engages in three simultaneous behaviors: rolling forward, spinning like a record, and following a path that orbits around a central point. The device, which operates without human or computer control, holds promise for developing soft robotic devices that can be used to navigate and map unknown environments.",[],"Mon, 08 Jan 2024 15:31:35 EST"
949,AI alters middle managers' work,https://www.sciencedaily.com/releases/2023/12/231221012822.htm,"The introduction of artificial intelligence is a significant part of the digital transformation bringing challenges and changes to the job descriptions among management. A study shows that integrating artificial intelligence systems into service teams increases demands imposed on middle management in the financial services field. In that sector, the advent of artificial intelligence has been fast and AI applications can implement a large proportion of routine work that was previously done by people. Many professionals in the service sector work in teams which include both humans and artificial intelligence systems, which sets new expectations on interactions, human relations, and leadership.",[],"Thu, 21 Dec 2023 01:28:22 EST"
950,"Meet 'Coscientist,' your AI lab partner",https://www.sciencedaily.com/releases/2023/12/231221012729.htm,"An artificial intelligence-driven system has autonomously learned about certain Nobel Prize-winning chemical reactions and designed a successful laboratory procedure to make them. The AI did so in just a few minutes and correctly on its first attempt. According to the authors, this is the first time that a non-organic intelligence planned, designed and executed this complex reaction that was invented by humans.",[],"Thu, 21 Dec 2023 01:27:29 EST"
951,Artificial intelligence can predict events in people's lives,https://www.sciencedaily.com/releases/2023/12/231218125850.htm,"Artificial intelligence can analyze registry data on people's residence, education, income, health and working conditions and, with high accuracy, predict life events.",[],"Mon, 18 Dec 2023 12:58:50 EST"
952,AI chatbot shows potential as diagnostic partner,https://www.sciencedaily.com/releases/2023/12/231211114509.htm,Physician-investigators compared a chatbot's probabilistic reasoning to that of human clinicians. The findings suggest that artificial intelligence could serve as useful clinical decision support tools for physicians.,[],"Mon, 11 Dec 2023 11:45:09 EST"
953,Exposure to soft robots decreases human fears about working with them,https://www.sciencedaily.com/releases/2023/12/231205114751.htm,"Seeing robots made with soft, flexible parts in action appears to lower people's anxiety about working with them or even being replaced by them. A study found that watching videos of a soft robot working with a person at picking and placing tasks lowered the viewers' safety concerns and feelings of job insecurity. This was true even when the soft robot was shown working in close proximity to the person. This finding shows soft robots hold a potential psychological advantage over rigid robots made of metal or other hard materials.",[],"Tue, 05 Dec 2023 11:47:51 EST"
954,AI networks are more vulnerable to malicious attacks than previously thought,https://www.sciencedaily.com/releases/2023/12/231204135128.htm,"Artificial intelligence tools hold promise for applications ranging from autonomous vehicles to the interpretation of medical images. However, a new study finds these AI tools are more vulnerable than previously thought to targeted attacks that effectively force AI systems to make bad decisions.",[],"Mon, 04 Dec 2023 13:51:28 EST"
955,A color-based sensor to emulate skin's sensitivity,https://www.sciencedaily.com/releases/2023/12/231201173202.htm,"In a step toward more autonomous soft robots and wearable technologies, researchers have created a device that uses color to simultaneously sense multiple mechanical and temperature stimuli.",[],"Fri, 01 Dec 2023 17:32:02 EST"
956,Brainstorming with a bot,https://www.sciencedaily.com/releases/2023/12/231201123612.htm,"Electronic nanomaterials experts have imagined how recent advances in artificial intelligence (AI) and machine learning (ML) could aid scientific brainstorming and ideation. To accomplish this, they have developed a chatbot with knowledge in the kinds of science he's been engaged in.",[],"Fri, 01 Dec 2023 12:36:12 EST"
957,Scientists use A.I.-generated images to map visual functions in the brain,https://www.sciencedaily.com/releases/2023/11/231130145431.htm,Researchers have demonstrated the use of AI-selected natural images and AI-generated synthetic images as neuroscientific tools for probing the visual processing areas of the brain. The goal is to apply a data-driven approach to understand how vision is organized while potentially removing biases that may arise when looking at responses to a more limited set of researcher-selected images.,[],"Thu, 30 Nov 2023 14:54:31 EST"
958,2D material reshapes 3D electronics for AI hardware,https://www.sciencedaily.com/releases/2023/11/231130145423.htm,"Researchers demonstrated monolithic 3D integration of layered 2D material into novel processing hardware for artificial intelligence computing. The new approach provides a material-level solution for fully integrating many functions into a single, small electronic chip -- and paves the way for advanced AI computing.",[],"Thu, 30 Nov 2023 14:54:23 EST"
959,How do you make a robot smarter? Program it to know what it doesn't know,https://www.sciencedaily.com/releases/2023/11/231128172842.htm,Engineers have come up with a new way to teach robots to know when they don't know. The technique involves quantifying the fuzziness of human language and using that measurement to tell robots when to ask for further directions. Telling a robot to pick up a bowl from a table with only one bowl is fairly clear. But telling a robot to pick up a bowl when there are five bowls on the table generates a much higher degree of uncertainty -- and triggers the robot to ask for clarification.,[],"Tue, 28 Nov 2023 17:28:42 EST"
960,Researchers engineer a material that can perform different tasks depending on temperature,https://www.sciencedaily.com/releases/2023/11/231128132308.htm,Researchers report that they have developed a new composite material designed to change behaviors depending on temperature in order to perform specific tasks. These materials are poised to be part of the next generation of autonomous robotics that will interact with the environment.,[],"Tue, 28 Nov 2023 13:23:08 EST"
961,Defending your voice against deepfakes,https://www.sciencedaily.com/releases/2023/11/231127180707.htm,"Computer scientists have developed AntiFake, a tool to protect voice recordings from unauthorized speech synthesis.",[],"Mon, 27 Nov 2023 18:07:07 EST"
962,New method uses crowdsourced feedback to help train robots,https://www.sciencedaily.com/releases/2023/11/231127132237.htm,A new technique enables an AI agent to be guided by data crowdsourced asynchronously from nonexpert human users as it learns to complete a task through reinforcement learning. The method trains the robot faster and better than other approaches.,[],"Mon, 27 Nov 2023 13:22:37 EST"
963,How we play together,https://www.sciencedaily.com/releases/2023/11/231121175256.htm,Psychologists are using EEG to research what games reveal about our ability to cooperate.,[],"Tue, 21 Nov 2023 17:52:56 EST"
964,"AI can 'lie and BS' like its maker, but still not intelligent like humans",https://www.sciencedaily.com/releases/2023/11/231120170942.htm,"A researcher contends that the understanding of AI is muddled by linguistics: That while indeed intelligent, AI cannot be intelligent in the way that humans are, even though 'it can lie and BS like its maker.'",[],"Mon, 20 Nov 2023 17:09:42 EST"
965,Creativity in the age of generative AI: A new era of creative partnerships,https://www.sciencedaily.com/releases/2023/11/231120170939.htm,"Generative AI (e.g., ChatGPT) has propelled AI into the mainstream, raising concerns about job displacement and creative work. Experts now emphasize a need to focus on 'co-creativity,' the human-AI interaction instead. Extensive research is needed for comprehending co-creativity which is crucial for the future development of AI.",[],"Mon, 20 Nov 2023 17:09:39 EST"
966,AI system self-organizes to develop features of brains of complex organisms,https://www.sciencedaily.com/releases/2023/11/231120124246.htm,Scientists have shown that placing physical constraints on an artificially-intelligent system -- in much the same way that the human brain has to develop and operate within physical and biological constraints -- allows it to develop features of the brains of complex organisms in order to solve tasks.,[],"Mon, 20 Nov 2023 12:42:46 EST"
967,AI: Researchers develop automatic text recognition for ancient cuneiform tablets,https://www.sciencedaily.com/releases/2023/11/231120124148.htm,"A new artificial intelligence (AI) software is now able to decipher difficult-to-read texts on cuneiform tablets. Instead of photos, the AI system uses 3D models of the tablets, delivering significantly more reliable results than previous methods. This makes it possible to search through the contents of multiple tablets to compare them with each other. It also paves the way for entirely new research questions.",[],"Mon, 20 Nov 2023 12:41:48 EST"
968,The mind's eye of a neural network system,https://www.sciencedaily.com/releases/2023/11/231116141058.htm,"A new tool, based on topology, makes finding the areas where neural networks are confused as simple as spotting mountaintops from an airplane. The ability to spot and address those areas of confusion should enable more confident application of neural networks in high-stakes decision scenarios or image prediction tasks like healthcare and research.",[],"Thu, 16 Nov 2023 14:10:58 EST"
969,Realistic talking faces created from only an audio clip and a person's photo,https://www.sciencedaily.com/releases/2023/11/231116140827.htm,"A team of researchers has developed a computer program that creates realistic videos that reflect the facial expressions and head movements of the person speaking, only requiring an audio clip and a face photo.   DIverse yet Realistic Facial Animations, or DIRFA, is an artificial intelligence-based program that takes audio and a photo and produces a 3D video showing the person demonstrating realistic and consistent facial animations synchronised with the spoken audio (see videos).",[],"Thu, 16 Nov 2023 14:08:27 EST"
970,Use it or lose it: New robotic system assesses mobility after stroke,https://www.sciencedaily.com/releases/2023/11/231116140354.htm,"Stroke is a leading cause of long-term disability worldwide. Each year more than 15 million people worldwide have strokes, and three-quarters of stroke survivors will experience impairment, weakness and paralysis in their arms and hands. Many stroke survivors rely on their stronger arm to complete daily tasks, from carrying groceries to combing their hair, even when the weaker arm has the potential to improve.",[],"Thu, 16 Nov 2023 14:03:54 EST"
971,This 3D printer can watch itself fabricate objects,https://www.sciencedaily.com/releases/2023/11/231115113339.htm,"Engineers have developed a high-throughput, multimaterial 3D inkjet printer that uses computer vision to rapidly and automatically control the amount of material being deposited during the printing process in real time. This enables the use of a wide range of materials for fabrication.",[],"Wed, 15 Nov 2023 11:33:39 EST"
972,Individual back training machine developed,https://www.sciencedaily.com/releases/2023/11/231114143740.htm,"18 percent of reported sick leave relates to musculoskeletal ailments, in particular back-related disorders. The GyroTrainer is an intelligent training device that resembles a balance board. It uses artificial intelligence to adjust the difficulty level to the individual patient's current ability.",[],"Tue, 14 Nov 2023 14:37:40 EST"
973,Engineers are on a failure-finding mission,https://www.sciencedaily.com/releases/2023/11/231109121552.htm,Engineers developed a technique to quickly identify a range of potential failures in a system before they are deployed in the real world.,[],"Thu, 09 Nov 2023 12:15:52 EST"
974,How human faces can teach androids to smile,https://www.sciencedaily.com/releases/2023/11/231109121541.htm,"A research team used 125 physical markers to understand the detailed mechanics of 44 different human facial motions. The aim was to better understand how to convey emotions with artificial faces. Beyond helping with the design of robots and androids, this research can also benefit computer graphics, facial recognition, and medical diagnoses.",[],"Thu, 09 Nov 2023 12:15:41 EST"
975,Machine learning gives users 'superhuman' ability to open and control tools in virtual reality,https://www.sciencedaily.com/releases/2023/11/231107131923.htm,Researchers have developed a virtual reality application where a range of 3D modelling tools can be opened and controlled using just the movement of a user's hand.,[],"Tue, 07 Nov 2023 13:19:23 EST"
976,Neuromorphic computing will be great... if hardware can handle the workload,https://www.sciencedaily.com/releases/2023/11/231106202950.htm,Scientists believe they may have discovered a way to rework the hardware of AI. By mimicking the synapses of the human brain.,[],"Mon, 06 Nov 2023 20:29:50 EST"
977,450-million-year-old organism finds new life in Softbotics,https://www.sciencedaily.com/releases/2023/11/231106202936.htm,"Researchers have used fossil evidence to engineer a soft robotic replica of pleurocystitids, a marine organism that existed nearly 450 million years ago and is believed to be one of the first echinoderms capable of movement using a muscular stem.",[],"Mon, 06 Nov 2023 20:29:36 EST"
978,AI should be better understood and managed -- new research warns,https://www.sciencedaily.com/releases/2023/11/231102135100.htm,"Artificial Intelligence (AI) and algorithms can and are being used to radicalize, polarize, and spread racism and political instability, says an academic. An expert argues that AI and algorithms are not just tools deployed by national security agencies to prevent malicious activity online, but can be contributors to polarization, radicalism and political violence -- posing a threat to national security.",[],"Thu, 02 Nov 2023 13:51:00 EDT"
979,Nanowire 'brain' network learns and remembers 'on the fly',https://www.sciencedaily.com/releases/2023/11/231101134804.htm,"Like a collection of 'Pick Up Sticks', this neural network has passed a critical step for developing machine intelligence. For the first time, a physical neural network has successfully been shown to learn and remember 'on the fly', in a way inspired by and similar to how the brain's neurons work. The result opens a pathway for developing efficient and low-energy machine intelligence for more complex, real-world learning and memory tasks.",[],"Wed, 01 Nov 2023 13:48:04 EDT"
980,The brain may learn about the world the same way some computational models do,https://www.sciencedaily.com/releases/2023/10/231030194459.htm,"New studies support the idea that the brain uses a process similar to a machine-learning approach known as 'self-supervised learning.' This type of machine learning allows computational models to learn about visual scenes based solely on the similarities and differences between them, with no labels or other information.",[],"Mon, 30 Oct 2023 19:44:59 EDT"
981,Robot stand-in mimics movements in VR,https://www.sciencedaily.com/releases/2023/10/231027110752.htm,Researchers have developed a souped-up telepresence robot that responds automatically and in real-time to a remote user's movements and gestures made in virtual reality.,[],"Fri, 27 Oct 2023 11:07:52 EDT"
982,Engineers develop breakthrough 'robot skin',https://www.sciencedaily.com/releases/2023/10/231026131623.htm,"Smart, stretchable and highly sensitive, a new soft sensor opens the door to a wide range of applications in robotics and prosthetics. When applied to the surface of a prosthetic arm or a robotic limb, the sensor skin provides touch sensitivity and dexterity, enabling tasks that can be difficult for machines such as picking up a piece of soft fruit. The sensor is also soft to the touch, like human skin, which helps make human interactions safer and more lifelike.",[],"Thu, 26 Oct 2023 13:16:23 EDT"
983,Vision via sound for the blind,https://www.sciencedaily.com/releases/2023/10/231025223433.htm,"Smart glasses that use a technique similar to a bat's echolocation could help blind and low-vision people navigate their surroundings, according to researchers.",[],"Wed, 25 Oct 2023 22:34:33 EDT"
984,Can AI grasp related concepts after learning only one?,https://www.sciencedaily.com/releases/2023/10/231025163006.htm,"Researchers have now developed a technique that advances the ability of these tools, such as ChatGPT, to make compositional generalizations. This technique, Meta-learning for Compositionality, outperforms existing approaches and is on par with, and in some cases better than, human performance.",[],"Wed, 25 Oct 2023 16:30:06 EDT"
985,Plant-based materials give 'life' to tiny soft robots,https://www.sciencedaily.com/releases/2023/10/231023124412.htm,"A team of researchers has created smart, advanced materials that will be the building blocks for a future generation of soft medical microrobots. These tiny robots have the potential to conduct medical procedures, such as biopsy, and cell and tissue transport, in a minimally invasive fashion.",[],"Mon, 23 Oct 2023 12:44:12 EDT"
986,Adaptive optical neural network connects thousands of artificial neurons,https://www.sciencedaily.com/releases/2023/10/231023124404.htm,"Physicists working with computer specialists have developed a so-called event-based architecture, using photonic processors. In a similar way to the brain, this makes possible the continuous adaptation of the connections within the neural network.",[],"Mon, 23 Oct 2023 12:44:04 EDT"
987,New cyber algorithm shuts down malicious robotic attack,https://www.sciencedaily.com/releases/2023/10/231011202416.htm,"Researchers have designed an algorithm that can intercept a man-in-the-middle (MitM) cyberattack on an unmanned military robot and shut it down in seconds. The algorithm, tested in real time, achieved a 99% success rate.",[],"Wed, 11 Oct 2023 20:24:16 EDT"
988,AI language models could help diagnose schizophrenia,https://www.sciencedaily.com/releases/2023/10/231009191615.htm,"Scientists have developed new tools, based on AI language models, that can characterize subtle signatures in the speech of patients diagnosed with schizophrenia.",[],"Mon, 09 Oct 2023 19:16:15 EDT"
989,Birders and AI push bird conservation to the next level,https://www.sciencedaily.com/releases/2023/10/231004132419.htm,"Big data and artificial intelligence (AI) are being used to model hidden patterns in nature, not just for one bird species, but for entire ecological communities across continents. And the models follow each species’ full annual life cycle, from breeding to fall migration to non-breeding grounds, and back north again during spring migration.",[],"Wed, 04 Oct 2023 13:24:19 EDT"
990,Could future AI crave a favorite food?,https://www.sciencedaily.com/releases/2023/10/231004132416.htm,"Can artificial intelligence (AI) get hungry? Develop a taste for certain foods? Not yet, but a team of researchers is developing a novel electronic tongue that mimics how taste influences what we eat based on both needs and wants, providing a possible blueprint for AI that processes information more like a human being.",[],"Wed, 04 Oct 2023 13:24:16 EDT"
991,Perplexity Poised To Become Latest AI Startup To Hit Unicorn Status — Report,https://news.crunchbase.com/ai/startup-perplexity-poised-unicorn-status-nvda/,Perplexity AI is reportedly nearing completion of a funding round that will give the AI search startup a unicorn valuation of around $1 billion.,[{'name': 'Chris Metinko'}],"Tue, 05 Mar 2024 17:50:37 +0000"
992,Which Overlooked Startup Sectors Will Be Powerful Investments In 2024?,https://news.crunchbase.com/venture/overlooked-startup-sectors-2024-dukach-one-way/,"While investors debated whether to bet on image-generation AI or medtech AI last year, several extremely consequential startup sectors ended up being overshadowed. Which sectors will grab investors' attention and dollars in 2024? Semyon Dukach, founding partner of One Way Ventures, shares what he thinks.",[{'name': 'Guest Author'}],"Tue, 05 Mar 2024 12:00:31 +0000"
993,The 10 Biggest Rounds Of February: Epic Games Leads The List Thanks To House Of Mouse Investment,https://news.crunchbase.com/venture/biggest-rounds-february-2024-ai-biotech-unicorn-epic/,February was a big month for big rounds. Companies needed to raise $170 million or more just to make the tailend of our list of largest U.S. venture funding deals.,[{'name': 'Chris Metinko'}],"Tue, 05 Mar 2024 12:00:22 +0000"
994,"No One Gushes About Govtech, But It Can Produce Some Nice Returns",https://news.crunchbase.com/policy-regulation/government-tech-startups-funding-opengov-acquisition-valuation/,"Startups have been quietly making some major contributions to help us deal with government entities. From modernizing parking payments or streamlining permit applications, venture-backed software and app developers are behind an assortment of tools getting funded.",[{'name': 'Joanna Glasner'}],"Mon, 04 Mar 2024 12:00:42 +0000"
995,The AI Gold Rush: How Startups Can Stake Their Claim In A Competitive Frontier,https://news.crunchbase.com/ai/startups-venture-funding-competition-gozes-entree/,"To succeed in this new age of AI maturation, entrepreneurs need to focus on building moats, Entrée Capital's Adi Gozes writes, and offers tips on how to get started.",[{'name': 'Guest Author'}],"Mon, 04 Mar 2024 12:00:05 +0000"
996,The Week’s 10 Biggest Funding Rounds: Fervo Energy And Glean Lead The Way In Another Strong Week,https://news.crunchbase.com/venture/biggest-funding-rounds-fervo-glean/,"After two crazy weeks where we saw 18 raises of $100 million or more, this week saw a slight slowdown but was still relatively strong when it came to big-dollar deals with five companies raising nine-figure rounds.",[{'name': 'Chris Metinko'}],"Fri, 01 Mar 2024 18:51:12 +0000"
997,The Crunchbase Tech Layoffs Tracker,https://news.crunchbase.com/startups/tech-layoffs/,"More than 191,000 workers at U.S.-based tech companies were laid off in mass job cuts in 2023, per a Crunchbase News tally, and the cuts have continued into 2024. See who the latest companies are to cut roles.",[{'name': 'Crunchbase News'}],"Fri, 01 Mar 2024 18:30:30 +0000"
998,"Musk Sues Altman, OpenAI For Breach Of Founding Agreement",https://news.crunchbase.com/ai/musk-openai-altman-lawsuit/,Elon Musk has filed a lawsuit against OpenAI and its executives for allegedly breaching the founding agreement of the company to develop artificial general intelligence for the benefit of humanity.,[{'name': 'Chris Metinko'}],"Fri, 01 Mar 2024 18:10:19 +0000"
999,Tech Layoffs Stay High As Extended Runways Reach Their Limit,https://news.crunchbase.com/layoffs/tech-startups-staff-cuts-shutdowns/,"Relief is not in sight. After tailing off a bit in December, job cuts picked up again in January, per the Crunchbase Tech Layoffs Tracker. February also brought a high number of mass layoffs, with both large-cap tech companies and startups reducing staff.",[{'name': 'Joanna Glasner'}],"Fri, 01 Mar 2024 12:00:10 +0000"
1000,"In A Latin American VC Winter, 6 Reasons For Optimism",https://news.crunchbase.com/business/latin-america-vc-optimism-gotthilf-roggio-latutid/,"Latin America was the fastest-growing venture capital market in the boom of 2021, dispelling historical neglect by investors, but that boom gave way to a bust. Latitud Ventures' Gina Gotthilf and Tomas Roggio share their six reasons for short- to mid-term optimism in the region.",[{'name': 'Guest Author'}],"Fri, 01 Mar 2024 12:00:07 +0000"
1001,Common Sense Product Recommendations using Large Language Models,https://www.databricks.com/blog/common-sense-product-recommendations-using-large-language-models,<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Check out our LLM Solution Accelerators for Retail for more details and to download the notebooks. Product recommendations are a core feature of...</div>,[],"Tue, 05 Mar 2024 16:21:29 GMT"
1002,StreamNative and Databricks Unite to Power Real-Time Data Processing with Pulsar-Spark Connector,https://www.databricks.com/blog/streamnative-and-databricks-unite-power-real-time-data-processing-pulsar-spark-connector,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">StreamNative, a leading Apache Pulsar-based real-time data platform solutions provider, and Databricks, the Data Intelligence Platform, are thrilled to announce the enhanced Pulsar-Spark...</div>",[],"Tue, 05 Mar 2024 06:00:00 GMT"
1003,Adding Intelligence to Databricks Search,https://www.databricks.com/blog/adding-intelligence-to-databricks-search,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">We are thrilled to announce major improvements to the search capabilities in your Databricks workspace. These enhancements build on DatabricksIQ, the Data Intelligence...</div>",[],"Mon, 04 Mar 2024 11:53:45 GMT"
1004,Coastal Community Bank Builds a Thriving Financial Ecosystem on Databricks Data Intelligence Platform,https://www.databricks.com/blog/coastal-community-bank-builds-thriving-financial-ecosystem-databricks-data-intelligence,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Special thanks to Barb MacLean, SVP, Head of Technology Operations and Implementation at Coastal Community Bank (Coastal) and Rob Cavallo, President at Cavallo...</div>",[],"Mon, 04 Mar 2024 10:18:35 GMT"
1005,Smarter Manufacturing: The Role of Governance in Streamlining Gen AI,https://www.databricks.com/blog/smarter-manufacturing-role-governance-streamlining-gen-ai,<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Artificial Intelligence (AI) is going to be embedded in every product and service a business produces and customers interact with. With Generative AI...</div>,[],"Mon, 04 Mar 2024 08:53:31 GMT"
1006,Announcing Public Preview of Delta Sharing with Cloudflare R2 Integration,https://www.databricks.com/blog/announcing-public-preview-delta-sharing-cloudflare-r2-integration,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Special thanks to Phillip Jones, Senior Product Manager, and Harshal Brahmbhatt, Systems Engineer from Cloudflare for their contributions to this blog. Organizations across...</div>",[],"Thu, 29 Feb 2024 08:02:04 GMT"
1007,A Deep Dive into the Latest Performance Improvements of Stateful Pipelines in Apache Spark Structured Streaming,https://www.databricks.com/blog/deep-dive-latest-performance-improvements-stateful-pipelines-apache-spark-structured-streaming,<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">This post is the second part of our two-part series on the latest performance improvements of stateful pipelines. The first part of this...</div>,[],"Wed, 28 Feb 2024 13:17:23 GMT"
1008,Performance Improvements for Stateful Pipelines in Apache Spark Structured Streaming,https://www.databricks.com/blog/performance-improvements-stateful-pipelines-apache-spark-structured-streaming,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Introduction Apache Spark™ Structured Streaming is a popular open-source stream processing platform that provides scalability and fault tolerance, built on top of the S...</div>",[],"Wed, 28 Feb 2024 07:46:12 GMT"
1009,Fine-Grained Human Feedback,https://www.databricks.com/blog/fine-grained-human-feedback,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">(This post written in collaboration with Zeqiu (Ellen) Wu and Yushi Hu, both PhD students affiliated with the University of Washington, and co-first...</div>",[],"Tue, 27 Feb 2024 23:22:44 GMT"
1010,The Unconscious Patient Problem: A Look at the Importance Of Entity Resolution in Healthcare and Life Sciences,https://www.databricks.com/blog/unconscious-patient-problem-look-importance-entity-resolution-healthcare-and-life-sciences,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">This blog was written in collaboration with Tim Sedlak, Senior Solutions Architect at Stardog In healthcare and life sciences, accuracy is everything. That's...</div>",[],"Tue, 27 Feb 2024 08:56:32 GMT"
1011,Revolutionizing Tech Marketing,https://www.databricks.com/blog/revolutionizing-tech-marketing,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Introduction On January 4th, a new era in digital marketing began as Google initiated the gradual removal of third-party cookies, marking a seismic...</div>",[],"Mon, 26 Feb 2024 09:07:14 GMT"
1012,Strengthening Cyber Resilience through Efficient Data Management: A Response to M-21-31,https://www.databricks.com/blog/strengthening-cyber-resilience-through-efficient-data-management-response-m-21-31,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">In today's environment, proactive cybersecurity is crucial to any public sector agency. For many organizations, log data that security professionals need for effective...</div>",[],"Thu, 22 Feb 2024 10:19:38 GMT"
1013,Announcing the General Availability of Unity Catalog Volumes,https://www.databricks.com/blog/announcing-general-availability-unity-catalog-volumes,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Today, we are excited to announce that Unity Catalog Volumes is now generally available on AWS, Azure, and GCP. Unity Catalog provides a...</div>",[],"Thu, 22 Feb 2024 07:00:00 GMT"
1014,Announcing the General Availability of Azure Private Link and Azure Storage firewall support for Databricks SQL Serverless,https://www.databricks.com/blog/announcing-general-availability-azure-private-link-and-azure-storage-firewall-support,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">We are excited to announce the upcoming general availability of Azure Private Link support for Databricks SQL (DBSQL) Serverless, planned in April 2024...</div>",[],"Wed, 21 Feb 2024 11:16:41 GMT"
1015,Databricks adds new migration Brickbuilder Solutions to help customers succeed with AI,https://www.databricks.com/blog/databricks-adds-new-migration-brickbuilder-solutions-help-customers-succeed-ai,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">For the past two years, Databricks has collaborated with leading consulting partners to build innovative solutions for industry, migration, and data and AI...</div>",[],"Thu, 15 Feb 2024 07:49:27 GMT"
1016,Accelerating Success with Databricks: A Deep Dive into antuit.ai's Decision and Customer Impact,https://www.databricks.com/blog/accelerating-success-databricks-deep-dive-antuitais-decision-and-customer-impact,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">In the dynamic realm of AI-driven forecasting, businesses navigate a landscape where strategic choices shape their trajectory. One such pivotal decision was made...</div>",[],"Thu, 15 Feb 2024 07:02:01 GMT"
1017,LIMIT: Less is More for Instruction Tuning,https://www.databricks.com/blog/limit-less-more-instruction-tuning,<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">How should you finetune a large language model for general-purpose question answering? One intriguing approach is that of supervised finetuning on a small...</div>,[],"Sat, 10 Feb 2024 00:54:32 GMT"
1018,US Air Force Hackathon: How Large Language Models Will Revolutionize USAF Flight Test,https://www.databricks.com/blog/us-air-force-hackathon-how-large-language-models-will-revolutionize-usaf-flight-test,<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">[DISTRIBUTION STATEMENT A. Approved for public release; Distribution is unlimited 412TW-PA-24004] The views expressed are those of the author and do not reflect...</div>,[],"Fri, 09 Feb 2024 09:46:38 GMT"
1019,Furthering Our Commitment to Responsible AI Development Through Industry and Government Organizations,https://www.databricks.com/blog/furthering-our-commitment-responsible-ai-development-through-industry-and-government,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">At Databricks, we've upheld principles of responsible development throughout our long-standing history of building innovative data and AI products. We are committed to...</div>",[],"Thu, 08 Feb 2024 09:57:32 GMT"
1020,"Linking the unlinkables; simple, automated, scalable data linking with Databricks ARC",https://www.databricks.com/blog/linking-unlinkables-simple-automated-scalable-data-linking-databricks-arc,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">In April 2023 we announced the release of Databricks ARC to enable simple, automated linking of data within a single table. Today we...</div>",[],"Tue, 06 Feb 2024 13:30:01 GMT"
1021,What’s New in Data Engineering and Streaming - January 2024,https://www.databricks.com/blog/whats-new-data-engineering-and-streaming-january-2024,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Databricks recently announced the Data Intelligence Platform, a natural evolution of the lakehouse architecture we pioneered. The idea of a Data Intelligence Platform...</div>",[],"Tue, 06 Feb 2024 12:45:21 GMT"
1022,Welldoc® and Databricks: Enhancing Cardiometabolic Care with Improved Data for Tailored Interventions,https://www.databricks.com/blog/welldocr-and-databricks-enhancing-cardiometabolic-care-improved-data-tailored-interventions,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">This blog was written in collaboration with Anand Iyer, PhD, MBA, Chief Analytics Officer and Abhi Kumbara, Data Science Manager at Welldoc The...</div>",[],"Fri, 02 Feb 2024 11:35:27 GMT"
1023,"OLMo is Here, Powered by Databricks",https://www.databricks.com/blog/ai2-olmo-is-here,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">As Chief Scientist (Neural Networks) at Databricks, I lead our research team toward the goal of giving everyone the ability to build and...</div>",[],"Thu, 01 Feb 2024 15:45:00 GMT"
1024,Faster Lakeview dashboards with Materialized Views,https://www.databricks.com/blog/faster-lakeview-dashboards-materialized-views,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">In this blog post, we will share how you can use Databricks SQL Materialized Views with Lakeview dashboards to deliver fresh data and...</div>",[],"Thu, 01 Feb 2024 10:45:50 GMT"
1025,M Science turns alternative data into actionable insights,https://www.databricks.com/blog/m-science-turns-alternative-data-actionable-insights,"<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">There are thousands of datasets available to institutional investors, each dataset promising to unlock significant insights in investment decisioning. Across the thousands of...</div>",[],"Thu, 01 Feb 2024 06:59:34 GMT"
1026,Gemma: Introducing new state-of-the-art open models,https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/,Gemma is built for responsible AI development from the same research and technology used to create Gemini models.,[],"Wed, 21 Feb 2024 13:06:16 +0000"
1027,Our next-generation model: Gemini 1.5,https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/,"The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",[],"Thu, 15 Feb 2024 15:00:50 +0000"
1028,The next chapter of our Gemini era,https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/,We're bringing Gemini to more Google products,[],"Thu, 08 Feb 2024 13:00:00 +0000"
1029,AlphaGeometry: An Olympiad-level AI system for geometry,https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/,Advancing AI reasoning in mathematics,[],"Wed, 17 Jan 2024 16:00:00 +0000"
1030,Shaping the future of advanced robotics,https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/,"Introducing AutoRT, SARA-RT, and RT-Trajectory",[],"Thu, 04 Jan 2024 11:39:00 +0000"
1031,Images altered to trick machine vision can influence humans too,https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/,"In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",[],"Tue, 02 Jan 2024 16:00:00 +0000"
1032,2023: A Year of Groundbreaking Advances in AI and Computing,https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/,This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.,[],"Fri, 22 Dec 2023 13:30:00 +0000"
1033,FunSearch: Making new discoveries in mathematical sciences using Large Language Models,https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/,"In a paper published in Nature, we introduce FunSearch, a method for searching for “functions” written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated “evaluator”, which guards against hallucinations and incorrect ideas.",[],"Thu, 14 Dec 2023 16:00:00 +0000"
1034,Google DeepMind at NeurIPS 2023,https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/,"The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",[],"Fri, 08 Dec 2023 15:01:00 +0000"
1035,Introducing Gemini: our largest and most capable AI model,https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/,Making AI more helpful for everyone,[],"Wed, 06 Dec 2023 15:13:00 +0000"
1036,Millions of new materials discovered with deep learning,https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/,"We share the discovery of 2.2 million new crystals  –  equivalent to nearly 800 years’ worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",[],"Wed, 29 Nov 2023 16:04:00 +0000"
1037,Transforming the future of music creation,https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/,"Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",[],"Thu, 16 Nov 2023 07:20:00 +0000"
1038,Empowering the next generation for an AI-enabled world,https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/,Experience AI's course and resources are expanding on a global scale,[],"Wed, 15 Nov 2023 10:00:00 +0000"
1039,GraphCast: AI model for faster and more accurate global weather forecasting,https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/,"We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",[],"Tue, 14 Nov 2023 15:00:00 +0000"
1040,A glimpse of the next generation of AlphaFold,https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/,"Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",[],"Tue, 31 Oct 2023 13:00:00 +0000"
1041,Evaluating social and ethical risks from generative AI,https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/,Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems,[],"Thu, 19 Oct 2023 15:00:00 +0000"
1042,Scaling up learning across many different robot types,https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/,"Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",[],"Tue, 03 Oct 2023 15:00:00 +0000"
1043,A catalogue of genetic mutations to help pinpoint the cause of diseases,https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/,New AI tool classifies the effects of 71 million ‘missense’ mutations.,[],"Tue, 19 Sep 2023 13:37:00 +0000"
1044,Identifying AI-generated images with SynthID,https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/,New tool helps watermark and identify synthetic images created by Imagen,[],"Tue, 29 Aug 2023 00:00:00 +0000"
1045,RT-2: New model translates vision and language into action,https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/,"Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",[],"Fri, 28 Jul 2023 00:00:00 +0000"
1046,Using AI to fight climate change,https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/,"AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",[],"Fri, 21 Jul 2023 00:00:00 +0000"
1047,Google DeepMind’s latest research at ICML 2023,https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/,"Exploring AI safety, adaptability, and efficiency for the real world",[],"Thu, 20 Jul 2023 00:00:00 +0000"
1048,Developing reliable AI tools for healthcare,https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/,"We’ve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",[],"Mon, 17 Jul 2023 00:00:00 +0000"
1049,Exploring institutions for global AI governance,https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/,New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.,[],"Tue, 11 Jul 2023 00:00:00 +0000"
1050,RoboCat: A self-improving robotic agent,https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/,"Robots are quickly becoming part of our everyday lives, but they’re often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data. Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",[],"Tue, 20 Jun 2023 00:00:00 +0000"
1051,AlphaDev discovers faster sorting algorithms,https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/,New algorithms will transform the foundations of computing,[],"Wed, 07 Jun 2023 00:00:00 +0000"
1052,An early warning system for novel AI risks,https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/,New research proposes a framework for evaluating general-purpose models against novel threats,[],"Thu, 25 May 2023 00:00:00 +0000"
1053,DeepMind’s latest research at ICLR 2023,https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/,"Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We’re proud to support the conference as a Diamond sponsor and DEI champion.",[],"Thu, 27 Apr 2023 00:00:00 +0000"
1054,How can we build human values into AI?,https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/,Drawing from philosophy to identify fair principles for ethical AI...,[],"Mon, 24 Apr 2023 00:00:00 +0000"
1055,Announcing Google DeepMind,https://deepmind.google/discover/blog/announcing-google-deepmind/,DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.,[],"Thu, 20 Apr 2023 00:00:00 +0000"
1056,Competitive programming with AlphaCode,https://deepmind.google/discover/blog/competitive-programming-with-alphacode/,Solving novel problems and setting a new milestone in competitive programming.,[],"Thu, 08 Dec 2022 00:00:00 +0000"
1057,AI for the board game Diplomacy,https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/,"Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication – and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",[],"Tue, 06 Dec 2022 00:00:00 +0000"
1058,"Mastering Stratego, the classic game of imperfect information",https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/,Game-playing artificial intelligence (AI) systems have advanced to a new frontier.,[],"Thu, 01 Dec 2022 00:00:00 +0000"
1059,DeepMind’s latest research at NeurIPS 2022,https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/,"NeurIPS is the world’s largest conference in artificial intelligence (AI) and machine learning (ML), and we’re proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",[],"Fri, 25 Nov 2022 00:00:00 +0000"
1060,Building interactive agents in video game worlds,https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/,"Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we’re publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts – and therefore, can begin to interact with people on their own terms.",[],"Wed, 23 Nov 2022 00:00:00 +0000"
1061,Benchmarking the next generation of never-ending learners,https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/,Learning how to build upon knowledge by tapping 30 years of computer vision research,[],"Tue, 22 Nov 2022 00:00:00 +0000"
1062,Best practices for data enrichment,https://deepmind.google/discover/blog/best-practices-for-data-enrichment/,Building a responsible approach to data collection with the Partnership on AI...,[],"Wed, 16 Nov 2022 00:00:00 +0000"
1063,"The pursuit of AI education—past, present, and future",https://deepmind.google/discover/blog/the-pursuit-of-ai-educationpast-present-and-future/,"Meet Sylvia Christie, our education partnerships manager who’s played a leading role in expanding our scholarship programme, which is marking its five-year anniversary.",[],"Tue, 08 Nov 2022 00:00:00 +0000"
1064,Stopping malaria in its tracks,https://deepmind.google/discover/blog/stopping-malaria-in-its-tracks/,Developing a vaccine that could save hundreds of thousands of lives,[],"Thu, 13 Oct 2022 15:00:00 +0000"
1065,Measuring perception in AI models,https://deepmind.google/discover/blog/measuring-perception-in-ai-models/,"Perception – the process of experiencing the world through senses – is a significant part of intelligence. And building agents with human-level perceptual understanding of the world is a central but challenging task, which is becoming increasingly important in robotics, self-driving cars, personal assistants, medical imaging, and more. So today, we’re introducing the Perception Test, a multimodal benchmark using real-world videos to help evaluate the perception capabilities of a model.",[],"Wed, 12 Oct 2022 00:00:00 +0000"
1066,How undesired goals can arise with correct rewards,https://deepmind.google/discover/blog/how-undesired-goals-can-arise-with-correct-rewards/,"As we build increasingly advanced artificial intelligence (AI) systems, we want to make sure they don’t pursue undesired goals. Such behaviour in an AI agent is often the result of specification gaming – exploiting a poor choice of what they are rewarded for. In our latest paper, we explore a more subtle mechanism by which AI systems may unintentionally learn to pursue undesired goals: goal misgeneralisation (GMG). GMG occurs when a system's capabilities generalise successfully but its goal does not generalise as desired, so the system competently pursues the wrong goal. Crucially, in contrast to specification gaming, GMG can occur even when the AI system is trained with a correct specification.",[],"Fri, 07 Oct 2022 00:00:00 +0000"
1067,Discovering novel algorithms with AlphaTensor,https://deepmind.google/discover/blog/discovering-novel-algorithms-with-alphatensor/,"In our paper, published today in Nature, we introduce AlphaTensor, the first artificial intelligence (AI) system for discovering novel, efficient, and provably correct algorithms for fundamental tasks such as matrix multiplication. This sheds light on a 50-year-old open question in mathematics about finding the fastest way to multiply two matrices. This paper is a stepping stone in DeepMind’s mission to advance science and unlock the most fundamental problems using AI. Our system, AlphaTensor, builds upon AlphaZero, an agent that has shown superhuman performance on board games, like chess, Go and shogi, and this work shows the journey of AlphaZero from playing games to tackling unsolved mathematical problems for the first time.",[],"Wed, 05 Oct 2022 00:00:00 +0000"
1068,Fighting osteoporosis before it starts,https://deepmind.google/discover/blog/fighting-osteoporosis-before-it-starts/,Detecting signs of disease before bones start to break,[],"Tue, 27 Sep 2022 14:16:00 +0000"
1069,Understanding the faulty proteins linked to cancer and autism,https://deepmind.google/discover/blog/understanding-the-faulty-proteins-linked-to-cancer-and-autism/,Helping uncover how protein mutations cause diseases and disorders,[],"Mon, 26 Sep 2022 15:19:00 +0000"
1070,Supporting the next generation of AI leaders,https://deepmind.google/discover/blog/supporting-the-next-generation-of-ai-leaders/,We’re partnering with six education charities and social enterprises in the United Kingdom (UK) to co-create a bespoke education programme to help tackle the gaps in STEM education and boost existing programmes.,[],"Mon, 26 Sep 2022 00:00:00 +0000"
1071,Solving the mystery of how an ancient bird went extinct,https://deepmind.google/discover/blog/solving-the-mystery-of-how-an-ancient-bird-went-extinct/,"Creating a tool to study extinct species from 50,000 years ago",[],"Thu, 22 Sep 2022 15:27:00 +0000"
1072,Building safer dialogue agents,https://deepmind.google/discover/blog/building-safer-dialogue-agents/,"In our latest paper, we introduce Sparrow – a dialogue agent that’s useful and reduces the risk of unsafe and inappropriate answers. Our agent is designed to talk with a user, answer questions, and search the internet using Google when it’s helpful to look up evidence to inform its responses.",[],"Thu, 22 Sep 2022 00:00:00 +0000"
1073,Targeting early-onset Parkinson’s with AI,https://deepmind.google/discover/blog/targeting-early-onset-parkinsons-with-ai/,Predictions that  pave the way to new treatments,[],"Wed, 21 Sep 2022 15:37:00 +0000"
1074,How our principles helped define AlphaFold’s release,https://deepmind.google/discover/blog/how-our-principles-helped-define-alphafolds-release/,"Our Operating Principles have come to define both our commitment to prioritising widespread benefit, as well as the areas of research and applications we refuse to pursue. These principles have been at the heart of our decision making since DeepMind was founded, and continue to be refined as the AI landscape changes and grows. They are designed for our role as a research-driven science company and consistent with Google’s AI principles.",[],"Wed, 14 Sep 2022 00:00:00 +0000"
1075,Maximising the impact of our breakthroughs,https://deepmind.google/discover/blog/maximising-the-impact-of-our-breakthroughs/,"Colin, CBO at DeepMind, discusses collaborations with Alphabet and how we integrate ethics, accountability, and safety into everything we do.",[],"Fri, 09 Sep 2022 00:00:00 +0000"
1076,My journey from DeepMind intern to mentor,https://deepmind.google/discover/blog/my-journey-from-deepmind-intern-to-mentor/,"Former intern turned intern manager, Richard Everett, describes his journey to DeepMind, sharing tips and advice for aspiring DeepMinders. The 2023 internship applications will open on the 16th September, please visit https://dpmd.ai/internshipsatdeepmind for more information.",[],"Thu, 08 Sep 2022 00:00:00 +0000"
1077,In conversation with AI: building better language models,https://deepmind.google/discover/blog/in-conversation-with-ai-building-better-language-models/,"Our new paper, In conversation with AI: aligning language models with human values, explores a different approach, asking what successful communication between humans and an artificial conversational agent might look like and what values should guide conversation in these contexts.",[],"Tue, 06 Sep 2022 00:00:00 +0000"
1078,From motor control to embodied intelligence,https://deepmind.google/discover/blog/from-motor-control-to-embodied-intelligence/,"Using human and animal motions to teach robots to dribble a ball, and simulated humanoid characters to carry boxes and play football",[],"Wed, 31 Aug 2022 00:00:00 +0000"
1079,Advancing conservation with AI-based facial recognition of turtles,https://deepmind.google/discover/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles/,"We came across Zindi – a dedicated partner with complementary goals – who are the largest community of African data scientists and host competitions that focus on solving Africa’s most pressing problems. Our Science team’s Diversity, Equity, and Inclusion (DE&amp;I) team worked with Zindi to identify a scientific challenge that could help advance conservation efforts and grow involvement in AI. Inspired by Zindi’s bounding box turtle challenge, we landed on a project with the potential for real impact: turtle facial recognition.",[],"Thu, 25 Aug 2022 00:00:00 +0000"
1080,Discovering when an agent is present in a system,https://deepmind.google/discover/blog/discovering-when-an-agent-is-present-in-a-system/,"We want to build safe, aligned artificial general intelligence (AGI) systems that pursue the intended goals of its designers. Causal influence diagrams (CIDs) are a way to model decision-making situations that allow us to reason about agent incentives. By relating training setups to the incentives that shape agent behaviour, CIDs help illuminate potential risks before training an agent and can inspire better agent designs. But how do we know when a CID is an accurate model of a training setup?",[],"Thu, 18 Aug 2022 00:00:00 +0000"
1081,Realising scientists are the real superheroes,https://deepmind.google/discover/blog/realising-scientists-are-the-real-superheroes/,"Meet Edgar Duéñez-Guzmán, a research engineer on our Multi-Agent Research team who’s drawing on knowledge of game theory, computer science, and social evolution to get AI agents working better together.",[],"Thu, 11 Aug 2022 00:00:00 +0000"
1082,The race to cure a billion people from a deadly parasitic disease,https://deepmind.google/discover/blog/the-race-to-cure-a-billion-people-from-a-deadly-parasitic-disease/,Accelerating the search for life saving leishmaniasis treatments,[],"Thu, 28 Jul 2022 16:49:00 +0000"
1083,Tracing the evolution of proteins back to the origin of life,https://deepmind.google/discover/blog/tracing-the-evolution-of-proteins-back-to-the-origin-of-life/,Looking into a protein’s past to unlock the mysteries of life itself,[],"Thu, 28 Jul 2022 16:30:00 +0000"
1084,How the honeybee could help protect species around the world,https://deepmind.google/discover/blog/how-the-honeybee-could-help-protect-species-around-the-world/,New insights into immunity to help protect the world’s flora,[],"Thu, 28 Jul 2022 16:25:00 +0000"
1085,AlphaFold transforms biology for millions around the world,https://deepmind.google/discover/blog/alphafold-transforms-biology-for-millions-around-the-world/,Big data that leads to discoveries that benefit everyone,[],"Thu, 28 Jul 2022 16:19:00 +0000"
1086,Advancing discovery of better drugs and medicine,https://deepmind.google/discover/blog/advancing-discovery-of-better-drugs-and-medicine/,Researchers are designing more effective drugs than ever before,[],"Thu, 28 Jul 2022 16:14:00 +0000"
1087,Creating plastic-eating enzymes that could save us from pollution,https://deepmind.google/discover/blog/creating-plastic-eating-enzymes-that-could-save-us-from-pollution/,Helping plastics become 100% recyclable,[],"Thu, 28 Jul 2022 16:10:00 +0000"
1088,AlphaFold unlocks one of the greatest puzzles in biology,https://deepmind.google/discover/blog/alphafold-unlocks-one-of-the-greatest-puzzles-in-biology/,Piecing together one of the largest molecular structures in human cells,[],"Thu, 28 Jul 2022 15:59:00 +0000"
1089,Accelerating the race against antibiotic resistance,https://deepmind.google/discover/blog/accelerating-the-race-against-antibiotic-resistance/,Unlocking a decade of data in minutes to help beat antibiotic resistance,[],"Thu, 28 Jul 2022 15:48:00 +0000"
1090,AlphaFold reveals the structure of the protein universe,https://deepmind.google/discover/blog/alphafold-reveals-the-structure-of-the-protein-universe/,"Today, in partnership with EMBL’s European Bioinformatics Institute (EMBL-EBI), we’re now releasing predicted structures for nearly all catalogued proteins known to science, which will expand the AlphaFold DB by over 200x - from nearly 1 million structures to over 200 million structures - with the potential to dramatically increase our understanding of biology.",[],"Thu, 28 Jul 2022 00:00:00 +0000"
1091,Putting the power of AlphaFold into the world’s hands,https://deepmind.google/discover/blog/putting-the-power-of-alphafold-into-the-worlds-hands/,"When we announced AlphaFold 2 last December, it was hailed as a solution to the 50-year old protein folding problem. Last week, we published the scientific paper and source code explaining how we created this highly innovative system, and today we’re sharing high-quality predictions for the shape of every single protein in the human body, as well as for the proteins of 20 additional organisms that scientists rely on for their research.",[],"Fri, 22 Jul 2022 00:00:00 +0000"
1092,The virtuous cycle of AI research,https://deepmind.google/discover/blog/the-virtuous-cycle-of-ai-research/,"We recently caught up with Petar Veličković, a research scientist at DeepMind. Along with his co-authors, Petar is presenting his paper The CLRS Algorithmic Reasoning Benchmark at ICML 2022 in Baltimore, Maryland, USA.",[],"Tue, 19 Jul 2022 00:00:00 +0000"
1093,"Perceiver AR: general-purpose, long-context autoregressive generation",https://deepmind.google/discover/blog/perceiver-ar-general-purpose-long-context-autoregressive-generation/,"We develop Perceiver AR, an autoregressive, modality-agnostic architecture which uses cross-attention to map long-range inputs to a small number of latents while also maintaining end-to-end causal masking. Perceiver AR can directly attend to over a hundred thousand tokens, enabling practical long-context density estimation without the need for hand-crafted sparsity patterns or memory mechanisms.",[],"Sat, 16 Jul 2022 00:00:00 +0000"
1094,DeepMind’s latest research at ICML 2022,https://deepmind.google/discover/blog/deepminds-latest-research-at-icml-2022/,"Starting this weekend, the thirty-ninth International Conference on Machine Learning (ICML 2022) is meeting from 17-23 July, 2022 at the Baltimore Convention Center in Maryland, USA, and will be running as a hybrid event. Researchers working across artificial intelligence, data science, machine vision, computational biology, speech recognition, and more are presenting and publishing their cutting-edge work in machine learning.",[],"Fri, 15 Jul 2022 00:00:00 +0000"
1095,Intuitive physics learning in a deep-learning model inspired by developmental psychology,https://deepmind.google/discover/blog/intuitive-physics-learning-in-a-deep-learning-model-inspired-by-developmental-psychology/,"Despite significant effort, current AI systems pale in their understanding of intuitive physics, in comparison to even very young children. In the present work, we address this AI problem, specifically by drawing on the field of developmental psychology.",[],"Mon, 11 Jul 2022 00:00:00 +0000"
1096,Human-centred mechanism design with Democratic AI,https://deepmind.google/discover/blog/human-centred-mechanism-design-with-democratic-ai/,"In our recent paper, published in Nature Human Behaviour, we provide a proof-of-concept demonstration that deep reinforcement learning (RL) can be used to find economic policies that people will vote for by majority in a simple game. The paper thus addresses a key challenge in AI research - how to train AI systems that align with human values.",[],"Mon, 04 Jul 2022 00:00:00 +0000"
1097,Leading a movement to strengthen machine learning in Africa,https://deepmind.google/discover/blog/leading-a-movement-to-strengthen-machine-learning-in-africa/,"Avishkar Bhoopchand, a research engineer on the Game Theory and Multi-agent team, shares his journey to DeepMind and how he’s working to raise the profile of deep learning across Africa.",[],"Thu, 23 Jun 2022 00:00:00 +0000"
1098,BYOL-Explore: Exploration with Bootstrapped Prediction,https://deepmind.google/discover/blog/byol-explore-exploration-with-bootstrapped-prediction/,"We present BYOL-Explore, a conceptually simple yet general approach for curiosity-driven exploration in visually-complex environments. BYOL-Explore learns a world representation, the world dynamics, and an exploration policy all-together by optimizing a single prediction loss in the latent space with no additional auxiliary objective. We show that BYOL-Explore is effective in DM-HARD-8, a challenging partially-observable continuous-action hard-exploration benchmark with visually-rich 3-D environments.",[],"Mon, 20 Jun 2022 00:00:00 +0000"
1099,Unlocking High-Accuracy Differentially Private Image Classification through Scale,https://deepmind.google/discover/blog/unlocking-high-accuracy-differentially-private-image-classification-through-scale/,"According to empirical evidence from prior works, utility degradation in DP-SGD becomes more severe on larger neural network models – including the ones regularly used to achieve the best performance on challenging image classification benchmarks. Our work investigates this phenomenon and proposes a series of simple modifications to both the training procedure and model architecture, yielding a significant improvement on the accuracy of DP training on standard image classification benchmarks.",[],"Fri, 17 Jun 2022 00:00:00 +0000"
1100,Bridging DeepMind research with Alphabet products,https://deepmind.google/discover/blog/bridging-deepmind-research-with-alphabet-products/,"Today we caught up with Gemma Jennings, a product manager on the Applied team, who led a session on vision language models at the AI Summit, one of the world’s largest AI events for business.",[],"Wed, 15 Jun 2022 00:00:00 +0000"
1101,Advocating for the LGBTQ+ community in AI research,https://deepmind.google/discover/blog/advocating-for-the-lgbtq-community-in-ai-research/,"Research scientist, Kevin McKee, tells how his early love of science fiction and social psychology inspired his career, and how he’s helping advance research in ‘queer fairness’, support human-AI collaboration, and study the effects of AI on the LGBTQ+ community.",[],"Wed, 01 Jun 2022 00:00:00 +0000"
1102,Evaluating Multimodal Interactive Agents,https://deepmind.google/discover/blog/evaluating-multimodal-interactive-agents/,"In this paper, we assess the merits of these existing evaluation metrics and present a novel approach to evaluation called the Standardised Test Suite (STS). The STS uses behavioural scenarios mined from real human interaction data.",[],"Fri, 27 May 2022 00:00:00 +0000"
1103,Kyrgyzstan to King’s Cross: the star baker cooking up code,https://deepmind.google/discover/blog/kyrgyzstan-to-kings-cross-the-star-baker-cooking-up-code/,"My day can vary, it really depends on which phase of the project I'm on. Let’s say we want to add a feature to our product – my tasks could range from designing solutions and working with the team to find the best one, to deploying new features into production and doing maintenance. Along the way, I’ll communicate changes to our stakeholders, write docs, code and test solutions, build analytics dashboards, clean-up old code, and fix bugs.",[],"Thu, 26 May 2022 00:00:00 +0000"
1104,Dynamic language understanding: adaptation to new knowledge in parametric and semi-parametric models,https://deepmind.google/discover/blog/dynamic-language-understanding-adaptation-to-new-knowledge-in-parametric-and-semi-parametric-models/,"To study how semi-parametric QA models and their underlying parametric language models (LMs) adapt to evolving knowledge, we construct a new large-scale dataset, StreamingQA, with human written and generated questions asked on a given date, to be answered from 14 years of time-stamped news articles. We evaluate our models quarterly as they read new articles not seen in pre-training. We show that parametric models can be updated without full retraining, while avoiding catastrophic forgetting.",[],"Thu, 26 May 2022 00:00:00 +0000"
1105,Building a culture of pioneering responsibly,https://deepmind.google/discover/blog/building-a-culture-of-pioneering-responsibly/,"When I joined DeepMind as COO, I did so in large part because I could tell that the founders and team had the same focus on positive social impact. In fact, at DeepMind, we now champion a term that perfectly captures my own values and hopes for integrating technology into people’s daily lives: pioneering responsibly. I believe pioneering responsibly should be a priority for anyone working in tech. But I also recognise that it’s especially important when it comes to powerful, widespread technologies like artificial intelligence. AI is arguably the most impactful technology being developed today. It has the potential to benefit humanity in innumerable ways – from combating climate change to preventing and treating disease. But it’s essential that we account for both its positive and negative downstream impacts.",[],"Tue, 24 May 2022 00:00:00 +0000"
1106,Open-sourcing MuJoCo,https://deepmind.google/discover/blog/open-sourcing-mujoco/,"In October 2021, we announced that we acquired the MuJoCo physics simulator, and made it freely available for everyone to support research everywhere. We also committed to developing and maintaining MuJoCo as a free, open-source, community-driven project with best-in-class capabilities. Today, we’re thrilled to report that open sourcing is complete and the entire codebase is on GitHub! Here, we explain why MuJoCo is a great platform for open-source collaboration and share a preview of our roadmap going forward.",[],"Mon, 23 May 2022 00:00:00 +0000"
1107,From LEGO competitions to DeepMind's robotics lab,https://deepmind.google/discover/blog/from-lego-competitions-to-deepminds-robotics-lab/,"If you want to be at DeepMind, go for it. Apply, interview, and just try. You might not get it the first time but that doesn’t mean you can’t try again. I never thought DeepMind would accept me, and when they did, I thought it was a mistake. Everyone doubts themselves – I’ve never felt like the smartest person in the room. I’ve often felt the opposite. But I’ve learned that, despite those feelings, I do belong and I do deserve to work at a place like this. And that journey, for me, started with just trying.",[],"Thu, 19 May 2022 00:00:00 +0000"
1108,Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning,https://deepmind.google/discover/blog/emergent-bartering-behaviour-in-multi-agent-reinforcement-learning/,"In our recent paper, we explore how populations of deep reinforcement learning (deep RL) agents can learn microeconomic behaviours, such as production, consumption, and trading of goods. We find that artificial agents learn to make economically rational decisions about production, consumption, and prices, and react appropriately to supply and demand changes.",[],"Mon, 16 May 2022 00:00:00 +0000"
1109,A Generalist Agent,https://deepmind.google/discover/blog/a-generalist-agent/,"Inspired by progress in large-scale language modelling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens.",[],"Thu, 12 May 2022 00:00:00 +0000"
1110,Active offline policy selection,https://deepmind.google/discover/blog/active-offline-policy-selection/,"To make RL more applicable to real-world applications like robotics, we propose using an intelligent evaluation procedure to select the policy for deployment, called active offline policy selection (A-OPS). In A-OPS, we make use of the prerecorded dataset and allow limited interactions with the real environment to boost the selection quality.",[],"Fri, 06 May 2022 00:00:00 +0000"
1111,Tackling multiple tasks with a single visual language model,https://deepmind.google/discover/blog/tackling-multiple-tasks-with-a-single-visual-language-model/,"We introduce Flamingo, a single visual language model (VLM) that sets a new state of the art in few-shot learning on a wide range of open-ended multimodal tasks.",[],"Thu, 28 Apr 2022 00:00:00 +0000"
1112,When a passion for bass and brass help build better tools,https://deepmind.google/discover/blog/when-a-passion-for-bass-and-brass-help-build-better-tools/,"We caught up with Kevin Millikin, a software engineer on the DevTools team. He’s in Salt Lake City this week to present at PyCon US, the largest annual gathering for those using and developing the open-source Python programming language.",[],"Thu, 28 Apr 2022 00:00:00 +0000"
1113,DeepMind’s latest research at ICLR 2022,https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2022/,"Beyond supporting the event as sponsors and regular workshop organisers, our research teams are presenting 29 papers, including 10 collaborations this year. Here’s a brief glimpse into our upcoming oral, spotlight, and poster presentations.",[],"Mon, 25 Apr 2022 00:00:00 +0000"
1114,An empirical analysis of compute-optimal large language model training,https://deepmind.google/discover/blog/an-empirical-analysis-of-compute-optimal-large-language-model-training/,"We ask the question: “What is the optimal model size and number of training tokens for a given compute budget?” To answer this question, we train models of various sizes and with various numbers of tokens, and estimate this trade-off empirically. Our main finding is that the current large language models are far too large for their compute budget and are not being trained on enough data.",[],"Tue, 12 Apr 2022 00:00:00 +0000"
1115,GopherCite: Teaching language models to support answers with verified quotes,https://deepmind.google/discover/blog/gophercite-teaching-language-models-to-support-answers-with-verified-quotes/,"Language models like Gopher can “hallucinate” facts that appear plausible but are actually fake. Those who are familiar with this problem know to do their own fact-checking, rather than trusting what language models say. Those who are not, may end up believing something that isn’t true. This paper describes GopherCite, a model which aims to address the problem of language model hallucination. GopherCite attempts to back up all of its factual claims with evidence from the web.",[],"Wed, 16 Mar 2022 00:00:00 +0000"
1116,Predicting the past with Ithaca,https://deepmind.google/discover/blog/predicting-the-past-with-ithaca/,"The birth of human writing marked the dawn of History and is crucial to our understanding of past civilisations and the world we live in today. For example, more than 2,500 years ago, the Greeks began writing on stone, pottery, and metal to document everything from leases and laws to calendars and oracles, giving a detailed insight into the Mediterranean region. Unfortunately, it’s an incomplete record. Many of the surviving inscriptions have been damaged over the centuries or moved from their original location. In addition, modern dating techniques, such as radiocarbon dating, cannot be used on these materials, making inscriptions difficult and time-consuming to interpret.",[],"Wed, 09 Mar 2022 00:00:00 +0000"
1117,Learning Robust Real-Time Cultural Transmission without Human Data,https://deepmind.google/discover/blog/learning-robust-real-time-cultural-transmission-without-human-data/,"In this work, we use deep reinforcement learning to generate artificial agents capable of test-time cultural transmission. Once trained, our agents can infer and recall navigational knowledge demonstrated by experts. This knowledge transfer happens in real time and generalises across a vast space of previously unseen tasks.",[],"Thu, 03 Mar 2022 00:00:00 +0000"
1118,Probing Image-Language Transformers for Verb Understanding,https://deepmind.google/discover/blog/probing-image-language-transformers-for-verb-understanding/,"Multimodal Image-Language transformers have achieved impressive results on a variety of tasks that rely on fine-tuning (e.g., visual question answering and image retrieval). We are interested in shedding light on the quality of their pretrained representations--in particular, if these models can distinguish verbs or they only use the nouns in a given sentence. To do so, we collect a dataset of image-sentence pairs consisting of 447 verbs that are either visual or commonly found in the pretraining data (i.e., the Conceptual Captions dataset). We use this dataset to evaluate the pretrained models in a zero-shot way.",[],"Wed, 23 Feb 2022 00:00:00 +0000"
1119,Accelerating fusion science through learned plasma control,https://deepmind.google/discover/blog/accelerating-fusion-science-through-learned-plasma-control/,Successfully controlling the nuclear fusion plasma in a tokamak with deep reinforcement learning,[],"Wed, 16 Feb 2022 00:00:00 +0000"
1120,MuZero’s first step from research into the real world,https://deepmind.google/discover/blog/muzeros-first-step-from-research-into-the-real-world/,Collaborating with YouTube to optimise video compression in the open source VP9 codec.,[],"Fri, 11 Feb 2022 00:00:00 +0000"
1121,Red Teaming Language Models with Language Models,https://deepmind.google/discover/blog/red-teaming-language-models-with-language-models/,"In our recent paper, we show that it is possible to automatically find inputs that elicit harmful text from language models by generating inputs using language models themselves. Our approach provides one tool for finding harmful model behaviours before users are impacted, though we emphasize that it should be viewed as one component alongside many other techniques that will be needed to find harms and mitigate them once found.",[],"Mon, 07 Feb 2022 00:00:00 +0000"
1122,DeepMind: The Podcast returns for Season 2,https://deepmind.google/discover/blog/deepmind-the-podcast-returns-for-season-2/,We believe artificial intelligence (AI) is one of the most significant technologies of our age and we want to help people understand its potential and how it’s being created.,[],"Tue, 25 Jan 2022 00:00:00 +0000"
1123,Spurious normativity enhances learning of compliance and enforcement behavior in artificial agents,https://deepmind.google/discover/blog/spurious-normativity-enhances-learning-of-compliance-and-enforcement-behavior-in-artificial-agents/,"In our recent paper we explore how multi-agent deep reinforcement learning can serve as a model of complex social interactions, like the formation of social norms. This new class of models could provide a path to create richer, more detailed simulations of the world.",[],"Tue, 18 Jan 2022 00:00:00 +0000"
1124,AlphaFold: Using AI for scientific discovery,https://deepmind.google/discover/blog/alphafold-using-ai-for-scientific-discovery/,We’re excited to share DeepMind’s first significant milestone in demonstrating how artificial intelligence research can drive and accelerate new scientific discoveries.,[],"Sat, 15 Jan 2022 00:00:00 +0000"
1125,Simulating matter on the quantum scale with AI,https://deepmind.google/discover/blog/simulating-matter-on-the-quantum-scale-with-ai/,"Solving some of the major challenges of the 21st Century, such as producing clean electricity or developing high temperature superconductors, will require us to design new materials with specific properties. To do this on a computer requires the simulation of electrons, the subatomic particles that govern how atoms bond to form molecules and are also responsible for the flow of electricity in solids.",[],"Thu, 09 Dec 2021 00:00:00 +0000"
1126,Teaching Language Models How to Coordinate,https://ieeetv.ieee.org/channels/computer-society/teaching-language-models-how-to-coordinate,"<span>Teaching Language Models How to Coordinate</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/teaching.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Thu, 02/29/2024 - 06:23</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 17 times\">17 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Thu, 29 Feb 2024 14:23:38 +0000"
1127,DBOS A Database oriented Operating System,https://ieeetv.ieee.org/video/dbos-a-database-oriented-operating-system,"<span>DBOS A Database oriented Operating System</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/DBOS.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Mon, 02/05/2024 - 12:22</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 48 times\">48 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Mon, 05 Feb 2024 20:22:13 +0000"
1128,Nonfungible Tokens (NFTs): Transformative Potential and Risk Management,https://ieeetv.ieee.org/video/nonfungible-tokens-transformative-potential-and-risk-management,"<span>Nonfungible Tokens (NFTs): Transformative Potential and Risk Management</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Park%20cover%20slide%201_0.jpg\" width=\"185\" /></div>
      
<span><span>p.wesling@ieee.org</span></span>

<span>Fri, 12/08/2023 - 11:24</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 6 times\">6 views</a>",[{'email': 'p.wesling@ieee.org'}],"Fri, 08 Dec 2023 19:24:23 +0000"
1129,ICADS '23 Panel Discussion: Should AI development really take a pause?,https://ieeetv.ieee.org/video/icads-23-panel-discussion-should-ai-development-really-take-a-pause,"<span>ICADS '23 Panel Discussion: Should AI development really take a pause?</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/paneldiscussion.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Tue, 08/01/2023 - 10:48</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 56 times\">56 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Tue, 01 Aug 2023 17:48:49 +0000"
1130,ICADS '23: Using Machine Learning Tools in the Cloud: Experience Gained from the Ask4Summary research project,https://ieeetv.ieee.org/video/icads-23-using-machine-learning-tools-in-the-cloud-experience-gained-from-the-ask4summary-research-project,"<span>ICADS '23: Using Machine Learning Tools in the Cloud: Experience Gained from the Ask4Summary research project</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/MACHINELEARNING.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Tue, 08/01/2023 - 10:48</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 22 times\">22 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Tue, 01 Aug 2023 17:48:32 +0000"
1131,ICADS '23 Keynote: AI-based Decision Frameworks for Smart Environments – Some Case Studies,https://ieeetv.ieee.org/video/icads-23-keynote-ai-based-decision-frameworks-for-smart-environments-some-case-studies,"<span>ICADS '23 Keynote: AI-based Decision Frameworks for Smart Environments – Some Case Studies</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/AIBASEDDECISION.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Tue, 08/01/2023 - 10:48</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 13 times\">13 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Tue, 01 Aug 2023 17:48:16 +0000"
1132,ICADS '23 talk: Performance-based content generation for language learning,https://ieeetv.ieee.org/video/icads-23-talk-performance-based-content-generation-for-language-learning,"<span>ICADS '23 talk: Performance-based content generation for language learning</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/performancebased.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Tue, 08/01/2023 - 10:47</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 9 times\">9 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Tue, 01 Aug 2023 17:47:43 +0000"
1133,World-Wide Camera Networks,https://ieeetv.ieee.org/video/world-wide-camera-networks,"<span>World-Wide Camera Networks</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/worldwidecameranetworks.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Mon, 04/24/2023 - 08:29</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 21 times\">21 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Mon, 24 Apr 2023 15:29:21 +0000"
1134,Security in Quantum Computing Era,https://ieeetv.ieee.org/video/security-in-quantum-computing-era,"<span>Security in Quantum Computing Era</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/SECURITYINQUANTUMCOMUTINGERA.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Tue, 03/07/2023 - 07:21</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 26 times\">26 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Tue, 07 Mar 2023 15:21:04 +0000"
1135,IEEE Quarter Tech Talk Table 8.0 (Part 1) | IEEE QT3 Series,https://ieeetv.ieee.org/channels/computer-society/ieee-quarter-tech-talk-table-80-part-1-ieee-qt3-series,"<span>IEEE Quarter Tech Talk Table 8.0 (Part 1) | IEEE QT3 Series</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/part1thumb.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Tue, 01/24/2023 - 11:46</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 403 times\">403 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Tue, 24 Jan 2023 19:46:52 +0000"
1136,"SSCI2022 - Plenary Talk 1 - Federated Learning, Knowledge Transfer, and Knowledge Distillation: At the Junction of Green Machine Learning and Granular Computing",https://ieeetv.ieee.org/video/ssci2022-plenary-talk-1-federated-learning-knowledge-transfer-and-knowledge-distillation-at-the-junction-of-green-machine-learning-and-granular-computing,"<span>SSCI2022 - Plenary Talk 1 - Federated Learning, Knowledge Transfer, and Knowledge Distillation: At the Junction of Green Machine Learning and Granular Computing</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/TALK1.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Thu, 02/16/2023 - 14:06</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 41 times\">41 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Thu, 16 Feb 2023 22:06:31 +0000"
1137,"SSCI2022 - Plenary Talk 2 - Evolutionary Machine Learning: Research, Applications and Challenges",https://ieeetv.ieee.org/video/ssci2022-plenary-talk-2-evolutionary-machine-learning-research-applications-and-challenges,"<span>SSCI2022 - Plenary Talk 2 - Evolutionary Machine Learning: Research, Applications and Challenges</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/TALK2.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Thu, 02/16/2023 - 14:06</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 24 times\">24 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Thu, 16 Feb 2023 22:06:04 +0000"
1138,SSCI2022 - Plenary Talk 3 - Composing Music by Evolutionary Computation,https://ieeetv.ieee.org/video/ssci2022-plenary-talk-3-composing-music-by-evolutionary-computation,"<span>SSCI2022 - Plenary Talk 3 - Composing Music by Evolutionary Computation</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/TALK3.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Thu, 02/16/2023 - 14:05</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 8 times\">8 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Thu, 16 Feb 2023 22:05:41 +0000"
1139,"SSCI2022 - Plenary Talk 4 - Learning with DNNs: Optimizer, Architecture and Formulation",https://ieeetv.ieee.org/video/ssci2022-plenary-talk-4-learning-with-dnns-optimizer-architecture-and-formulation,"<span>SSCI2022 - Plenary Talk 4 - Learning with DNNs: Optimizer, Architecture and Formulation</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/TALK4.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Thu, 02/16/2023 - 13:50</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 11 times\">11 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Thu, 16 Feb 2023 21:50:18 +0000"
1140,SSCI2022 - Plenary Talk 5 - Lifelong Learning on the Edge with Adaptive Resonance Theory and Incremental Cluster Validity Indices,https://ieeetv.ieee.org/video/ssci2022-plenary-talk-5-lifelong-learning-on-the-edge-with-adaptive-resonance-theory-and-incremental-cluster-validity-indices,"<span>SSCI2022 - Plenary Talk 5 - Lifelong Learning on the Edge with Adaptive Resonance Theory and Incremental Cluster Validity Indices</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/TALK5.png\" width=\"185\" /></div>
      
<span><span>n.lehotzky@ieee.org</span></span>

<span>Thu, 02/16/2023 - 13:30</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 68 times\">68 views</a>",[{'email': 'n.lehotzky@ieee.org'}],"Thu, 16 Feb 2023 21:30:59 +0000"
1141,Democratizing NLP: Considerations From Resources To Algorithms,https://ieeetv.ieee.org/video/democratizing-nlp,"<span>Democratizing NLP: Considerations From Resources To Algorithms</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Democratizing%20NLP.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 12/20/2022 - 13:41</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 45 times\">45 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 20 Dec 2022 21:41:40 +0000"
1142,IEEE ICDL 2022 Keynote 7 - Modeling the Learning Circuits of the Insect Brain,https://ieeetv.ieee.org/video/ieee-icdl-2022-keynote-7,"<span>IEEE ICDL 2022 Keynote 7 - Modeling the Learning Circuits of the Insect Brain</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20ICDL%202022%20Keynote%207.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Thu, 12/15/2022 - 10:25</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 15 times\">15 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Thu, 15 Dec 2022 18:25:56 +0000"
1143,IEEE ICDL 2022 Keynote 6 - The Mind of a Bee,https://ieeetv.ieee.org/video/ieee-icdl-2022-keynote-6,"<span>IEEE ICDL 2022 Keynote 6 - The Mind of a Bee</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20ICDL%202022%20Keynote%206.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Thu, 12/15/2022 - 09:59</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 6 times\">6 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Thu, 15 Dec 2022 17:59:27 +0000"
1144,IEEE ICDL 2022 Keynote 5 - Towards a Conscious Machine,https://ieeetv.ieee.org/video/ieee-icdl-2022-keynote-5,"<span>IEEE ICDL 2022 Keynote 5 - Towards a Conscious Machine</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20ICDL%202022%20Keynote%205.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Thu, 12/15/2022 - 09:56</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 7 times\">7 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Thu, 15 Dec 2022 17:56:33 +0000"
1145,IEEE ICDL 2022 Keynote 4 - The Transformative Power of Modern AI Methods,https://ieeetv.ieee.org/video/ieee-icdl-2022-keynote-4,"<span>IEEE ICDL 2022 Keynote 4 - The Transformative Power of Modern AI Methods</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20ICDL%202022%20Keynote%204.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Thu, 12/15/2022 - 09:51</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 13 times\">13 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Thu, 15 Dec 2022 17:51:59 +0000"
1146,SPCC SIG Virtual Seminar: Recent Advances in Non-Orthogonal Multiple Access in 6G Wireless Networks,https://ieeetv.ieee.org/video/spcc-sig-virtual-seminar-recent-advances-in-non-orthogonal-multiple-access-in-6g-wireless-networks,"<span>SPCC SIG Virtual Seminar: Recent Advances in Non-Orthogonal Multiple Access in 6G Wireless Networks  </span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/SPCC%20SIG%20Virtual%20Seminar-%20Recent%20Advances.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 01/18/2022 - 09:01</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 23 times\">23 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 18 Jan 2022 17:01:12 +0000"
1147,Darryl Burton & John Greaves: Fireside Chat on Blockchain Elevated Health Care Regulatory Impact,https://ieeetv.ieee.org/future_directions/darryl-burton-john-greaves-fireside-chat-on-blockchain-elevated-health-care-regulatory-impact,"<span>Darryl Burton & John Greaves: Fireside Chat on Blockchain Elevated Health Care Regulatory Impact</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Darryl%20Burton%20%26%20John%20Greaves-%20Fireside%20Chat%20on%20Blockchain.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 09/14/2021 - 06:24</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 14 times\">14 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 14 Sep 2021 13:24:50 +0000"
1148,Sandra Ro & John Greaves: Fireside Chat on Blockchain Elevated Health Care Standards,https://ieeetv.ieee.org/future_directions/sandra-ro-john-greaves-fireside-chat-on-blockchain-elevated-health-care-standards,"<span>Sandra Ro & John Greaves: Fireside Chat on Blockchain Elevated Health Care Standards</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Sandra%20Ro%20%26%20John%20Greaves-%20Fireside%20Chat%20on%20Blockchain.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 09/14/2021 - 06:10</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 17 times\">17 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 14 Sep 2021 13:10:25 +0000"
1149,John Palfreyman & John Greaves: Fireside Chat on Enterprises Blockchain in Health care,https://ieeetv.ieee.org/future_directions/john-palfreyman-john-greaves-fireside-chat-on-enterprises-blockchain-in-health-care,"<span>John Palfreyman & John Greaves: Fireside Chat on Enterprises Blockchain in Health care</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/John%20Palfreyman%20%26%20John%20Greaves-%20Fireside%20Chat%20on%20Enterprises%20Blockchain%20in%20Health%20care.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 09/14/2021 - 05:21</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 12 times\">12 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 14 Sep 2021 12:21:28 +0000"
1150,Aman Khera & John Greaves: Fireside Chat on Blockchain Elevated Health Care,https://ieeetv.ieee.org/future_directions/aman-khera-john-greaves-fireside-chat-on-blockchain-elevated-health-care,"<span>Aman Khera & John Greaves: Fireside Chat on Blockchain Elevated Health Care</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Aman%20Khera%20%26%20John%20Greaves-%20Fireside%20Chat.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 09/14/2021 - 04:59</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 29 times\">29 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 14 Sep 2021 11:59:34 +0000"
1151,Gora Datta - Fireside Chat - IEEE Healthcare: Blockchain & AI Virtual Series,https://ieeetv.ieee.org/future_directions/gora-datta-ieee-healthcare-blockchain-ai-virtual-series-session-9,"<span>Gora Datta - Fireside Chat - IEEE Healthcare: Blockchain & AI Virtual Series</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/John%20Greaves-%20Fireside%20Chat%20on%20Present%20%26%20Future%20Trends%20for%20Blockchain%20Elevated%20Healthcare_0.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Tue, 09/14/2021 - 04:35</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 50 times\">50 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Tue, 14 Sep 2021 11:35:10 +0000"
1152,IEEE Healthcare Blockchain AI Virtual Forum Session 6 Seg4 Panel3,https://ieeetv.ieee.org/video/ieee-healthcare-blockchain-ai-virtual-forum-session-6-seg4-panel3,"<span>IEEE Healthcare Blockchain AI Virtual Forum Session 6 Seg4 Panel3</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20Healthcare%20Blockchain%20AI%20Virtual%20Forum%20Session%206%20Seg4%20Panel3.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Fri, 04/23/2021 - 15:37</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 16 times\">16 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Fri, 23 Apr 2021 22:37:37 +0000"
1153,IEEE Healthcare Blockchain AI Virtual Forum Session 6 Seg3 Panel2,https://ieeetv.ieee.org/video/ieee-healthcare-blockchain-ai-virtual-forum-session-6-seg3-panel2,"<span>IEEE Healthcare Blockchain AI Virtual Forum Session 6 Seg3 Panel2</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20Healthcare%20Blockchain%20and%20AI-%20Future%20of%20Work%20and%20Certification%20Panel%202.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Fri, 04/23/2021 - 15:31</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 19 times\">19 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Fri, 23 Apr 2021 22:31:54 +0000"
1154,IEEE Healthcare Blockchain AI Session6 Seg2 Panel1,https://ieeetv.ieee.org/video/ieee-healthcare-blockchain-ai-session6-seg2-panel1,"<span>IEEE Healthcare Blockchain AI Session6 Seg2 Panel1</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/IEEE%20Healthcare%20Blockchain%20AI%20Session6%20Seg2%20Panel1.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Fri, 04/23/2021 - 15:24</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 21 times\">21 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Fri, 23 Apr 2021 22:24:43 +0000"
1155,Preparing Teachers for a Quantum Tomorrow,https://ieeetv.ieee.org/video/preparing-teachers-for-a-quantum-tomorrow,"<span>Preparing Teachers for a Quantum Tomorrow</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Preparing%20Teachers%20for%20a%20Quantum%20Tomorrow.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Fri, 04/23/2021 - 12:33</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 47 times\">47 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Fri, 23 Apr 2021 19:33:50 +0000"
1156,Process to Check Your IEEE Membership Number,https://ieeetv.ieee.org/video/process-to-check-your-ieee-membership-number,"<span>Process to Check Your IEEE Membership Number</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Process%20to%20Check%20Your%20IEEE%20Membership%20Number.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Wed, 09/29/2021 - 10:21</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 1370 times\">1370 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Wed, 29 Sep 2021 17:21:18 +0000"
1157,Registration Process to Become a Professional Member,https://ieeetv.ieee.org/video/registration-process-to-become-a-professional-member,"<span>Registration Process to Become a Professional Member</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Registration%20Process%20to%20Become%20a%20Professional%20Member.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Wed, 09/29/2021 - 10:04</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 625 times\">625 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Wed, 29 Sep 2021 17:04:13 +0000"
1158,Registration Process to Become a Student Member,https://ieeetv.ieee.org/video/registration-process-to-become-a-student-member,"<span>Registration Process to Become a Student Member</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Registration%20Process%20to%20Become%20a%20Student%20Member.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Wed, 09/29/2021 - 09:37</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 1427 times\">1427 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Wed, 29 Sep 2021 16:37:20 +0000"
1159,IEEE Brain Neurotech Entrepreneurs Workshop: Panel Discussion,https://ieeetv.ieee.org/ieee-brain-neurotech-entrepreneurs-workshop-panel-discussion,"<span>IEEE Brain Neurotech Entrepreneurs Workshop: Panel Discussion</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133478.jpg\" width=\"185\" /></div>
      
<span><span>lbboiko@handma…</span></span>

<span>Mon, 09/07/2020 - 05:31</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 32 times\">32 views</a>",[{'email': 'lbboiko@handmadeinteractive.com'}],"Mon, 07 Sep 2020 12:31:13 +0000"
1160,IEEE Brain: Funding Your Neurotech Start-Up with NIH SBIR/STTR Awards,https://ieeetv.ieee.org/ieee-brain-funding-your-neurotech-start-up-with-nih-sbir-sttr-awards,"<span>IEEE Brain: Funding Your Neurotech Start-Up with NIH SBIR/STTR Awards </span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133333.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Sun, 06/28/2020 - 23:39</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 57 times\">57 views</a>",[{'name': 'admin'}],"Mon, 29 Jun 2020 06:39:44 +0000"
1161,IEEE Brain: Raising Capital From Angel Investors,https://ieeetv.ieee.org/ieee-brain-raising-capital-from-angel-investors,"<span>IEEE Brain: Raising Capital From Angel Investors</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133326.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Sun, 06/28/2020 - 23:38</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 37 times\">37 views</a>",[{'name': 'admin'}],"Mon, 29 Jun 2020 06:38:45 +0000"
1162,IEEE Brain: Abbott Neuromodulation - The Importance and Practice of Late-stage Innovation,https://ieeetv.ieee.org/ieee-brain-abbott-neuromodulation-the-importance-and-practice-of-late-stage-innovation,"<span>IEEE Brain: Abbott Neuromodulation - The Importance and Practice of Late-stage Innovation</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133322.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Sun, 06/28/2020 - 23:38</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 109 times\">109 views</a>",[{'name': 'admin'}],"Mon, 29 Jun 2020 06:38:45 +0000"
1163,IEEE Brain: Platypus Neuro : Applied Neuroscience and Optimized Human Performance at Scale,https://ieeetv.ieee.org/ieee-brain-platypus-neuro-applied-neuroscience-and-optimized-human-performance-at-scale,"<span>IEEE Brain: Platypus Neuro : Applied Neuroscience and Optimized Human Performance at Scale</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133321.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Sun, 06/28/2020 - 23:38</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 74 times\">74 views</a>",[{'name': 'admin'}],"Mon, 29 Jun 2020 06:38:45 +0000"
1164,"IEEE Brain: Backyard Brains: How We Bootstrapped a Low-Fi, High-Tech Neuroscience Company",https://ieeetv.ieee.org/ieee-brain-backyard-brains-how-we-bootstrapped-a-low-fi-high-tech-neuroscience-company,"<span>IEEE Brain: Backyard Brains: How We Bootstrapped a Low-Fi, High-Tech Neuroscience Company</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133320.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Sun, 06/28/2020 - 23:38</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 31 times\">31 views</a>",[{'name': 'admin'}],"Mon, 29 Jun 2020 06:38:45 +0000"
1165,IEEE Brain: Nia Therapeutics: Building an Early-stage Medical Device Business,https://ieeetv.ieee.org/ieee-brain-nia-therapeutics-building-an-early-stage-medical-device-business,"<span>IEEE Brain: Nia Therapeutics: Building an Early-stage Medical Device Business</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/133319.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Sun, 06/28/2020 - 23:38</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 192 times\">192 views</a>",[{'name': 'admin'}],"Mon, 29 Jun 2020 06:38:45 +0000"
1166,Opportunities in the Internet of Things,https://ieeetv.ieee.org/careers/opportunities-in-the-internet-of-things,"<span>Opportunities in the Internet of Things</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/132561.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Mon, 12/16/2019 - 23:49</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 512 times\">512 views</a>",[{'name': 'admin'}],"Tue, 17 Dec 2019 07:49:03 +0000"
1167,Fengrui Shi: Game Theoretic and Auction-based Algorithms Towards Opportunistic Edge-Processing in LPWA LoRa Networks: WF-IoT 2016,https://ieeetv.ieee.org/fengrui-shi-game-theoretic-and-auction-based-algorithms-towards-opportunistic-edge-processing-in-lpwa-lora-networks-wf-iot-2016,"<span>Fengrui Shi: Game Theoretic and Auction-based Algorithms Towards Opportunistic Edge-Processing in LPWA LoRa Networks: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131671.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 639 times\">639 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1168,Levente Klein: Drone-based Reconstruction for 3D Geospatial Data Processing: WF-IoT 2016,https://ieeetv.ieee.org/levente-klein-drone-based-reconstruction-for-3d-geospatial-data-processing-wf-iot-2016,"<span>Levente Klein: Drone-based Reconstruction for 3D Geospatial Data Processing: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131670.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 644 times\">644 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1169,Fengrui Shi: OppNet: Enabling Citizen-Centric Urban IoT Data Collection Through Opportunistic Connectivity Service: WF-IoT 2016,https://ieeetv.ieee.org/fengrui-shi-oppnet-enabling-citizen-centric-urban-iot-data-collection-through-opportunistic-connectivity-service-wf-iot-2016,"<span>Fengrui Shi: OppNet: Enabling Citizen-Centric Urban IoT Data Collection Through Opportunistic Connectivity Service: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131669.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 572 times\">572 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1170,Compressive Sensing Tutorial: A Game Changing Technology for Energy Efficient IoT Sensor Networks: WF-IoT 2016,https://ieeetv.ieee.org/compressive-sensing-tutorial-a-game-changing-technology-for-energy-efficient-iot-sensor-networks-wf-iot-2016,"<span>Compressive Sensing Tutorial: A Game Changing Technology for Energy Efficient IoT Sensor Networks: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131668.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 867 times\">867 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1171,Fengrui Shi: Knowledge Co-creation in the OrganiCity: Data Annotation with JAMAiCA,https://ieeetv.ieee.org/fengrui-shi-knowledge-co-creation-in-the-organicity-data-annotation-with-jamaica,"<span>Fengrui Shi: Knowledge Co-creation in the OrganiCity: Data Annotation with JAMAiCA</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131667.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 553 times\">553 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1172,Q&A: Pindar Wong Keynote: WF-IoT 2016,https://ieeetv.ieee.org/q-and-a-pindar-wong-keynote-wf-iot-2016,"<span>Q&amp;A: Pindar Wong Keynote: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131660.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 453 times\">453 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1173,Keynote Pindar Wong: Calculating Consensus Reality For an Internet of Trust: WF-IoT 2016,https://ieeetv.ieee.org/keynote-pindar-wong-calculating-consensus-reality-for-an-internet-of-trust-wf-iot-2016,"<span>Keynote Pindar Wong: Calculating Consensus Reality For an Internet of Trust: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131659.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 518 times\">518 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1174,Q&A: Paul Mockapetris Keynote: WF-IoT 2016,https://ieeetv.ieee.org/q-and-a-paul-mockapetris-keynote-wf-iot-2016,"<span>Q&amp;A: Paul Mockapetris Keynote: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131658.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 433 times\">433 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1175,Keynote Paul Mockapetris: The Internet: How the Most Useful Tool in the World Became Dangerous: WF-IoT 2016,https://ieeetv.ieee.org/keynote-paul-mockapetris-the-internet-how-the-most-useful-tool-in-the-world-became-dangerous-wf-iot-2016,"<span>Keynote Paul Mockapetris: The Internet: How the Most Useful Tool in the World Became Dangerous: WF-IoT 2016</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/131657.jpg\" width=\"185\" /></div>
      
<span><span>admin</span></span>

<span>Tue, 02/20/2018 - 03:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 437 times\">437 views</a>",[{'name': 'admin'}],"Tue, 20 Feb 2018 11:43:19 +0000"
1176,Assistive Robots for People with Impairments,https://ieeetv.ieee.org/video/assistive-robots-for-people-with-impairments,"<span>Assistive Robots for People with Impairments</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Screen%20Shot%202022-12-20%20at%209.11.02%20AM.png\" width=\"185\" /></div>
      
<span><span>r.umali@ieee.org</span></span>

<span>Tue, 12/20/2022 - 05:59</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 233 times\">233 views</a>",[{'email': 'r.umali@ieee.org'}],"Tue, 20 Dec 2022 13:59:10 +0000"
1177,ROBUST DEPTH ESTIMATION FOR ROBOTS WITH STEREO CAMERAS USING BESPOKE DNNS,https://ieeetv.ieee.org/video/robust-depth-estimation-for-robots-with-stereo-cameras-using-bespoke-dnns,"<span>ROBUST DEPTH ESTIMATION FOR ROBOTS WITH STEREO CAMERAS USING BESPOKE DNNS</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Screen%20Shot%202022-12-20%20at%209.18.54%20AM.png\" width=\"185\" /></div>
      
<span><span>r.umali@ieee.org</span></span>

<span>Tue, 12/20/2022 - 05:57</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 207 times\">207 views</a>",[{'email': 'r.umali@ieee.org'}],"Tue, 20 Dec 2022 13:57:40 +0000"
1178,How Humanoid General Purpose Robots Can Solve the World’s Labor Crisis,https://ieeetv.ieee.org/video/how-humanoid-general-purpose-robots-can-solve-the-worlds-labor-crisis,"<span>How Humanoid General Purpose Robots Can Solve the World’s Labor Crisis</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/How%20Humanoid%20General%20Purpose%20Robots%20Can%20Solve.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Fri, 07/01/2022 - 13:31</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 268 times\">268 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Fri, 01 Jul 2022 20:31:22 +0000"
1179,"Recent Advances in ROS 2, SCV Robotics & Automation Society Chapter Meeting",https://ieeetv.ieee.org/video/recent-advances-in-ros-2-scv-robotics-automation-society-chapter-meeting,"<span>Recent Advances in ROS 2, SCV Robotics & Automation Society Chapter Meeting</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Recent-Advances-in-ROS-2.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Thu, 05/12/2022 - 06:56</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 92 times\">92 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Thu, 12 May 2022 13:56:14 +0000"
1180,Open-Source Dynamic Server & Modular Controller Package,https://ieeetv.ieee.org/video/open-source-dynamic-server-modular-controller-package,"<span>Open-Source Dynamic Server & Modular Controller Package</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Open-Source%20Dynamic%20Server%20%26%20Modular%20Controller%20Package.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Mon, 04/04/2022 - 11:25</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 51 times\">51 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Mon, 04 Apr 2022 18:25:34 +0000"
1181,"Telepresence & How It Is Changing Our Society,  January 2022 SCV RAS Chapter Meeting",https://ieeetv.ieee.org/video/telepresence-and-how-it-is-changing-our-society-january-2022-scv-ras-chapter-meeting,"<span>Telepresence & How It Is Changing Our Society,  January 2022 SCV RAS Chapter Meeting</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/Telepresence%20How%20It%20Is%20Changing%20Our%20Society%20January%202022.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Mon, 02/14/2022 - 11:33</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 57 times\">57 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Mon, 14 Feb 2022 19:33:18 +0000"
1182,ICBNA 2022,https://ieeetv.ieee.org/video/icbna-2022,"<span>ICBNA 2022</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/ICBNA%202022_0.png\" width=\"185\" /></div>
      
<span><span>ingrid@ingridm…</span></span>

<span>Fri, 02/04/2022 - 09:43</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 71 times\">71 views</a>",[{'email': 'ingrid@ingridmarie.com'}],"Fri, 04 Feb 2022 17:43:54 +0000"
1183,Robotics History: Narratives and Networks Oral Histories: Steve Cousins,https://ieeetv.ieee.org/channels/ras/robotics-history-narratives-and-networks-oral-histories-steve-cousins,"<span>Robotics History: Narratives and Networks Oral Histories: Steve Cousins</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/initial/medium/0.jpg\" width=\"185\" /></div>
      
<span><span>alexis.simoes@…</span></span>

<span>Tue, 11/23/2021 - 08:07</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 40 times\">40 views</a>",[{'email': 'alexis.simoes@ieee.org'}],"Tue, 23 Nov 2021 16:07:42 +0000"
1184,Robotics History: Narratives and Networks Oral Histories: Lydia Kavraki,https://ieeetv.ieee.org/channels/ras/robotics-history-narratives-and-networks-oral-histories-lydia-kavraki,"<span>Robotics History: Narratives and Networks Oral Histories: Lydia Kavraki</span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img alt=\"\" class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/initial/medium/0.jpg\" width=\"185\" /></div>
      
<span><span>alexis.simoes@…</span></span>

<span>Tue, 11/23/2021 - 06:35</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 0 times\">0 views</a>",[{'email': 'alexis.simoes@ieee.org'}],"Tue, 23 Nov 2021 14:35:57 +0000"
1185,Future of Robotics,https://ieeetv.ieee.org/channels/societies/future-of-robotics-,"<span>Future of Robotics </span>

            <div class=\"field field--name-field-video-medium-image field--type-image field--label-hidden field--item\">  <img class=\"img-responsive\" height=\"104\" src=\"https://ieeetv.ieee.org/assets/video-images/medium/future%20of%20robotics%20thumbnail.png\" width=\"185\" /></div>
      
<span><span>alexis.simoes@…</span></span>

<span>Tue, 11/09/2021 - 12:04</span>
<a class=\"view-counter\" href=\"https://ieeetv.ieee.org/\" title=\"Video has been viewed 6124 times\">6124 views</a>",[{'email': 'alexis.simoes@ieee.org'}],"Tue, 09 Nov 2021 20:04:20 +0000"
1186,Shrimper — A Small Search Engine Crafted in Rust,https://medium.com/artificialis/shrimper-a-small-search-engine-crafted-in-rust-577734fb592f?source=rss----a81c8d170222---4,"<h3>Shrimper — A Small Search Engine Crafted in Rust</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*H9IUzZ3fGZmvu4ug1G8XUA.png\" /><figcaption>image by some robot</figcaption></figure><p>INTRODUCTION</p><p>Creating a search engine in Rust is an excellent way to start exploring the language’s strengths in performance and safety.</p><p>This project transitions indexing and searching concepts into Rust’s ecosystem, challenging but rewarding due to Rust’s unique syntax and paradigms.</p><p>We’d start by setting up the Rust environment, including essential tools and dependencies. Then, defining data models using structs and Rust crates tantivy for indexing/searching and serde for serialization. Through implementing a basic search engine, you'll learn to manage indexing and execute search queries!</p><h3>OUTLINE &amp; REQUIREMENTS:</h3><h3>1. Setup Environment</h3><ul><li>Rust and Cargo (Rust’s package manager and build system) installed. If not, you can install them from the official Rust website.</li></ul><h3>2. Project Setup</h3><p>Create a new Rust project:</p><pre>cargo new shrimp_engine<br />cd shrimp_engine</pre><h3>3. Dependencies</h3><p>You might need a few crates (Rust libraries) to help with parsing and data handling. For example:</p><ul><li><strong>tantivy</strong> for indexing and searching text (similar to Lucene in the Java world).</li><li><strong>serde</strong> and <strong>serde_json</strong> for JSON parsing if your data is in JSON format.</li></ul><p>Add these to your <strong>Cargo.toml</strong> file:</p><pre>[package]<br />name = &quot;shrimp-engine&quot;<br />version = &quot;0.1.0&quot;<br />edition = &quot;2021&quot;<br /><br />[dependencies]<br />tantivy = &quot;0.17&quot;<br />serde = &quot;1.0&quot;<br />serde_json = &quot;1.0&quot;</pre><h3>4. Define Data Structure</h3><p>Decide on the structure of the documents you’ll be indexing. For a basic example, consider a simple struct representing documents with a title and body.</p><pre>use serde::{Serialize, Deserialize};</pre><pre>#[derive(Serialize, Deserialize, Debug)]<br />struct Document {<br />    title: String,<br />    body: String,<br />}</pre><h3>5 . The Index</h3><p>Using <strong>tantivy</strong>, create an index schema based on your data structure, and then add documents to the index.</p><pre>rustCopy code<br />use tantivy::{schema::*, Index, doc};</pre><pre>fn create_index() -&gt; tantivy::Result&lt;()&gt; {<br />    // Define the schema<br />    let mut schema_builder = Schema::builder();<br />    schema_builder.add_text_field(&quot;title&quot;, TEXT | STORED);<br />    schema_builder.add_text_field(&quot;body&quot;, TEXT);<br />    let schema = schema_builder.build();</pre><pre>    // Create the index in a directory<br />    let index = Index::create_in_ram(schema.clone());</pre><pre>    // Get the index writer<br />    let mut index_writer = index.writer(50_000_000)?;</pre><pre>    // Add documents<br />    let title = schema.get_field(&quot;title&quot;).unwrap();<br />    let body = schema.get_field(&quot;body&quot;).unwrap();</pre><pre>    // Example document<br />    let doc = doc!(title =&gt; &quot;Example Title&quot;, body =&gt; &quot;This is the body of the document.&quot;);<br />    index_writer.add_document(doc)?;</pre><pre>    // Commit the documents to the index<br />    index_writer.commit()?;</pre><pre>    Ok(())<br />}</pre><h3>6. Searching</h3><p>Implement a function to search the index.</p><p>You’ll need to create <strong>a searcher</strong> and <strong>query parser.</strong></p><pre>use tantivy::query::QueryParser;<br />use tantivy::collector::TopDocs;</pre><pre>fn search_index(index: &amp;Index, query_str: &amp;str) -&gt; tantivy::Result&lt;()&gt; {<br />    let reader = index.reader()?;<br />    let searcher = reader.searcher();</pre><pre>    let schema = index.schema();<br />    let title = schema.get_field(&quot;title&quot;).unwrap();<br />    let body = schema.get_field(&quot;body&quot;).unwrap();<br />    let query_parser = QueryParser::for_index(&amp;index, vec![title, body]);</pre><pre>    let query = query_parser.parse_query(query_str)?;<br />    let top_docs = searcher.search(&amp;query, &amp;TopDocs::with_limit(10))?;</pre><pre>    for (_, doc_address) in top_docs {<br />        let retrieved_doc = searcher.doc(doc_address)?;<br />        println!(&quot;{:?}&quot;, retrieved_doc);<br />    }</pre><pre>    Ok(())<br />}</pre><h3>Putting it all together 🍤</h3><p>Now, let’s combine the indexing and searching into a main function, where we can modify the documents, the index, and queries:</p><pre>use serde::{Serialize, Deserialize};<br />use tantivy::{schema::*, Index, doc, query::QueryParser, collector::TopDocs, TantivyError};<br /><br /><br /><br /><br />#[derive(Serialize, Deserialize, Debug)]<br />struct Document {<br />    title: String,<br />    body: String,<br />}<br /><br />fn create_index() -&gt; Result&lt;Index, TantivyError&gt; {<br />    let mut schema_builder = Schema::builder();<br />    schema_builder.add_text_field(&quot;title&quot;, TEXT | STORED);<br />    schema_builder.add_text_field(&quot;body&quot;, TEXT);<br />    let schema = schema_builder.build();<br /><br />    let index = Index::create_in_ram(schema.clone());<br /><br />    let mut index_writer = index.writer(50_000_000)?;<br />    let title = schema.get_field(&quot;title&quot;).unwrap();<br />    let body = schema.get_field(&quot;body&quot;).unwrap();<br />    let doc = doc!(title =&gt; &quot;Example Title&quot;, body =&gt; &quot;the body of the document.&quot;);<br />    index_writer.add_document(doc)?;<br />    index_writer.commit()?;<br /><br />    Ok(index)<br />}<br /><br />fn search_index(index: &amp;Index, query_str: &amp;str) -&gt; Result&lt;(), TantivyError&gt; {<br />    let reader = index.reader()?;<br />    let searcher = reader.searcher();<br /><br />    let schema = index.schema();<br />    let title = schema.get_field(&quot;title&quot;).unwrap();<br />    let body = schema.get_field(&quot;body&quot;).unwrap();<br />    let query_parser = QueryParser::for_index(&amp;index, vec![title, body]);<br /><br />    let query = query_parser.parse_query(query_str)?;<br />    let top_docs = searcher.search(&amp;query, &amp;TopDocs::with_limit(10))?;<br /><br />    for (_, doc_address) in top_docs {<br />        let retrieved_doc = searcher.doc(doc_address)?;<br />        println!(&quot;{:?}&quot;, retrieved_doc);<br />    }<br /><br />    Ok(())<br />}<br /><br />fn main() -&gt; Result&lt;(), TantivyError&gt; {<br />    println!(&quot;Hello, Shrimp!&quot;);<br /><br />    // Create the index and store it<br />    let index = create_index()?;<br /><br />    // Search within the created index<br />    search_index(&amp;index, &quot;Example&quot;)?;<br /><br />    Ok(())<br />}</pre><p>Let’s break down the crucial components and their roles in the system:</p><h4>Serde</h4><ul><li>serde::{Serialize, Deserialize}: These traits allow for the easy conversion of Rust structs to and from a format suitable for saving (like JSON), which is essential for working with data that needs to be indexed or retrieved.</li></ul><h4>Tantivy</h4><ul><li>tantivy::{schema::*, Index, doc, query::QueryParser, collector::TopDocs, TantivyError}:</li></ul><p>The components from the tantivy crate are used for building the search engine's core functionality, from creating an index to querying it.</p><h4>Document Struct</h4><ul><li>Document Struct: Represents the data structure for documents to be indexed. Each document has a title and a body, mimicking a simple webpage or document in a real-world search engine.</li></ul><h4>the Schema</h4><p><strong>The schema</strong> defines the structure of the index, specifying which fields (here, title and body) should be indexed and how (e.g., stored, text-analyzed). An in-memory index is created, and documents are added to this index. Each document added is defined by the Document struct, which is then serialized for indexing. Changes are committed to the index, making it searchable.</p><h3>The Shrimps’ Core Mechanism :</h3><h4>1- Index Reader and Searcher:</h4><p>To search the index, an index reader is instantiated, creating a searcher capable of executing queries against the index.</p><h4><strong>2- Query Parsing and Execution</strong></h4><p>A query parser interprets a query string, transforming it into a query object based on the defined schema. The searcher then uses this query to find and rank relevant documents.</p><h4>3- Retrieving and Displaying Results</h4><p>The top matching documents (up to a limit) are retrieved and displayed. The ability to extract and review indexed content based on search queries.</p><h3>Main Function</h3><p>The main function ties everything together, first creating an index with at least one document and then performing a search within this index.</p><p>The simplicity of this setup demonstrates a fully functional search engine capable of indexing and searching text 🍤</p><h3>Key Takeaways</h3><ul><li>The use of tantivy for indexing and searching provides a Rust-centric approach to text search, which offers high performance and safety.</li><li>serde's role ensures that complex data structures can be easily managed, serialized, and deserialized within the Rust ecosystem.</li><li>This example serves as a foundational framework, illustrating how Rust can be used to build search solutions 🍤</li></ul><h3>Conclusion</h3><p>This example is intended to give you a starting point in search engine construction. Rust’s ownership and concurrency model, along with its type system, provide a robust foundation for building more complex and high-performance search engines.</p><p>We can expand this project by adding features like real-time indexing, advanced text processing, and custom scoring algorithms. Expect those features in the series of articles dedicated to search engines and information retrieval — all in Rust 🍤</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=577734fb592f\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/shrimper-a-small-search-engine-crafted-in-rust-577734fb592f\">Shrimper — A Small Search Engine Crafted in Rust</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Iva @ AkashaDB'}],"Mon, 12 Feb 2024 16:20:09 GMT"
1187,How to Evaluate an LLM's Ability to Follow Instructions,https://medium.com/artificialis/how-to-evaluate-an-llms-ability-to-follow-instructions-9c6ac57a8e22?source=rss----a81c8d170222---4,"<h4>Assessing the Impact of Decoding Strategies on the Instruction Following Evaluation for Large Language Models Benchmark</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*V4QdGHrrt9ncmNok\" /><figcaption>Photo by <a href=\"https://unsplash.com/@paus_d_?utm_source=medium&amp;utm_medium=referral\">Sean D</a> on <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Recently I’ve been intellectually obsessed with two things:</p><ol><li>How do models generate text? (Trying to grok how various LLM decoding strategies impact the resulting generations)</li><li>And how do we gauge how good they are at it? (The minefield known as LLM evaluation)</li></ol><p>It’s not just idle curiosity. It’s my job.</p><p>I’ve been handed this cool yet daunting task: give the new kid on the block, <a href=\"https://deci.ai/blog/introducing-decilm-7b-the-fastest-and-most-accurate-7b-large-language-model-to-date/\">DeciLM-7B</a>, a thorough vibe check. So, here’s the deal. It’s supposed to stand toe-to-toe with the big gun in town — Mistral-7B-v0.1. That’s our competition.</p><blockquote>Author’s note: I originally wrote all this code prior to the release of Mistral-7B-Instruct-v0.2.</blockquote><p><strong>And me?</strong></p><p>I’m digging deep, comparing these two. Imagine late nights, endless papers, tons of coffee — nine yards of a research binge. Then bam! Call it fate, serendipity, or just good timing — two pieces drop from the AI heavens. One is a deep dive into “I<strong>nstruction-Following Evaluation for Large Language Models</strong>,” and the other is Damien Benveniste’s eye-opener on LLM decoding strategies. Talk about perfect timing.</p><p>That lit a spark.</p><p>Why not mix these up? <strong>Why not use these techniques to put DeciLM-7B and Mistral-7B-v0.1 through their paces? I’m a scientist at heart — exploring, experimenting, and evaluating is what I do!</strong></p><h4>🌉Benchmarks vs. Practical Application</h4><p>Reading performance metrics off a leaderboard is one thing; getting your hands dirty with the actual model is quite another.</p><p>Sure, benchmarks are cool, but they don’t give you the feel or the intuition of how a model <strong><em>actually</em></strong><em> </em>works. To get that, you’ve got to hack around with the model and throw real-world prompts at it — like you’d do in day-to-day tasks.</p><p>That’s where the rubber meets the road.</p><p><strong>How do these LLMs perform when it comes to following instructions, and more importantly, how do you accurately measure that ability?</strong></p><h4>🚀 Instruction-Following Evaluation for Large Language Models</h4><p>Evaluating the capability of Large Language Models (LLMs) to follow instructions isn’t a walk in the park. It’s<a href=\"https://www.aisnakeoil.com/p/evaluating-llms-is-a-minefield?r=dtkzn&amp;utm_campaign=post&amp;utm_medium=web\"> more like a stroll through a minefield</a>.</p><p>Jeffrey Zhou and colleagues highlight this intricate issue in their “<a href=\"https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Farxiv.org%2Fabs%2F2311.07911\">Instruction-Following Evaluation for Large Language Models</a>” paper, which provides a more refined, objective, and detailed framework for assessing LLMs’ abilities to follow instructions.</p><p>I like this benchmark because<strong> it’s concrete and representative of how I would use an LLM</strong>. It feels more like a benchmark for AI Engineers building applications using LLMs. The prompts also do a great job of capturing the nuances of human language, which is filled with ambiguities and subjectivities.</p><p>And these are the types of prompts that make consistent LLM evaluation a pain in the a — I mean, a daunting task.</p><h4>🔍 Existing Evaluation Methods</h4><p>The paper identifies three main methods for evaluating LLMs, each with its pitfalls:</p><ol><li><strong>🧑‍🔬 Human Evaluation: </strong>Traditional yet laden with labour and costs. The subjectivity inherent in human judgment adds a layer of unreliability.</li><li><strong>🤖 Model-Based Evaluation:</strong> This relies on another model’s accuracy to judge the LLM…but what if the judge is flawed?</li><li><strong>📈 Quantitative Benchmarks:</strong> Scalable and standardized, yes, but they can miss the forest for the trees in understanding the subtleties of instruction-following.</li></ol><h4>🌟 Introducing IFEval</h4><p>The authors propose a novel approach, <a href=\"https://arxiv.org/abs/2311.07911\">IFEval</a>, focusing on ‘<strong>verifiable instructions.</strong>’</p><p>These crystal-clear commands leave <strong>no room for subjective interpretation </strong>— think word counts or specific formatting like JSON. They’re atomic instructions that allow you to use a “simple, interpretable, deterministic program to verify whether corresponding responses follow the instructions”.</p><p>This methodology aims at making the evaluation process more automated, accurate, and free from ambiguity.</p><h4>👨🏽‍🔬 Setting the Stage for Experimentation</h4><p>Wrapping my head around Jeffrey Zhou and the team’s insights was just the beginning. I wanted to see these models, DeciLM-7B and Mistral-7B-v0.1, not just walk the walk in a controlled environment but also talk the talk — no pun intended.</p><p>And right then, I stumbled upon something that would add a new layer of interestingness to this experiment.</p><h4>🌌 Inspiration from the AI Edge</h4><p>When I thought I was getting a solid grip on how these models tackle real-world prompts, <a href=\"https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fnewsletter.theaiedge.io%2Fp%2Fhow-llms-generate-text\">Damien Benveniste’s piece from the AI Edge Newsletter hit my radar</a>.</p><p>Talk about timing.</p><p>He did a deep dive into the nuts and bolts of decoding strategies for text generation in LLMs — something that could amp up my understanding and experimentation. Benveniste went beyond scratching the surface; he broke down the complex mechanics of how these models weave their magic with words.</p><p>This was exactly what I was looking for!</p><h4>🔍 Overview of LLM Decoding Strategies</h4><p>Benveniste’s exploration into LLMs focuses on how they predict the next token and generate a stream of tokens relevant to a specific prompt or task.</p><p>He details <strong>four distinct strategies for text generation</strong>, each with pros and cons, and examines how these methods influence the quality of the generated text:</p><ol><li>🏹 Greedy Search</li><li>🎲 Multinomial Sampling</li><li>🔦 Beam Search</li><li>🔦 Beam Search w/ Multinomial Sampling</li><li>🔄 Contrastive Search</li></ol><p>I’ll explain these LLM decoding strategies later in this blog.</p><h4>🔮 An Experiment Bridging Theory to Practice</h4><p>There it was, the lightbulb moment.</p><p>Why not mesh these generation techniques I’d just learned with the IFEval benchmark? What if these text-generation strategies could be applied to the models evaluated in the IFEval benchmark? Imagine the insights that could be gleaned from seeing how different methods influence a model’s ability to follow instructions!</p><p>It was a perfect blend of theory and practical experimentation, and I was armed with a bunch of Colab Pro+ units. It felt like the stars aligned- perfect for a hands-on experiment, right?</p><h3>🤖 The Contenders: DeciLM-7B-Instruct and Mistral-7B-v0.1</h3><p>DeciLM-7B-Instruct and Mistral-7B-Instruct-v0.1 — these were my champions.</p><p>Each had its flair and promise. The goal was to see how each model responded to the IFEval benchmark under the influence of the different text generation techniques outlined by Benveniste.</p><p><strong>⏲️ Against the Clock: GPU Generation Time Tracking</strong></p><p>And hey, we’ve been boasting about our model’s speed over Mistral’s.</p><p>So, I figured an interesting twist to this experiment was monitoring the generation time on the GPU for each model and strategy. This wasn’t just about the quality or fidelity of the generated text; it was also a race against time, measuring the efficiency of each approach in a high-performance computing environment. Well, kind of. In this case, it’s an A100 from Google Colab.</p><p>A stopwatch in one hand, a magnifying glass in the other — I was ready to see what these models could do and how quickly they could do it.</p><h4>Preliminaries: Install Dependencies, Import Libraries, and Load Models</h4><pre>%%capture<br />!pip install huggingface_hub<br />!pip install transformers<br />!pip install accelerate<br />!pip install bitsandbytes<br />!pip install ninja<br />!pip install datasets<br /><br /><br /># for IFEval:<br />!pip install langdetect nltk absl-py immutabledict</pre><pre>import os<br /><br />import json<br />import os<br />from pathlib import Path<br />from typing import List<br /># Related third-party imports<br />import nltk<br />import torch<br />from datasets import Dataset, load_dataset<br />from tqdm import tqdm<br />from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline<br />nltk.download('punkt')<br /><br />os.environ['LC_ALL'] = 'en_US.UTF-8'<br />os.environ['LANG'] = 'en_US.UTF-8'<br />os.environ['LC_CTYPE'] = 'en_US.UTF-8'</pre><pre># @title<br />def instantiate_huggingface_model(<br />    model_name,<br />    quantization_config=None,<br />    device_map=&quot;auto&quot;,<br />    use_cache=True,<br />    trust_remote_code=None,<br />    pad_token=None,<br />    padding_side=&quot;left&quot;<br />):<br />    &quot;&quot;&quot;<br />    Instantiate a HuggingFace model with optional quantization using the BitsAndBytes library.<br /><br />    Parameters:<br />    - model_name (str): The name of the model to load from HuggingFace's model hub.<br />    - quantization_config (BitsAndBytesConfig, optional): Configuration for model quantization.<br />      If None, defaults to a pre-defined quantization configuration for 4-bit quantization.<br />    - device_map (str, optional): Device placement strategy for model layers ('auto' by default).<br />    - use_cache (bool, optional): Whether to cache model outputs (False by default).<br />    - trust_remote_code (bool, optional): Whether to trust remote code for custom layers (True by default).<br />    - pad_token (str, optional): The pad token to be used by the tokenizer. If None, uses the EOS token.<br />    - padding_side (str, optional): The side on which to pad the sequences ('left' by default).<br /><br />    Returns:<br />    - model (PreTrainedModel): The instantiated model ready for inference or fine-tuning.<br />    - tokenizer (PreTrainedTokenizer): The tokenizer associated with the model.<br /><br />    The function will throw an exception if model loading fails.<br />    &quot;&quot;&quot;<br /><br />    # If quantization_config is not provided, use the default configuration<br />    if quantization_config is None:<br />        quantization_config = BitsAndBytesConfig(<br />            load_in_4bit=True,<br />            bnb_4bit_use_double_quant=True,<br />            bnb_4bit_quant_type=&quot;nf4&quot;,<br />            bnb_4bit_compute_dtype=torch.bfloat16<br />        )<br /><br />    model = AutoModelForCausalLM.from_pretrained(<br />        model_name,<br />        quantization_config=quantization_config,<br />        device_map=device_map,<br />        use_cache=use_cache,<br />        trust_remote_code=trust_remote_code<br />    )<br /><br />    tokenizer = AutoTokenizer.from_pretrained(model_name)<br /><br />    if pad_token is not None:<br />        tokenizer.pad_token = pad_token<br />    else:<br />        tokenizer.pad_token = tokenizer.eos_token<br />    tokenizer.padding_side = padding_side<br /><br />    return model, tokenizer<br /><br />decilm, decilm_tokenizer = instantiate_huggingface_model(&quot;Deci/DeciLM-7B-instruct&quot;, trust_remote_code=True)<br /><br />mistral, mistral_tokenizer = instantiate_huggingface_model(&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;)<br /><br />deci_generator = pipeline(&quot;text-generation&quot;,<br />                          model=decilm,<br />                          tokenizer=decilm_tokenizer,<br />                          device_map=&quot;auto&quot;,<br />                          max_length=4096,<br />                          return_full_text=False<br />)<br /><br />mistral_generator = pipeline(&quot;text-generation&quot;,<br />                          model=mistral,<br />                          tokenizer=mistral_tokenizer,<br />                          device_map=&quot;auto&quot;,<br />                          max_length=4096,<br />                          return_full_text=False<br />)<br /><br />pipelines = {<br />    'DeciLM': deci_generator,<br />    'Mistral': mistral_generator<br />}</pre><h3>👨🏽‍🎨 LLM Decoding Strategies</h3><h4>⛺️ Baseline</h4><p>This is an empty dictionary, and it will use the default generation parameters from HuggingFace, except for the temperature setting. Which I will set to a small, near-zero value. In my experience with smaller models, I’ve noticed they follow instructions better when the temperature is small.</p><pre>baseline = {'temperature': 1e-4}</pre><h4>🏹 Greedy Search Generation</h4><p><strong>🔧How It Works: </strong>Greedy Search selects the most probable next token at each step of the sequence generation without considering the overall sequence. To enable greedy search, you set the parameters num_beams=1 and do_sample=False.</p><p><strong>⚖️ Pros and Cons: It’s simple and fast, but it tends to lack creativity and, depending on the model, might lead to repetitive text.</strong> This is because it doesn’t look ahead or reconsider past choices.</p><pre>greedy_config = {<br />    'num_beams': 1,<br />    'do_sample': False,<br />    'temperature': 1e-4<br />}</pre><h4>🎲 Multinomial Sampling Generation</h4><p><strong>🔧How It Works:</strong> It samples the next token based on the probability distribution provided by the model rather than just picking the most probable token. To enable multinomial sampling set do_sample=True and num_beams=1.</p><p><strong>⚖️ Pros and Cons:</strong> While this approach will give you varied and interesting outputs, it may sometimes generate less coherent or relevant text.</p><pre>multinomial_config = {<br />    'num_beams': 1,<br />    'do_sample': True,<br />    'temperature': 1e-4<br />}</pre><h4>🔦 Beam Search Generation</h4><p><strong>🔧How It Works:</strong> Beam Search keeps track of a fixed number of the most probable sequences at each step and expands each for the next token. It balances between greedy and exhaustive searches. Beam search is enabled when you specify a value for num_beams (number of hypotheses to keep track of) greater than 1, typically 4 or 5.</p><p><strong>⚖️ Pros and Cons: </strong>This method leads to more coherent and high-quality text but it’s slower and more computationally intensive than greedy search. The quality of the result depends heavily on the size of the “beam” (the number of sequences considered).</p><pre>beam_search_config = {<br />    'num_beams': 5,<br />    'do_sample': False,<br />    'temperature': 1e-4,<br />    'early_stopping':True<br />}</pre><h4>🔦Beam Search w/ 🎲 Multinomial</h4><p><strong>🔧How It Works: </strong>This approach combines Beam Search and Multinomial Sampling. Beam Search is applied with randomness in selecting the next tokens. To use this decoding strategy, you need to set num_beams larger than 1, and do_sample=True.</p><p><strong>⚖️ Pros and Cons:</strong> Balances the benefits of Beam Search in generating coherent sequences with the creativity of Multinomial Sampling. But it’s more complex and computationally demanding.</p><pre>beam_search_multinomial_config = {<br />    'num_beams': 5,<br />    'do_sample': True,<br />    'temperature': 1e-4,<br />    'early_stopping':True<br />}</pre><h4>🔄 Contrastive Search Generation</h4><p><strong>🔧How It Works:</strong> Contrastive Search reduces the typicality of the generated text by contrasting the chosen token with other potential candidates, considering both probability and diversity. The two main parameters that enable and control the behaviour of contrastive search are penalty_alpha and top_k. It assesses the best tokens and applies penalties to reorder them based on criteria like repetition and diversity. Note you can read about this method in the original 2022 paper, <a href=\"https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Farxiv.org%2Fabs%2F2202.06417\">A Contrastive Framework for Neural Text Generation</a></p><p><strong>⚖️ Pros and Cons: </strong>The tradeoff here is the relevance and coherence of generated text in exchange for diversity and novelty. Requires sophisticated mechanisms to balance between contrastiveness and relevance.</p><pre>contrastive_search_config = {<br />    'penalty_alpha': 0.42,<br />    'top_k': 250,<br />    'temperature': 1e-4<br />}</pre><h4>📖 Put all settings in a dictionary</h4><p>This just makes it easier to iterate over everything.</p><pre>gen_configs = {<br />    &quot;baseline&quot;:baseline,<br />    &quot;greedy_search&quot;:greedy_config,<br />    &quot;multinomial_sampling&quot;:multinomial_config,<br />    &quot;beam_search&quot;:beam_search_config,<br />    &quot;beam_search_multinomial&quot;:beam_search_multinomial_config,<br />    &quot;contrastive_search&quot;:contrastive_search_config<br />}</pre><h3>🚀 The Dataset: 540+ Rows</h3><p>We’ve got a dataset here that’s over 540 rows strong. But let’s not get carried away — this is a blog, not a thesis. For simplicity’s sake, we’re narrowing it down to 100 rows.</p><h4>🔢 10 Rounds per Prompt</h4><p>Each prompt gets the full treatment — 12 generations with a different model + config combo. So, that’s 12 variations for every single prompt.</p><h4>⏱ The Reality of Local LLMs: It’s a Time-Eater</h4><p>Anyone who’s dabbled with local LLMs knows this: Text generation takes its sweet time. To keep this post from turning into a marathon, I’m picking 100 prompts at random.</p><h4>👊 For the Hardcore</h4><p>Do you have time and GPUs to burn? Feel free to run the gauntlet with all 540+ prompts.</p><pre>dataset = load_dataset(&quot;harpreetsahota/Instruction-Following-Evaluation-for-Large-Language-Models&quot;, split='train')<br /><br />dataset = dataset.shuffle(seed=42)<br />subset = dataset.select(range(100))<br /><br /># You'll need this as a jsonl file later, so let's save it now<br />subset.to_json('subset_for_eval.jsonl')<br /><br />def convert_kwargs_in_jsonl(file_path):<br />    &quot;&quot;&quot;<br />    Modifies a JSONL file by converting 'kwargs' from a JSON-formatted string to a dictionary.<br /><br />    This adjustment is necessary because the Hugging Face datasets library automatically expands<br />    schemas, potentially altering the original structure of data with variable schema fields like 'kwargs'.<br />    Converting 'kwargs' to a dictionary before loading into Hugging Face datasets avoids this issue.<br /><br />    Parameters:<br />    - file_path (str): Path to the JSONL file to be modified.<br /><br />    The function overwrites the original file with the modified data. Ensure to backup the original file<br />    before running this function.<br /><br />    Example:<br />    convert_kwargs_in_jsonl(&quot;path/to/jsonl_file.jsonl&quot;)<br />    &quot;&quot;&quot;<br />    modified_data = []<br /><br />    with open(file_path, 'r') as file:<br />        for line in file:<br />            line_data = json.loads(line)<br />            if 'kwargs' in line_data and isinstance(line_data['kwargs'], str):<br />                line_data['kwargs'] = json.loads(line_data['kwargs'])<br />            modified_data.append(line_data)<br /><br />    with open(file_path, 'w') as file:<br />        for item in modified_data:<br />            file.write(json.dumps(item) + '\\n')<br /><br /># Replace 'your_file.jsonl' with the path to your JSONL file<br />convert_kwargs_in_jsonl(&quot;/content/subset_for_eval.jsonl&quot;)</pre><blockquote><strong>Author’s Note: </strong>I used the instruction prompt for DeciLM. Mistral’s model didn’t have any specific prompt format, though it mentioned that you should wrap your prompt in &lt;s&gt;[INST] and [/INST]. I didn’t do that here, and it could possibly impact the final results. I’ll put this out there as a challenge to my good friend <a href=\"https://medium.com/u/ae9cae9cbcd2\">Sophia Yang, Ph.D.</a> — take this code, wrap it in the Mistral prompt, and see how it goes! 😉</blockquote><pre>SYSTEM_PROMPT_TEMPLATE = &quot;&quot;&quot;<br />### System:<br />You are an AI assistant that follows instructions extremely well. Help as much as you can.<br />### User:<br />{instruction}<br />### Assistant:<br />&quot;&quot;&quot;<br /><br />def get_prompt_with_template(message: str) -&gt; str:<br />    return SYSTEM_PROMPT_TEMPLATE.format(instruction=message)<br /><br />def preprocess_prompt(model_name: str, prompt: str) -&gt; str:<br />    if model_name == 'DeciLM':<br />        return get_prompt_with_template(prompt)<br />    elif model_name == 'Mistral':<br />        return f&quot;&lt;s&gt;[INST]{prompt}[/INST]&quot;<br />    else:<br />        return prompt  # Default case, no special preprocessing<br /><br />def generate_responses(row, model_name, pipeline, config):<br />    &quot;&quot;&quot;<br />    Generates a response using a specified model with a given generation configuration<br />    and measures the time taken for generation on the GPU.<br /><br />    Parameters:<br />    row (dict): A dictionary representing a row in the dataset.<br />    model_name (str): The name of the model.<br />    pipeline (Pipeline): The pipeline object for the model.<br />    config (dict): The generation configuration.<br /><br />    Returns:<br />    dict: Generated text and the time taken for generation.<br />    &quot;&quot;&quot;<br />    # Preprocess prompt based on the model<br />    processed_prompt = preprocess_prompt(model_name, row['prompt'])<br /><br />    # Initialize CUDA events for timing<br />    start_event = torch.cuda.Event(enable_timing=True)<br />    end_event = torch.cuda.Event(enable_timing=True)<br /><br />    # Time the generation process<br />    start_event.record()<br />    try:<br />        response = pipeline(processed_prompt, **config)[0]['generated_text']<br />    except RuntimeError as e:<br />        response = &quot;Failed Generation&quot;<br />    end_event.record()<br /><br />    # Synchronize and calculate time<br />    torch.cuda.synchronize()<br />    time_taken = start_event.elapsed_time(end_event) / 1000.0  # Time in seconds<br />    return {f'{model_name}_response': response, f'{model_name}_time': time_taken}</pre><h3>⏳ Just a heads up, this will take a while</h3><p>The following took ~14 hours to run.</p><pre># Iterate over configurations and models, and generate responses<br />for config_name, config in gen_configs.items():<br />    for model_name, model_pipeline in pipelines.items():<br />        # Prepare new column names<br />        response_column = f'{model_name}_{config_name}_response'<br />        time_column = f'{model_name}_{config_name}_time'<br /><br />        # Initialize lists to store data<br />        responses, times = [], []<br /><br />        # Process dataset<br />        for row in tqdm(subset, desc=f'Processing {model_name} with {config_name}'):<br />            result = generate_responses(row, model_name, model_pipeline, config)<br />            responses.append(result[f'{model_name}_response'])<br />            times.append(result[f'{model_name}_time'])<br /><br />        # Update the dataset with new columns<br />        subset = subset.add_column(response_column, responses)<br />        subset = subset.add_column(time_column, times)</pre><p>Since the above code will take at least a couple of hours to run, running the following cell is a good idea to push your results to HuggingFace immediately.</p><pre>subset.push_to_hub(&quot;&lt;your-hf-username&gt;/IFEval_Experiments&quot;)</pre><p>If you don’t want to run the code yourself, you can download the dataset directly if you wish. Just run the following line of code.</p><pre>data = load_dataset(&quot;harpreetsahota/IFEval_Experiments&quot;, split=&quot;train&quot;)</pre><p>But I encourage you to run this yourself to verify my results independently.</p><h3>⏱️ Timing Generations</h3><p>DeciLM consistently proves to be a superior choice, especially when efficiency and speed are the priorities.</p><p><strong>🏎️ DeciLM’s Remarkable Speed: </strong>In my comparative analysis across various strategies, DeciLM consistently outperforms Mistral. Its ability to process tasks swiftly is unmatched, making it the go-to option for time-sensitive applications.</p><p><strong>✅Advantages Over Mistral: </strong>While Mistral has its merits in handling complex strategies, it falls behind in processing time. DeciLM’s lead in speed is evident and substantial, demonstrating its robustness and superior optimization.</p><p><strong>📲 Ideal for a Range of Applications: </strong>Whether it’s simple or complex tasks, DeciLM shows remarkable versatility, handling them with greater efficiency than Mistral. This makes DeciLM a more flexible and reliable choice in various scenarios.</p><p>⤵️ <strong>The Bottom Line:</strong> DeciLM is the undisputed choice for anyone looking for a model that delivers quick and efficient results.</p><pre>import pandas as pd<br />import matplotlib.pyplot as plt<br />import seaborn as sns<br /><br />def prepare_average_time_data(dataset, models, strategies):<br />    &quot;&quot;&quot;<br />    Prepare the average time data for plotting.<br /><br />    Args:<br />        dataset (Dataset): HuggingFace dataset object.<br />        models (list): List of model names.<br />        strategies (list): List of strategies.<br /><br />    Returns:<br />        pd.DataFrame: A DataFrame with the average time data.<br />    &quot;&quot;&quot;<br />    # Initialize a dictionary to hold cumulative time and counts for averaging<br />    time_data = {(model, strategy): {'total_time': 0, 'count': 0}<br />                 for model in models for strategy in strategies}<br /><br />    # Process each record in the dataset<br />    for record in dataset:<br />        for model in models:<br />            for strategy in strategies:<br />                time_column = f&quot;{model}_{strategy}_time&quot;<br />                if time_column in record and record[time_column] is not None:<br />                    time_data[(model, strategy)]['total_time'] += record[time_column]<br />                    time_data[(model, strategy)]['count'] += 1<br /><br />    # Calculate the average time and prepare data for DataFrame<br />    data_for_df = []<br />    for (model, strategy), time_info in time_data.items():<br />        if time_info['count'] &gt; 0:<br />            avg_time = time_info['total_time'] / time_info['count']<br />            data_for_df.append({'Model': model, 'Strategy': strategy, 'Average Time': avg_time})<br /><br />    return pd.DataFrame(data_for_df)<br /><br />def plot_average_time_by_strategy(df):<br />    &quot;&quot;&quot;<br />    Plots the average time by strategy for different models.<br /><br />    Parameters:<br />    df (DataFrame): A pandas DataFrame containing the columns 'Model', 'Strategy', and 'Average Time'.<br />    &quot;&quot;&quot;<br />    plt.figure(figsize=(12, 6))<br />    sns.barplot(x='Strategy', y='Average Time', hue='Model', data=df, palette=['blue', 'orange'])<br />    plt.title('Average Time by Strategy and Model')<br />    plt.xticks(rotation=45)<br />    plt.ylabel('Average Time (Seconds)')<br />    plt.xlabel('Strategy')<br />    plt.legend(title='Model')<br />    plt.tight_layout()<br />    plt.show()<br /><br />models = ['DeciLM', 'Mistral']<br />strategies = ['baseline', 'greedy_search', 'multinomial_sampling', 'beam_search', 'beam_search_multinomial', 'contrastive_search']<br /><br />df_avg_time = prepare_average_time_data(subset, models, strategies)<br /><br />plot_average_time_by_strategy(df_avg_time)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*N_EoAY8at79HZWUi.png\" /><figcaption>By Author</figcaption></figure><h3>👨🏾‍🍳 Prepare for Evaluation with IFEval</h3><p>To run IFEval we’ll need to prepare our environment and datasets.</p><p>Here’s what needs to be done:</p><ul><li>Clone the repo and install dependencies</li><li>Format data: Save each generation + strategy combo from the dataset we created as a jsonl file with two entries: prompt and response</li></ul><h4>Clone the repo</h4><p>The IFEval code is in the Google Research repo, which is massive. The below code will download the entire repo but only extract the IFEval code.</p><pre>%%bash<br />curl -L https://github.com/google-research/google-research/archive/master.zip -o google-research-master.zip<br />unzip google-research-master.zip &quot;google-research-master/instruction_following_eval/*&quot;</pre><h4>👩🏿‍🔧 Install dependencies</h4><pre>!pip install absl-py<br />!pip install -r /content/google-research-master/instruction_following_eval/requirements.txt<br />!mkdir /content/output</pre><h4>🔷 Format Data</h4><pre>def save_as_jsonl(dataset: Dataset, prompt_column: str, response_column: str, output_dir: Path) -&gt; None:<br />    &quot;&quot;&quot;<br />    Saves specific columns of a Hugging Face dataset as JSONL files.<br /><br />    Args:<br />        dataset (Dataset): The Hugging Face dataset to process.<br />        prompt_column (str): The name of the column in the dataset that contains the prompts.<br />        response_column (str): The name of the column in the dataset that contains the responses.<br />        output_dir (Path): The directory where the JSONL files will be saved.<br /><br />    Returns:<br />        None<br />    &quot;&quot;&quot;<br />    output_file = output_dir / f'{response_column}.jsonl'<br />    with open(output_file, 'w') as f:<br />        for example in dataset:  # Replace 'train' with the appropriate dataset split<br />            json_object = {<br />                &quot;prompt&quot;: example[prompt_column],<br />                &quot;response&quot;: example[response_column]<br />            }<br />            f.write(json.dumps(json_object) + '\\n')<br /><br /># Define your prompt and response columns<br />prompt_column = 'prompt'<br /><br />response_columns = ['DeciLM_baseline_response',<br />                    'Mistral_baseline_response',<br />                    'DeciLM_greedy_search_response',<br />                    'Mistral_greedy_search_response',<br />                    'DeciLM_multinomial_sampling_response',<br />                    'Mistral_multinomial_sampling_response',<br />                    'DeciLM_beam_search_response',<br />                    'Mistral_beam_search_response',<br />                    'DeciLM_beam_search_multinomial_response',<br />                    'Mistral_beam_search_multinomial_response',<br />                    'DeciLM_contrastive_search_response',<br />                    'Mistral_contrastive_search_response']<br /><br />output_dir = Path('/content/google-research-master/instruction_following_eval/data')<br /><br />for response_column in response_columns:<br />    save_as_jsonl(subset, prompt_column, response_column, output_dir)</pre><h4>🛠 IFEval in Action</h4><p>The implementation involved crafting 25 verifiable instructions into 541 diverse prompts, a process that was both meticulous and rigorous:</p><ul><li><strong>Generating base prompts:</strong> This step involves creating the initial set of prompts.</li><li><strong>Adding variety in phrasing:</strong> To ensure a comprehensive evaluation, each prompt is rephrased to increase the diversity of its presentation, avoiding monotonous or repetitive phrasing.</li><li><strong>A final manual review:</strong> This step involved thoroughly inspecting the rephrased prompts to guarantee their quality, relevance, and alignment with the intended instructional goals.</li></ul><p><strong>The table below describes the 25 verifiable instructions and their descriptions.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*lAVJ6Pbs_1cMJ5xrXIqyWQ.png\" /></figure><h4>Example prompt, instruction, and generations</h4><p>You’ll notice the complete prompt that should be provided as input to the model and a list of instructions and keyword arguments that the framework uses to assess adherence to the prompt.</p><p>You can also see an example of the completion from each model's baseline configuration.</p><pre>subset[42]['prompt'], subset[42]['instruction_id_list'], subset[42]['kwargs']</pre><pre>('Can you give me an example for a journal entry about stress management? Tell me how you come up with the example. Your entire response should contain less than 6 sentences.',<br /> ['length_constraints:number_sentences'],<br /> '[{&quot;relation&quot;: &quot;less than&quot;, &quot;num_sentences&quot;: 6}]')<br /></pre><pre>print(subset[42]['DeciLM_baseline_response'])</pre><pre>Sure, here's an example of a journal entry about stress management:<br /><br />&quot;Today, I experienced a lot of stress due to a heavy workload and personal issues. To manage my stress, I decided to take a break and go for a walk. As I walked, I focused on my breath and the beauty of nature around me. This helped me feel more relaxed and recharged, allowing me to approach my tasks with a clearer mind.&quot;<br /><br />I came up with this example by thinking about common stressors and how people might manage them. I then used my own experience to create a relatable and helpful entry.</pre><pre>print(subset[42]['Mistral_baseline_response'])</pre><pre> Example: &quot;Today, I practiced stress management by taking a break from technology and spending time in nature. I went for a walk in the park and listened to the sound of the birds and the rustling of the leaves. This helped me to clear my mind and reduce feelings of anxiety and stress.&quot;<br /><br />I came up with this example by reflecting on my own experiences with stress management. I know that taking a break from technology and spending time in nature can be helpful in reducing stress levels. So, I decided to write about a specific instance where I practiced this technique and the positive effects it had on me.</pre><h3>How does IFEval work?</h3><p>This evaluation framework is designed to comprehensively test and compare LLMs based on their ability to understand and follow instructions. It combines strict and loose accuracy assessments at both the prompt and instruction levels, supported by a robust testing system to ensure the accuracy and reliability of the evaluation process.</p><ol><li><strong>Preparation: </strong>The system sets instructions using the instruction framework and loads input data.</li><li><strong>Evaluation</strong>: The evaluation_main.py script processes these inputs and compares the system’s responses against the expected outcomes defined by the instructions.</li><li><strong>Result Analysis:</strong> The system generates results that detail how well the instructions were followed under different evaluation criteria (strict vs. loose).</li><li><strong>Testing and Validation: </strong>Test scripts are used throughout to ensure the integrity of the instruction framework and the reliability of the evaluation process.</li></ol><h3>🏃🏽‍♂️💨 Run Evaluation</h3><p>I appreciate its objective approach to evaluating language models.</p><p>Unlike other methods that might require subjective interpretation or additional language models for evaluation, IFEval offers a clear-cut, binary system: the model either follows the given instruction or doesn’t. This simplicity is invaluable, especially when running on a CPU without high-powered resources. Such a straightforward evaluation is a vital sanity check in comparing language models, ensuring they meet specific criteria crucial in high-stakes scenarios.</p><p>This objectivity in assessment provides a reliable baseline for measuring a model’s instruction-following capabilities, an essential factor in its practical application.</p><p>The code below sets up IFEval in your environment and then runs the evaluation. All of this happens on the CPU, and it’s really quick. The evaluation results are written to a text file, so we have to parse them ourselves. Once the results are parsed, we can analyze them and plot them.</p><pre>import sys<br />sys.path.append('/content/google-research-master/instruction_following_eval')</pre><pre>%cd /content/google-research-master<br /><br />log_file = &quot;/content/output/all_responses_log.txt&quot;  # Single log file for all responses<br />os.makedirs(&quot;/content/output&quot;, exist_ok=True)<br /><br />for response_column in response_columns:<br />    response_file = f&quot;/content/google-research-master/instruction_following_eval/data/{response_column}.jsonl&quot;<br />    output_dir = f&quot;/content/output/{response_column}&quot;<br /><br />    # Create the output directory if it doesn't exist<br />    os.makedirs(output_dir, exist_ok=True)<br /><br />    # Run the script for each response file and append output to the log file<br />    !python -m instruction_following_eval.evaluation_main \\<br />      --input_data=/content/subset_for_eval.jsonl \\<br />      --input_response_data={response_file} \\<br />      --output_dir={output_dir} &amp;&gt;&gt; {log_file}<br /><br />    print(f&quot;Completed evaluation for {response_column}&quot;)<br /><br /># Print a message when all processing is complete<br />print(f&quot;All evaluations complete. Check the log file: {log_file} for details.&quot;)</pre><pre>import re<br />import pandas as pd<br />def parse_log(file_path):<br />    &quot;&quot;&quot;<br />    Parses the log file to extract baseline response names and their associated<br />    accuracy scores under both strict and loose evaluation regimes.<br /><br />    Parameters:<br />    file_path (str): Path to the log file.<br /><br />    Returns:<br />    dict: A dictionary with the results for strict and loose<br />    &quot;&quot;&quot;<br />    # Regular expression to match the relevant lines in the log data<br />    pattern = r&quot;/content/output/(?P&lt;response&gt;[\\w_]+)/eval_results_(?P&lt;type&gt;\\w+).jsonl Accuracy Scores:\\n&quot; \\<br />              r&quot;prompt-level: (?P&lt;prompt_level&gt;[\\d.]+)\\n&quot; \\<br />              r&quot;instruction-level: (?P&lt;instruction_level&gt;[\\d.]+)\\n&quot;<br /><br />    # Dictionary to store the parsed data<br />    results = {}<br /><br />    # Read the log file<br />    with open(file_path, 'r') as file:<br />        log_data = file.read()<br /><br />        # Find all matches and process them<br />        for match in re.finditer(pattern, log_data, re.MULTILINE):<br />            response = match.group(&quot;response&quot;)<br />            eval_type = f&quot;eval_results_{match.group('type')}&quot;<br />            prompt_level = float(match.group(&quot;prompt_level&quot;))<br />            instruction_level = float(match.group(&quot;instruction_level&quot;))<br /><br />            # Initialize the response dictionary if not already present<br />            if response not in results:<br />                results[response] = {}<br />            # Store the scores in the corresponding dictionary<br />            results[response][eval_type] = {<br />                &quot;prompt-level&quot;: prompt_level,<br />                &quot;instruction-level&quot;: instruction_level<br />            }<br /><br />    return results<br /><br />parsed_log = parse_log(&quot;/content/output/all_responses_log.txt&quot;)<br /><br /># Create a list of dictionaries for DataFrame construction<br />data_for_df = []<br />for response_name, response_data in parsed_log.items():<br />    # Split the response_name to separate the model and the strategy<br />    parts = response_name.split('_')<br />    model_name = parts[0]<br />    strategy = '_'.join(parts[1:-1])  # Join all parts except the first and last<br /><br />    # Now create a row for each eval_type<br />    for eval_type, scores in response_data.items():<br />        row = {<br />            'Model': model_name,<br />            'Strategy': strategy,<br />            'Evaluation Type': eval_type.split('_')[-1],  # Get 'strict' or 'loose'<br />            'Prompt Level': scores['prompt-level'],<br />            'Instruction Level': scores['instruction-level']<br />        }<br />        data_for_df.append(row)<br /><br /># Create the DataFrame<br />df = pd.DataFrame(data_for_df)</pre><pre><br />import matplotlib.pyplot as plt<br />import pandas as pd<br /><br />def get_strategy_data(df, strategy):<br />    &quot;&quot;&quot;<br />    Filter the DataFrame for a specific strategy.<br /><br />    Args:<br />        df (pd.DataFrame): The DataFrame to filter.<br />        strategy (str): The strategy to filter by.<br /><br />    Returns:<br />        pd.DataFrame: Filtered DataFrame.<br />    &quot;&quot;&quot;<br />    return df[df['Strategy'] == strategy]<br /><br />def plot_model_bars(ax, strategy_data, model_colors, bar_positions, strategy_index):<br />    &quot;&quot;&quot;<br />    Plot bars for each model in the given strategy data.<br /><br />    Args:<br />        ax (matplotlib.axes.Axes): The axis to plot on.<br />        strategy_data (pd.DataFrame): Data for the specific strategy.<br />        model_colors (dict): A dictionary mapping models to colors.<br />        bar_positions (list): Positions for each bar in the plot.<br />        strategy_index (int): Index of the current strategy.<br /><br />    Returns:<br />        None<br />    &quot;&quot;&quot;<br />    for j, (model, color) in enumerate(model_colors.items()):<br />        prompt_level = strategy_data[strategy_data['Model'] == model]['Prompt Level'].values<br />        if prompt_level.size &gt; 0:<br />            ax.bar(bar_positions[j], prompt_level[0], color=color, width=0.4, label=model if strategy_index == 0 else &quot;&quot;)<br /><br />def plot_evaluation(df, evaluation_type, model_colors, ax, strategies, column_to_plot):<br />    &quot;&quot;&quot;<br />    Plot the evaluation data as a bar chart for a specified column.<br /><br />    Args:<br />        df (pd.DataFrame): The DataFrame containing evaluation data.<br />        evaluation_type (str): The type of evaluation ('strict' or 'loose').<br />        model_colors (dict): A dictionary mapping models to colors.<br />        ax (matplotlib.axes.Axes): The matplotlib axis to plot on.<br />        strategies (list): A list of strategies to evaluate.<br />        column_to_plot (str): The column name to plot.<br /><br />    Returns:<br />        None<br />    &quot;&quot;&quot;<br />    for i, strategy in enumerate(strategies):<br />        strategy_data = df[df['Strategy'] == strategy]<br />        bar_positions = [i - 0.2, i + 0.2]<br /><br />        for j, (model, color) in enumerate(model_colors.items()):<br />            values = strategy_data[strategy_data['Model'] == model][column_to_plot].values<br />            if values.size &gt; 0:<br />                ax.bar(bar_positions[j], values[0], color=color, width=0.4, label=model if i == 0 else &quot;&quot;)<br /><br />    ax.set_xticks(range(len(strategies)))<br />    ax.set_xticklabels(strategies, rotation=45, ha='right')<br />    ax.set_ylabel(column_to_plot.replace('_', ' ').title())<br />    ax.set_title(f&quot;{evaluation_type.capitalize()} Evaluation: {column_to_plot.replace('_', ' ').title()}&quot;)<br /><br />    if evaluation_type == 'strict':<br />        handles, labels = ax.get_legend_handles_labels()<br />        ax.legend(handles, labels, loc='best')<br /><br />def plot_strict_and_loose(df, model_colors, column_to_plot):<br />    &quot;&quot;&quot;<br />    Set up and plot for strict and loose evaluations for a specified column.<br /><br />    Args:<br />        df (pd.DataFrame): The DataFrame containing the evaluation data.<br />        model_colors (dict): A dictionary mapping models to colors.<br />        column_to_plot (str): The column name to plot.<br /><br />    Returns:<br />        None<br />    &quot;&quot;&quot;<br />    df_strict = df[df['Evaluation Type'] == 'strict']<br />    df_loose = df[df['Evaluation Type'] == 'loose']<br />    strategies = sorted(df['Strategy'].unique())<br /><br />    fig, axs = plt.subplots(1, 2, figsize=(14, 7), sharey=True)<br />    plot_evaluation(df_strict, 'strict', model_colors, axs[0], strategies, column_to_plot)<br />    plot_evaluation(df_loose, 'loose', model_colors, axs[1], strategies, column_to_plot)<br /><br />    plt.tight_layout()<br />    plt.show()<br /><br /># Example usage<br />model_colors = {'DeciLM': 'blue', 'Mistral': 'orange'}</pre><h3>📏 Clear Metrics for Evaluation</h3><p>IFEval introduces two key metrics for evaluating the adherence of large language models (LLMs) to instructions:</p><ol><li><strong>✅ Strict Accuracy:</strong> This metric is a straightforward assessment: did the LLM follow the instructions exactly as stated? It’s a binary evaluation — either the instruction was followed (True), or it wasn’t (False).</li><li><strong>🔄 Loose Accuracy:</strong> It’s a more lenient metric that aims to reduce false negatives by accounting for variations in how an LLM might execute the instructions.</li></ol><h3>🔍 Bringing It All Together</h3><p>The evaluation results in four distinct accuracy scores, combining strict and loose assessments at both the prompt and instruction levels:</p><ol><li>🎯 Prompt-level strict-accuracy</li><li>📏 Instruction-level strict-accuracy</li><li>🌐 Prompt-level loose-accuracy</li><li>🔍 Instruction-level loose-accuracy</li></ol><h3>Prompt-Level Evaluation: Comparing the Models with Different Decoding Strategies</h3><h4>🎯 Prompt-level strict-accuracy</h4><p>This metric calculates the percentage of prompts in which all verifiable instructions are followed. It assesses the model’s ability to adhere to every instruction within a single prompt.</p><ul><li>DeciLM consistently outperforms Mistral in strict accuracy across all strategies. Its highest strict accuracy is observed with the ‘beam_search’ strategy (0.43), indicating its capability to follow instructions precisely.</li><li>Mistral shows lower strict accuracy, with its highest being 0.34 under the ‘baseline’ and ‘greedy_search’ strategies. This suggests a relative weakness in following instructions exactly as stated compared to DeciLM.</li></ul><h4>🌐 Prompt-level loose-accuracy</h4><p>This is the prompt-level accuracy computed with a loose criterion. The ‘loose’ criterion involves more lenient standards for following instructions, allowing for variations in the responses that still capture the essence of the instructions.</p><ul><li>DeciLM also leads in loose accuracy, demonstrating a better understanding of the essence of instructions. Its highest score is 0.46, achieved with both ‘baseline’ and ‘greedy_search’ LLM decoding strategies.</li><li>While trailing behind DeciLM, Mistral performs well in loose accuracy with the ‘baseline’ and ‘greedy_search’ LLM decoding strategies (0.40). This indicates a reasonable ability to capture the intent of instructions, though not as effectively as DeciLM.</li></ul><p>DeciLM outperforms Mistral in strict and loose accuracy metrics at the prompt level, regardless of the strategy used. This suggests that DeciLM is better equipped to understand and adhere to instructions in various contexts. Mistral, while showing reasonable capability, particularly in loose accuracy, falls behind in strictly adhering to instructions, indicating potential areas for improvement.</p><p>DeciLM demonstrates more balance in understanding the literal and nuanced aspects of instructions. It looks like a more effective model for tasks which require precision and adaptability in language understanding.</p><pre># column_to_plot =   # Specify the column you want to plot<br />plot_strict_and_loose(df, model_colors, column_to_plot='Prompt Level')</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*xRkcqDYHH8FWLXMZLcRcfg.png\" /><figcaption>By Author</figcaption></figure><h3>Instruction-Level Evaluation: Comparing the Models with Different Decoding Strategies</h3><h4>📏 Instruction-level strict-accuracy</h4><p>This metric measures the percentage of individual verifiable instructions that are followed, regardless of the prompt they appear in. It focuses on the model’s consistency in following each type of instruction across different prompts.</p><ul><li>DeciLM’s scores are higher, indicating a better ability to follow instructions exactly as stated.</li><li>Mistral’s lower scores suggest a need for improvement in strict adherence to instructions.</li></ul><h4>🔍 Instruction-level loose-accuracy</h4><p>Similar to prompt-level loose accuracy, this metric is computed at the instruction level with a loose criterion. It evaluates how well the model follows each instruction across different prompts, with some leniency in how strictly the instructions must be followed.</p><ul><li>DeciLM again leads, showing its capability to interpret instructions with some flexibility.</li><li>Mistral performs better in loose accuracy than strict but still trails behind DeciLM.</li></ul><p>DeciLM demonstrates stronger performance in instruction adherence at the instruction level, both strictly and loosely, across all evaluated strategies. Mistral, while showing some capability, especially in loose accuracy, needs improvements to match DeciLM's performance.</p><p>The choice of strategy significantly affects the models’ performance, highlighting the importance of strategy selection in model deployment for specific tasks.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Jw12iRm5nwlIrjXPcmdmaA.png\" /><figcaption>By Author</figcaption></figure><h3>🚀 Wrapping Up</h3><p>Juggling the intricacies of LLM evaluation and decoding strategies has been challenging and immensely enjoyable. A big shout out to the authors whose genius lit the fuse for this firecracker of a project. Your work more than sparked my curiosity; it set off a full-blown fireworks show in my brain!</p><p><strong>The IFEval framework is a gem and has rightly earned its place in my evals toolkit.</strong> It offers a fresh perspective on how we assess instruction-following in language models. To my fellow AI enthusiasts, I hope my explorations shed light on this framework’s potential. Keep the conversation going in the <a href=\"https://www.deeplearningdaily.community/\">Deep Learning Daily Discord</a> community for deeper dives and lively discussions.</p><p>Starting this project, I had no clue what to expect. Mistral v0.1 has a lot of hype behind it, and DeciLM is the underdog. But in my experiments, DeciLM was nailing task after task. Didn’t see that coming!</p><p>The next thing to do is compare Mistral v0.2 with and without the appropriate prompt template. I invite my counterpart (and my good friend) <a href=\"https://medium.com/u/ae9cae9cbcd2\">Sophia Yang, Ph.D.</a>, to do this! There is nothing wrong with a little friendly competition!</p><p>My invitation to the community is to take my work, build on it, and challenge it. Independent exploration by others in the community is not just welcome; it’s essential for validating and enriching our collective understanding.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9c6ac57a8e22\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/how-to-evaluate-an-llms-ability-to-follow-instructions-9c6ac57a8e22\">How to Evaluate an LLM's Ability to Follow Instructions</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Harpreet Sahota'}],"Thu, 08 Feb 2024 22:10:22 GMT"
1188,AI Assistants via OpenAI and Hugging Face API,https://medium.com/artificialis/ai-assistants-via-openai-and-hugging-face-api-332fc945837c?source=rss----a81c8d170222---4,"<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*LR2G23zOG0Pjp3wxlXLxAQ.jpeg\" /><figcaption>image created by Lexica AI</figcaption></figure><h4><strong>quick hands-on tutorial</strong></h4><h3>Introduction</h3><p>In this guide, we’ll explore the Assistant APIs from OpenAI. We will learn about the primary features of the Assistants API, including the Code Interpreter, Knowledge Retrieval, and Function Calling capabilities.</p><p>This hand-on will show how to equip Assistant’s with tools and function that would enable it to provide technical solutions by executing Python code, retrieve knowledge from the database and many more.</p><p>You’ll be also introduced to other advanced technologies from OpenAI, such as Whisper, Dalle-3, Speech to Text, and the GPT-4 vision API. These tools are essential for anyone looking to develop sophisticated AI assistants using a variety of APIs.</p><p>Then, you’ll learn how to use the free Hugging Face Inference API to get access to the thousands of models hosted on their platform.</p><p>By the end of this tutorial, you’ll gain a solid understanding on how to apply these technologies in your AI projects.</p><h3>Open AI Assistant’s Built-in Functionalities</h3><p><a href=\"https://platform.openai.com/docs/assistants/overview\">The OpenAI Assistants API</a> includes three main functionalities: Code Interpreter, Retrieval, and Function Calling.</p><p><strong>[Code Interpreter]</strong></p><p>The Assistant can use Code Interpreter automatically when you upload a file with data. It’s a tool that transforms the LLM into a more accurate computational problem-solver that can handle tasks like solving complex math equations. It can also generate files with data and images of graphs from the same Python code. It’s a useful way to trust the output from the assistant and a great tool when analyzing data.</p><p><strong>[Knowledge Retrieval]</strong></p><p>Knowledge Retrieval is OpenAI’s own <a href=\"https://arxiv.org/abs/2005.11401\">RAG</a> system offered as part of the Assistants API. KR allows multiple uploads. Once the files are uploaded and passed to the Assistant, OpenAI will automatically chunk your documents, index them, store the embeddings, and implement vector search to retrieve relevant content to answer user queries.</p><p><strong>[Function Calling]</strong></p><p>Function calling allows you to describe functions or tools to the Assistant and have it return the functions that need to be called along with their arguments. It's a powerful way to add new capabilities to your Assistant.</p><h3>How To Set Up an Assistant</h3><p>You have two distinct pathways depending on your needs and expertise:</p><ul><li><a href=\"https://platform.openai.com/playground\"><strong>Assistants Playground</strong></a>: Ideal for those looking to get a feel for the Assistant’s capabilities without going into complex integrations.</li><li><a href=\"https://platform.openai.com/docs/assistants/overview\"><strong>Detailed Integration through the API</strong></a>: Best suited for those who require a more customized and in-depth setup.</li></ul><p><strong>STEP-BY-STEP ASSISTANT CREATION:</strong></p><p><strong>Creating an </strong><strong>Assistant</strong>:</p><p><strong>Purpose</strong>: An Assistant object represents an entity/agent that can be configured to respond to users’ messages in different ways using several parameters.</p><p><strong>Model Selection</strong>: you can specify any version of GPT-3.5 or GPT-4 models, including fine-tuned models. OpenAI recommends using its <a href=\"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\">latest models</a> with the Assistants API for best results and maximum compatibility with tools. Thus, choose between <strong>gpt-3.5-turbo-1106</strong> or <strong>gpt-4-1106-preview</strong> models.</p><p><strong>Tools:</strong> The Assistant supports the <strong>Code Interpreter</strong> for technical queries that require Python code execution or <strong>Knowledge Retrieval</strong> to augment the Assistant with proprietary external information.</p><p><strong>Setting up a </strong><strong>Thread</strong>:</p><p><strong>Role</strong>: A Thread acts as the foundational unit of user interaction. It can be seen as a single <strong>conversation</strong>. Pass any user-specific context and files in this thread by <a href=\"https://platform.openai.com/docs/api-reference/messages/createMessage\">creating Messages</a>.</p><pre>thread = client.beta.threads.create()</pre><p><strong>Customization</strong>: In Thread, ingest user-specific contexts or attach necessary files so each conversation is unique and personalized.</p><p>Threads don’t have a size limit. You can add as many messages as you want to a conversation/Thread. The Assistant will ensure that requests to the model fit within the maximum context window, using relevant optimization techniques used in ChatGPT, such as truncation.</p><p><strong>Adding a </strong><strong>Message</strong>:</p><p><strong>Definition</strong>: Messages are user inputs, and the Assistant’s answers are appended to a Thread. User inputs can be questions or commands.</p><p><strong>Function</strong>: They serve as the primary mode of communication between the user and the Assistant.</p><pre>message = client.beta.threads.messages.create(<br />    thread_id=thread.id,<br />    role=&quot;user&quot;,<br />    content=&quot;I need to solve the equation `3x + 11 = 14`. Please, help!&quot;<br />)</pre><p>Messages can include <strong>text, images, and other files</strong>. Messages are stored as a list on the Thread. Using GPT-4 with Vision is not supported here. You can upload images and have them <a href=\"https://platform.openai.com/docs/assistants/tools/knowledge-retrieval\">processed via retrieval</a>.</p><p><strong>Activation</strong>: For the Assistant to respond to the user message, you must <a href=\"https://platform.openai.com/docs/api-reference/runs/createRun\">create a Run</a>. The Assistant will then automatically decide what previous Messages to include in the context window for the model.</p><blockquote>⚠️ NOTE: You can <a href=\"https://platform.openai.com/docs/api-reference/runs/createRun#runs-createrun-instructions\">optionally pass additional instructions</a> to the Assistant while creating the Run, but these <strong>will override</strong> the default instructions of the Assistant!</blockquote><p><strong>Process</strong>: The Assistant processes the entire Thread, employs its tools if required, and formulates an appropriate response.</p><p>During its run, the Assistant can call tools or create Messages. Examining Run Steps allows you to check how the Assistant is getting to its final results.</p><p>The assistant’s response to a Run:</p><pre>messages = client.beta.threads.messages.list(thread_id=thread.id)</pre><p>These responses are displayed to the user! During this Run, the Assistant added two new Messages to the Thread.</p><h3>ASSISTANT’S CORE MECHANISM:</h3><p>Creating an Assistant only requires specifying the <strong>model</strong>.</p><p>You can further customize the behavior of the Assistant:</p><ol><li>Use the <strong>instructions</strong> parameter to guide the personality of the Assistant and define its goals. Instructions are similar to system messages in the Chat Completions API.</li><li>Use the <strong>tools</strong> parameter to give the Assistant access to up to 128 tools in parallel. You can give it access to OpenAI-hosted tools (Conde Interpreter, Knowledge Retrieval) or call third-party tools via <strong>function calling</strong>.</li><li>Use the <strong>file_ids</strong> parameter to give the tools access to files. Files are uploaded using the <strong>File</strong> U<a href=\"https://platform.openai.com/docs/api-reference/files/create\">pload endpoint</a>.</li></ol><h3>Example demonstration:</h3><p>Imagine you’re developing an AI assistant for a tech company. This assistant needs to provide detailed product support using a comprehensive knowledge base.</p><pre>mkdir openai-assistants &amp;&amp; cd openai-assistants<br />python3 -m venv openai-assistants-env<br />source openai-assistants-env/bin/activate</pre><pre>pip3 install python-dotenv<br />pip3 install --upgrade openai<br /># fire up VSCode and let's get rolling!<br />code .</pre><p>Replace the text with your OpenAI API key, which you can get from your <a href=\"https://platform.openai.com/api-keys\">OpenAI developer account</a>.</p><pre>OPENAI_API_KEY=&quot;sh-xxx&quot;</pre><pre>$ pip install -U -q openai</pre><h3>Upload Files to a Knowledge Base:</h3><p>First, make a folder to store all the files you’ll create. <strong>Upload</strong> a detailed PDF manual of a product line (e.g., “tech_manual.pdf”) using the API:</p><pre>from openai import OpenAI<br /><br /><br />client = OpenAI()<br />file = client.beta.files.upload(<br /> file=open(&quot;tech_manual.pdf&quot;, &quot;rb&quot;),<br /> filetype=&quot;application/pdf&quot;,<br /> description=&quot;Tech product manual&quot;<br />)</pre><p>Now you can create the assistant with an uploaded file and with the ability to retrieve: tools=[{&quot;type&quot;: &quot;retrieval&quot;}]</p><pre>assistant = client.beta.assistants.create(<br />  instructions=&quot;You are a tech support chatbot. Use the product manual to respond accurately to customer inquiries.&quot;,<br />  model=&quot;gpt-4-1106-preview&quot;,<br />  tools=[{&quot;type&quot;: &quot;retrieval&quot;}],<br />  file_ids=[file.id]<br />)</pre><p><strong>User Interaction</strong>: To interact with the assistant, you need a <strong>thread and a </strong><strong>message:</strong></p><p>The message should contain the customer's question. Here's an example:</p><pre>thread = client.beta.threads.create()<br />   message = client.beta.threads.messages.create(<br />       thread_id=thread.id,<br />       role=&quot;user&quot;,<br />       content=&quot;How do I reset my Model X device?&quot;,<br />   )</pre><h3>RUN Thread:</h3><ul><li>A customer asks, “<em>How do I reset my Model X device?</em>”</li><li>The assistant accesses the uploaded manual, performs a vector search to find the relevant section, and provides clear, step-by-step reset instructions.</li></ul><pre>run = client.beta.threads.runs.create(<br />   thread_id=thread.id,<br />   assistant_id=assistant.id,<br />)<br /># the run will enter the **queued** state before it continues it's execution.</pre><h3>Information retrieval:</h3><p>After the run is complete, you can retrieve the assistant’s response:</p><pre>messages = client.beta.threads.messages.list(<br />	thread_id=thread.id<br />)</pre><pre>assistant_response = messages.data[0].content[0].text.value</pre><p>The output result should contain the assistant’s response to the customer’s question based on knowledge from the uploaded manual.</p><p>The full code and more examples are in the Colab notebook attached in the Resources section.</p><h3>OpenAI’s Other Advanced Models</h3><p>OpenAI also offers different types of models that are not yet integrated into the Assistants API but are accessible. These models offer voice processing, image understanding, and image generation capabilities.</p><h3><a href=\"https://huggingface.co/openai/whisper-large-v3\">Whisper-v3</a></h3><p>Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. It is a transformer-based encoder-decoder model, which is a type of <em>sequence-to-sequence</em> model. The latest large-v3 model shows improved performance over various languages compared to Whisper large-v2. OpenAI released the model’s weights with an <strong>Apache License 2.0.</strong> The model is available on <a href=\"https://huggingface.co/openai/whisper-large-v3\">Hugging Face</a>.</p><h3><a href=\"https://platform.openai.com/docs/guides/text-to-speech\">Text to Speech</a></h3><p>TTS is an AI model that converts text to natural-sounding spoken text. They offer two different model variates: <strong>tts-1</strong> is optimized for real-time text-to-speech use cases, and <strong>tts-1-hd</strong> is optimized for quality. These models can be used with the <a href=\"https://platform.openai.com/docs/guides/text-to-speech\">Speech endpoint in the Audio API</a>.</p><h3><a href=\"https://openai.com/dall-e-3\">Dall-E 3</a></h3><p>A newer iteration of the DALL-E model is designed for image generation. It can create images based on user prompts, making it a valuable tool for graphic designers, artists, and anyone to generate images quickly and efficiently. You can access the model through the <a href=\"https://platform.openai.com/docs/guides/images/generations\">image generation endpoint</a>.</p><h3><a href=\"https://openai.com/research/gpt-4v-system-card\">GPT-4 Vision</a></h3><p>GPT-4 with Vision enables you to ask questions about the contents of images. Visual question answering (VQA) is an important computer vision research field. You can also perform other vision tasks, such as Optical Character Recognition (OCR), where a model reads text in an image.</p><p>Using GPT-4 with Vision, you can ask questions about what is or is not in an image, how objects relate in an image, the spatial relationships between two objects (is one object to the left or right of another), the color of an object, and more.</p><p>GPT-4V is available through the <a href=\"https://openai.com/?ref=blog.roboflow.com\">OpenAI web interface for ChatGPT Plus</a> subscribers and through <a href=\"https://platform.openai.com/docs/guides/vision/vision\">their API</a>. This expands the model’s utility beyond the traditional text-only inputs, enabling it to be applied in a wider range of contexts. It handles images through the Chat Completions API, but note that the Assistants API does not support GPT-4V at this time.</p><p>GPT4-V supports advanced use cases like creating image captions, in-depth analysis of visual content, and interpreting text and graphics in documents.</p><h3>Hugging Face Inference API</h3><p>Hugging Face (HF) offers a free service for testing and evaluating over 150,000 publicly available machine learning models hosted on their platform through their <a href=\"https://huggingface.co/docs/api-inference/index\">Inference API.</a></p><p>HF provides a wide range of models, including transformer and diffusion-based models, that can help solve various NLP or vision tasks such as text classification, sentiment analysis, named entity recognition, etc.</p><blockquote>💡 Note that these free Inference APIs are <strong>rate-limited</strong> and not meant for production use. You can check out their <a href=\"https://huggingface.co/inference-endpoints\">Inference Endpoint service if you want good performance</a>.</blockquote><h3>Steps to use the Inference API</h3><ol><li><a href=\"https://huggingface.co/login\">Login</a> to Hugging Face.</li><li>Navigate to your profile on the top right navigation bar, then click “Edit profile.”</li><li>Click on the “Access Tokens” menu item.</li><li>Set the HF HUB API token:</li></ol><pre>export HUGGINGFACEHUB_API_TOKEN=your-token</pre><p>Use the HUGGINGFACEHUB_API_TOKEN as an environment variable</p><pre>import os<br />from huggingface_hub import HfApi</pre><pre> hf_api = HfApi(token=os.getenv(&quot;HUGGINGFACEHUB_API_TOKEN&quot;))</pre><p><strong>Run the Inference API</strong></p><p>Inference is the process of using a trained model to predict new data. The huggingface_hub library provides an easy way to call a service that runs inference for hosted models. As described above, you have two types of services available.</p><ul><li><a href=\"https://huggingface.co/docs/api-inference/index\"><strong>Inference API</strong></a>: run accelerated inference on Hugging Face’s infrastructure <strong>for free</strong>.</li><li><a href=\"https://huggingface.co/docs/inference-endpoints/index\"><strong>Inference Endpoints</strong></a>: easily deploy models to production <strong>(paid)</strong></li></ul><h4>Choose a model from the <a href=\"https://huggingface.co/models\">Model Hub</a></h4><p>The model checkpoints are stored in the Model Hub; you can search and share them. Note that not all models are available on the Inference API. Once the endpoint has been created, you should see a URL endpoint of it like the following:</p><pre>ENDPOINT = &lt;https://api-inference.huggingface.co/models/&gt;&lt;MODEL_ID&gt;</pre><p><strong>Run the inference:</strong></p><pre>import requests<br />API_URL = &quot;&lt;https://api-inference.huggingface.co/models/&gt;&lt;MODEL_ID&gt;&quot;<br />headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}<br />def query(payload):<br />    response = requests.post(API_URL, headers=headers, json=payload)<br />    return response.json()<br />data = query(&quot;Can you please let us know more&quot;)</pre><h3>Hugging Face Tasks</h3><p>The team at <a href=\"https://huggingface.co/tasks\">Hugging Face has categorized</a> several models into the different tasks they can solve. You can find models for popular NLP tasks: Question Answering, Sentence Similarity, Summarization, Table Question Answering, and more.</p><p>Here is another example of using the Inference API for a summarization task:</p><pre>API_TOKEN = 'your_api_token_here'<br />model_name = 'facebook/bart-large-cnn'<br />text_to_summarize = &quot;Hugging Face's API simplifies accessing powerful NLP models for tasks like summarization, transforming verbose texts into concise, insightful summaries.&quot;<br />endpoint = f'&lt;https://api-inference.huggingface.co/models/{model_name}&gt;'<br />headers = {'Authorization': f'Bearer {API_TOKEN}'}<br />data = {'inputs': text_to_summarize}<br />response = requests.post(endpoint, headers=headers, json=data)<br />summarized_text = response.json()[0]['summary_text']<br />print(summarized_text)</pre><p>The pre-trained model used above is<strong>[facebook/bart-large-cnn](&lt;https://huggingface.co/facebook/bart-large-cnn&gt;) </strong>trained by Meta demonstrates the ability to produce clear and concise summaries.</p><blockquote><strong>Note:</strong> Not all models are available in this Inference API. Verify if the model is available by reviewing its ‘<em>Model card</em>’.</blockquote><h4>Sentiment analysis task:</h4><pre>headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}<br />API_URL = &quot;&lt;https://api-inference.huggingface.co/models/distilbert-base-uncased-finetuned-sst-2-english&gt;&quot;</pre><pre>def query(payload):<br />    response = requests.post(API_URL, headers=headers, json=payload)<br />    return response.json()</pre><pre>data = query({&quot;inputs&quot;: &quot;I love how this app simplifies complex tasks effortlessly . I'm frustrated by the frequent errors in the software's latest update&quot;})<br />print(data)</pre><h4>Text-to-image task:</h4><pre>model_id = &quot;runwayml/stable-diffusion-v1-5&quot;<br />pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)<br />pipe = pipe.to(&quot;cuda&quot;)</pre><pre>prompt = &quot;Create an image of a futuristic cityscape on an alien planet, featuring towering skyscrapers with glowing neon lights, a sky filled with multiple moons, and inhabitants of various alien species walking through vibrant market streets&quot;<br />image = pipe(prompt).images[0]</pre><pre>image.save(&quot;generated-image.png&quot;)</pre><blockquote>Image generated with stable diffusion is saved to your environment!</blockquote><p>You can also encode a sentence and get text embeddings.</p><pre>from sentence_transformers import SentenceTransformer<br />sentences = [&quot;GAIA's questions are rooted in practical use cases, requiring AI systems to interact with a diverse and uncertain world, reflecting real-world applications.&quot;, &quot; GAIA questions require accurate execution of complex sequences of actions, akin to the Proof of Work concept, where the solution is simple to verify but challenging to generate.&quot;]</pre><pre>model = SentenceTransformer('Equall/english-beta-0.3', use_auth_token=API_TOKEN)<br />embeddings = model.encode(sentences)<br />print(embeddings)</pre><blockquote><em>[[ 0.76227915 -0.5500489 -1.5719271 … -0.34034422 -0.27251056 0.12204967] [ 0.29783687 0.6476462 -2.0379746 … -0.28033397 -1.3997376 0.25214267]]</em></blockquote><p>You can also experiment with image-captioning models:</p><pre>from transformers import pipeline</pre><pre>image_to_text = pipeline(&quot;image-to-text&quot;, model=&quot;nlpconnect/vit-gpt2-image-captioning&quot;)</pre><pre>image_to_text(&quot;&lt;https://ankur3107.github.io/assets/images/image-captioning-example.png&gt;&quot;)</pre><pre># [{'generated_text': 'a soccer game with a player jumping to catch the ball '}]</pre><p>And also perform experiments with classification and image-to-text models, pre-trained on ImageNet:</p><pre>from transformers import ViTImageProcessor, ViTForImageClassification<br />from PIL import Image<br />import requests</pre><pre>url = '&lt;http://images.cocodataset.org/val2017/000000039769.jpg&gt;'<br />image = Image.open(requests.get(url, stream=True).raw)</pre><pre>processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')<br />model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')</pre><pre>inputs = processor(images=image, return_tensors=&quot;pt&quot;)<br />outputs = model(**inputs)<br />logits = outputs.logits<br /># model predicts one of the 1000 ImageNet classes<br />predicted_class_idx = logits.argmax(-1).item()<br />print(&quot;Predicted class:&quot;, model.config.id2label[predicted_class_idx])</pre><blockquote>preprocessor_config.json: 100%</blockquote><blockquote>160/160 [00:00&lt;00:00, 10.5kB/s]</blockquote><blockquote>config.json: 100%</blockquote><blockquote>69.7k/69.7k [00:00&lt;00:00, 3.60MB/s]</blockquote><blockquote>model.safetensors: 100%</blockquote><blockquote>346M/346M [00:02&lt;00:00, 162MB/s]</blockquote><p>the output calculated give us the prediction of an image provided:</p><pre>Predicted class: Egyptian cat</pre><p>Now we’ll scrape a web page using Rapid API to get the articles and summarize them with a huggingface model using HF model inference API.</p><pre># Function to fetch text from the API<br />def fetch_text_from_api():<br />    url = &quot;&lt;https://lexper.p.rapidapi.com/v1.1/extract&gt;&quot;<br />    querystring = {<br />        &quot;url&quot;: &quot;&lt;https://techcrunch.com/2023/11/25/neuralink-elon-musks-brain-implant-startup-quietly-raises-an-additional-43m/&gt;&quot;,<br />        &quot;js_timeout&quot;: &quot;30&quot;,<br />        &quot;media&quot;: &quot;true&quot;<br />    }<br />    headers = {<br />        &quot;X-RapidAPI-Key&quot;: &quot;xxx&quot;,<br />        &quot;X-RapidAPI-Host&quot;: &quot;lexper.p.rapidapi.com&quot;<br />    }<br />    response = requests.get(url, headers=headers, params=querystring)<br />    data = response.json()<br />    # Extract the relevant text from the API response<br />    # Adjust the following line according to the structure of your API response<br />    return data.get('article', {}).get('text', '')</pre><pre># Function to summarize the text using Hugging Face API<br />def query_huggingface(payload):<br />    API_URL = &quot;&lt;https://api-inference.huggingface.co/models/facebook/bart-large-cnn&gt;&quot;<br />    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}<br />    response = requests.post(API_URL, headers=headers, json=payload)<br />    return response.json()</pre><pre># Fetch the text<br />text_to_summarize = fetch_text_from_api()</pre><pre># Summarize the text<br />summarization_payload = {<br />    &quot;inputs&quot;: text_to_summarize,<br />    &quot;parameters&quot;: {&quot;do_sample&quot;: False},<br />}</pre><pre>summary_response = query_huggingface(summarization_payload)<br />print(summary_response)</pre><blockquote><em>[{‘summary_text’: ‘Elon Musk-founded company raises $43 million in new venture capital. The company is developing implantable chips that can read brain waves. Critics say the company has a toxic workplace culture and unethical research practices. In June, Reuters reported that the company was valued at about $5 billion.’}]</em></blockquote><h3>Conclusion</h3><p>You have learned how to use the OpenAI Assistants API, and its essential components like Threads and Messages. On a concrete example its shown how the AI assistant can be deployed as a tech support, empowering customer interaction.</p><p>In Hugging Face’s free Inference API section, through practical implementations, you’ve seen how to authenticate, access models via the Model Hub, and perform various NLP tasks.</p><p>Hope this quick walkthrough was helpuful and gave you additonal perspective on Assistants construct, especially the ones you can construct via API — .</p><p>Cheers!</p><p>RESOURCES<br />the Google colab notebook:</p><p><a href=\"https://colab.research.google.com/drive/1GkjoTZUd2rpwIvxmCZreKo5ZUZN6i7vJ#scrollTo=9FDX0V0el1_T\">Google Colaboratory</a></p><blockquote><em>Note: This article is previously published on Notion, you can read the version written as the lesson for Towards-AI courses on RAG SYSTEMS for Activeloop.</em></blockquote><blockquote><a href=\"https://signalism.notion.site/Crafting-AI-Assistants-via-OpenAI-and-Hugging-Face-API-92c7331225c54eb1966856bbc662b808?pvs=4\"><em>https://signalism.notion.site/Crafting-AI-Assistants-via-OpenAI-and-Hugging-Face-API-92c7331225c54eb1966856bbc662b808?pvs=4</em></a></blockquote><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=332fc945837c\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/ai-assistants-via-openai-and-hugging-face-api-332fc945837c\">AI Assistants via OpenAI and Hugging Face API</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Iva @ AkashaDB'}],"Wed, 10 Jan 2024 11:23:15 GMT"
1189,Detecting ships in satellite imagery: five years later…,https://medium.com/artificialis/detecting-ships-in-satellite-imagery-five-years-later-28df2e83f987?source=rss----a81c8d170222---4,"<p>In 2018, when I was still working at Airbus Defence and Space, I organised a challenge on Kaggle to detect ships in Airbus SPOT satellite imagery (@ 1.5 meters resolution).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yJDbxqHJzzeN855YNNXBvQ.png\" /><figcaption>Home page of the Airbus Ship Detection Challenge on Kaggle</figcaption></figure><p><a href=\"https://medium.com/artificialis/important-things-you-should-know-before-organizing-a-kaggle-competition-3911b71701fb\">Check my article</a> about the successes and issues that we encountered. That’s a whole story in itself!</p><p>One of the interesting characteristics of the challenge was the <strong>oriented bounding boxes annotations</strong>. When we annotated the dataset, we decided to create rotated rectangles to closely fit the ships that we saw on the imagery. Intuitively, we thought that classic bounding boxes were including too much background. Of course, this was not perfect as well for small speed boats which we could not clearly separate from their wake.</p><p>But at the time, there was very little literature about oriented bounding boxes. So the Kaggle team decided to encode our rectangle bounding boxes into RLE which is a format suited for creating binary masks. And actually most teams used deep learning architectures suited to mask prediction. I will analyse the best practices for segmentation used by the participants and described on Kaggle forums. And then present a completely different approach based on new oriented bounding box architectures.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/913/1*wpQxH6QhtZIlzMutF139Lw.png\" /><figcaption>Bounding box around a ship and corresponding mask (encoded in RLE format)</figcaption></figure><h3>Analysis of winner solutions in 2018</h3><p>But before developing a segmentation model to identify the ships, the participants needed to overcome a first problem of unbalanced classes.</p><p><strong>The sea is mostly void of ships</strong>. And waves or clouds can look like small ships on a satellite image. So we wanted the dataset to include some images of sea without any ships and with various conditions of weather and sea formation.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/612/1*t7KTpllegyf7o7U3eUfg3Q.png\" /><figcaption>Image of sea with no ships — there can be a lot a variation!</figcaption></figure><p>But, unfortunately, the way we generated the imagery created a LOT of images with no ships ; actually out of 231,723 imagery extracts of 768 x 768 pixels, only 81,723 had ships on them. Models usually do not like to be trained on too many empty images, so it made sense to reduce the number of empty images during the training.</p><p>But if the segmenter had not seen a lot of empty images during training, this meant that it would be prone to over-detection during inference. So most of the participants created a two stage detector with first a classifier and then segmenter. The purpose of the classifier was to detect if the image was likely to contain ships and only send these likely images to the segmenter.</p><p>The other reason to create a classifier was that the chosen metric for scoring participants was very biased against detecting a single ship when there was none. This in itself will be the subject for another post. It definitely pushed participants to create this two-stage detector.</p><blockquote>This is not a bad thing because classifiers are much faster then segmentation models and, as I said earlier, sea is mostly void of ships — so this means that the detector was going faster on vast areas of open sea.</blockquote><h3>First step : Ship &lt;&gt; No Ship Classifier</h3><p>Training a good Ship &lt;&gt; No Ship classifier was more important for this competition than having a very good performing segmentation model. The objective was to fight fight false positives (bright spots, wave glare, etc). The classifier should, of course, to be as good as possible and to avoid classifying images with ships as images without ships. But note, that there is an asymmetry in this process: if an image with ship was classified without ship it was lost forever although an error in the other direction could potentially be corrected by the segmenter.</p><p>Back in 2018, the architectures selected for this task where mostly all flavours of ResNet (ResNet-18, ResNet-34, ResNet-50, ResNet-101 and ResNet-152) with some others like DPN-68, DPN-92 or DenseNet-121. A simple training of a ResNet-50 over 10 epochs leads to a 0.975 accuracy which was good but not enough to be in the top 3.</p><p>All the winners decided to train an «ensemble» of models for the classifier. Either by training different architectures or the same architecture on different split of the training data (using cross-validation). Then the results from the various models would just be summed and averaged.</p><h3>Second step : Segmenter</h3><p>Segmentation models are neural networks which produces a mask from an input image. They are usually U-shaped and for this called U-Net. The left side of the U is the encoder which encode the semantic information while reducing the spatial dimension. Then, the right side of the U acts as a decoder to generate the mask containing the semantic information at the correct location. To make sure that the reconstruction is fine-grained, there are shortcuts connections from the encoding branch to the decoding branch to convey the spatial information which has been lost in the semantic encoding.</p><p>All winners used U-Net architecture with various backbones (i.e. encoders). Some participants used FPN architectures and other Mask-RCNN architectures (see below). Larger backbones are not always a must. Smaller architectures like ResNet-34 could work well if trained long enough.</p><p>Since that images where pretty large (768x768 pixels) to fit in large batches in the GPU memory, one smart trick was to use 256x256 crops, randomly selected around the center of the ships. Of course, resizing images was out of questions because it will make the small ships disappear.</p><p>Of course, since the dataset was unbalanced and had a lot of empty images, it was important to reduce number of images with no ships. But one should make sure not to remove them completely. A mix of 20% of images with no ships was important to help the model understand that this could be a normal situation. This could also be done by augmenting the images with ships compared to the images without ships.</p><p>Most participants used several U-Net either with different architecture or specialised on various tasks (like large ships and small ships). The final “ensembling” step was mostly to sum or average the various generated masks. In some case, TTA (or Test Time Augmentation) was also used. This means that the same image was sent to the model after being flipped and/or rotated. The results will then be averaged again.</p><p><a href=\"https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71667\"><em>https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71667</em></a></p><p><a href=\"https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71664\"><em>https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71664</em></a></p><h3>Final step : Post processing</h3><p>After the U-Net had produced a mask, the the last step was to vectorise this mask and create distinct polygons for each individual ship. But, in fact, to deal with ships which were docked side by side, an extra trick was necessary.</p><p>The exterior boundary of the ship had to be treated as a second class. Some participants also decided to treat the contact zone between two ships as a third class. In any case, the trick was to make sure to identify this area as it was key in being able to reconstruct the individual shape of each ship when they were side by side.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/768/0*qBYFCWvdJVFb1khV.png\" /><figcaption>Image extracted from discussion below</figcaption></figure><p><a href=\"https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71659\"><em>https://www.kaggle.com/competitions/airbus-ship-detection/discussion/7165</em></a><a href=\"https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71659\"><em>9</em></a></p><p>The rest of the processing is then done by using python Computer Vision like rasterio or ski-image. Using morphological tools like erosion and dilatation to remove objects under a specific threshold, using a convex hull function, creating an image of distance from border of objects, extracting local peaks or centroid, using watershed techniques and finally vectorisation.</p><p>One interesting technique was definitely to use <strong>pseudo-labelling</strong>. The dataset included a large number of unlabelled tiles which was designed to be used to test the model. Participants were expected to predict ships on the test dataset and submit the resulting predictions as RLE masks. But the predictions could also be used to further train the model and potentially increase slightly the performance of the model.</p><p>When all these steps were done the best possible way, it was possible to reach the highest score on the leaderboard. Typically above 0.854. <a href=\"https://www.youtube.com/watch?v=0Opb8gB1p4w\">Here is a nice video</a> of how trials and errors can lead to an honorable submission.</p><h3>Rotated rectangle or Oriented bounding boxes?</h3><p>Starting from vectorised annotations to generate masks, then using segmentation architectures to generate raster masks and finally vectorising the predicted masks to deliver oriented bounding boxes made a few participants explore other techniques.</p><p>Some participants were quite successful using Mask-RCNN although it was based on simple axis-aligned bounding boxes. <a href=\"https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71607\">Check the following Kaggle post</a>.</p><p>At the time, we would also see the first papers on ArXiv about oriented bounding box architectures. The main idea was to add an extra parameter to the model to predict the orientation of the bounding box either as a discreet parameter or a continuous parameter. In the later case, there was some added complexity to the code as an angle is non-continuous between 359.99° and 0°.</p><p>At the time, a few participants <a href=\"https://www.kaggle.com/competitions/airbus-ship-detection/discussion/71875\">experimented with oriented bounding boxes</a> detector which seemed like a reasonable thing to do but they did not get very good results.</p><p><strong><em>Let’s explore what we can do in 2023 in that respect!</em></strong></p><h3>How to get oriented bounding boxes annotation?</h3><p>Before being able to implement new type of solution, we need to have oriented bounding boxes annotations. And although Airbus created the annotation as rectangles, these are not available in the Kaggle dataset.</p><p>So we need to recreate them from the RLE encodings. Kaggle grandmaster iafoss created an new version of the dataset with oriented bounding boxes but, unfortunately, it is based on the original version of the dataset. Actually, there are two version of the dataset and only the last one is available. Check <a href=\"https://medium.com/artificialis/important-things-you-should-know-before-organizing-a-kaggle-competition-3911b71701fb\">my previous post</a> for a longer story about why this is the case.</p><p>Again we will be using some fantastic python packages like rasterio and shapely. Here is the code to convert RLE to oriented bounding boxes. You can check this Kaggle notebook to see it in action.</p><pre>    # convert RLE encoded pixels into binary mask<br />    mask = encode_mask(str(row.EncodedPixels), shape=(768,768))<br /><br />    # vectorize mask into GeoJSON<br />    value = 0.0<br />    for polygon, value in list(features.shapes(mask)):<br />        if value == 1.0:<br />            break<br />    if value != 1.0:<br />        print('Error while vectorizing mask')<br /><br />    # get oriented bounding box around shape<br />    coords = polygon['coordinates'][0]<br />    obbox = MultiPoint(coords).minimum_rotated_rectangle<br /><br />    # get center of bounding box and correct for half a pixel<br />    xc, yc = list(obbox.centroid.coords)[0]<br />    xc, yc = xc - 0.5, yc - 0.5<br />    <br />    # get external coordinates of oriented rectangle<br />    # compute length, width and angle<br />    p1, p2, p3, p4, p5 = list((obbox.exterior.coords))<br />    dx = math.sqrt((p3[0] - p2[0])**2 + (p3[1] - p2[1])**2)<br />    dy = math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)<br />    angle = math.atan2((p3[1] - p2[1]), (p3[0] - p2[0]))<br />    #length = max(d1, d2)<br />    #height = min(d1, d2)</pre><p>Some examples to check for quality. The visualisation scripts are mostly based on iafoss work that you can found <a href=\"https://www.kaggle.com/code/iafoss/rotating-bounding-boxes-ship-localization\">here</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*0VKl0S72AkleghP_266okw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*G24pb9l-pHkrsSw2ssQIEg.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YSAG7a6LAY3-Fs_pGU-sIA.png\" /></figure><p>These examples show that although some ships are easy to detect, there are also many cases where the boundaries are not clear, the acquisition angle not vertical or the colour very similar to the sea colour.</p><blockquote>Let’s now dive into a new fantastic framework to work with oriented bounding boxes detectors. It is called MMRotate from Open MMLab.</blockquote><h3>Introducing OpenMMLab and MMRotate</h3><p>In one of <a href=\"https://medium.com/artificialis/how-to-choose-a-deep-learning-model-to-detect-aircrafts-in-satellite-imagery-cd7d106e76ad\">my previous post</a>, I presented and used <a href=\"https://airctic.com/\">IceVision</a> to test various model architectures on the same task. Another fantastic framework to experiment with various computer vision deep learning architectures is the <a href=\"https://openmmlab.com/\">OpenMMLab</a> framework.</p><blockquote>OpenMMLab is an open-source algorithm platform for computer vision. It aims to provide a solid benchmark and promote reproducibility for academic research. We have released more than 30 high-quality projects and toolboxes in various research areas such as image classification, object detection, semantic segmentation, action recognition, etc. OpenMMLab has made public more than 300 algorithms and 2,400 checkpoints. Over the past years, OpenMMLab has gained popularity in both academia and industry. It receives over 78,000 stars on GitHub and involves more than 1,700 contributors in the community.</blockquote><p>The code base is available on GitHub and is organised in various independent task-specific packages which all rely on foundation libraries <strong>MMEngine</strong> for training loops, <strong>MMCV</strong> for computer vision functions and <strong>PyTorch</strong> as Deep Learning library.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*R_zN35FHXj4_KsL7.png\" /><figcaption>From <a href=\"https://github.com/open-mmlab\">OpenLab GitHub page</a></figcaption></figure><p>Aside <strong>MMDetection</strong> which offers model architectures and tools for standard bounding box detection, there a specific package for oriented bounding boxes which is called <strong>MMRotate.</strong></p><p>The code was published and very actively updated one year ago in spring 2022. Recently the team has focused on introducing the MMEngine module which centralise the deep learning related code and reorganising the various modules accordingly.</p><h4>Install the MMRotate package and its dependencies</h4><p>In the following code, we will stick with the version 0.3.4 from 2022. <br />The corresponding documentation is <a href=\"https://mmrotate.readthedocs.io/en/v0.3.4/get_started.html\">here</a>. Note that we make sure to install the corresponding MMCV and MMDet versions.</p><pre># Install MMCV and MMDetection<br />RUN pip install -U openmim<br />RUN mim install mmcv-full==1.7.1<br />RUN mim install mmdet==2.28.2<br /><br /># Install MMRotate v0.3.4<br />RUN git clone --depth 1 --branch v0.3.4 https://github.com/open-mmlab/mmrotate.git<br />WORKDIR mmrotate</pre><h4>Create a custom Data Loader for our data</h4><p>A simple way to adapt the code to a specific use case is to convert the training data to the DOTA format as described <a href=\"https://mmrotate.readthedocs.io/en/v0.3.4/tutorials/customize_dataset.html\">here</a>.</p><p>I usually like to preserve the source data as it is so that I can more easily manage multiple version of it. For MMRotate, this mostly involves creating a new <strong>Dataset Type</strong> and loading annotations directly from where they are stored. In our case, since the source annotation are provided as a CSV file, I am using a pandas DataFrame to read and store the annotations.</p><p>Here is the code that will help you create your own Dataset Type:</p><pre>from mmrotate.datasets.builder import ROTATED_DATASETS, PIPELINES<br />from mmrotate.datasets.dota import DOTADataset<br />import glob<br />import numpy as np<br />import pandas as pd<br />from mmrotate.core import poly2obb_np<br />import os.path as osp<br />import os<br /><br />from mmdet.datasets.pipelines import LoadImageFromFile<br />from PIL import Image<br /><br />def convert_rbb2polygon(bbox):<br />    xc, yc, w, h, ag = bbox<br />    wx, wy = w / 2 * np.cos(ag), w / 2 * np.sin(ag)<br />    hx, hy = -h / 2 * np.sin(ag), h / 2 * np.cos(ag)<br />    p1 = (xc - wx - hx, yc - wy - hy)<br />    p2 = (xc + wx - hx, yc + wy - hy)<br />    p3 = (xc + wx + hx, yc + wy + hy)<br />    p4 = (xc - wx + hx, yc - wy + hy)<br />    poly = np.array([p1[0], p1[1], p2[0], p2[1], p3[0], p3[1], p4[0], p4[1]])<br />    return poly<br />        <br />def convert_rbb2polygons(bboxes):<br />    polygons = []<br />    for i, bbox in enumerate(bboxes):<br />        poly = convert_rbb2polygon(bbox)<br />        polygons.append(poly)<br />    return polygons<br /><br />@ROTATED_DATASETS.register_module()<br />class AirbusShipDataset(DOTADataset):<br />    &quot;&quot;&quot;Airbus Ship dataset for detection.&quot;&quot;&quot;<br /><br />    CLASSES = ('ship',)<br /><br />    def load_annotations(self, ann_file):<br />        &quot;&quot;&quot;<br />            Args:<br />                ann_folder: folder which contains the CSV file witn annotations<br />        &quot;&quot;&quot;<br />        cls_map = {c: i<br />           for i, c in enumerate(self.CLASSES)<br />           }<br />        <br />        data_infos = []<br />        if not os.path.isfile(ann_file) :  # test phase<br />            img_files = glob.glob(self.img_prefix + '*.jpg')<br />            for img_file in img_files:<br />                data_info = {}<br />                img_id = osp.split(img_file)[1][:-4]<br />                img_name = img_id + '.jpg'<br />                data_info['filename'] = img_name<br />                data_info['ann'] = {}<br />                data_info['ann']['bboxes'] = []<br />                data_info['ann']['labels'] = []<br />                data_infos.append(data_info)<br />        else:<br />            box_df = pd.read_csv(ann_file)<br />            <br />            # parse all images<br />            for ImageId, ann_df in box_df.groupby('ImageId'):<br />                data_info = {}<br />                img_id = osp.split(ImageId)[1][:-4]<br />                img_name = ImageId #img_id + '.jpg'<br />                data_info['filename'] = img_name<br />                data_info['ann'] = {}<br />                gt_bboxes = []<br />                gt_labels = []<br />                gt_polygons = []<br />                gt_bboxes_ignore = []<br />                gt_labels_ignore = []<br />                gt_polygons_ignore = []<br /><br />                if len(ann_df) == 0 and self.filter_empty_gt:<br />                    continue<br />                    <br />                # parse all annotations in this image<br />                for row_index, row in ann_df.iterrows():<br />                    <br />                    # read annotation<br />                    x, y, w, h, a = row['xc'], row['yc'], row['dx'], row['dy'], row['angle'], <br />                    label = cls_map['ship']<br />                    <br />                    # add to lists of annotations for this image<br />                    gt_bboxes.append([x, y, w, h, a])<br />                    gt_labels.append(label)<br />                    poly = convert_rbb2polygon([x, y, w, h, a])<br />                    gt_polygons.append(poly)<br /><br />                if gt_bboxes:<br />                    data_info['ann']['bboxes'] = np.array(<br />                        gt_bboxes, dtype=np.float32)<br />                    data_info['ann']['labels'] = np.array(<br />                        gt_labels, dtype=np.int64)<br />                    data_info['ann']['polygons'] = np.array(<br />                        gt_polygons, dtype=np.float32)<br />                else:<br />                    data_info['ann']['bboxes'] = np.zeros((0, 5),<br />                                                          dtype=np.float32)<br />                    data_info['ann']['labels'] = np.array([], dtype=np.int64)<br />                    data_info['ann']['polygons'] = np.zeros((0, 8),<br />                                                            dtype=np.float32)<br /><br />                if gt_polygons_ignore:<br />                    data_info['ann']['bboxes_ignore'] = np.array(<br />                        gt_bboxes_ignore, dtype=np.float32)<br />                    data_info['ann']['labels_ignore'] = np.array(<br />                        gt_labels_ignore, dtype=np.int64)<br />                    data_info['ann']['polygons_ignore'] = np.array(<br />                        gt_polygons_ignore, dtype=np.float32)<br />                else:<br />                    data_info['ann']['bboxes_ignore'] = np.zeros(<br />                        (0, 5), dtype=np.float32)<br />                    data_info['ann']['labels_ignore'] = np.array(<br />                        [], dtype=np.int64)<br />                    data_info['ann']['polygons_ignore'] = np.zeros(<br />                        (0, 8), dtype=np.float32)<br /><br />                data_infos.append(data_info)<br /><br />        self.img_ids = [*map(lambda x: x['filename'][:-3], data_infos)]<br />        return data_infos</pre><h4>Configuration file</h4><p>MMRotate is all <a href=\"https://mmrotate.readthedocs.io/en/v0.3.4/tutorials/customize_config.html\">about configuration files</a> as the other OpenMMLab components. You can certainly use MMRotate without but they are the best way to manage various experiments. The idea behind this is that all the parameters for your dataset, you model and your training loop are actually stored in a configuration file (as a Python dictionary or a YAML file).</p><p>This makes it very easy to compared parameters between two experiments (i.e. training of a model). This also enables you to start from one of the existing configuration files and just modify the parameters that you need. OpenMMLab provides a <a href=\"https://mmrotate.readthedocs.io/en/v0.3.4/model_zoo.html\">benchmark and model zoo page</a> where you will find all the base configuration files that you can tweak to your needs.</p><p>For exemple, here, we select <strong>ReDet</strong> which is described in this paper:<br /><a href=\"https://arxiv.org/abs/2103.07733\"><em>ReDet: A Rotation-equivariant Detector for Aerial Object Detection</em></a><em>. </em>The following code download the configuration file for the model with a ResNet-50 backbone, the training loop as well as the associated pre-trained weights on the DOTA dataset.</p><pre># We use mim to download the pre-trained checkpoints for inference and finetuning.<br />!mim download mmrotate --config redet_re50_refpn_1x_dota_ms_rr_le90 --dest .<br /><br />CONFIG_FILE = 'redet_re50_refpn_1x_dota_ms_rr_le90.py'<br /><br />cfg = Config.fromfile(CONFIG_FILE)<br />print(f'Config:\\n{cfg.pretty_text}')</pre><p>We need to make a few changes to this configuration file. We can copy and modify the file or we can make the changes programmatically to the configuration in memory. So we can use Python rather than YAML.</p><p>Here we define the source data:</p><pre># Change the dataset type from DOTADataset to AirbusShipDataset<br />cfg.dataset_type = 'AirbusShipDataset'<br /><br /># Change the location of the root folder for training data<br />cfg.data_root = '/data/share/airbus-ship-detection/'<br /><br /># Change the size of the image (instead of 1024 with DOTA)<br />cfg.img_size = 768<br /><br /># Adapt the number of images accordingly with your GPU memory<br />cfg.data.samples_per_gpu=20<br /><br /># Define the value for normalization<br /># This needs to be computed in the EDA<br /># MMRotate uses cv2 to read imagery so it expects BGR and not RGB<br /># Re-order the channels to RGB after normalization<br />cfg.img_norm_cfg = dict(<br />    mean=[52.29048625, 73.2539164, 80.97759001], <br />    std=[53.09640994, 47.58987537, 42.15418378], <br />    to_rgb=True)</pre><p>And next, the data pre-processing:</p><pre>cfg.train_pipeline = [<br />    # Read images from file with MMDet (cv2)<br />    dict(type='LoadImageFromFile'),<br />    # Read annotations. This is the function that we overloaded earlier<br />    dict(type='LoadAnnotations', with_bbox=True),<br />    # Resize to the initial size of the model<br />    # For satellite images, we want to avoid any downscaling<br />    dict(type='RResize', img_scale=(cfg.img_size, cfg.img_size)),<br />    # Define a 'flip' augmentation<br />    dict(<br />        type='RRandomFlip',<br />        flip_ratio=[0.25, 0.25, 0.25],<br />        direction=['horizontal', 'vertical', 'diagonal'],<br />        version='le90'),<br />    # Define a 'rotation' augmentation<br />    dict(<br />        type='PolyRandomRotate',<br />        rotate_ratio=0.5,<br />        angles_range=180,<br />        auto_bound=False,<br />        version='le90'),<br />    # Normalize the radiometry<br />    dict(type='Normalize', **cfg.img_norm_cfg),<br />    # Pad the image to be divisible by 32<br />    dict(type='Pad', size_divisor=32),<br />    # Return images, bboxes and labels as tensors<br />    dict(type='DefaultFormatBundle'),<br />    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])<br />]</pre><p>Then, we initialise the training data source with our previous parameters: the dataset type, the dataset root, the train.csv file with train annotations and the train data pipeline.</p><pre>cfg.data.train=dict(<br />    type=cfg.dataset_type,<br />    ann_file='train.csv',<br />    img_prefix='train_v2/',<br />    pipeline=cfg.train_pipeline,<br />    version='le90',<br />    data_root=cfg.data_root<br />)</pre><p>We also need to tweak the final layers of the model because DOTA has 15 classes and we have only one class (for ships)</p><pre># modify num classes of the model in two bbox head<br />cfg.model.roi_head.bbox_head[0].num_classes = len(AirbusShipDataset.CLASSES)<br />cfg.model.roi_head.bbox_head[1].num_classes = len(AirbusShipDataset.CLASSES)</pre><p>There are many more modifications that you can make, like modifying the learning rate, the learning rate policy, the anchor generator, etc… Here we just define the maximum epochs and the logging interval.</p><pre>cfg.runner.max_epochs = 50<br />cfg.log_config.interval = 200</pre><p>Finally, I like to organise the logs by architecture and date and I make sure to save the configuration file with the logs so that I can retrieve it later if needed.</p><pre># Get architecture name from config file name<br />config_name = os.path.basename(CONFIG_FILE)<br />keyname = config_name.split('_')[0]<br /><br /># Get current time<br />now = datetime.datetime.now()<br />date_time = now.strftime(&quot;%Y-%m-%d-%H-%M-%S&quot;)<br /><br /># Set up folder to save config file and logs<br />cfg.work_dir = os.path.join('./logs', keyname, date_time)<br /><br /># Create folder<br />mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))<br /><br /># Save updated configuration file in logs folder<br />cfg.dump(os.path.join(cfg.work_dir, config_name))</pre><p>After we have finished modifying the configuration file, the next step is to train the model.</p><pre>from mmdet.models import build_detector<br />from mmdet.apis import train_detector<br /><br /># Build the train dataset (and optionaly validation dataset)<br />datasets = [build_dataset(cfg.data.train)]<br /><br /># Build the detection model<br />model = build_detector(cfg.model)<br /><br /># Launch training<br />train_detector(model, datasets, cfg, distributed=False, validate=False)</pre><p>After 20 epochs, the metrics (mAP) reaches a plateau and we can stop the training to display some outputs.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/524/1*xwGRR6k_H7Q-tqeYyHN1pw.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/437/1*Cr2dR59Rjm5bRj7gDBe-kg.png\" /></figure><p>The models performs pretty well in most case and deals pretty well with ships close to each other. The models runs faster than UNet and delivers directly oriented bounding boxes.</p><p>Of course, this is not directly an exceptional model like the ones which were on top of the leaderboard. Some improvement points are:</p><ul><li>Add a classifier before the detector to remove false detections</li><li>Modify the anchor generator to fit the specific shape of ships</li><li>Add TTA (Test-Time Augmentation)</li><li>Increase the dataset by doing pseudo-labelling on the test data</li></ul><blockquote>But globally it is very easy to apply MMRotate to this dataset and the OpenMMLab framework should have its place in most R&amp;D work for object detection on satellite and aerial imagery.</blockquote><h3>Conclusion</h3><p>If you have not already experimented with OpenMMLab and MMRotate, I hope that this blog post will motivate you to test it. I am using it in many of my projects and I am impressed. It requires somewhat of a learning curve but it definitely worth it as it is a powerful yet flexible tool.</p><p>If you like this post, please <strong>clap</strong> for it, <strong>follow</strong> me and <strong>read</strong> my other articles:</p><ul><li><a href=\"https://medium.com/artificialis/is-yolov8-suitable-for-satellite-imagery-d9a2659a50ab\">Is YOLOv8 suitable for satellite imagery?</a></li><li><a href=\"https://medium.com/artificialis/how-to-choose-a-deep-learning-model-to-detect-aircrafts-in-satellite-imagery-cd7d106e76ad\">How to choose a deep learning architecture to detect aircrafts in satellite imagery?</a></li><li><a href=\"https://medium.com/artificialis/oil-storage-detection-on-airbus-imagery-with-yolox-9e38eb6f7e62\">Oil Storage Detection on Airbus Imagery with YOLOX</a></li><li><a href=\"https://medium.com/artificialis/detecting-aircrafts-on-airbus-pleiades-imagery-with-yolov5-5f3d464b75ad\">Detecting aircraft on Airbus Pleiades imagery with YOLOv5</a></li><li><a href=\"https://medium.com/artificialis/important-things-you-should-know-before-organizing-a-kaggle-competition-3911b71701fb\">Things you should know before organising a Kaggle Competition</a></li></ul><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=28df2e83f987\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/detecting-ships-in-satellite-imagery-five-years-later-28df2e83f987\">Detecting ships in satellite imagery: five years later…</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Jeff Faudi'}],"Thu, 16 Nov 2023 08:40:20 GMT"
1190,Sound Bytes Part 1: The ABCs of Sound and Digitization,https://medium.com/artificialis/sound-bytes-part-1-the-abcs-of-sound-and-digitization-94423e756969?source=rss----a81c8d170222---4,<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/artificialis/sound-bytes-part-1-the-abcs-of-sound-and-digitization-94423e756969?source=rss----a81c8d170222---4\"><img src=\"https://cdn-images-1.medium.com/max/1792/0*8NE47vcCOfwCt3KI\" width=\"1792\" /></a></p><p class=\"medium-feed-snippet\">Diving into the world of sound and how Deep Learning enhances our audio experience</p><p class=\"medium-feed-link\"><a href=\"https://medium.com/artificialis/sound-bytes-part-1-the-abcs-of-sound-and-digitization-94423e756969?source=rss----a81c8d170222---4\">Continue reading on Artificialis »</a></p></div>,[{'name': 'Alessandro Lamberti'}],"Tue, 31 Oct 2023 08:28:06 GMT"
1191,Building Music Recommendation System,https://medium.com/artificialis/music-recommendation-system-with-scikit-learn-30f4d07c60b3?source=rss----a81c8d170222---4,"<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*-2g1Ue_GUvNkCaSb\" /><figcaption>Photo by <a href=\"https://unsplash.com/@alpridephoto?utm_source=medium&amp;utm_medium=referral\">Андрей Сизов</a> on <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>If you are a user of any social media or any websites, I am sure you could be caught in the tracking net of one of them. Do you wonder how those systems are made? I mean, the recommendation system can make you obsess with your time. Or if you are curious about how recommendation systems are made, let’s create a simple top ten music recommendation system with Scikit-Learn.</p><p>There are three types of systems. <strong>Collaborative filtering</strong> and <strong>Content-based filtering</strong> are the two main systems, and <strong>Hybrid</strong> recommendation is the combination of those two systems. Most recommendation systems now use the hybrid one.</p><p>If you want to read more without continuing my blog,</p><blockquote>Recommender system. (2023, April 17). In <em>Wikipedia</em>. <a href=\"https://en.wikipedia.org/wiki/Recommender_system\">https://en.wikipedia.org/wiki/Recommender_system</a></blockquote><h3>Collaborative filtering</h3><p>Collaborative filtering recommends a user based on their past user histories, their preferences, and their interests. There are many types of filtering methods in collaborative filtering. But the most popular one is <strong>user-based collaborative filtering</strong>.</p><p><strong>User-Based collaborative filtering</strong> depends on similarity between users. It looks at one’s preferences and recommends another user based on what the first user did. For example, if you are a programmer, recommend the videos that are viewed by other programmers too.</p><figure><img alt=\"Collaborative filtering (User-Based)\" src=\"https://cdn-images-1.medium.com/max/1024/1*3-5ilXK1ZTjcUzjXRPLANg.png\" /><figcaption>Collaborative filtering (User-Based)</figcaption></figure><h3>Content-Based filtering</h3><p>Content-based filtering is pretty simple. Depending on what he liked in the past, recommend an item that is similar to his preferences. Unlike user-based filtering, content-based filtering only focuses on a single user.</p><figure><img alt=\"Content-Based filtering\" src=\"https://cdn-images-1.medium.com/max/1024/1*MI0WwFxPQzf8ZGdfeVwj9w.png\" /><figcaption>Content-Based filtering</figcaption></figure><p>The main disadvantage of this filtering system is, “<strong>What if for a new user?</strong>” How can we handle this? Yes, we have “user-based filtering”. But let’s talk about <strong>Hybrid</strong> recommendations in the next section.</p><h3>Hybrid recommendation</h3><p>This is the most commonly used recommendation method now a days. It is the combination of two or more filtering systems. The more common are, as described above, user-based filtering and content-based filtering systems. For example, you won’t see the most-viewed videos in your country if you don’t sign in to YouTube. But after signing in, you will see the recommended videos based on your past history.</p><h3>Building recommendation system in Python</h3><p>It is time to build our own recommendation system using Python. Although we can write from scratch using math and just Python, we can get help from a library called Scikit-Learn. And there are some other libraries that are specific designed for building recommendation systems.</p><p>In this blog, we will take a look at how “content-based filtering” systems are made.</p><h4>CountVectorizer</h4><p>CountVectorizer converts a collection of documents into a matrix of word counts. Let’s see how CountVectorizer works.</p><p>Here is a sentence: “Nikola Tesla invented the alternating current”. CountVectorizer will convert that sentence into something like this:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ToZRDVumaeZ42kCOsiBZ1w.png\" /></figure><p>You can see that CountVectorizer counts the word frequency. If there are more than two the in that sentence, you will see 2 instead of 1.</p><p>To be clear, let’s add one more sentence to that same vector. “Thomas Edison invented the direct current”</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*52ywx6NevmpluWTlDYSgqg.png\" /></figure><p>It is saying it will create a new column with a word if the new inserted word in the new sentence doesn’t exist. The limitation of CountVectorizer is that it also counts less important words like a , the , and . But CountVectorizer is suitable for our project. We don’t need to use it in complete sentences.</p><h4>Python codes</h4><p>We will import the required dependencies and read the data. We will only use the first 1000 simples to load faster in development.</p><pre># import requried dependencies<br />import pandas as pd<br />from sklearn.feature_extraction.text import CountVectorizer<br />from sklearn.metrics.pairwise import cosine_similarity<br /><br /># read the data<br />df = pd.read_csv(&quot;data/song-dataset.csv&quot;, low_memory=False)[:1000]</pre><p>Clean the data frame. We will remove the non-required columns from the data frame.</p><pre># remove duplicates<br />df = df.drop_duplicates(subset=&quot;Song Name&quot;)<br /><br /># drop Null values<br />df = df.dropna(axis=0)<br /><br /># Drop the non-required columns<br />df = df.drop(df.columns[3:], axis=1)</pre><p>Removing spaces from the “Artist Name” column. Because if there is a space between the names, CountVectorizer will count that single name as one word.</p><pre># Removing space from &quot;Artist Name&quot; column<br />df[&quot;Artist Name&quot;] = df[&quot;Artist Name&quot;].str.replace(&quot; &quot;, &quot;&quot;)</pre><p>Combine all the column values into a single new column value,</p><pre># Combine all columns and assgin as new column<br />df[&quot;data&quot;] = df.apply(lambda value: &quot; &quot;.join(value.astype(&quot;str&quot;)), axis=1)</pre><p>Initialize the CountVectorizer,</p><pre># models<br />vectorizer = CountVectorizer()<br />vectorized = vectorizer.fit_transform(df[&quot;data&quot;])<br />similarities = cosine_similarity(vectorized)<br /><br /># Assgin the new dataframe with `similarities` values<br />df_tmp = pd.DataFrame(similarities, columns=df[&quot;Song Name&quot;], index=df[&quot;Song Name&quot;]).reset_index()</pre><p>Finally,</p><pre>true = True<br />while true:<br />    print(&quot;The Top 10 Song Recommendation System&quot;)<br />    print(&quot;-------------------------------------&quot;)<br />    print(&quot;This will generate the 10 songs from the database thoese are similar to the song you entered.&quot;)<br /><br />    # Asking the user for a song, it will loop until the song name is in our database.<br />    while True:<br />        input_song = input(&quot;Please enter the name of song: &quot;)<br /><br />        if input_song in df_tmp.columns:<br />            recommendation = df_tmp.nlargest(11, input_song)[&quot;Song Name&quot;]<br />            break<br />        <br />        else:<br />            print(&quot;Sorry, there is no song name in our database. Please try another one.&quot;)<br />    <br />    print(&quot;You should check out these songs: \\n&quot;)<br />    for song in recommendation.values[1:]:<br />        print(song)<br /><br />    print(&quot;\\n&quot;)<br />    # Asking the user for the next command, it will loop until the right command.<br />    while True:<br />        next_command = input(&quot;Do you want to generate again for the next song? [yes, no] &quot;)<br /><br />        if next_command == &quot;yes&quot;:<br />            break<br /><br />        elif next_command == &quot;no&quot;:<br />            # `true` will be false. It will stop the whole script<br />            true = False<br />            break<br /><br />        else:<br />            print(&quot;Please type 'yes' or 'no'&quot;)</pre><p>What does the above code work? Here is the brief explanation,</p><ul><li>Asking the user for a song, it will loop until the song name is in our database.</li><li>Asking the user for the next command, it will loop until the right command.</li><li>true will be false. It will stop the whole script.</li></ul><h4>Final result</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/746/1*Yg88XBa9nLiQFkI5VSH-CQ.gif\" /><figcaption>Final result</figcaption></figure><h4>Full codes and CSV files are on GitHub</h4><p>The codes and get the CSV files I used in this blog are uploaded to my GitHub account,</p><p><a href=\"https://github.com/sithukhantai/music-recommendation-system\">GitHub - sithukhantai/music-recommendation-system: Building the top 10 music recommendation system using Scikit-Learn</a></p><p>If you want to see the above figures in live-action, <a href=\"https://whimsical.com/music-recommendation-sytem-RVp7KL4oCAt74UsZVfr8vC\">see here</a>.</p><h3>Conclusion</h3><p>In this article, we implemented a simple music recommendation system using Scikit-Learn. You can explore more and more. The thing is, the more it is good, the more it is complicated. Here is <a href=\"https://365datascience.com/tutorials/how-to-build-recommendation-system-in-python/\">a great blog</a> by <a href=\"https://www.natasshaselvaraj.com\">Natassha Selvaraj</a> on implementing the book recommendation system if you are willing to know about the book recommendation system.</p><p>I hope this blog will help you, and see you in the next blog.</p><h3>References</h3><ul><li><a href=\"https://365datascience.com/tutorials/how-to-build-recommendation-system-in-python/\">How to Build a Recommendation System in Python</a> by Natassha Selvaraj</li></ul><p><em>If you like to read my blogs, you can follow me on </em><a href=\"https://sithukhantai.medium.com\"><strong><em>Medium</em></strong></a></p><p><em>If you have any problem or want to contact me, </em><a href=\"mailto:sithukhantai@gmail.com\"><strong><em>email me</em></strong></a></p><p><em>You can also follow the </em><a href=\"https://medium.com/artificialis\"><strong><em>Artificialis</em></strong></a><em> publication where I mostly publish my blogs.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=30f4d07c60b3\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/music-recommendation-system-with-scikit-learn-30f4d07c60b3\">Building Music Recommendation System</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Sithu Khant'}],"Tue, 11 Jul 2023 07:26:47 GMT"
1192,The Future is Self-Supervised: An Introduction to DINOv2,https://medium.com/artificialis/the-future-is-self-supervised-an-introduction-to-dinov2-c3c37f0dfb6f?source=rss----a81c8d170222---4,<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/artificialis/the-future-is-self-supervised-an-introduction-to-dinov2-c3c37f0dfb6f?source=rss----a81c8d170222---4\"><img src=\"https://cdn-images-1.medium.com/max/1453/1*86nxzctYEr19NPQ6PWYl0A.png\" width=\"1453\" /></a></p><p class=\"medium-feed-snippet\">Self-supervised learning is a type of machine learning where systems are trained to predict or solve tasks using only a raw dataset&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://medium.com/artificialis/the-future-is-self-supervised-an-introduction-to-dinov2-c3c37f0dfb6f?source=rss----a81c8d170222---4\">Continue reading on Artificialis »</a></p></div>,[{'name': 'Alessandro Lamberti'}],"Tue, 27 Jun 2023 09:18:58 GMT"
1193,Easily build a Web App with Haar Cascades and OpenCV.js,https://medium.com/artificialis/easily-build-a-web-app-with-haar-cascades-and-opencv-js-aa46be637096?source=rss----a81c8d170222---4,"<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HPvIOX9kLTp4-YOFNC9cLQ.png\" /><figcaption>Fig — 01 Image By Author Inspired By (<a href=\"https://www.freepik.com/free-vector/face-recognition-biometric-scan-cyber-security-technology-blue-tone_16406566.htm#query=facial%20recognition&amp;position=33&amp;from_view=keyword&amp;track=ais\">rawpixel</a>)</figcaption></figure><p>I’ve been building computer vision based applications for some hands on practice and curious indulgences, but they were mostly desktop native. However, just recently I came across a client who needed an application built using opencv.js. It was a fairly complex problem, which needed days to figure out considering my average java-scripting experience.</p><p>Although, I pulled through but it was a challenging ordeal. So I thought to work on my web-development skills before landing another order. After some experience, I learned that the most effective method to enhance my skills was to adopt a project-based approach and assist fellow learners in the process.</p><p>Here I am, starting the journey by trying to build a face detection web application using none other then Haar cascade and our very own OpenCV.js.</p><p>So without wasting any time, lets dive into the coding part!</p><h3>Setting up the VS code editor</h3><p>Before actually commencing our coding expedition, we need to setup our editor. Here’s what we’ll do</p><ol><li>Install the Live Server extension.</li><li>Install Auto Rename Tag</li><li>Install Prettier</li></ol><p>We don’t need to hard code the installation process, for those who are new to the platform just navigate to the top left — just below the Run and Debug you’d see the “<strong>Extensions”</strong> icon. From there you’d know what to do!</p><h3>Downloading Requisites</h3><p>After setting the code editor, we need to download opencv.js package and the Haar cascade xml files. To download the opencv.js package files, copy the entire script from <a href=\"https://docs.opencv.org/3.4.0/opencv.js\">here</a> and save it on a notepad as a opencv.js file. Move the saved opencv.js file to your project directory. Now download the Haar-cascade trained xml’s for face and eyes detection from this <a href=\"https://github.com/opencv/opencv/tree/master/data/haarcascades\">git repo</a>. Similarly, move the downloaded xml file to the project directory.</p><h3>JavaScripting</h3><h3>Utility.js</h3><p>Now we’re all set to start the coding process. We’ll be dividing the java-scripting in two files. In the first file named “Utils.js”, we’ll be setting up the library, file fetching, canvas display and camera initialization process. The second file would focus solely on defining the logic of Haar cascade and related operations.</p><pre>function Utils(errorOutputId) { <br />    let self = this;<br />    this.errorOutput = document.getElementById(errorOutputId);</pre><p>Initializing a Utils(utility) Class and assigning an error output element to display the error messages.</p><pre>const OPENCV_URL = 'opencv.js';<br />    this.loadOpenCv = function(onloadCallback) {<br />        let script = document.createElement('script');<br />        script.setAttribute('async', '');<br />        script.setAttribute('type', 'text/javascript');<br />        script.addEventListener('load', () =&gt; {<br />                // Checking the loading of the buildInformation<br />           if (cv.getBuildInformation)<br />            {<br />                console.log(cv.getBuildInformation());<br />                onloadCallback();<br />            }<br />            else<br />            {<br />                // Web Assembly check<br />                cv['onRuntimeInitialized']=()=&gt;{<br />                    console.log(cv.getBuildInformation());<br />                    onloadCallback();<br />                }<br />            }<br />        });<br />        script.addEventListener('error', () =&gt; {<br />            self.printError('Failed to load ' + OPENCV_URL);<br />        });<br />        script.src = OPENCV_URL;<br />        let node = document.getElementsByTagName('script')[0];<br />        node.parentNode.insertBefore(script, node);<br />    };</pre><p>Dynamically loading the OpenCV.js library in the browser. It creates a Script element and sets some required attributes. Event Listeners are added to handle the error reports and the loading of the script. The conditional statement <strong>“if-else”</strong> checks the “<strong><em>cv.getBuildInformation”</em></strong> if it exists or not. If it checks positive, the <strong>“<em>onloadCallback()</em>”</strong> function is invoked else it indicates the library is using Web-Assembly(WASP) so it creates an <strong><em>“onRuntimeInitialized”</em></strong> callback to be called when Runtime is initialized. In short the above snippets ensures appropriate loading of the opencv.js library.</p><pre>this.createFileFromUrl = function(path, url, callback) {<br />        let request = new XMLHttpRequest();<br />        request.open('GET', url, true);<br />        request.responseType = 'arraybuffer';<br />        request.onload = function(ev) {<br />            if (request.readyState === 4) {<br />                if (request.status === 200) {<br />                    let data = new Uint8Array(request.response);<br />                    cv.FS_createDataFile('/', path, data, true, false, false);<br />                    callback();<br />                } else {<br />                    self.printError('Failed to load ' + url + ' status: ' + request.status);<br />                }<br />            }<br />        };<br />        request.send();<br />    };</pre><p>This snippet is useful for fetching image or video data from external sources, but we’ll be using the live webcam to capture the results in Realtime. The <strong><em>createFileFromUrl</em></strong> method fetches a file from a given URL and creates a virtual file in the virtual file system. It uses an <strong>XMLHttpRequest</strong> to retrieve the file as an array buffer. On successful retrieval, it converts the response to a <strong>Uint8Array </strong>and creates the virtual file using <strong><em>“cv.FS_createDataFile”</em></strong>. The callback function is invoked once the file creation is complete.</p><pre>this.loadImageToCanvas = function(url, cavansId) {<br />        let canvas = document.getElementById(cavansId);<br />        let ctx = canvas.getContext('2d');<br />        let img = new Image();<br />        img.crossOrigin = 'anonymous';<br />        img.onload = function() {<br />            canvas.width = img.width;<br />            canvas.height = img.height;<br />            ctx.drawImage(img, 0, 0, img.width, img.height);<br />        };<br />        img.src = url;<br />    };</pre><p>The above snippet is responsible for creating a canvas object to display the image. The <strong><em>“loadImageToCanvas”</em></strong> function takes two elements i.e., a url and a canvas Id. The let canvas variable fetches the canvas element from the html document using the <strong><em>“canvasId”</em></strong> passed as a parameter. To draw on the canvas, we’ll use the <strong><em>.getContext(‘2d’)</em></strong> method to define the rendering context. We’ll then create an image object to represent the image that’ll be loaded, followed by defining crossOrigin property to <strong><em>‘anonymous’</em>. </strong>This ensures that images can be accessed from different domains. Then we have an onload event handler, that defines the post-loading events for an image. The succeeding lines equal the image width and height to that of the canvas, followed by a <strong><em>drawImage</em></strong> function to overlay the image on a specified coordinate and shape. Finally the <strong><em>img.src </em></strong>fetches the image from the url.</p><pre>this.executeCode = function(textAreaId) {<br />        try {<br />            this.clearError();<br />            let code = document.getElementById(textAreaId).value;<br />            eval(code);<br />        } catch (err) {<br />            this.printError(err);<br />        }<br />    };<br />this.clearError = function() {<br />        this.errorOutput.innerHTML = '';<br />    };<br />    this.printError = function(err) {<br />        if (typeof err === 'undefined') {<br />            err = '';<br />        } else if (typeof err === 'number') {<br />            if (!isNaN(err)) {<br />                if (typeof cv !== 'undefined') {<br />                    err = 'Exception: ' + cv.exceptionFromPtr(err).msg;<br />                }<br />            }<br />        } else if (typeof err === 'string') {<br />            let ptr = Number(err.split(' ')[0]);<br />            if (!isNaN(ptr)) {<br />                if (typeof cv !== 'undefined') {<br />                    err = 'Exception: ' + cv.exceptionFromPtr(ptr).msg;<br />                }<br />            }<br />        } else if (err instanceof Error) {<br />            err = err.stack.replace(/\\n/g, '&lt;br&gt;');<br />        }<br />        this.errorOutput.innerHTML = err;<br />    };</pre><p>This part of the code is intended for exception handling. The excuteCode function takes <strong><em>“textAreaId”</em></strong> as a parameters and executes the code while the catch block holds any error associated with the execution. The <strong><em>clearError</em></strong> function set the <strong><em>errorOutput</em></strong> element to an empty string. The entire snippet follows the same evaluation format by catching any errors that occur, and formats the error messages based on the type of error encountered before displaying them in the error output element.</p><pre>this.loadCode = function(scriptId, textAreaId) {<br />        let scriptNode = document.getElementById(scriptId);<br />        let textArea = document.getElementById(textAreaId);<br />        if (scriptNode.type !== 'text/code-snippet') {<br />            throw Error('Unknown code snippet type');<br />        }<br />        textArea.value = scriptNode.text.replace(/^\\n/, '');<br />    };</pre><p>The above code snippet defines a function that loads code from a script element and populates <strong><em>textArea</em></strong> element with that code. the <strong><em>loadCode</em></strong> function takes two parameters i.e., the <strong><em>scriptId</em></strong> and the <strong><em>textAreaId</em></strong> which are later fetched from html and stored in <strong><em>scriptNode</em></strong> and textArea using the <strong><em>.getElementById</em></strong>. Later an exception check is initiated by ensuring the <strong><em>scriptNode.type</em></strong> to be code-snippet. The text content of the script element after successful conformation gets assigned to the value property of the <strong><em>textArea</em></strong>.</p><pre>function onVideoCanPlay() {<br />        if (self.onCameraStartedCallback) {<br />            self.onCameraStartedCallback(self.stream, self.video);<br />        }<br />    };</pre><p>This snippet defines a function <strong><em>onVideoCanPlay()</em></strong> that is typically used as an event handler. When the video can be played, it checks if the<strong><em> “onCamerStartedCallback”</em></strong> function is defined. If it is, the <strong><em>“onCamerStartedCallback”</em></strong> function is called, passing the <strong><em>self.stream</em></strong> and <strong><em>self.video</em></strong> as arguments. The purpose of this function is to trigger a callback function when the video is ready to play, allowing further actions or processing to be performed.</p><pre>this.startCamera = function(resolution, callback, videoId) {<br />        const constraints = {<br />            'qvga': {width: {exact: 320}, height: {exact: 240}},<br />            'vga': {width: {exact: 640}, height: {exact: 480}}};<br />        let video = document.getElementById(videoId);<br />        if (!video) {<br />            video = document.createElement('video');<br />        }<br />let videoConstraint = constraints[resolution];<br />        if (!videoConstraint) {<br />            videoConstraint = true;<br />        }<br />        navigator.mediaDevices.getUserMedia({video: videoConstraint, audio: false})<br />            .then(function(stream) {<br />                video.srcObject = stream;<br />                video.play();<br />                self.video = video;<br />                self.stream = stream;<br />                self.onCameraStartedCallback = callback;<br />                video.addEventListener('canplay', onVideoCanPlay, false);<br />            })<br />            .catch(function(err) {<br />                self.printError('Camera Error: ' + err.name + ' ' + err.message);<br />            });<br />    };<br />    this.stopCamera = function() {<br />        if (this.video) {<br />            this.video.pause();<br />            this.video.srcObject = null;<br />            this.video.removeEventListener('canplay', onVideoCanPlay);<br />        }<br />        if (this.stream) {<br />            this.stream.getVideoTracks()[0].stop();<br />        }<br />    };<br />};</pre><p>The code defines two functions, “<strong><em>startCamera”</em></strong> and “<strong><em>stopCamera”</em></strong>, which are responsible for controlling the camera stream.</p><p>The “<strong><em>startCamera”</em></strong> function takes three parameters: “<strong><em>resolution”</em></strong>, “<strong><em>callback”</em></strong>, and “<strong><em>videoId”</em></strong>. It sets up the desired resolution options and creates a video element for displaying the camera stream. It then uses the “<strong><em>navigator.mediaDevices.getUserMedia”</em></strong> method to request access to the camera’s video stream. If the request is successful, the stream is assigned to the video element’s “<strong><em>srcObject”</em></strong> property, and the stream starts playing. The function also assigns the video element, stream, and callback to corresponding properties for later use. Additionally, an event listener is added to the video element for the <strong><em>“canplay”</em></strong> event, which triggers the <strong><em>onVideoCanPlay</em></strong> function.</p><p>On the other hand, the “<strong>stopCamera”</strong> function doesn’t take any parameters. It checks if the video element exists and, if so, pauses the video playback, clears the <strong><em>srcObject</em></strong> property to stop the camera stream, and removes the <strong>“<em>canplay</em>”</strong> event listener. Furthermore, if the stream exists, it stops the video tracks associated with the stream.</p><p>With this comes the end of our utils.js file, now we’ll move towards the haar.js file to finalize our Haar detector. But before that, here’s the entire snippet of the Utils.js.</p><pre>function Utils(errorOutputId) { <br />    let self = this;<br />    this.errorOutput = document.getElementById(errorOutputId);<br />const OPENCV_URL = 'opencv.js';<br />    this.loadOpenCv = function(onloadCallback) {<br />        let script = document.createElement('script');<br />        script.setAttribute('async', '');<br />        script.setAttribute('type', 'text/javascript');<br />        script.addEventListener('load', () =&gt; {<br />            if (cv.getBuildInformation)<br />            {<br />                console.log(cv.getBuildInformation());<br />                onloadCallback();<br />            }<br />            else<br />            {<br />                cv['onRuntimeInitialized']=()=&gt;{<br />                    console.log(cv.getBuildInformation());<br />                    onloadCallback();<br />                }<br />            }<br />        });<br />        script.addEventListener('error', () =&gt; {<br />            self.printError('Failed to load ' + OPENCV_URL);<br />        });<br />        script.src = OPENCV_URL;<br />        let node = document.getElementsByTagName('script')[0];<br />        node.parentNode.insertBefore(script, node);<br />    };<br />    this.createFileFromUrl = function(path, url, callback) {<br />        let request = new XMLHttpRequest();<br />        request.open('GET', url, true);<br />        request.responseType = 'arraybuffer';<br />        request.onload = function(ev) {<br />            if (request.readyState === 4) {<br />                if (request.status === 200) {<br />                    let data = new Uint8Array(request.response);<br />                    cv.FS_createDataFile('/', path, data, true, false, false);<br />                    callback();<br />                } else {<br />                    self.printError('Failed to load ' + url + ' status: ' + request.status);<br />                }<br />            }<br />        };<br />        request.send();<br />    };<br />    this.loadImageToCanvas = function(url, cavansId) {<br />        let canvas = document.getElementById(cavansId);<br />        let ctx = canvas.getContext('2d');<br />        let img = new Image();<br />        img.crossOrigin = 'anonymous';<br />        img.onload = function() {<br />            canvas.width = img.width;<br />            canvas.height = img.height;<br />            ctx.drawImage(img, 0, 0, img.width, img.height);<br />        };<br />        img.src = url;<br />    };<br />    this.executeCode = function(textAreaId) {<br />        try {<br />            this.clearError();<br />            let code = document.getElementById(textAreaId).value;<br />            eval(code);<br />        } catch (err) {<br />            this.printError(err);<br />        }<br />    };<br />    this.clearError = function() {<br />        this.errorOutput.innerHTML = '';<br />    };<br />    this.printError = function(err) {<br />        if (typeof err === 'undefined') {<br />            err = '';<br />        } else if (typeof err === 'number') {<br />            if (!isNaN(err)) {<br />                if (typeof cv !== 'undefined') {<br />                    err = 'Exception: ' + cv.exceptionFromPtr(err).msg;<br />                }<br />            }<br />        } else if (typeof err === 'string') {<br />            let ptr = Number(err.split(' ')[0]);<br />            if (!isNaN(ptr)) {<br />                if (typeof cv !== 'undefined') {<br />                    err = 'Exception: ' + cv.exceptionFromPtr(ptr).msg;<br />                }<br />            }<br />        } else if (err instanceof Error) {<br />            err = err.stack.replace(/\\n/g, '&lt;br&gt;');<br />        }<br />        this.errorOutput.innerHTML = err;<br />    };<br />    this.loadCode = function(scriptId, textAreaId) {<br />        let scriptNode = document.getElementById(scriptId);<br />        let textArea = document.getElementById(textAreaId);<br />        if (scriptNode.type !== 'text/code-snippet') {<br />            throw Error('Unknown code snippet type');<br />        }<br />        textArea.value = scriptNode.text.replace(/^\\n/, '');<br />    };<br />    this.addFileInputHandler = function(fileInputId, canvasId) {<br />        let inputElement = document.getElementById(fileInputId);<br />        inputElement.addEventListener('change', (e) =&gt; {<br />            let files = e.target.files;<br />            if (files.length &gt; 0) {<br />                let imgUrl = URL.createObjectURL(files[0]);<br />                self.loadImageToCanvas(imgUrl, canvasId);<br />            }<br />        }, false);<br />    };<br />    function onVideoCanPlay() {<br />        if (self.onCameraStartedCallback) {<br />            self.onCameraStartedCallback(self.stream, self.video);<br />        }<br />    };<br />    this.startCamera = function(resolution, callback, videoId) {<br />        const constraints = {<br />            'qvga': {width: {exact: 320}, height: {exact: 240}},<br />            'vga': {width: {exact: 640}, height: {exact: 480}}};<br />        let video = document.getElementById(videoId);<br />        if (!video) {<br />            video = document.createElement('video');<br />        }<br />        let videoConstraint = constraints[resolution];<br />        if (!videoConstraint) {<br />            videoConstraint = true;<br />        }<br />        navigator.mediaDevices.getUserMedia({video: videoConstraint, audio: false})<br />            .then(function(stream) {<br />                video.srcObject = stream;<br />                video.play();<br />                self.video = video;<br />                self.stream = stream;<br />                self.onCameraStartedCallback = callback;<br />                video.addEventListener('canplay', onVideoCanPlay, false);<br />            })<br />            .catch(function(err) {<br />                self.printError('Camera Error: ' + err.name + ' ' + err.message);<br />            });<br />    };<br />    this.stopCamera = function() {<br />        if (this.video) {<br />            this.video.pause();<br />            this.video.srcObject = null;<br />            this.video.removeEventListener('canplay', onVideoCanPlay);<br />        }<br />        if (this.stream) {<br />            this.stream.getVideoTracks()[0].stop();<br />        }<br />    };<br />};</pre><h3>Haar.js</h3><p>As we’re done with the utility setup, we’ll code the detection part by creating a file named haar.js. We’ll start the coding now, without any delays!</p><pre>let isFaceDetection = true; // Flag to indicate whether face detection is enabled<br />function switchDetection() {<br />    isFaceDetection = !isFaceDetection; // Toggle the flag<br />}</pre><p>The above code snippet initializes with a detection check for the face strictly followed by a toggle function <strong><em>switchDetection()</em></strong>. This switch function is used to add an additional toggling feature in the application, such that the user can navigate between the face detection or the face and eyes detection by clicking the switch button. The function of the switch button is thoroughly explained in the code below.</p><pre>function addNavigationButtons() {<br />    // Create a button for switching detection<br />    let switchButton = document.createElement('button');<br />    switchButton.textContent = 'Switch Detection';<br />    switchButton.addEventListener('click', switchDetection);<br />// Append the button to the body<br />    // Get the button container element<br />    let buttonContainer = document.getElementById('buttonContainer');<br />    // Append the button to the button container<br />    buttonContainer.appendChild(switchButton);<br />}</pre><p>This code is quite simple to follow. The <strong><em>addNavigationButtons() </em></strong>function first creates a “<strong><em>switchButton”</em></strong> variable to create a button element and add in the text content of choice. The next line is the event handling for the switch button by passing in the event name <strong><em>‘click’ </em></strong>and the callback function <strong><em>‘switchDetection()’</em> </strong>that we created above. Next we fetch the button container through the id defined in the html and store it inside the <strong><em>buttonContainer</em></strong> variable. Don’t worry we’ll get to see the html part in the final stages of this project. The last thing we’ll do is add our <strong><em>switchButton</em></strong> as a child element to the fetched <strong><em>“buttonContainer”</em></strong> element from the html. This is done to allow the access inside the html editor for style or other required changes to this button element.</p><pre>function openCvReady() {<br />    cv['onRuntimeInitialized'] = () =&gt; {<br />        let video = document.getElementById(&quot;cam_input&quot;); // video is the id of video tag<br />        navigator.mediaDevices.getUserMedia({ video: true, audio: false })<br />        .then(function(stream) {<br />            video.srcObject = stream;<br />            video.play();<br />        })<br />        .catch(function(err) {<br />            console.log(&quot;An error occurred! &quot; + err);<br />        });<br />        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);<br />        let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);<br />        let gray = new cv.Mat();<br />        let cap = new cv.VideoCapture(cam_input);<br />        let faces = new cv.RectVector();<br />        let eyes = new cv.RectVector();<br />        let faceClassifier = new cv.CascadeClassifier();<br />        let eyeClassifier = new cv.CascadeClassifier();<br />        let utils = new Utils('errorMessage');<br />        let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to face cascade xml<br />        let eyeCascadeFile = 'haarcascade_eye.xml'; // path to eye cascade xml<br />        utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () =&gt; {<br />            faceClassifier.load(faceCascadeFile); // in the callback, load the face cascade from file<br />        });<br />        utils.createFileFromUrl(eyeCascadeFile, eyeCascadeFile, () =&gt; {<br />            eyeClassifier.load(eyeCascadeFile); // in the callback, load the eye cascade from file<br />        });<br />        const FPS = 24;</pre><p>Here the <strong><em>opencvReady()</em></strong> function is a callback which initiates with the loading of the <strong><em>OpenCV</em></strong> library. <strong><em>onRuntimeInitialized </em></strong>is an event that is triggered when the library is initialized and a class-back function is assigned to it using an arrow. Inside the callback the video element is retrieved using the ID <strong><em>“cam_input”</em></strong>. Then a promise based function <strong><em>“navigator.mediaDevices.getUserMedia” </em></strong>is used to request access to user’s camera which upon access returns a promise using <strong><em>then()</em></strong> function. It assigns the stream to the <strong><em>“srcObject”</em></strong> property of the video element and starts playing the video. The <strong><em>catch( ) </em></strong>method is used to log errors. Next, several variables and objects are initialized. These include <strong><em>src</em></strong> , <strong><em>dst </em></strong>and <strong><em>gray</em></strong>, which are instances of OpenCV matrices used for image processing. <strong><em>cap</em></strong> is a <strong><em>VideoCapture </em></strong>object that provides access to video frames. <strong><em>faces</em></strong> and <strong><em>eyes </em></strong>are <strong><em>RectVector </em></strong>objects that will store the detected faces and eyes, respectively. <strong><em>faceClassifier</em></strong> and <strong><em>eyesClassifier </em></strong>are instances of <strong><em>CascadeClassifier </em></strong>, which are used to load and apply trained cascade classifiers for face and eye detection. An instance of the <strong><em>Utils </em></strong>class is created, which provides utility functions. The constructor of <strong><em>Utils</em></strong> takes an argument, “<strong><em>errorMessage”</em></strong>, which is the ID of an HTML element used to display error messages. The <strong><em>utils.createFileFromUrl()</em></strong> function is called to asynchronously load the cascade classifier XML files. It takes the file path, a callback function, and optional parameters. In the callback function, the XML file is loaded using <strong><em>faceClassifer.load() </em></strong>and <strong>eyeClassifier.load() </strong>methods. Finally, <strong><em>FPS </em></strong>is set to 24, indicating the desired frames per second for video processing.</p><pre>function processVideo() {<br />            let begin = Date.now();<br />            cap.read(src);<br />            src.copyTo(dst);<br />            cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);<br />if (isFaceDetection) {<br />                try {<br />                    faceClassifier.detectMultiScale(gray, faces, 1.1, 3, 0);<br />                    console.log(faces.size());<br />                } catch (err) {<br />                    console.log(err);<br />                }<br />                for (let i = 0; i &lt; faces.size(); ++i) {<br />                    let face = faces.get(i);<br />                    let point1 = new cv.Point(face.x, face.y);<br />                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);<br />                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);<br />                }<br />            } else {<br />                try {<br />                    faceClassifier.detectMultiScale(gray, faces, 1.1, 3, 0);<br />                    eyeClassifier.detectMultiScale(gray, eyes, 1.1, 3, 0);<br />                    console.log(eyes.size());<br />                } catch (err) {<br />                    console.log(err);<br />                }<br />                for (let i = 0; i &lt; faces.size(); ++i) {<br />                    let face = faces.get(i);<br />                    let point1 = new cv.Point(face.x, face.y);<br />                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);<br />                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);<br />                }<br />                for (let i = 0; i &lt; eyes.size(); ++i) {<br />                    let eye = eyes.get(i);<br />                    let point1 = new cv.Point(eye.x, eye.y);<br />                    let point2 = new cv.Point(eye.x + eye.width, eye.y + eye.height);<br />                    cv.rectangle(dst, point1, point2, [0, 255, 0, 255]);<br />                }<br />            }<br />            cv.imshow(&quot;canvas_output&quot;, dst);<br />            // schedule next one.<br />            let delay = 1000 / FPS - (Date.now() - begin);<br />            setTimeout(processVideo, delay);<br />        }<br />        // Add navigation buttons<br />        addNavigationButtons();<br />        // schedule first one.<br />        setTimeout(processVideo, 0);<br />    };</pre><p>The <strong><em>“processVideo()” </em></strong>function is responsible for processing video frames in real-time. It starts by capturing a frame from the video source and converting it to grayscale. The function then determines whether to perform face detection or both face and eye detection based on the <strong><em>“isFaceDetection”</em></strong> flag. If face detection is enabled, it uses a face classifier to detect faces in the frame and draws rectangles around them. If both face and eye detection are enabled, it also uses an eye classifier to detect eyes within the detected faces and draws rectangles around them. The processed frame with the drawn rectangles is displayed on a canvas. The function then calculates the delay required to achieve a desired frame rate and schedules the next frame processing using <strong><em>setTimeout()</em></strong>. Additionally, the <strong><em>addNavigationButtons()</em></strong> function is called to add buttons for toggling between face and eye detection. Overall, this code allows for real-time video processing with face and eye detection capabilities.</p><p>With this comes the end of the JavaScripting part. Before moving forward to the html let’s just take a look at the entire Haar.js part.</p><pre>let isFaceDetection = true; // Flag to indicate whether face detection is enabled<br />function switchDetection() {<br />    isFaceDetection = !isFaceDetection; // Toggle the flag<br />}<br />function addNavigationButtons() {<br />    // Create a button for switching detection<br />    let switchButton = document.createElement('button');<br />    switchButton.textContent = 'Switch Detection';<br />    switchButton.addEventListener('click', switchDetection);<br />    // Append the button to the body<br />    // Get the button container element<br />    let buttonContainer = document.getElementById('buttonContainer');<br />    // Append the button to the button container<br />    buttonContainer.appendChild(switchButton);<br />}<br />function openCvReady() {<br />    cv['onRuntimeInitialized'] = () =&gt; {<br />        let video = document.getElementById(&quot;cam_input&quot;); // video is the id of video tag<br />        navigator.mediaDevices.getUserMedia({ video: true, audio: false })<br />        .then(function(stream) {<br />            video.srcObject = stream;<br />            video.play();<br />        })<br />        .catch(function(err) {<br />            console.log(&quot;An error occurred! &quot; + err);<br />        });<br />        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);<br />        let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);<br />        let gray = new cv.Mat();<br />        let cap = new cv.VideoCapture(cam_input);<br />        let faces = new cv.RectVector();<br />        let eyes = new cv.RectVector();<br />        let faceClassifier = new cv.CascadeClassifier();<br />        let eyeClassifier = new cv.CascadeClassifier();<br />        let utils = new Utils('errorMessage');<br />        let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to face cascade xml<br />        let eyeCascadeFile = 'haarcascade_eye.xml'; // path to eye cascade xml<br />        utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () =&gt; {<br />            faceClassifier.load(faceCascadeFile); // in the callback, load the face cascade from file<br />        });<br />        utils.createFileFromUrl(eyeCascadeFile, eyeCascadeFile, () =&gt; {<br />            eyeClassifier.load(eyeCascadeFile); // in the callback, load the eye cascade from file<br />        });<br />        const FPS = 24;<br />        function processVideo() {<br />            let begin = Date.now();<br />            cap.read(src);<br />            src.copyTo(dst);<br />            cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);<br />            if (isFaceDetection) {<br />                try {<br />                    faceClassifier.detectMultiScale(gray, faces, 1.1, 3, 0);<br />                    console.log(faces.size());<br />                } catch (err) {<br />                    console.log(err);<br />                }<br />                for (let i = 0; i &lt; faces.size(); ++i) {<br />                    let face = faces.get(i);<br />                    let point1 = new cv.Point(face.x, face.y);<br />                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);<br />                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);<br />                }<br />            } else {<br />                try {<br />                    faceClassifier.detectMultiScale(gray, faces, 1.1, 3, 0);<br />                    eyeClassifier.detectMultiScale(gray, eyes, 1.1, 3, 0);<br />                    console.log(eyes.size());<br />                } catch (err) {<br />                    console.log(err);<br />                }<br />                for (let i = 0; i &lt; faces.size(); ++i) {<br />                    let face = faces.get(i);<br />                    let point1 = new cv.Point(face.x, face.y);<br />                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);<br />                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);<br />                }<br />                for (let i = 0; i &lt; eyes.size(); ++i) {<br />                    let eye = eyes.get(i);<br />                    let point1 = new cv.Point(eye.x, eye.y);<br />                    let point2 = new cv.Point(eye.x + eye.width, eye.y + eye.height);<br />                    cv.rectangle(dst, point1, point2, [0, 255, 0, 255]);<br />                }<br />            }<br />            cv.imshow(&quot;canvas_output&quot;, dst);<br />            // schedule next one.<br />            let delay = 1000 / FPS - (Date.now() - begin);<br />            setTimeout(processVideo, delay);<br />        }<br />        // Add navigation buttons<br />        addNavigationButtons();<br />        // schedule first one.<br />        setTimeout(processVideo, 0);<br />    };<br />}</pre><h3>Html</h3><p>We’ll now be coding the html part for basic interfacing and getting things together.</p><pre>&lt;!DOCTYPE html&gt;<br />&lt;html lang=&quot;en&quot;&gt;<br />&lt;head&gt;<br />    &lt;meta charset=&quot;UTF-8&quot;&gt;<br />    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;<br />    &lt;title&gt;Opencv JS&lt;/title&gt;<br />    &lt;style&gt;<br />        body {<br />            font-family: Arial, sans-serif;<br />            background-color: #f4f4f4;<br />            margin: 0;<br />            padding: 0;<br />            display: flex;<br />            justify-content: center;<br />            align-items: center;<br />            height: 100vh;<br />            flex-direction: column;<br />        }<br />        h2, h3 {<br />            text-align: center;<br />            color: #333;<br />            margin: 0;<br />            padding: 10px;<br />        }<br />        video, canvas {<br />            display: block;<br />            margin: 0 auto;<br />            background-color: #000;<br />            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.3);<br />        }<br />        #buttonContainer {<br />            padding: 7px 15px;<br />            font-size: 10px;<br />            background-color: #4CAF50;<br />            color: #fff;<br />            border: none;<br />            border-radius: 2px;<br />            cursor: pointer;<br />            transition: background-color 0.3s ease;<br />        }<br />        #buttonContainer:hover {<br />            background-color: #45a049;<br />        }<br />    &lt;/style&gt;<br />    &lt;script async src=&quot;js/opencv.js&quot; onload=&quot;openCvReady();&quot;&gt;&lt;/script&gt;<br />    &lt;script src=&quot;js/haar.js&quot;&gt;&lt;/script&gt;<br />    &lt;script src=&quot;js/utils.js&quot;&gt;&lt;/script&gt;<br />&lt;/head&gt;<br />&lt;body&gt;<br />    &lt;video id=&quot;cam_input&quot; height=&quot;320&quot; width=&quot;480&quot;&gt;&lt;/video&gt;<br />    &lt;canvas id=&quot;canvas_output&quot;&gt;&lt;/canvas&gt;<br />    &lt;h2&gt;Haar Cascade Based Face and Eyes Detection&lt;/h2&gt;<br />    &lt;h3&gt;Click the button to toggle between Simple Face Detection and Face + Eyes Detection.&lt;/h3&gt;<br />    &lt;div id=&quot;buttonContainer&quot;&gt;<br />    &lt;/div&gt;<br />    &lt;/body&gt;<br />&lt;/html&gt;</pre><p>The code is basic html coding and nothing so complex to need explanation. However, its important to understand the path to the opencv.js library file that we downloaded earlier. As you can see, the opencv.js, haar.js and utils.js files are all in the same folder <strong><em>“js”</em></strong>, whereas<strong><em> </em></strong>the html file for the above code is placed alongside the “<strong><em>js”</em></strong> directory. You can adjust the paths according to your requirements.</p><p>Below is the output for both the face detection and face and eyes detection. Pardon the background</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*J4N66T4cocHmQo-LqTduGg.png\" /><figcaption>Fig — 02 Image By author. (Haar Cascade Face Detection)</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1-XNtPPutS0uph77-T2T0A.png\" /><figcaption>Fig — 03 Image By author. (Haar Cascade Face and Eyes Detection)</figcaption></figure><p>Download the entire code and auxiliary files from my <a href=\"https://github.com/nbeeeel/haar-cascade-web-application-using-opencv.js\">Github repo</a>.</p><h3>Conclusion</h3><p>In this tutorial we implemented Haar cascade face and eye detection using opencv.js on our web application. We also went through the details of the code in order to learn the purpose of each method. This way we’ll be learning both computer vision and web development. I hope this tutorial adds some value to your learning journey and if some stuff is missed or you have some suggestions, do let me know. If you want the code and the related files do visit my <a href=\"https://github.com/nbeeeel/haar-cascade-web-application-using-opencv.js\">Github</a> for this project.</p><p><strong><em>Till next time….. Stay Blessed!</em></strong></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=aa46be637096\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/easily-build-a-web-app-with-haar-cascades-and-opencv-js-aa46be637096\">Easily build a Web App with Haar Cascades and OpenCV.js</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Nabeel Khan'}],"Thu, 22 Jun 2023 19:21:44 GMT"
1194,Getting Started with Depth Estimation using MiDaS and Python,https://medium.com/artificialis/getting-started-with-depth-estimation-using-midas-and-python-d0119bfe1159?source=rss----a81c8d170222---4,"<p>Getting Started with Depth Estimation using MiDaS and Python</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GOIdx95IUMsHNP7YnIkzdw.png\" /><figcaption>Fig — 01 Image by Author Inspired by <a href=\"https://pixabay.com/users/sambeetarts-1339110/\">Sambeetarts</a> on <a href=\"https://pixabay.com/illustrations/geometric-design-computer-1732847/\">Pixabay</a></figcaption></figure><p>Measuring<strong> </strong>distance of an object from camera poses a significant challenge within the computer vision domain, due to the lack of inherent depth information in 2D images, perspective distortion, variable object sizes, camera calibration requirements, and occlusion in complex scenes. Distance estimation via perspective projection, for instance, relies on variables such as the size of the sensor, focal length, and the actual height of the object. The computation of these unknown variables adds to the complexity of the task.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/598/1*tTdzp9ChZ6uT47gCXMzAmg.png\" /><figcaption>Fig — 02 (Formula for Distance to Object)</figcaption></figure><p>A series of traditional and deep learning based approaches have been in service for quite some time to provide an effective solution to distance estimation. Solutions involving stereo vision have proven to be effective and accurate in depth calculation, however there’s always a search for a much efficient and inexpensive alternative. Deep learning has shown itself to thrive in such constraints, pushing the boundaries of possibilities to a whole new level and bringing to reality depth estimation models for monocular vision — one of which we’ll be exploring in this article.</p><p>Following my recent <a href=\"https://medium.com/artificialis/swift-and-simple-calculate-object-distance-with-ease-in-just-few-lines-of-code-38889575bb12?source=your_stories_page-------------------------------------\">distance measurement using media-pipe</a> tutorial, I intended to build upon the notion of monocular depth estimation by bringing all possible approaches — to provide you with best options for your fun projects.</p><p>In this article, I’ll be estimating the distance of an object using a hybrid of media-pipe pose estimation module and MiDaS depth estimation model. But before that, let’s just take a quick overview of what we’ll be covering in this article.</p><ol><li><strong>MiDaS overview.</strong></li><li><strong>Distance measurement using Media-pipe landmarks and MiDaS depth map.</strong></li></ol><h3>MiDaS</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iHcmPCWez148p32CP2nToA.png\" /><figcaption>Fig — 03 (MiDaS Depth Estimation) Image by Author Inspired by <a href=\"https://pixabay.com/users/mikes-photography-1860391/\">Mikes-Photography</a> on <a href=\"https://pixabay.com/videos/cars-motorway-speed-motion-traffic-1900/\">Pixabay</a></figcaption></figure><p>MiDaS(Multiple Depth Estimation Accuracy with Single Network) is a deep learning based residual model built atop Res-Net for monocular depth estimation. MiDaS is known to have shown promising results in depth estimation from single images. Below is the generic overview of the MiDaS architecture:</p><ol><li><strong>Encoder-Decoder Architecture</strong></li></ol><p>MiDaS is based on an encoder-decoder architecture, where the encoder part is responsible for high level feature extraction and the decoder generates the depth map from these features via up-sampling.</p><p>2. <strong>Backbone</strong></p><p>MiDaS typically uses a residual network (ResNet-50 or ResNet-101) for feature extraction because it is robust to vanishing gradients. Allowing MiDaS to extract multi-channeled feature maps from input images, capturing hierarchical information at varying scales.</p><p>3. <strong>Multi-Scale Feature Fusion</strong></p><p>Skip connections and feature fusion is incorporated within MiDaS to allow accurate depth estimation. Feature maps from earlier layers are connected to the later layers via skip connections for accessing low level details during up-sampling. With feature fusion, the multi-scale feature maps are combined to ensure the effective exploitation of both local and global information for depth estimation.</p><p>4. <strong>Up-Sampling and Refinement</strong></p><p>The final depth map is generated using up-sampling. The general techniques used for the up-sampling are bi-linear interpolation or transposed convolutions to increase the spatial resolution of the feature maps. Feature fusion is employed to combine the depth maps with corresponding skip connections in order to refine the depth estimation.</p><h3>Python Code for distance measurement</h3><pre>import cv2<br />import torch<br />import mediapipe as mp<br />import numpy as np<br />from scipy.interpolate import RectBivariateSpline</pre><pre>mp_pose = mp.solutions.pose<br />pose = mp_pose.Pose(static_image_mode=False)</pre><p>Importing required packages and initializing media-pipe pose estimation class <strong><em>mp_pose.Pose</em></strong>.</p><pre>#Downloading the model from TorchHub.<br />midas = torch.hub.load('intel-isl/MiDaS','MiDaS_small')<br />midas.to('cpu')<br />midas.eval()</pre><p>Downloading MiDaS_small model from torch hub. You can download the python executable for MiDaS through <a href=\"https://github.com/isl-org/MiDaS\">Github</a> once, instead. There are three variants of MiDaS available on torch hub and can be downloaded by substituting <strong>‘<em>DPT_Large</em>’</strong> or <strong>‘<em>DPT_Hybrid</em>’ </strong>for<strong> ‘<em>MiDaS_small</em>’</strong>. The general performance of all three variants is given below :</p><ol><li><strong>Small variant </strong>: Lowest accuracy and high inference rate.</li><li><strong>Hybrid variant</strong> : Medium accuracy and medium inference speed</li><li><strong>Large variant </strong>: Highest accuracy with lowest inference speed.</li></ol><p>If you’ve a <strong>Cuda</strong> compatible GPU, then you can replace the <strong><em>midas.to(‘cpu’)</em></strong> with <strong><em>midas.to(“cuda”)</em></strong> to maximize the inference speed.</p><pre>#Performing preprocessing on input for small model <br />transforms = torch.hub.load('intel-isl/MiDaS','transforms')<br />transform = transforms.small_transform</pre><pre>#Converting Depth to distance<br />def depth_to_distance(depth_value,depth_scale):<br />  return -1.0/(depth_value*depth_scale)</pre><p>Applying the requisite preprocessing on the input image/ video frame for MiDaS small model. Followed by a function <strong>‘depth_to_distance’</strong> defined for converting the calculated depth values into the respective distance values.</p><pre>cap = cv2.VideoCapture('')<br />while cap.isOpened():<br />  ret, frame = cap.read()<br /><br />  img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)<br /><br />  cv2.imshow('Walking',img)<br /><br />  if cv2.waitKey(2) &amp;0xFF == ord('q'):<br />    cap.release()<br />    cv2.destroyAllWindows()</pre><p>Reading the video input and applying color space transformation using <strong>cv2.cvtColor</strong> function. As cv2 reads images in BGR format we need to convert it to RGB for standard visuals. Let run the code to check if its working right so far.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*tc3crTchEIlC3uUj7crQJA.gif\" /><figcaption>Fig — 04 (A person walking in the woods) Gif by Author Inspired by <a href=\"https://pixabay.com/users/matthias_groeneveld-4535957/\">Matthias Groeneveld</a> on <a href=\"https://pixabay.com/videos/hiking-walking-man-alone-nature-109277/\">Pixabay</a></figcaption></figure><p>Next we will extract the landmarks from the video frame using Media-Pipe using the below code.</p><pre># Detect the body landmarks in the frame<br />    results = pose.process(img)<br /><br />    # Check if landmarks are detected<br />    if results.pose_landmarks is not None:<br />        # Draw Landmarks<br />        mp_drawing = mp.solutions.drawing_utils<br />        mp_drawing.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*BAvpgsjucGY1nanjac5BzQ.gif\" /><figcaption>Fig — 05 (Keypoints Detected)</figcaption></figure><p>After successfully drawing the detected landmarks, we’ll now extract the waist landmarks as a reference for the distance estimation. Lets write the code to extract the waist landmarks.</p><pre># Extract Landmark Coordinates<br />        landmarks = []<br />        for landmark in results.pose_landmarks.landmark:<br />            landmarks.append((landmark.x, landmark.y, landmark.z))<br /><br />        # Extract left and right waist Landmarks<br />        waist_landmarks = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP],<br />                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]]<br />        #Finding midpoint from waist    <br />        mid_point = ((waist_landmarks[0].x + waist_landmarks[1].x) / 2, (waist_landmarks[0].y + waist_landmarks[1].y) / 2)<br />        mid_x , mid_y = mid_point</pre><p>Extracting the x and y coordinate values for both landmarks and calculating the midpoint. You can pick any landmark of your choice depending on the use-case from the pose-landmark list on <a href=\"https://developers.google.com/mediapipe/solutions/vision/pose_landmarker\">Media-pipe</a>.</p><p>Moving forward, we’ll pass our video through MiDaS depth estimation model to get the depth map.</p><pre>imgbatch = transform(img).to('cpu')<br /><br />    # Making a prediction<br />    with torch.no_grad():<br />        prediction = midas(imgbatch)<br />        prediction = torch.nn.functional.interpolate(<br />            prediction.unsqueeze(1),<br />            size=img.shape[:2],<br />            mode='bicubic',<br />            align_corners=False<br />        ).squeeze()<br /><br />    output = prediction.cpu().numpy()<br />    #Normalizing the output predictions for cv2 to read.<br />    output_norm = cv2.normalize(output, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)<br /><br />    cv2.imshow('Walking',output_norm)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*hWbpd1NzmCVJ1HHG4lJc4A.gif\" /><figcaption>Fig — 06 (MiDaS Depth Map)</figcaption></figure><p>Above is the depth map extracted through MiDaS, also change the <strong><em>waitKey </em></strong>value to<strong><em> </em></strong>1 to decrease the frame delay. You can also change the output of the depth map to a colored map using the code below, but we’ll be using the standard black and white map in this project.</p><pre>#Colored Depth map<br />output_norm = (output_norm*255).astype(np.uint8)<br />output_norm = cv2.applyColorMap(output_norm, cv2.COLORMAP_MAGMA)</pre><p>We’ll then use the from waist landmarks extracted earlier, to calculate the depth value using MiDaS.</p><pre>#Creating a spline array of non-integer grid<br />        h , w = output_norm.shape<br />        x_grid = np.arange(w)<br />        y_grid = np.arange(h)<br /><br />        # Create a spline object using the output_norm array<br />        spline = RectBivariateSpline(y_grid, x_grid, output_norm)</pre><p>The use of a spline array in above code snippet enables the creation of a smooth and continuous representation of the <strong><em>output_norm</em></strong> array on a non-integer grid. The need for a spline array arises from the normalization of the output predictions, resulting in an array with floating-point values. By utilizing a spline object, more accurate and versatile computations or visualizations can be performed by interpolating values based on the given data.</p><pre>#Passing the x and y co-ordinates distance function to calculate distance.<br />#Tweak with the depth scale to see what suits you!<br />depth_scale = 1<br />depth_mid_filt = spline(mid_y,mid_x)<br />depth_midas = depth_to_distance(depth_mid_filt, depth_scale)<br /><br />#Displaying the distance.<br />cv2.putText(img, &quot;Depth in unit: &quot; + str(<br />            np.format_float_positional(depth_mid_filt , precision=3)), (20, 50), cv2.FONT_HERSHEY_SIMPLEX,<br />                    1, (255, 255, 255), 3)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*V689v_yP8e6aNJ4HK7DOAA.gif\" /><figcaption>Fig — 07 (Depth Calculation)</figcaption></figure><p>The depth values are fluctuating a bit. To stabilize the values we’ll use a exponential mean average filter on the depth values and then see the improvements.</p><pre>#Adjust alpha values to suit your need<br />alpha = 0.2<br />previous_depth = 0.0<br /><br />#Applying exponential moving average filter<br />def apply_ema_filter(current_depth):<br />    global previous_depth<br />    filtered_depth = alpha * current_depth + (1 - alpha) * previous_depth<br />    previous_depth = filtered_depth  # Update the previous depth value<br />    return filtered_depth</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*u82MQbed3TBJJeSCVxl-gg.gif\" /><figcaption>Fig — 08 (Applying EMA Filter)</figcaption></figure><p>Here we can witness considerable difference in the fluctuation after applying Exponential Mean Average Filter on distance value.</p><p>Lets just take a look at the entire code snippet.</p><pre>import cv2<br />import torch<br />import matplotlib.pyplot as plt<br />import mediapipe as mp<br />import numpy as np<br />import shutil<br />from scipy.interpolate import RectBivariateSpline<br /><br />#To Clear the model cache<br /># shutil.rmtree(torch.hub.get_dir(), ignore_errors=True)<br /><br />#Initializing the body landmarks detection module<br />mp_pose = mp.solutions.pose<br />pose = mp_pose.Pose(static_image_mode=False)<br /><br /># #download the model<br />midas = torch.hub.load('intel-isl/MiDaS','MiDaS_small')<br />midas.to('cpu')<br />midas.eval()<br /><br />#Process image<br />transforms = torch.hub.load('intel-isl/MiDaS','transforms')<br />transform = transforms.small_transform<br /><br />alpha = 0.2<br />previous_depth = 0.0<br />depth_scale = 1.0<br /><br />#Applying exponential moving average filter<br />def apply_ema_filter(current_depth):<br />    global previous_depth<br />    filtered_depth = alpha * current_depth + (1 - alpha) * previous_depth<br />    previous_depth = filtered_depth  # Update the previous depth value<br />    return filtered_depth<br /><br /><br />#Define depth to distance<br />def depth_to_distance(depth_value,depth_scale):<br />    return 1.0 / (depth_value*depth_scale)<br /><br />def depth_to_distance1(depth_value,depth_scale):<br />    return -1.0 / (depth_value*depth_scale)<br /><br />cap = cv2.VideoCapture('distance1.mp4')<br />while cap.isOpened():<br />    ret, frame = cap.read()<br /><br />    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<br /><br />    # Detect the body landmarks in the frame<br />    results = pose.process(img)<br /><br />    # Check if landmarks are detected<br />    if results.pose_landmarks is not None:<br />        # Draw Landmarks<br />        # mp_drawing = mp.solutions.drawing_utils<br />        # mp_drawing.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)<br /><br />        # Extract Landmark Coordinates<br />        landmarks = []<br />        for landmark in results.pose_landmarks.landmark:<br />            landmarks.append((landmark.x, landmark.y, landmark.z))<br /><br />        waist_landmarks = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP],<br />                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]]<br /><br />        mid_point = ((waist_landmarks[0].x + waist_landmarks[1].x) / 2, (waist_landmarks[0].y + waist_landmarks[1].y) / 2,(waist_landmarks[0].z + waist_landmarks[1].z) /2)<br />        mid_x,mid_y = mid_point<br /><br />        <br />        imgbatch = transform(img).to('cpu')<br /><br />        # Making a prediction<br />        with torch.no_grad():<br />            prediction = midas(imgbatch)<br />            prediction = torch.nn.functional.interpolate(<br />                prediction.unsqueeze(1),<br />                size=img.shape[:2],<br />                mode='bicubic',<br />                align_corners=False<br />            ).squeeze()<br /><br />        output = prediction.cpu().numpy()<br />        output_norm = cv2.normalize(output, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)<br /><br />        # Creating a spline array of non-integer grid<br />        h, w = output_norm.shape<br />        x_grid = np.arange(w)<br />        y_grid = np.arange(h)<br /><br />        # Create a spline object using the output_norm array<br />        spline = RectBivariateSpline(y_grid, x_grid, output_norm)<br />        depth_mid_filt = spline(mid_y,mid_x)<br />        depth_midas = depth_to_distance(depth_mid_filt, depth_scale)<br />        depth_mid_filt = (apply_ema_filter(depth_midas)/10)[0][0]<br />        <br />        cv2.putText(img, &quot;Depth in unit: &quot; + str(<br />            np.format_float_positional(depth_mid_filt , precision=3)) , (20, 50), cv2.FONT_HERSHEY_SIMPLEX,<br />                    1, (255, 255, 255), 3)<br />        <br />        cv2.imshow('Walking',img)<br /><br />    if cv2.waitKey(1) &amp;0xFF == ord('q'):<br />        cap.release()<br />        cv2.destroyAllWindows()</pre><h3>Conclusion</h3><p>In this article we calculated the distance of an object from the camera using the MiDaS depth estimation model while leveraging the reference landmark extracted from Media-pipe. The following approach can be used to detect distance of multiple objects/people and integrated into mini projects based on proximity.</p><p>You can download the source code using <a href=\"https://github.com/nbeeeel/Distance-Measurement-Using-MiDaS\"><strong>Github </strong></a>link<strong>.</strong></p><h3>References</h3><p>[1] Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler and Vladlen Koltun, <a href=\"https://arxiv.org/abs/1907.01341\">Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer</a> (2020), IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</p><p>[2] Ranftl, Alexey Bochkovskiy and Vladlen Koltun, <a href=\"https://arxiv.org/abs/2103.13413\">Vision Transformers for Dense Prediction</a> (2021), ArXiv preprint.</p><p>[3] Camillo Lugaresi, Jiuqiang Tang, Hadon Nash, Chris McClanahan, Esha Uboweja, Michael Hays, Fan Zhang, Chuo-Ling Chang, Ming Guang Yong, Juhyun Lee, Wan-Teh Chang, Wei Hua, Manfred Georg and Matthias Grundmann, <a href=\"https://arxiv.org/abs/1906.08172\">MediaPipe: A Framework for Building Perception Pipelines</a> (2019), ArXiv preprint.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d0119bfe1159\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/getting-started-with-depth-estimation-using-midas-and-python-d0119bfe1159\">Getting Started with Depth Estimation using MiDaS and Python</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Nabeel Khan'}],"Mon, 12 Jun 2023 11:23:32 GMT"
1195,Navigating Math for Computer Vision: Your Ultimate Roadmap,https://medium.com/artificialis/navigating-math-for-computer-vision-your-ultimate-roadmap-8389a0d7b7be?source=rss----a81c8d170222---4,"<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4wD92Z8uTSzKQ8S9fHmPBQ.png\" /></figure><p>I got myself occupied with developing an understanding of Convolutional Neural Networks, as part of my final year project themed around object detection. However, absorbing the mathematical principles defining the fundamentals of the subject was not an easy feat. I had to joust with the underlying concepts and for the first time see numbers as a representation of images, which to be honest was not easy for me to get my head around. Anyways, I did eventually made sense of the maths behind the representation and manipulation of images albeit after some sleepless nights.</p><p>Coming to the point, learning algebra, calculus or other numerical concepts to develop an understanding of computer vision or image processing would in itself be a debilitating ordeal, unless a clarity in relation between images and their numeric representation is established. Many of us are familiar with the vital role mathematics plays within the computer vision domain while those of you who aren’t, would be vaguely familiarized through this post along with a roadmap to conquer your fear of sophisticated Greek and Latin representations that contribute a sizeable proportion of modern day mathematics. So its been established, conquering mathematical methods is an imperative objective in our quest to becoming a CV expert and there is no other way. Hence we should embrace it as a powerful language to explain densely intricate phenomenon, an archaic tool to decrypt the mysteries of visual data and a pathway to innovation. One of the many effective ways to demystify the language of the Gods for CV whilst being creative and robust in our comprehension of it is to leverage python, as it will aid greatly in closely observing the image response to subsequent mathematical operations while also providing high dimensional visualizations via its arsenal of libraries.</p><p>After introduction to my hard-earned epiphany, let me walk you through a generic overview of mathematical concepts that play a critical role in image processing and computer vision.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/259/1*FjRRyfGC58ua7iBgnU_3Pg.jpeg\" /><figcaption><a href=\"https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html\">credits</a></figcaption></figure><h3>Goal of the article</h3><ol><li>Familiarize with the role of various mathematical methods in Computer Vision.</li><li>Provide a complete mathematical roadmap for Computer Vision research and development.</li></ol><h3><strong>Linear Algebra</strong></h3><p>Linear Algebra comes into play as we represent images in the form of vectors, matrices and tensors.</p><h3><strong>Calculus</strong></h3><p>Calculus helps derive and optimize mathematical models for image processing and computer vision tasks.</p><h3>Probability and Statistics</h3><p>Probability and Statistics help us model and analyse image data, including feature extraction, image segmentation and object detection.</p><h3>Signal Processing</h3><p>To filter and transform images for artifacts and noise removal as well as to extract meaningful information in time-frequency domain, we employ signal processing techniques such as Fourier Analysis and wavelet transforms.</p><h3>Differential Equations</h3><p>Differential Equations are leveraged to model Dynamic Systems such as optical flow, motion estimation and image registration.</p><h3>Geometry</h3><p>Geometry is important for spatial transformations and 3D reconstruction of objects in computer vision.</p><h3>Optimization</h3><p>Optimization is used to develop algorithms and models for image denoising, deblurring, and super-resolution.</p><h3>Mathematics Roadmap For Image Processing and Computer Vision</h3><p>Below is the roadmap of mathematical methods for computer vision that will contribute sufficiently in your computer vision research and development journey.</p><h3><strong>Linear Algebra</strong></h3><ul><li>Vector spaces and subspaces: Understanding properties and operations.</li><li>Matrix factorizations: Singular value decomposition (SVD) and eigenvalue decomposition.</li><li>Linear regression: Modeling relationships between variables for regression tasks.</li><li>Principal Component Analysis (PCA): Dimensionality reduction technique.</li></ul><h3>Calculus</h3><ul><li>Multivariable calculus: Partial derivatives, gradients, and optimization in multiple dimensions.</li><li>Chain rule: Calculating derivatives in composite functions.</li><li>Hessian matrix: Analyzing curvature and optimization in higher dimensions.</li><li>Variational calculus: Euler-Lagrange equations for energy minimization problems.</li></ul><h3>Probability and Statistics</h3><ul><li>Random processes: Modeling temporal and spatial uncertainty in computer vision.</li><li>Markov chains: Analyzing sequential and temporal data.</li><li>Statistical pattern recognition: Statistical techniques for object recognition and classification.</li><li>Bayesian decision theory: Decision-making under uncertainty.</li></ul><h3>Signal Processing</h3><p><strong>Sampling Theory</strong></p><ul><li>Nyquist-Shannon sampling theorem: Principles of converting continuous signals to discrete signals.</li><li>Aliasing: Understanding the effects of under-sampling and frequency folding.</li></ul><p><strong>Image Filtering</strong></p><ul><li>Linear filters: Convolution, correlation, and their applications for noise reduction and image enhancement.</li><li>Non-linear filters: Median filtering, bilateral filtering, and their use in preserving edges and reducing noise.</li></ul><p><strong>Frequency Domain Analysis</strong></p><ul><li>Discrete Fourier Transform (DFT): Transforming signals from time domain to frequency domain.</li><li>Fast Fourier Transform (FFT): Efficient algorithms for computing the DFT.</li><li>Power spectra: Analyzing signal content and identifying dominant frequencies.</li></ul><p><strong>Wavelet Theory</strong></p><ul><li>Continuous Wavelet Transform (CWT): Analysis of signals at different scales and resolutions.</li><li>Discrete Wavelet Transform (DWT): Decomposing signals into wavelet coefficients for efficient representation.</li><li>Wavelet packet analysis: Further analysis and decomposition of signals using wavelet packets.</li></ul><p><strong>Filter Design</strong></p><ul><li>Finite Impulse Response (FIR) filters: Designing filters with finite-duration impulse responses.</li><li>Infinite Impulse Response (IIR) filters: Designing filters with infinite-duration impulse responses.</li><li>Filter banks: Constructing filter banks for multi-resolution analysis and synthesis.</li></ul><p><strong>Image Compression</strong></p><ul><li>Transform coding: Applying transformations like Discrete Cosine Transform (DCT) for efficient data representation.</li><li>Quantization: Reducing precision while preserving essential image information.</li><li>Entropy coding: Techniques like Huffman coding and arithmetic coding for further compression.</li></ul><p><strong>Image Restoration</strong></p><ul><li>Inverse problems: Modeling image deblurring, super-resolution, and image reconstruction.</li><li>Regularization: Balancing fidelity to observed data and prior assumptions in restoration tasks.</li></ul><h3>Differential Equations</h3><ul><li>Partial differential equations (PDEs) in computer vision: Heat equation, wave equation, and diffusion equation for image analysis and restoration.</li><li>Level set methods: Implicit representation of curves and surfaces for segmentation tasks.</li><li>Active contours (Snakes): Contour evolution for object boundary detection.</li></ul><h3>Geometry</h3><ul><li>3D geometry: Representing and transforming 3D objects and scenes.</li><li>Camera geometry: Pinhole camera model, intrinsic and extrinsic camera parameters.</li><li>Structure from motion: Estimating 3D structure from 2D image sequences.</li><li>3D reconstruction: Techniques for building 3D models from multiple images.</li></ul><h3>Optimization</h3><ul><li>Nonlinear optimization: Techniques like Newton’s method and Levenberg — Marquardt algorithm.</li><li>Convex hulls: Convex polytopes and their applications in computer vision.</li><li>Graph cuts: Energy minimization for image segmentation and object recognition.</li><li>Combinatorial optimization: Solving NP-hard problems in computer vision.</li></ul><h3>Conclusion</h3><p>Computer Vision has grown rapidly in the last decade, owing to the vehement endeavors of the research community. To keep pace with the research and publications within the domain, an understanding of governing mathematical principles is imperative. Hence this article, intended to unravel the roadmap required for a career as a researcher or even a developer in Computer Vision domain.</p><p>I hope the aforementioned roadmap would navigate your computer vision journey. If some facets were left unattended, do let me know in the comment section.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8389a0d7b7be\" width=\"1\" /><hr /><p><a href=\"https://medium.com/artificialis/navigating-math-for-computer-vision-your-ultimate-roadmap-8389a0d7b7be\">Navigating Math for Computer Vision: Your Ultimate Roadmap</a> was originally published in <a href=\"https://medium.com/artificialis\">Artificialis</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",[{'name': 'Nabeel Khan'}],"Wed, 31 May 2023 14:34:35 GMT"
1196,Nonlinear dynamics and stability analysis of locally-active Mott memristors using a physics-based compact model,https://arxiv.org/abs/2403.01036,"arXiv:2403.01036v1 Announce Type: new 
Abstract: Locally-active memristors are a class of emerging nonlinear dynamic circuit elements that hold promise for scalable yet biomimetic neuromorphic circuits. Starting from a physics-based compact model, we performed small-signal linearization analyses and applied Chua's local activity theory to a one-dimensional locally-active vanadium dioxide Mott memristor based on an insulator-to-metal phase transition. This approach allows a connection between the dynamical behaviors of a Mott memristor and its physical device parameters, which could guide materials and device development for neuromorphic circuit applications. We also examined the applicability of local analyses on a second-order circuit consists of a vanadium dioxide memristor coupled to an external reactive element, specifically a parallel capacitor. Finally, we show that global nonlinear techniques including nullclines and phase portraits provide insights on instabilities and persistent oscillations near non-hyperbolic fixed points, such as the creation of a stable limit cycle in a supercritical Hopf bifurcation, with some of the bifurcation characteristics distinctive from the general predictions.",[{'name': 'Wei Yi'}],
1197,Acceleration of digital memcomputing by jumps,https://arxiv.org/abs/2403.01627,"arXiv:2403.01627v1 Announce Type: new 
Abstract: In this article, we present the potential benefits of incorporating jumps into the dynamics of digital memcomputing machines (DMMs), which have been developed to address complex optimization problems. We illustrate the potential speed improvement of a DMM solver with jumps over an unmodified DMM solver by solving Boolean satisfiability (SAT) problems of different complicatedness. Our findings suggest that jumps can modify scaling exponents and improve solving times by up to 75 %. Interestingly, the advantages of jumps can be seen in cases where the size of the jump is so large that otherwise the continuous dynamics of voltage variables becomes almost binary.",[{'name': 'Yuriy V. Pershin'}],
1198,Training Computer Scientists for the Challenges of Hybrid Quantum-Classical Computing,https://arxiv.org/abs/2403.00885,"arXiv:2403.00885v1 Announce Type: cross 
Abstract: As we enter the post-Moore era, we experience the rise of various non-von-Neumann-architectures to address the increasing computational demand for modern applications, with quantum computing being among the most prominent and promising technologies. However, this development creates a gap in current computer science curricula since most quantum computing lectures are strongly physics-oriented and have little intersection with the remaining curriculum of computer science. This fact makes designing an appealing course very difficult, in particular for non-physicists. Furthermore, in the academic community, there is consensus that quantum computers are going to be used only for specific computational tasks (e.g., in computational science), where hybrid systems - combined classical and quantum computers - facilitate the execution of an application on both quantum and classical computing resources. A hybrid system thus executes only certain suitable parts of an application on the quantum machine, while other parts are executed on the classical components of the system. To fully exploit the capabilities of hybrid systems and to meet future requirements in this emerging field, we need to prepare a new generation of computer scientists with skills in both distributed computing and quantum computing. To bridge this existing gap in standard computer science curricula, we designed a new lecture and exercise series on Hybrid Quantum-Classical Systems, where students learn how to decompose applications and implement computational tasks on a hybrid quantum-classical computational continuum. While learning the inherent concepts underlying quantum systems, students are obligated to apply techniques and methods they are already familiar with, making the entrance to the field of quantum computing comprehensive yet appealing and accessible to students of computer science.","[{'name': 'Vincenzo De Maio, Meerzhan Kanatbekova, Felix Zilk, Nicolai Friis, Tobias Guggemos, Ivona Brandic'}]",
1199,Boosting the Efficiency of Quantum Divider through Effective Design Space Exploration,https://arxiv.org/abs/2403.01206,"arXiv:2403.01206v1 Announce Type: cross 
Abstract: Rapid progress in the design of scalable, robust quantum computing necessitates efficient quantum circuit implementation for algorithms with practical relevance. For several algorithms, arithmetic kernels, in particular, division plays an important role. In this manuscript, we focus on enhancing the performance of quantum slow dividers by exploring the design choices of its sub-blocks, such as, adders. Through comprehensive design space exploration of state-of-the-art quantum addition building blocks, our work have resulted in an impressive achievement: a reduction in Toffoli Depth of up to 94.06%, accompanied by substantial reductions in both Toffoli and Qubit Count of up to 91.98% and 99.37%, respectively. This paper offers crucial perspectives on efficient design of quantum dividers, and emphasizes the importance of adopting a systematic design space exploration approach.","[{'name': 'Siyi Wang, Eugene Lim, Anupam Chattopadhyay'}]",
1200,Efficient FIR filtering with Bit Layer Multiply Accumulator,https://arxiv.org/abs/2403.01351,"arXiv:2403.01351v1 Announce Type: cross 
Abstract: Bit Layer Multiplier Accumulator (BLMAC) is an efficient method to perform dot products without multiplications that exploits the bit level sparsity of the weights. A total of 1,980,000 low, high, band pass and band stop type I FIR filters were generated by systematically sweeping through the cut off frequencies and by varying the number of taps from 55 to 255. After their coefficients were quantized to 16 bits, applying the filter using a BLMAC required, on average, from ~123.3 to ~513.6 additions, depending on the number of taps. A BLMAC dot product machine, specialised for 127 taps FIR filters, was designed for AMD FPGAs. The design footprint is ~110 LUTs, including coefficient and sample storage and is able to apply the filter in ~232 clock cycles on average. This implies a filtering rate of 1.4-3.4 Msamples/s, depending on the FPGA family.",[{'name': 'Vincenzo Liguori'}],
1201,Spatially parallel decoding for multi-qubit lattice surgery,https://arxiv.org/abs/2403.01353,"arXiv:2403.01353v1 Announce Type: cross 
Abstract: Running quantum algorithms protected by quantum error correction requires a real time, classical decoder. To prevent the accumulation of a backlog, this decoder must process syndromes from the quantum device at a faster rate than they are generated. Most prior work on real time decoding has focused on an isolated logical qubit encoded in the surface code. However, for surface code, quantum programs of utility will require multi-qubit interactions performed via lattice surgery. A large merged patch can arise during lattice surgery -- possibly as large as the entire device. This puts a significant strain on a real time decoder, which must decode errors on this merged patch and maintain the level of fault-tolerance that it achieves on isolated logical qubits.
  These requirements are relaxed by using spatially parallel decoding, which can be accomplished by dividing the physical qubits on the device into multiple overlapping groups and assigning a decoder module to each. We refer to this approach as spatially parallel windows. While previous work has explored similar ideas, none have addressed system-specific considerations pertinent to the task or the constraints from using hardware accelerators. In this work, we demonstrate how to configure spatially parallel windows, so that the scheme (1) is compatible with hardware accelerators, (2) supports general lattice surgery operations, (3) maintains the fidelity of the logical qubits, and (4) meets the throughput requirement for real time decoding. Furthermore, our results reveal the importance of optimally choosing the buffer width to achieve a balance between accuracy and throughput -- a decision that should be influenced by the device's physical noise.","[{'name': 'Sophia Fuhui Lin, Eric C. Peterson, Krishanu Sankar, Prasahnt Sivarajah'}]",
1202,Quantum Computing: Vision and Challenges,https://arxiv.org/abs/2403.02240,"arXiv:2403.02240v1 Announce Type: cross 
Abstract: The recent development of quantum computing, which makes use of entanglement, superposition, and other quantum fundamental concepts, has the ability to provide substantial processing advantages over traditional computing. These quantum features help solve many hard problems that cannot be solved with traditional computing methods. These problems are in areas like modeling quantum mechanics, logistics, making chemical-based advances, designing drugs, statistical science, sustainable energy, banking, reliable communication, and quantum chemical engineering. The last few years have witnessed remarkable advancements in quantum software and algorithm creation as well as quantum hardware research, which have significantly advanced the prospect of the realization of quantum computers. It would be helpful to have comprehensive literature research on this area to grasp the current status and find outstanding problems that require considerable attention from the research community working in the quantum computing industry. To better understand quantum computing, this paper examines the foundations and vision based on current research in this area. We discuss cutting-edge developments in quantum computer hardware advancement, and subsequent advances in quantum cryptography, quantum software, and high-scalability quantum computers. Many potential challenges and exciting new trends for quantum technology research and development are highlighted in this paper for a wider debate.","[{'name': 'Sukhpal Singh Gill, Oktay Cetinkaya, Stefano Marrone, Elias F. Combarro, Daniel Claudino, David Haunschild, Leon Schlote, Huaming Wu, Carlo Ottaviani, Xiaoyuan Liu, Sree Pragna Machupalli, Kamalpreet Kaur, Priyansh Arora, Ji Liu, Salman Shamshad, Ahmed Farouk, Houbing Herbert Song, Steve Uhlig, Kotagiri Ramamohanarao'}]",
1203,MITS: A Quantum Sorcerer Stone For Designing Surface Codes,https://arxiv.org/abs/2402.11027,"arXiv:2402.11027v2 Announce Type: replace-cross 
Abstract: In the evolving landscape of quantum computing, determining the most efficient parameters for Quantum Error Correction (QEC) is paramount. Various quantum computers possess varied types and amounts of physical noise. Traditionally, simulators operate in a forward paradigm, taking parameters such as distance, rounds, and physical error to output a logical error rate. However, usage of maximum distance and rounds of the surface code might waste resources. An approach that relies on trial and error to fine-tune QEC code parameters using simulation tools like STIM can be exceedingly time-consuming. Additionally, daily fluctuations in quantum error rates can alter the ideal QEC settings needed. As a result, there is a crucial need for an automated solution that can rapidly determine the appropriate QEC parameters tailored to the current conditions. To bridge this gap, we present MITS, a tool designed to reverse-engineer the well-known simulator STIM for designing QEC codes. MITS accepts the specific noise model of a quantum computer and a target logical error rate as input and outputs the optimal surface code rounds and code distances. This guarantees minimal qubit and gate usage, harmonizing the desired logical error rate with the existing hardware limitations on qubit numbers and gate fidelity. We explored and compared multiple heuristics and machine learning models for training/designing MITS and concluded that XGBoost and Random Forest regression were most effective, with Pearson correlation coefficients of 0.98 and 0.96 respectively.","[{'name': 'Avimita Chatterjee, Debarshi Kundu, Swaroop Ghosh'}]",
1204,Q-Embroidery: A Study on Weaving Quantum Error Correction into the Fabric of Quantum Classifiers,https://arxiv.org/abs/2402.11127,"arXiv:2402.11127v3 Announce Type: replace-cross 
Abstract: Quantum computing holds transformative potential for various fields, yet its practical application is hindered by the susceptibility to errors. This study makes a pioneering contribution by applying quantum error correction codes (QECCs) for complex, multi-qubit classification tasks. We implement 1-qubit and 2-qubit quantum classifiers with QECCs, specifically the Steane code, and the distance 3 & 5 surface codes to analyze 2-dimensional and 4-dimensional datasets. This research uniquely evaluates the performance of these QECCs in enhancing the robustness and accuracy of quantum classifiers against various physical errors, including bit-flip, phase-flip, and depolarizing errors. The results emphasize that the effectiveness of a QECC in practical scenarios depends on various factors, including qubit availability, desired accuracy, and the specific types and levels of physical errors, rather than solely on theoretical superiority.","[{'name': 'Avimita Chatterjee, Debarshi Kundu, Swaroop Ghosh'}]",
1205,Teaching Quantum Computing with Videos,https://research.library.fordham.edu/cs_facultypubs/1,"<p>Quantum computing will likely change our world as we know it today. In bringing together fields such as quantum mechanics, mathematics, and computer science in their construction and application, quantum computers hold a promise of tremendous increase in processing power when compared to present day technology. For an educator, teaching this topic requires that consideration be given to the fact that quantum computing is not only based on hard-to-teach aspects of physics, math, and computing, but that quantum computing itself is still in the early stages of its development. What is certain is that concepts such as Shor’s and Grover’s algorithms have already been developed specifically for use with quantum computing. Both algorithms are the beneficiaries of quantum properties such as superposition and entanglement which are at the core of the new technology. This paper is presented in a bottom up structure starting with the explanation of the basic component, the qubit, before moving to superposition and entanglement and ending with a lucid explanation of both of the algorithms. Due to the complex nature of the topic, teaching this subject requires that certain measures be taken to teach all students at all levels and have them feel comfortable within themselves about the topic. The course is meant for anyone who wants to learn quantum computing. It is furthermore recommended that those attending have a blank slate so we start with new students. We would like to see a variety of students taking and passing the course, with that in mind, the explanations of the topics are done without employing an excessive amount of math common to other courses in quantum computing. The recommended approach for teaching is through the use of videos and a curriculum which is broken down so topics are made more general and the discussion of that effort is the main focus</p>",[{'name': 'Daniel A. Sabol et al.'}],"Thu, 25 Apr 2019 21:30:19 PDT"
1206,On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs,https://arxiv.org/abs/2403.00783,"arXiv:2403.00783v1 Announce Type: new 
Abstract: Plan synthesis aims to generate a course of actions or policies to transit given initial states to goal states, provided domain models that could be designed by experts or learnt from training data or interactions with the world. Intrigued by the claims of emergent planning capabilities in large language models (LLMs), works have been proposed to investigate the planning effectiveness of LLMs, without considering any utilization of off-the-shelf planning techniques in LLMs. In this paper, we aim to further study the insight of the planning capability of LLMs by investigating the roles of LLMs in off-the-shelf planning frameworks. To do this, we investigate the effectiveness of embedding LLMs into one of the well-known planning frameworks, graph-based planning, proposing a novel LLMs-based planning framework with LLMs embedded in two levels of planning graphs, i.e., mutual constraints generation level and constraints solving level. We empirically exhibit the effectiveness of our proposed framework in various planning domains.","[{'name': 'Hankz Hankui Zhuo, Xin Chen, Rong Pan'}]",
1207,A New Dynamic Distributed Planning Approach: Application to DPDP Problems,https://arxiv.org/abs/2403.00805,"arXiv:2403.00805v1 Announce Type: new 
Abstract: In this work, we proposed a new dynamic distributed planning approach that is able to take into account the changes that the agent introduces on his set of actions to be planned in order to take into account the changes that occur in his environment. Our approach fits into the context of distributed planning for distributed plans where each agent can produce its own plans. According to our approach the generation of the plans is based on the satisfaction of the constraints by the use of the genetic algorithms. Our approach is to generate, a new plan by each agent, whenever there is a change in its set of actions to plan. This in order to take into account the new actions introduced in its new plan. In this new plan, the agent takes, each time, as a new action set to plan all the old un-executed actions of the old plan and the new actions engendered by the changes and as a new initial state; the state in which the set of actions of the agent undergoes a change. In our work, we used a concrete case to illustrate and demonstrate the utility of our approach.",[{'name': 'Zakaria Tolba'}],
1208,Bootstrapping Cognitive Agents with a Large Language Model,https://arxiv.org/abs/2403.00810,"arXiv:2403.00810v1 Announce Type: new 
Abstract: Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. On the other hand cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent based entirely on large language models. Our experiments indicate that large language models are a good source of information for cognitive architectures, and the cognitive architecture in turn can verify and update the knowledge of large language models to a specific domain.","[{'name': 'Feiyu Zhu, Reid Simmons'}]",
1209,Cognitive Bias in High-Stakes Decision-Making with LLMs,https://arxiv.org/abs/2403.00811,"arXiv:2403.00811v1 Announce Type: new 
Abstract: Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across different commercial and open-source models. We demonstrate that our self-help debiasing effectively mitigate cognitive bias without having to manually craft examples for each bias type.","[{'name': 'Jessica Echterhoff, Yao Liu, Abeer Alessa, Julian McAuley, Zexue He'}]",
1210,Adapting to Teammates in a Cooperative Language Game,https://arxiv.org/abs/2403.00823,"arXiv:2403.00823v1 Announce Type: new 
Abstract: The game of Codenames has recently emerged as a domain of interest for intelligent agent design. The game is unique due to the way that language and coordination between teammates play important roles. Previous approaches to designing agents for this game have utilized a single internal language model to determine action choices. This often leads to good performance with some teammates and inferior performance with other teammates, as the agent cannot adapt to any specific teammate. In this paper we present the first adaptive agent for playing Codenames. We adopt an ensemble approach with the goal of determining, during the course of interacting with a specific teammate, which of our internal expert agents, each potentially with its own language model, is the best match. One difficulty faced in this approach is the lack of a single numerical metric that accurately captures the performance of a Codenames team. Prior Codenames research has utilized a handful of different metrics to evaluate agent teams. We propose a novel single metric to evaluate the performance of a Codenames team, whether playing a single team (solitaire) game, or a competitive game against another team. We then present and analyze an ensemble agent which selects an internal expert on each turn in order to maximize this proposed metric. Experimental analysis shows that this ensemble approach adapts to individual teammates and often performs nearly as well as the best internal expert with a teammate. Crucially, this success does not depend on any previous knowledge about the teammates, the ensemble agents, or their compatibility. This research represents an important step to making language-based agents for cooperative language settings like Codenames more adaptable to individual teammates.","[{'name': 'Christopher Archibald, Spencer Brosnahan'}]",
1211,TroubleLLM: Align to Red Team Expert,https://arxiv.org/abs/2403.00829,"arXiv:2403.00829v1 Announce Type: new 
Abstract: Large Language Models (LLMs) become the start-of-the-art solutions for a variety of natural language tasks and are integrated into real-world applications. However, LLMs can be potentially harmful in manifesting undesirable safety issues like social biases and toxic content. It is imperative to assess its safety issues before deployment. However, the quality and diversity of test prompts generated by existing methods are still far from satisfactory. Not only are these methods labor-intensive and require large budget costs, but the controllability of test prompt generation is lacking for the specific testing domain of LLM applications. With the idea of LLM for LLM testing, we propose the first LLM, called TroubleLLM, to generate controllable test prompts on LLM safety issues. Extensive experiments and human evaluation illustrate the superiority of TroubleLLM on generation quality and generation controllability.","[{'name': 'Zhuoer Xu, Jianping Zhang, Shiwen Cui, Changhua Meng, Weiqiang Wang'}]",
1212,MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices,https://arxiv.org/abs/2403.00830,"arXiv:2403.00830v1 Announce Type: new 
Abstract: Large language models (LLMs) are revolutionizing various domains with their remarkable natural language processing (NLP) abilities. However, deploying LLMs in resource-constrained edge computing and embedded systems presents significant challenges. Another challenge lies in delivering medical assistance in remote areas with limited healthcare facilities and infrastructure. To address this, we introduce MedAide, an on-premise healthcare chatbot. It leverages tiny-LLMs integrated with LangChain, providing efficient edge-based preliminary medical diagnostics and support. MedAide employs model optimizations for minimal memory footprint and latency on embedded edge devices without server infrastructure. The training process is optimized using low-rank adaptation (LoRA). Additionally, the model is trained on diverse medical datasets, employing reinforcement learning from human feedback (RLHF) to enhance its domain-specific capabilities. The system is implemented on various consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\\% accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an energy-efficient healthcare assistance platform that alleviates privacy concerns due to edge-based deployment, thereby empowering the community.","[{'name': 'Abdul Basit, Khizar Hussain, Muhammad Abdullah Hanif, Muhammad Shafique'}]",
1213,Position Paper: Agent AI Towards a Holistic Intelligence,https://arxiv.org/abs/2403.00833,"arXiv:2403.00833v1 Announce Type: new 
Abstract: Recent advancements in large foundation models have remarkably enhanced our understanding of sensory information in open-world environments. In leveraging the power of foundation models, it is crucial for AI research to pivot away from excessive reductionism and toward an emphasis on systems that function as cohesive wholes. Specifically, we emphasize developing Agent AI -- an embodied system that integrates large foundation models into agent actions. The emerging field of Agent AI spans a wide range of existing embodied and agent-based multimodal interactions, including robotics, gaming, and healthcare systems, etc. In this paper, we propose a novel large action model to achieve embodied intelligent behavior, the Agent Foundation Model. On top of this idea, we discuss how agent AI exhibits remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Furthermore, we discuss the potential of Agent AI from an interdisciplinary perspective, underscoring AI cognition and consciousness within scientific discourse. We believe that those discussions serve as a basis for future research directions and encourage broader societal engagement.","[{'name': 'Qiuyuan Huang, Naoki Wake, Bidipta Sarkar, Zane Durante, Ran Gong, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Noboru Kuno, Ade Famoti, Ashley Llorens, John Langford, Hoi Vo, Li Fei-Fei, Katsu Ikeuchi, Jianfeng Gao'}]",
1214,ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph,https://arxiv.org/abs/2403.00839,"arXiv:2403.00839v1 Announce Type: new 
Abstract: While achieving remarkable progress in a broad range of tasks, large language models (LLMs) remain significantly limited in properly using massive external tools. Existing in-context learning approaches simply format tools into a list of plain text descriptions and input them to LLMs, from which, LLMs generate a sequence of tool calls to solve problems step by step. Such a paradigm ignores the intrinsic dependency between tools and offloads all reasoning loads to LLMs, making them restricted to a limited number of specifically designed tools. It thus remains challenging for LLMs to operate on a library of massive tools, casting a great limitation when confronted with real-world scenarios. This paper proposes ToolNet, a plug-and-play framework that scales up the number of tools to thousands with a moderate increase in token consumption. ToolNet organizes tools into a directed graph. Each node represents a tool, and weighted edges denote tool transition. Starting from an initial tool node, an LLM navigates in the graph by iteratively choosing the next one from its successors until the task is resolved. Extensive experiments show that ToolNet can achieve impressive results in challenging multi-hop tool learning datasets and is resilient to tool failures.","[{'name': 'Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang, Yuchen Liu, Dongkuan Xu'}]",
1215,Team Formation amidst Conflicts,https://arxiv.org/abs/2403.00859,"arXiv:2403.00859v1 Announce Type: new 
Abstract: In this work, we formulate the problem of team formation amidst conflicts. The goal is to assign individuals to tasks, with given capacities, taking into account individuals' task preferences and the conflicts between them. Using dependent rounding schemes as our main toolbox, we provide efficient approximation algorithms. Our framework is extremely versatile and can model many different real-world scenarios as they arise in educational settings and human-resource management. We test and deploy our algorithms on real-world datasets and we show that our algorithms find assignments that are better than those found by natural baselines. In the educational setting we also show how our assignments are far better than those done manually by human experts. In the human resource management application we show how our assignments increase the diversity of teams. Finally, using a synthetic dataset we demonstrate that our algorithms scale very well in practice.","[{'name': 'Iasonas Nikolaou, Evimaria Terzi'}]",
1216,"Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights",https://arxiv.org/abs/2403.00861,"arXiv:2403.00861v1 Announce Type: new 
Abstract: Generative AI applications, such as ChatGPT or DALL-E, have shown the world their impressive capabilities in generating human-like text or image. Diving deeper, the science stakeholder for those AI applications are Deep Generative Models, a.k.a DGMs, which are designed to learn the underlying distribution of the data and generate new data points that are statistically similar to the original dataset. One critical question is raised: how can we leverage DGMs into morden retail supply chain realm? To address this question, this paper expects to provide a comprehensive review of DGMs and discuss their existing and potential usecases in retail supply chain, by (1) providing a taxonomy and overview of state-of-the-art DGMs and their variants, (2) reviewing existing DGM applications in retail supply chain from a end-to-end view of point, and (3) discussing insights and potential directions on how DGMs can be further utilized on solving retail supply chain problems.","[{'name': 'Yuan Wang, Lokesh Kumar Sambasivan, Mingang Fu, Prakhar Mehrotra'}]",
1217,The Algorithm Configuration Problem,https://arxiv.org/abs/2403.00898,"arXiv:2403.00898v1 Announce Type: new 
Abstract: The field of algorithmic optimization has significantly advanced with the development of methods for the automatic configuration of algorithmic parameters. This article delves into the Algorithm Configuration Problem, focused on optimizing parametrized algorithms for solving specific instances of decision/optimization problems. We present a comprehensive framework that not only formalizes the Algorithm Configuration Problem, but also outlines different approaches for its resolution, leveraging machine learning models and heuristic strategies. The article categorizes existing methodologies into per-instance and per-problem approaches, distinguishing between offline and online strategies for model construction and deployment. By synthesizing these approaches, we aim to provide a clear pathway for both understanding and addressing the complexities inherent in algorithm configuration.","[{'name': \"Gabriele Iommazzo, Claudia D'Ambrosio, Antonio Frangioni, Leo Liberti\"}]",
1218,Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using Counterfactuals As Guides?,https://arxiv.org/abs/2403.00980,"arXiv:2403.00980v1 Announce Type: new 
Abstract: Recently, counterfactuals using \"if-only\" explanations have become very popular in eXplainable AI (XAI), as they describe which changes to feature-inputs of a black-box AI system result in changes to a (usually negative) decision-outcome. Even more recently, semi-factuals using \"even-if\" explanations have gained more attention. They elucidate the feature-input changes that do \\textit{not} change the decision-outcome of the AI system, with a potential to suggest more beneficial recourses. Some semi-factual methods use counterfactuals to the query-instance to guide semi-factual production (so-called counterfactual-guided methods), whereas others do not (so-called counterfactual-free methods). In this work, we perform comprehensive tests of 8 semi-factual methods on 7 datasets using 5 key metrics, to determine whether counterfactual guidance is necessary to find the best semi-factuals. The results of these tests suggests not, but rather that computing other aspects of the decision space lead to better semi-factual XAI.","[{'name': 'Saugat Aryal, Mark T. Keane'}]",
1219,The Case for Animal-Friendly AI,https://arxiv.org/abs/2403.01199,"arXiv:2403.01199v1 Announce Type: new 
Abstract: Artificial intelligence is seen as increasingly important, and potentially profoundly so, but the fields of AI ethics and AI engineering have not fully recognized that these technologies, including large language models (LLMs), will have massive impacts on animals. We argue that this impact matters, because animals matter morally.
  As a first experiment in evaluating animal consideration in LLMs, we constructed a proof-of-concept Evaluation System, which assesses LLM responses and biases from multiple perspectives. This system evaluates LLM outputs by two criteria: their truthfulness, and the degree of consideration they give to the interests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using a set of structured queries and predefined normative perspectives. Preliminary results suggest that the outcomes of the tested models can be benchmarked regarding the consideration they give to animals, and that generated positions and biases might be addressed and mitigated with more developed and validated systems.
  Our research contributes one possible approach to integrating animal ethics in AI, opening pathways for future studies and practical applications in various fields, including education, public policy, and regulation, that involve or relate to animals and society. Overall, this study serves as a step towards more useful and responsible AI systems that better recognize and respect the vital interests and perspectives of all sentient beings.","[{'name': 'Sankalpa Ghose, Yip Fai Tse, Kasra Rasaee, Jeff Sebo, Peter Singer'}]",
1220,Soft Reasoning on Uncertain Knowledge Graphs,https://arxiv.org/abs/2403.01508,"arXiv:2403.01508v1 Announce Type: new 
Abstract: The study of machine learning-based logical query-answering enables reasoning with large-scale and incomplete knowledge graphs. This paper further advances this line of research by considering the uncertainty in the knowledge. The uncertain nature of knowledge is widely observed in the real world, but \\textit{does not} align seamlessly with the first-order logic underpinning existing studies. To bridge this gap, we study the setting of soft queries on uncertain knowledge, which is motivated by the establishment of soft constraint programming. We further propose an ML-based approach with both forward inference and backward calibration to answer soft queries on large-scale, incomplete, and uncertain knowledge graphs. Theoretical discussions present that our methods share the same complexity as state-of-the-art inference algorithms for first-order queries. Empirical results justify the superior performance of our approach against previous ML-based methods with number embedding extensions.","[{'name': 'Weizhi Fei, Zihao Wang, Hang Yin, Yang Duan, Hanghang Tong, Yangqiu Song'}]",
1221,How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems,https://arxiv.org/abs/2403.01757,"arXiv:2403.01757v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through extensive empirical studies focused on a well-known combinatorial optimization problem, i.e., capacitated vehicle routing problem. The results are compared against those obtained from the LLM-based optimization algorithms that rely solely on textual prompts, demonstrating the significant advantages of our multimodal approach.","[{'name': 'Yuxiao Huang, Wenjie Zhang, Liang Feng, Xingyu Wu, Kay Chen Tan'}]",
1222,CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text,https://arxiv.org/abs/2403.01784,"arXiv:2403.01784v1 Announce Type: new 
Abstract: Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. Evaluation based on such $\\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems. However, in this context, current evaluation methods are either limited in task coverage or lack standardization. To address this issue, we propose using category theory as a framework for evaluation. Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. We present an automatic evaluation framework called $\\textbf{CatCode}$ ($\\textbf{Cat}$egory $\\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, Text-Davinci, and CodeGeeX.","[{'name': 'Zhenru Lin, Yiqun Yao, Yang Yuan'}]",
1223,SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for Adaptive Real-Time Subtask Recognition,https://arxiv.org/abs/2403.01816,"arXiv:2403.01816v1 Announce Type: new 
Abstract: Instead of making behavioral decisions directly from the exponentially expanding joint observational-action space, subtask-based multi-agent reinforcement learning (MARL) methods enable agents to learn how to tackle different subtasks. Most existing subtask-based MARL methods are based on hierarchical reinforcement learning (HRL). However, these approaches often limit the number of subtasks, perform subtask recognition periodically, and can only identify and execute a specific subtask within the predefined fixed time period, which makes them inflexible and not suitable for diverse and dynamic scenarios with constantly changing subtasks. To break through above restrictions, a \\textbf{S}liding \\textbf{M}ultidimensional t\\textbf{A}sk window based m\\textbf{U}ti-agent reinforcement learnin\\textbf{G} framework (SMAUG) is proposed for adaptive real-time subtask recognition. It leverages a sliding multidimensional task window to extract essential information of subtasks from trajectory segments concatenated based on observed and predicted trajectories in varying lengths. An inference network is designed to iteratively predict future trajectories with the subtask-oriented policy network. Furthermore, intrinsic motivation rewards are defined to promote subtask exploration and behavior diversity. SMAUG can be integrated with any Q-learning-based approach. Experiments on StarCraft II show that SMAUG not only demonstrates performance superiority in comparison with all baselines but also presents a more prominent and swift rise in rewards during the initial training stage.","[{'name': 'Wenjing Zhang, Wei Zhang'}]",
1224,Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism,https://arxiv.org/abs/2403.01832,"arXiv:2403.01832v1 Announce Type: new 
Abstract: This paper delves into the contrasting roles of data within academic and industrial spheres, highlighting the divergence between Data-Centric AI and Model-Agnostic AI approaches. We argue that while Data-Centric AI focuses on the primacy of high-quality data for model performance, Model-Agnostic AI prioritizes algorithmic flexibility, often at the expense of data quality considerations. This distinction reveals that academic standards for data quality frequently do not meet the rigorous demands of industrial applications, leading to potential pitfalls in deploying academic models in real-world settings. Through a comprehensive analysis, we address these disparities, presenting both the challenges they pose and strategies for bridging the gap. Furthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which aims to reconcile these differences by integrating model considerations into data optimization processes. This approach underscores the necessity for evolving data requirements that are sensitive to the nuances of both academic research and industrial deployment. By exploring these discrepancies, we aim to foster a more nuanced understanding of data's role in AI development and encourage a convergence of academic and industrial standards to enhance AI's real-world applicability.","[{'name': 'Chanjun Park, Minsoo Khang, Dahyun Kim'}]",
1225,Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost Benchmarks,https://arxiv.org/abs/2403.01888,"arXiv:2403.01888v1 Announce Type: new 
Abstract: While deep learning has celebrated many successes, its results often hinge on the meticulous selection of hyperparameters (HPs). However, the time-consuming nature of deep learning training makes HP optimization (HPO) a costly endeavor, slowing down the development of efficient HPO tools. While zero-cost benchmarks, which provide performance and runtime without actual training, offer a solution for non-parallel setups, they fall short in parallel setups as each worker must communicate its queried runtime to return its evaluation in the exact order. This work addresses this challenge by introducing a user-friendly Python package that facilitates efficient parallel HPO with zero-cost benchmarks. Our approach calculates the exact return order based on the information stored in file system, eliminating the need for long waiting times and enabling much faster HPO evaluations. We first verify the correctness of our approach through extensive testing and the experiments with 6 popular HPO libraries show its applicability to diverse libraries and its ability to achieve over 1000x speedup compared to a traditional approach. Our package can be installed via pip install mfhpo-simulator.","[{'name': 'Shuhei Watanabe, Neeratyoy Mallik, Edward Bergman, Frank Hutter'}]",
1226,A Scoping Review of Energy-Efficient Driving Behaviors and Applied State-of-the-Art AI Methods,https://arxiv.org/abs/2403.02053,"arXiv:2403.02053v1 Announce Type: new 
Abstract: The transportation sector remains a major contributor to greenhouse gas emissions. The understanding of energy-efficient driving behaviors and utilization of energy-efficient driving strategies are essential to reduce vehicles' fuel consumption. However, there is no comprehensive investigation into energy-efficient driving behaviors and strategies. Furthermore, many state-of-the-art AI models have been applied for the analysis of eco-friendly driving styles, but no overview is available. To fill the gap, this paper conducts a thorough literature review on ecological driving behaviors and styles and analyzes the driving factors influencing energy consumption and state-of-the-art methodologies. With a thorough scoping review process, the methodological and related data are compared. The results show that the factors that impact driving behaviors can be summarized into eleven features including speed, acceleration, deceleration, pedal, and so on. This paper finds that supervised/unsupervised learning algorithms and reinforcement learning frameworks have been popularly used to model the vehicle's energy consumption with multi-dimensional data. Furthermore, the literature shows that the driving data are collected from either simulators or real-world experiments, and the real-world data are mainly stored and transmitted by meters, controller area networks, onboard data services, smartphones, and additional sensors installed in the vehicle. Based on driving behavior factors, driver characteristics, and safety rules, this paper recommends nine energy-efficient driving styles including four guidelines for the drivers' selection and adjustment of the vehicle parameters, three recommendations for the energy-efficient driving styles in different driving scenarios, and two subjective suggestions for different types of drivers and employers.","[{'name': 'Zhipeng Ma, Bo N{\\\\o}rregaard J{\\\\o}rgensen, Zheng Ma'}]",
1227,Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism,https://arxiv.org/abs/2403.02054,"arXiv:2403.02054v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers from LLMs and discuss method limitations and potential research directions.","[{'name': 'Shuvayan Brahmachary, Subodh M. Joshi, Aniruddha Panda, Kaushik Koneripalli, Arun Kumar Sagotra, Harshil Patel, Ankush Sharma, Ameya D. Jagtap, Kaushic Kalyanaraman'}]",
1228,Cognition is All You Need - The Next Layer of AI Above Large Language Models,https://arxiv.org/abs/2403.02164,"arXiv:2403.02164v1 Announce Type: new 
Abstract: Recent studies of the applications of conversational AI tools, such as chatbots powered by large language models, to complex real-world knowledge work have shown limitations related to reasoning and multi-step problem solving. Specifically, while existing chatbots simulate shallow reasoning and understanding they are prone to errors as problem complexity increases. The failure of these systems to address complex knowledge work is due to the fact that they do not perform any actual cognition. In this position paper, we present Cognitive AI, a higher-level framework for implementing programmatically defined neuro-symbolic cognition above and outside of large language models. Specifically, we propose a dual-layer functional architecture for Cognitive AI that serves as a roadmap for AI systems that can perform complex multi-step knowledge work. We propose that Cognitive AI is a necessary precursor for the evolution of higher forms of AI, such as AGI, and specifically claim that AGI cannot be achieved by probabilistic approaches on their own. We conclude with a discussion of the implications for large language models, adoption cycles in AI, and commercial Cognitive AI development.","[{'name': 'Nova Spivack, Sam Douglas, Michelle Crames, Tim Connors'}]",
1229,Koopman-Assisted Reinforcement Learning,https://arxiv.org/abs/2403.02290,"arXiv:2403.02290v1 Announce Type: new 
Abstract: The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman (HJB) equation, are ubiquitous in reinforcement learning (RL) and control theory. However, these equations quickly become intractable for systems with high-dimensional states and nonlinearity. This paper explores the connection between the data-driven Koopman operator and Markov Decision Processes (MDPs), resulting in the development of two new RL algorithms to address these limitations. We leverage Koopman operator techniques to lift a nonlinear system into new coordinates where the dynamics become approximately linear, and where HJB-based methods are more tractable. In particular, the Koopman operator is able to capture the expectation of the time evolution of the value function of a given system via linear dynamics in the lifted coordinates. By parameterizing the Koopman operator with the control actions, we construct a ``Koopman tensor'' that facilitates the estimation of the optimal value function. Then, a transformation of Bellman's framework in terms of the Koopman tensor enables us to reformulate two max-entropy RL algorithms: soft value iteration and soft actor-critic (SAC). This highly flexible framework can be used for deterministic or stochastic systems as well as for discrete or continuous-time dynamics. Finally, we show that these Koopman Assisted Reinforcement Learning (KARL) algorithms attain state-of-the-art (SOTA) performance with respect to traditional neural network-based SAC and linear quadratic regulator (LQR) baselines on four controlled dynamical systems: a linear state-space system, the Lorenz system, fluid flow past a cylinder, and a double-well potential with non-isotropic stochastic forcing.","[{'name': 'Preston Rozwood, Edward Mehrez, Ludger Paehler, Wen Sun, Steven L. Brunton'}]",
1230,An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots,https://arxiv.org/abs/2403.00765,"arXiv:2403.00765v1 Announce Type: cross 
Abstract: As data science applications gain adoption across industries, the tooling landscape matures to facilitate the life cycle of such applications and provide solutions to the challenges involved to boost the productivity of the people involved. Reinforcement learning with agents in a 3D world could still face challenges: the knowledge required to use a simulation software as well as the utilization of a standalone simulation software in unattended training pipelines.
  In this paper we review tools and approaches to train reinforcement learning agents for robots in 3D worlds with respect to the robot Robotino and argue that the separation of the simulation environment for creators of virtual worlds and the model development environment for data scientists is not a well covered topic. Often both are the same and data scientists require knowledge of the simulation software to work directly with their APIs. Moreover, sometimes creators of virtual worlds and data scientists even work on the same files. We want to contribute to that topic by describing an approach where data scientists don't require knowledge about the simulation software. Our approach uses the standalone simulation software Webots, the Robot Operating System to communicate with simulated robots as well as the simulation software itself and container technology to separate the simulation from the model development environment. We put emphasize on the APIs the data scientists work with and the use of a standalone simulation software in unattended training pipelines. We show the parts that are specific to the Robotino and the robot task to learn.","[{'name': 'Tobias Haubold, Petra Linke'}]",
1231,Do Weibo platform experts perform better at predicting stock market?,https://arxiv.org/abs/2403.00772,"arXiv:2403.00772v1 Announce Type: cross 
Abstract: Sentiment analysis can be used for stock market prediction. However, existing research has not studied the impact of a user's financial background on sentiment-based forecasting of the stock market using artificial neural networks. In this work, a novel combination of neural networks is used for the assessment of sentiment-based stock market prediction, based on the financial background of the population that generated the sentiment. The state-of-the-art language processing model Bidirectional Encoder Representations from Transformers (BERT) is used to classify the sentiment and a Long-Short Term Memory (LSTM) model is used for time-series based stock market prediction. For evaluation, the Weibo social networking platform is used as a sentiment data collection source. Weibo users (and their comments respectively) are divided into Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor (UFA) groups according to their background information, as collected by Weibo. The Hong Kong Hang Seng index is used to extract historical stock market change data. The results indicate that stock market prediction learned from the AFA group users is 39.67% more precise than that learned from the UFA group users and shows the highest accuracy (87%) when compared to existing approaches.","[{'name': 'Ziyuan Ma, Conor Ryan, Jim Buckley, Muslim Chochlov'}]",
1232,Empirical and Experimental Insights into Data Mining Techniques for Crime Prediction: A Comprehensive Survey,https://arxiv.org/abs/2403.00780,"arXiv:2403.00780v1 Announce Type: cross 
Abstract: This survey paper presents a comprehensive analysis of crime prediction methodologies, exploring the various techniques and technologies utilized in this area. The paper covers the statistical methods, machine learning algorithms, and deep learning techniques employed to analyze crime data, while also examining their effectiveness and limitations. We propose a methodological taxonomy that classifies crime prediction algorithms into specific techniques. This taxonomy is structured into four tiers, including methodology category, methodology sub-category, methodology techniques, and methodology sub-techniques. Empirical and experimental evaluations are provided to rank the different techniques. The empirical evaluation assesses the crime prediction techniques based on four criteria, while the experimental evaluation ranks the algorithms that employ the same sub-technique, the different sub-techniques that employ the same technique, the different techniques that employ the same methodology sub-category, the different methodology sub-categories within the same category, and the different methodology categories. The combination of methodological taxonomy, empirical evaluations, and experimental comparisons allows for a nuanced and comprehensive understanding of crime prediction algorithms, aiding researchers in making informed decisions. Finally, the paper provides a glimpse into the future of crime prediction techniques, highlighting potential advancements and opportunities for further research in this field",[{'name': 'Kamal Taha'}],
1233,ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework,https://arxiv.org/abs/2403.00781,"arXiv:2403.00781v1 Announce Type: cross 
Abstract: The profound impact of food on health necessitates advanced nutrition-oriented food recommendation services. Conventional methods often lack the crucial elements of personalization, explainability, and interactivity. While Large Language Models (LLMs) bring interpretability and explainability, their standalone use falls short of achieving true personalization. In this paper, we introduce ChatDiet, a novel LLM-powered framework designed specifically for personalized nutrition-oriented food recommendation chatbots. ChatDiet integrates personal and population models, complemented by an orchestrator, to seamlessly retrieve and process pertinent information. The result is a dynamic delivery of personalized and explainable food recommendations, tailored to individual user preferences. Our evaluation of ChatDiet includes a compelling case study, where we establish a causal personal model to estimate individual nutrition effects. Our assessments, including a food recommendation test showcasing a 92\\% effectiveness rate, coupled with illustrative dialogue examples, underscore ChatDiet's strengths in explainability, personalization, and interactivity.","[{'name': 'Zhongqi Yang, Elahe Khatibi, Nitish Nagesh, Mahyar Abbasian, Iman Azimi, Ramesh Jain, Amir M. Rahmani'}]",
1234,Ploutos: Towards interpretable stock movement prediction with financial large language model,https://arxiv.org/abs/2403.00782,"arXiv:2403.00782v1 Announce Type: cross 
Abstract: Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverage rearview-mirror prompting mechanism to guide GPT-4 to generate rationales, and a dynamic token weighting mechanism to finetune LLM by increasing key tokens weight. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and interpretability.","[{'name': 'Hanshuang Tong, Jun Li, Ning Wu, Ming Gong, Dongmei Zhang, Qi Zhang'}]",
1235,"Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges",https://arxiv.org/abs/2403.00784,"arXiv:2403.00784v1 Announce Type: cross 
Abstract: Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. A key highlight of our survey is the comparison between BERT's encoder-based models and the latest generative Large Language Models (LLMs), such as ChatGPT, which rely on decoders. Despite the popularity of LLMs, we find that for specific tasks, finely tuned BERT encoders still outperform, and at a lower deployment cost. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.","[{'name': 'Jiajia Wang, Jimmy X. Huang, Xinhui Tu, Junmei Wang, Angela J. Huang, Md Tahmid Rahman Laskar, Amran Bhuiyan'}]",
1236,"PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care",https://arxiv.org/abs/2403.00788,"arXiv:2403.00788v1 Announce Type: cross 
Abstract: This study introduces and evaluates the PRECISE framework, utilizing OpenAI's GPT-4 to enhance patient engagement by providing clearer and more accessible chest X-ray reports at a sixth-grade reading level. The framework was tested on 500 reports, demonstrating significant improvements in readability, reliability, and understandability. Statistical analyses confirmed the effectiveness of the PRECISE approach, highlighting its potential to foster patient-centric care delivery in healthcare decision-making.","[{'name': 'Satvik Tripathi, Liam Mutter, Meghana Muppuri, Suhani Dheer, Emiliano Garza-Frias, Komal Awan, Aakash Jha, Michael Dezube, Azadeh Tabari, Christopher P. Bridge, Dania Daye'}]",
1237,Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations,https://arxiv.org/abs/2403.00790,"arXiv:2403.00790v1 Announce Type: cross 
Abstract: In this paper, we explore the intriguing similarities between the structure of a discrete neural network, such as a spiking network, and the composition of a piano piece. While both involve nodes or notes that are activated sequentially or in parallel, the latter benefits from the rich body of music theory to guide meaningful combinations. We propose a novel approach that leverages musical grammar to regulate activations in a spiking neural network, allowing for the representation of symbols as attractors. By applying rules for chord progressions from music theory, we demonstrate how certain activations naturally follow others, akin to the concept of attraction. Furthermore, we introduce the concept of modulating keys to navigate different basins of attraction within the network. Ultimately, we show that the map of concepts in our model is structured by the musical circle of fifths, highlighting the potential for leveraging music theory principles in deep learning algorithms.",[{'name': 'Tofara Moyo'}],
1238,$\\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024,https://arxiv.org/abs/2403.00791,"arXiv:2403.00791v1 Announce Type: cross 
Abstract: Language-molecule models have emerged as an exciting direction for molecular discovery and understanding. However, training these models is challenging due to the scarcity of molecule-language pair datasets. At this point, datasets have been released which are 1) small and scraped from existing databases, 2) large but noisy and constructed by performing entity linking on the scientific literature, and 3) built by converting property prediction datasets to natural language using templates. In this document, we detail the $\\textit{L+M-24}$ dataset, which has been created for the Language + Molecules Workshop shared task at ACL 2024. In particular, $\\textit{L+M-24}$ is designed to focus on three key benefits of natural language in molecule design: compositionality, functionality, and abstraction.","[{'name': 'Carl Edwards, Qingyun Wang, Lawrence Zhao, Heng Ji'}]",
1239,Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models,https://arxiv.org/abs/2403.00794,"arXiv:2403.00794v1 Announce Type: cross 
Abstract: Humor is a fundamental facet of human cognition and interaction. Yet, despite recent advances in natural language processing, humor detection remains a challenging task that is complicated by the scarcity of datasets that pair humorous texts with similar non-humorous counterparts. In our work, we investigate whether large language models (LLMs), can generate synthetic data for humor detection via editing texts. We benchmark LLMs on an existing human dataset and show that current LLMs display an impressive ability to `unfun' jokes, as judged by humans and as measured on the downstream task of humor detection. We extend our approach to a code-mixed English-Hindi humor dataset, where we find that GPT-4's synthetic data is highly rated by bilingual annotators and provides challenging adversarial examples for humor classifiers.","[{'name': 'Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen McKeown'}]",
1240,Executing Natural Language-Described Algorithms with Large Language Models: An Investigation,https://arxiv.org/abs/2403.00795,"arXiv:2403.00795v1 Announce Type: cross 
Abstract: Executing computer programs described in natural language has long been a pursuit of computer science. With the advent of enhanced natural language understanding capabilities exhibited by large language models (LLMs), the path toward this goal has been illuminated. In this paper, we seek to examine the capacity of present-day LLMs to comprehend and execute algorithms outlined in natural language. We established an algorithm test set sourced from Introduction to Algorithm, a well-known textbook that contains many representative widely-used algorithms. To systematically assess LLMs' code execution abilities, we selected 30 algorithms, generated 300 random-sampled instances in total, and evaluated whether popular LLMs can understand and execute these algorithms. Our findings reveal that LLMs, notably GPT-4, can effectively execute programs described in natural language, as long as no heavy numeric computation is involved. We believe our findings contribute to evaluating LLMs' code execution abilities and would encourage further investigation and application for the computation power of LLMs.","[{'name': 'Xin Zheng, Qiming Zhu, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun'}]",
1241,Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes: Functional and Augmented Data Structures in Financial Forecasting,https://arxiv.org/abs/2403.00796,"arXiv:2403.00796v1 Announce Type: cross 
Abstract: In this paper, we explore the application of Gaussian Processes (GPs) for predicting mean-reverting time series with an underlying structure, using relatively unexplored functional and augmented data structures. While many conventional forecasting methods concentrate on the short-term dynamics of time series data, GPs offer the potential to forecast not just the average prediction but the entire probability distribution over a future trajectory. This is particularly beneficial in financial contexts, where accurate predictions alone may not suffice if incorrect volatility assessments lead to capital losses. Moreover, in trade selection, GPs allow for the forecasting of multiple Sharpe ratios adjusted for transaction costs, aiding in decision-making. The functional data representation utilized in this study enables longer-term predictions by leveraging information from previous years, even as the forecast moves away from the current year's training data. Additionally, the augmented representation enriches the training set by incorporating multiple targets for future points in time, facilitating long-term predictions. Our implementation closely aligns with the methodology outlined in, which assessed effectiveness on commodity futures. However, our testing methodology differs. Instead of real data, we employ simulated data with similar characteristics. We construct a testing environment to evaluate both data representations and models under conditions of increasing noise, fat tails, and inappropriate kernels-conditions commonly encountered in practice. By simulating data, we can compare our forecast distribution over time against a full simulation of the actual distribution of our test set, thereby reducing the inherent uncertainty in testing time series models on real data. We enable feature prediction through augmentation and employ sub-sampling to ensure the feasibility of GPs.",[{'name': 'Narayan Tondapu'}],
1242,An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning,https://arxiv.org/abs/2403.00799,"arXiv:2403.00799v1 Announce Type: cross 
Abstract: Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available at https://github.com/cyzhh/MMOS.","[{'name': 'Zui Chen, Yezeng Chen, Jiaqi Han, Zhijie Huang, Ji Qi, Yi Zhou'}]",
1243,Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes,https://arxiv.org/abs/2403.00800,"arXiv:2403.00800v1 Announce Type: cross 
Abstract: Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at https://github.com/cyzhh/Brain.","[{'name': 'Yezeng Chen, Zui Chen, Yi Zhou'}]",
1244,Towards a Theoretical Understanding of Two-Stage Recommender Systems,https://arxiv.org/abs/2403.00802,"arXiv:2403.00802v1 Announce Type: cross 
Abstract: Production-grade recommender systems rely heavily on a large-scale corpus used by online media services, including Netflix, Pinterest, and Amazon. These systems enrich recommendations by learning users' and items' embeddings projected in a low-dimensional space with two-stage models (two deep neural networks), which facilitate their embedding constructs to predict users' feedback associated with items. Despite its popularity for recommendations, its theoretical behaviors remain comprehensively unexplored. We study the asymptotic behaviors of the two-stage recommender that entail a strong convergence to the optimal recommender system. We establish certain theoretical properties and statistical assurance of the two-stage recommender. In addition to asymptotic behaviors, we demonstrate that the two-stage recommender system attains faster convergence by relying on the intrinsic dimensions of the input features. Finally, we show numerically that the two-stage recommender enables encapsulating the impacts of items' and users' attributes on ratings, resulting in better performance compared to existing methods conducted using synthetic and real-world data experiments.",[{'name': 'Amit Kumar Jaiswal'}],
1245,LiMAML: Personalization of Deep Recommender Models via Meta Learning,https://arxiv.org/abs/2403.00803,"arXiv:2403.00803v1 Announce Type: cross 
Abstract: In the realm of recommender systems, the ubiquitous adoption of deep neural networks has emerged as a dominant paradigm for modeling diverse business objectives. As user bases continue to expand, the necessity of personalization and frequent model updates have assumed paramount significance to ensure the delivery of relevant and refreshed experiences to a diverse array of members. In this work, we introduce an innovative meta-learning solution tailored to the personalization of models for individual members and other entities, coupled with the frequent updates based on the latest user interaction signals. Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to adapt per-task sub-networks using recent user interaction data. Given the near infeasibility of productionizing original MAML-based models in online recommendation systems, we propose an efficient strategy to operationalize meta-learned sub-networks in production, which involves transforming them into fixed-sized vectors, termed meta embeddings, thereby enabling the seamless deployment of models with hundreds of billions of parameters for online serving. Through extensive experimentation on production data drawn from various applications at LinkedIn, we demonstrate that the proposed solution consistently outperforms the baseline models of those applications, including strong baselines such as using wide-and-deep ID based personalization approach. Our approach has enabled the deployment of a range of highly personalized AI models across diverse LinkedIn applications, leading to substantial improvements in business metrics as well as refreshed experience for our members.","[{'name': 'Ruofan Wang, Prakruthi Prabhakar, Gaurav Srivastava, Tianqi Wang, Zeinab S. Jalali, Varun Bharill, Yunbo Ouyang, Aastha Nigam, Divya Venugopalan, Aman Gupta, Fedor Borisyuk, Sathiya Keerthi, Ajith Muralidharan'}]",
1246,Uncovering Customer Issues through Topological Natural Language Analysis,https://arxiv.org/abs/2403.00804,"arXiv:2403.00804v1 Announce Type: cross 
Abstract: E-commerce companies deal with a high volume of customer service requests daily. While a simple annotation system is often used to summarize the topics of customer contacts, thoroughly exploring each specific issue can be challenging. This presents a critical concern, especially during an emerging outbreak where companies must quickly identify and address specific issues. To tackle this challenge, we propose a novel machine learning algorithm that leverages natural language techniques and topological data analysis to monitor emerging and trending customer issues. Our approach involves an end-to-end deep learning framework that simultaneously tags the primary question sentence of each customer's transcript and generates sentence embedding vectors. We then whiten the embedding vectors and use them to construct an undirected graph. From there, we define trending and emerging issues based on the topological properties of each transcript. We have validated our results through various methods and found that they are highly consistent with news sources.","[{'name': 'Shu-Ting Pi, Sidarth Srinivasan, Yuying Zhu, Michael Yang, Qun Liu'}]",
1247,IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model,https://arxiv.org/abs/2403.00808,"arXiv:2403.00808v1 Announce Type: cross 
Abstract: Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model (IPED), an innovative approach for extracting relational triples. Our classifier-free solution adopts an implicit strategy using block coverage to complete the tables, avoiding the limitations of explicit tagging methods. Additionally, we introduce a generative model structure, the block-denoising diffusion model, to collaborate with our implicit perspective and effectively circumvent redundant information disruptions. Experimental results on two popular datasets demonstrate that IPED achieves state-of-the-art performance while gaining superior inference speed and low computational complexity. To support future research, we have made our source code publicly available online.","[{'name': 'Jianli Zhao, Changhao Xu, Bin Jiang'}]",
1248,"Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT",https://arxiv.org/abs/2403.00809,"arXiv:2403.00809v1 Announce Type: cross 
Abstract: This study introduces a dedicated model aimed at solving the BRAINTEASER task 9 , a novel challenge designed to assess models lateral thinking capabilities through sentence and word puzzles. Our model demonstrates remarkable efficacy, securing Rank 1 in sentence puzzle solving during the test phase with an overall score of 0.98. Additionally, we explore the comparative performance of ChatGPT, specifically analyzing how variations in temperature settings affect its ability to engage in lateral thinking and problem-solving. Our findings indicate a notable performance disparity between the dedicated model and ChatGPT, underscoring the potential of specialized approaches in enhancing creative reasoning in AI.","[{'name': 'Abdelhak Kelious, Mounir Okirim'}]",
1249,LoRA Meets Dropout under a Unified Framework,https://arxiv.org/abs/2403.00812,"arXiv:2403.00812v1 Announce Type: cross 
Abstract: With the remarkable capabilities, large language models (LLMs) have emerged as essential elements in numerous NLP applications, while parameter-efficient finetuning, especially LoRA, has gained popularity as a lightweight approach for model customization. Meanwhile, various dropout methods, initially designed for full finetuning with all the parameters updated, alleviates overfitting associated with excessive parameter redundancy. Hence, a possible contradiction arises from negligible trainable parameters of LoRA and the effectiveness of previous dropout methods, which has been largely overlooked. To fill this gap, we first confirm that parameter-efficient LoRA is also overfitting-prone. We then revisit transformer-specific dropout methods, and establish their equivalence and distinctions mathematically and empirically. Building upon this comparative analysis, we introduce a unified framework for a comprehensive investigation, which instantiates these methods based on dropping position, structural pattern and compensation measure. Through this framework, we reveal the new preferences and performance comparisons of them when involved with limited trainable parameters. This framework also allows us to amalgamate the most favorable aspects into a novel dropout method named HiddenKey. Extensive experiments verify the remarkable superiority and sufficiency of HiddenKey across multiple models and tasks, which highlights it as the preferred approach for high-performance and parameter-efficient finetuning of LLMs.","[{'name': 'Sheng Wang, Liheng Chen, Jiyue Jiang, Boyang Xue, Lingpeng Kong, Chuan Wu'}]",
1250,UrbanGPT: Spatio-Temporal Large Language Models,https://arxiv.org/abs/2403.00813,"arXiv:2403.00813v1 Announce Type: cross 
Abstract: Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. Consequently, it becomes necessary to build a spatio-temporal model with strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce.","[{'name': 'Zhonghang Li, Lianghao Xia, Jiabin Tang, Yong Xu, Lei Shi, Long Xia, Dawei Yin, Chao Huang'}]",
1251,RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records,https://arxiv.org/abs/2403.00815,"arXiv:2403.00815v1 Announce Type: cross 
Abstract: We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \\url{https://github.com/ritaranx/RAM-EHR}.","[{'name': 'Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Bowen Jin, May D. Wang, Joyce C. Ho, Carl Yang'}]",
1252,CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering,https://arxiv.org/abs/2403.00816,"arXiv:2403.00816v1 Announce Type: cross 
Abstract: Document Visual Question Answering (DVQA) is a task that involves responding to queries based on the content of images. Existing work is limited to locating information within a single page and does not facilitate cross-page question-and-answer interaction. Furthermore, the token length limitation imposed on inputs to the model may lead to truncation of segments pertinent to the answer. In this study, we introduce a simple but effective methodology called CFRet-DVQA, which focuses on retrieval and efficient tuning to address this critical issue effectively. For that, we initially retrieve multiple segments from the document that correlate with the question at hand. Subsequently, we leverage the advanced reasoning abilities of the large language model (LLM), further augmenting its performance through instruction tuning. This approach enables the generation of answers that align with the style of the document labels. The experiments demonstrate that our methodology achieved state-of-the-art or competitive results with both single-page and multi-page documents in various fields.","[{'name': 'Jinxu Zhang, Yongqi Yu, Yu Zhang'}]",
1253,InteraRec: Interactive Recommendations Using Multimodal Large Language Models,https://arxiv.org/abs/2403.00822,"arXiv:2403.00822v1 Announce Type: cross 
Abstract: Weblogs, comprised of records detailing user activities on any website, offer valuable insights into user preferences, behavior, and interests. Numerous recommendation algorithms, employing strategies such as collaborative filtering, content-based filtering, and hybrid methods, leverage the data mined through these weblogs to provide personalized recommendations to users. Despite the abundance of information available in these weblogs, identifying and extracting pertinent information and key features necessitates extensive engineering endeavors. The intricate nature of the data also poses a challenge for interpretation, especially for non-experts. In this study, we introduce a sophisticated and interactive recommendation framework denoted as InteraRec, which diverges from conventional approaches that exclusively depend on weblogs for recommendation generation. This framework captures high-frequency screenshots of web pages as users navigate through a website. Leveraging state-of-the-art multimodal large language models (MLLMs), it extracts valuable insights into user preferences from these screenshots by generating a user behavioral summary based on predefined keywords. Subsequently, this summary is utilized as input to an LLM-integrated optimization setup to generate tailored recommendations. Through our experiments, we demonstrate the effectiveness of InteraRec in providing users with valuable and personalized offerings.","[{'name': 'Saketh Reddy Karra, Theja Tulabandhula'}]",
1254,Information Flow Routes: Automatically Interpreting Language Models at Scale,https://arxiv.org/abs/2403.00824,"arXiv:2403.00824v1 Announce Type: cross 
Abstract: Information flows by routes inside the network via mechanisms implemented in the model. These routes can be represented as graphs where nodes correspond to token representations and edges to operations inside the network. We automatically build these graphs in a top-down manner, for each prediction leaving only the most important nodes and edges. In contrast to the existing workflows relying on activation patching, we do this through attribution: this allows us to efficiently uncover existing circuits with just a single forward pass. Additionally, the applicability of our method is far beyond patching: we do not need a human to carefully design prediction templates, and we can extract information flow routes for any prediction (not just the ones among the allowed templates). As a result, we can talk about model behavior in general, for specific types of predictions, or different domains. We experiment with Llama 2 and show that the role of some attention heads is overall important, e.g. previous token heads and subword merging heads. Next, we find similarities in Llama 2 behavior when handling tokens of the same part of speech. Finally, we show that some model components can be specialized on domains such as coding or multilingual texts.","[{'name': 'Javier Ferrando, Elena Voita'}]",
1255,Self-Refinement of Language Models from External Proxy Metrics Feedback,https://arxiv.org/abs/2403.00827,"arXiv:2403.00827v1 Announce Type: cross 
Abstract: It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning Llama-2-13B-Chat on the synthetic dialogue data generated by ProMiSe yields significant performance improvements over the zero-shot baseline as well as a supervised fine-tuned model on human annotated data.","[{'name': \"Keshav Ramji, Young-Suk Lee, Ram\\\\'on Fernandez Astudillo, Md Arafat Sultan, Tahira Naseem, Asim Munawar, Radu Florian, Salim Roukos\"}]",
1256,Deep Learning Detection Method for Large Language Models-Generated Scientific Content,https://arxiv.org/abs/2403.00828,"arXiv:2403.00828v1 Announce Type: cross 
Abstract: Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models have the potential to generate scientific content that is indistinguishable from that written by humans. Hence, LLMs carry severe consequences for the scientific community, which relies on the integrity and reliability of publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. AI-Catcher is a multimodal model that fuses hidden patterns derived from MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset is collected to enhance AI-generated text detection tools, AIGTxt. AIGTxt contains 3000 records collected from published academic articles across ten domains and divided into three classes: Human-written, ChatGPT-generated, and Mixed text. Several experiments are conducted to evaluate the performance of AI-Catcher. The comparative results demonstrate the capability of AI-Catcher to distinguish between human-written and ChatGPT-generated scientific text more accurately than alternative methods. On average, AI-Catcher improved accuracy by 37.4%.","[{'name': 'Bushra Alhijawi, Rawan Jarrar, Aseel AbuAlRub, Arwa Bader'}]",
1257,Explainable Session-based Recommendation via Path Reasoning,https://arxiv.org/abs/2403.00832,"arXiv:2403.00832v1 Announce Type: cross 
Abstract: This paper explores providing explainability for session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting point for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR, and introduce path midpoint reward to enhance the exploration efficiency in knowledge graphs. To improve the completeness of the knowledge graph and to diversify the paths of explanation, we incorporate extracted feature information from images into the knowledge graph. We instantiate PR4SR in five state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and compare it with other explainable SR frameworks, to demonstrate the effectiveness of PR4SR for recommendation and explanation tasks through extensive experiments with these approaches on four datasets.","[{'name': 'Yang Cao, Shuo Shang, Jun Wang, Wei Zhang'}]",
1258,Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics,https://arxiv.org/abs/2403.00834,"arXiv:2403.00834v1 Announce Type: cross 
Abstract: Generative Artificial Intelligence (AI) models can propose solutions to scientific problems beyond human capability. To truly make conceptual contributions, researchers need to be capable of understanding the AI-generated structures and extracting the underlying concepts and ideas. When algorithms provide little explanatory reasoning alongside the output, scientists have to reverse-engineer the fundamental insights behind proposals based solely on examples. This task can be challenging as the output is often highly complex and thus not immediately accessible to humans. In this work we show how transferring part of the analysis process into an immersive Virtual Reality (VR) environment can assist researchers in developing an understanding of AI-generated solutions. We demonstrate the usefulness of VR in finding interpretable configurations of abstract graphs, representing Quantum Optics experiments. Thereby, we can manually discover new generalizations of AI-discoveries as well as new understanding in experimental quantum optics. Furthermore, it allows us to customize the search space in an informed way - as a human-in-the-loop - to achieve significantly faster subsequent discovery iterations. As concrete examples, with this technology, we discover a new resource-efficient 3-dimensional entanglement swapping scheme, as well as a 3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our results show the potential of VR for increasing a human researcher's ability to derive knowledge from graph-based generative AI that, which is a common abstract data representation used in diverse fields of science.","[{'name': 'Philipp Schmidt, S\\\\\"oren Arlt, Carlos Ruiz-Gonzalez, Xuemei Gu, Carla Rodr\\\\\\'iguez, Mario Krenn'}]",
1259,CLLMs: Consistency Large Language Models,https://arxiv.org/abs/2403.00835,"arXiv:2403.00835v1 Announce Type: cross 
Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\\times$ to 3.4$\\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.","[{'name': 'Siqi Kou, Lanxiang Hu, Zhezhi He, Zhijie Deng, Hao Zhang'}]",
1260,EyeGPT: Ophthalmic Assistant with Large Language Models,https://arxiv.org/abs/2403.00840,"arXiv:2403.00840v1 Announce Type: cross 
Abstract: Artificial intelligence (AI) has gained significant attention in healthcare consultation due to its potential to improve clinical workflow and enhance medical communication. However, owing to the complex nature of medical information, large language models (LLM) trained with general world knowledge might not possess the capability to tackle medical-related tasks at an expert level. Here, we introduce EyeGPT, a specialized LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In particular, we proposed a comprehensive evaluation framework that encompasses a diverse dataset, covering various subspecialties of ophthalmology, different users, and diverse inquiry intents. Moreover, we considered multiple evaluation metrics, including accuracy, understandability, trustworthiness, empathy, and the proportion of hallucinations. By assessing the performance of different EyeGPT variants, we identify the most effective one, which exhibits comparable levels of understandability, trustworthiness, and empathy to human ophthalmologists (all Ps>0.05). Overall, ur study provides valuable insights for future research, facilitating comprehensive comparisons and evaluations of different strategies for developing specialized LLMs in ophthalmology. The potential benefits include enhancing the patient experience in eye care and optimizing ophthalmologists' services.","[{'name': 'Xiaolan Chen, Ziwei Zhao, Weiyi Zhang, Pusheng Xu, Le Gao, Mingpu Xu, Yue Wu, Yinwen Li, Danli Shi, Mingguang He'}]",
1261,Offline Fictitious Self-Play for Competitive Games,https://arxiv.org/abs/2403.00841,"arXiv:2403.00841v1 Announce Type: cross 
Abstract: Offline Reinforcement Learning (RL) has received significant interest due to its ability to improve policies in previously collected datasets without online interactions. Despite its success in the single-agent setting, offline multi-agent RL remains a challenge, especially in competitive games. Firstly, unaware of the game structure, it is impossible to interact with the opponents and conduct a major learning paradigm, self-play, for competitive games. Secondly, real-world datasets cannot cover all the state and action space in the game, resulting in barriers to identifying Nash equilibrium (NE). To address these issues, this paper introduces Off-FSP, the first practical model-free offline RL algorithm for competitive games. We start by simulating interactions with various opponents by adjusting the weights of the fixed dataset with importance sampling. This technique allows us to learn best responses to different opponents and employ the Offline Self-Play learning framework. In this framework, we further implement Fictitious Self-Play (FSP) to approximate NE. In partially covered real-world datasets, our methods show the potential to approach NE by incorporating any single-agent offline RL method. Experimental results in Leduc Hold'em Poker show that our method significantly improves performances compared with state-of-the-art baselines.","[{'name': 'Jingxiao Chen, Weiji Xie, Weinan Zhang, Yong yu, Ying Wen'}]",
1262,Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning,https://arxiv.org/abs/2403.00843,"arXiv:2403.00843v1 Announce Type: cross 
Abstract: Traditional recommendation setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the recommendation decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite Reinforcement Learning (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of recommendation data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch.
  In this context, we propose to leverage the remarkable planning capabilities over sparse data of Large Language Models (LLMs) for long-term recommendation. The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized recommendation scenarios, as the model's pre-training may not naturally encompass these principles, necessitating the need to inspire or teach the model. To achieve this, we propose a Bi-level Learnable LLM Planner framework, which combines macro-learning and micro-learning through a hierarchical mechanism. The framework includes a Planner and Reflector for acquiring high-level guiding principles and an Actor-Critic component for planning personalization. Extensive experiments validate the superiority of the framework in learning to plan for long-term recommendations.","[{'name': 'Wentao Shi, Xiangnan He, Yang Zhang, Chongming Gao, Xinyue Li, Jizhi Zhang, Qifan Wang, Fuli Feng'}]",
1263,Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning,https://arxiv.org/abs/2403.00854,"arXiv:2403.00854v1 Announce Type: cross 
Abstract: Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of dysarthric speech. We evaluated on the Universal Access Speech dataset using leave-one-speaker-out cross-validation, our model demonstrated superior performance over traditional machine learning approaches, with an accuracy of $70.48\\%$ and an F1 score of $59.23\\%$. Our SALR model also exceeded the previous benchmark for AI-based classification, which used support vector machines, by $16.58\\%$. We open the black box of our model by visualising the latent space where we can observe how the model substantially reduces speaker-specific cues and amplifies task-specific ones, thereby showing its robustness. In conclusion, SALR establishes a new benchmark in speaker-independent multi-class dysarthria severity classification using generative AI. The potential implications of our findings for broader clinical applications in automated dysarthria severity assessments.","[{'name': 'Lauren Stumpf, Balasundaram Kadirvelu, Sigourney Waibel, A. Aldo Faisal'}]",
1264,Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs,https://arxiv.org/abs/2403.00858,"arXiv:2403.00858v1 Announce Type: cross 
Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional alignment procedure. For the finetuning step, we use instruction-response pairs generated by target model for distillation in plausible data distribution, and propose a new Total Variation Distance++ (TVD++) loss that incorporates variance reduction techniques inspired from the policy gradient method in reinforcement learning. Our empirical results show that Llama 2 Chat Drafter 115M with speculative decoding achieves up to 2.3 block efficiency and 2.4$\\times$ speed-up relative to autoregressive decoding on various tasks with no further task-specific fine-tuning.","[{'name': 'Raghavv Goel, Mukul Gagrani, Wonseok Jeon, Junyoung Park, Mingu Lee, Christopher Lott'}]",
1265,Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions,https://arxiv.org/abs/2403.00860,"arXiv:2403.00860v1 Announce Type: cross 
Abstract: A feedforward neural network using rectified linear units constructs a mapping from inputs to outputs by partitioning its input space into a set of convex regions where points within a region share a single affine transformation. In order to understand how neural networks work, when and why they fail, and how they compare to biological intelligence, we need to understand the organization and formation of these regions. Step one is to design and implement algorithms for exact region enumeration in networks beyond toy examples.
  In this work, we present parallel algorithms for exact enumeration in deep (and shallow) neural networks. Our work has three main contributions: (1) we present a novel algorithm framework and parallel algorithms for region enumeration; (2) we implement one of our algorithms on a variety of network architectures and experimentally show how the number of regions dictates runtime; and (3) we show, using our algorithm's output, how the dimension of a region's affine transformation impacts further partitioning of the region by deeper layers.
  To our knowledge, we run our implemented algorithm on networks larger than all of the networks used in the existing region enumeration literature. Further, we experimentally demonstrate the importance of parallelism for region enumeration of any reasonably sized network.","[{'name': 'Sabrina Drammis, Bowen Zheng, Karthik Srinivasan, Robert C. Berwick, Nancy A. Lynch, Robert Ajemian'}]",
1266,NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications,https://arxiv.org/abs/2403.00862,"arXiv:2403.00862v1 Announce Type: cross 
Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 11 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safety considerations.","[{'name': 'Miao Li, Ming-Bin Chen, Bo Tang, Shengbin Hou, Pengyu Wang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Keming Mao, Peng Cheng, Yi Luo'}]",
1267,LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction,https://arxiv.org/abs/2403.00863,"arXiv:2403.00863v1 Announce Type: cross 
Abstract: Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality recommendations and enhancing customer satisfaction. The recently emerging Large Language Models (LLMs) have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different LLMs due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single LLM dominating all others. Considering the diverse strengths and weaknesses of LLMs, it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called LLM-ensemble to ensemble different LLMs' outputs for attribute value extraction. We iteratively learn the weights for different LLMs to aggregate the labels with weights to predict the final attribute value. Not only can our proposed method be proven theoretically optimal, but it also ensures efficient computation, fast convergence, and safe deployment. We have also conducted extensive experiments with various state-of-the-art LLMs, including Llama2-13B, Llama2-70B, PaLM-2, GPT-3.5, and GPT-4, on Walmart's internal data. Our offline metrics demonstrate that the LLM-ensemble method outperforms all the state-of-the-art single LLMs on Walmart's internal dataset. This method has been launched in several production models, leading to improved Gross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate (CVR), and Add-to-Cart Rate (ATC).","[{'name': 'Chenhao Fang, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Kaushiki Nag, Evren Korpeoglu, Sushant Kumar, Kannan Achan'}]",
1268,Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning,https://arxiv.org/abs/2403.00865,"arXiv:2403.00865v1 Announce Type: cross 
Abstract: In this paper, we develop upon the topic of loss function learning, an emergent meta-learning paradigm that aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for task and model-agnostic loss function learning via a hybrid search approach. The framework first uses genetic programming to find a set of symbolic loss functions. Second, the set of learned loss functions is subsequently parameterized and optimized via unrolled differentiation. The versatility and performance of the proposed framework are empirically validated on a diverse set of supervised learning tasks. Results show that the learned loss functions bring improved convergence, sample efficiency, and inference performance on tabulated, computer vision, and natural language processing problems, using a variety of task-specific neural network architectures.","[{'name': 'Christian Raymond, Qi Chen, Bing Xue, Mengjie Zhang'}]",
1269,Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes,https://arxiv.org/abs/2403.00867,"arXiv:2403.00867v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can significantly improve the LLM's rejection capability for malicious jailbreak queries, while maintaining the model's performance for benign user queries by adjusting the detection threshold.","[{'name': 'Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho'}]",
1270,SoftTiger: A Clinical Foundation Model for Healthcare Workflows,https://arxiv.org/abs/2403.00868,"arXiv:2403.00868v1 Announce Type: cross 
Abstract: We release and introduce SoftTiger, a clinical large language model (CLaM) designed as a foundation model for healthcare workflows. The narrative and unstructured nature of clinical notes is a major obstacle for healthcare intelligentization. We address a critical problem of structuring clinical notes into clinical data, according to international interoperability standards. We collect and annotate data for three critical subtasks, namely, international patient summary, clinical impression and medical encounter. We then supervised fine-tuned a state-of-the-art LLM using public and credentialed clinical data. The training is orchestrated in a way that the target model can first support basic clinical tasks such as abbreviation expansion and temporal information extraction, and then learn to perform more complex downstream clinical tasks such as impression and encounter summary. Moreover, we address, several modeling challenges in the healthcare context, e.g., extra long context window. Our blind pairwise evaluation shows that SoftTiger outperforms other popular open-source models and GPT-3.5, comparable to Gemini-pro, and only has a mild gap from GPT-4. We believe that LLMs may become a step-stone towards healthcare digitalization and democratization. Therefore, we publicly release SoftTiger models at scales of 13 billion and 70 billion parameters, as well as datasets and code for our innovative scalable evaluation, hopefully, making a significant contribution to the healthcare industry.","[{'name': 'Ye Chen, Igor Couto, Wei Cai, Cong Fu, Bruno Dorneles'}]",
1271,Teach LLMs to Phish: Stealing Private Information from Language Models,https://arxiv.org/abs/2403.00871,"arXiv:2403.00871v1 Announce Type: cross 
Abstract: When large language models are trained on private data, it can be a significant privacy risk for them to memorize and regurgitate sensitive information. In this work, we propose a new practical data extraction attack that we call \"neural phishing\". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%. Our attack assumes only that an adversary can insert as few as 10s of benign-appearing sentences into the training dataset using only vague priors on the structure of the user data.","[{'name': 'Ashwinee Panda, Christopher A. Choquette-Choo, Zhengming Zhang, Yaoqing Yang, Prateek Mittal'}]",
1272,DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases,https://arxiv.org/abs/2403.00872,"arXiv:2403.00872v1 Announce Type: cross 
Abstract: The task of converting natural language queries into SQL queries is intricate, necessitating a blend of precise techniques for an accurate translation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a significant development in this domain. This paper introduces DFIN (Decomposed Focused-In-Context), an innovative extension of DIN-SQL that enhances Text-to-SQL conversion by addressing schema linking errors, which are a major source of inaccuracies. DFIN uniquely alternates between prompting techniques and Retrieval-Augmented Generation (RAG), adapting to the size and complexity of the database schema. A preprocessing phase embeds database definitions and leverages annotated files, akin to those in the BIRD dataset, facilitating the runtime retrieval of pertinent schema information. This strategy significantly reduces the token count for schema linking prompts, enabling the use of a standard GPT-4 model over its larger context variant, thus handling large-scale databases more effectively and economically. Our evaluation on the BIRD dataset, a challenging real-world benchmark, demonstrates that DFIN not only scales efficiently but also improves accuracy, achieving a score of 51.69. This improvement surpasses DIN-SQL method (the current third-place), which is the highest-ranked model employing in-context learning rather than fine-tuning, previously scoring 50.72. The advancement of DFIN underscores the evolving capabilities of in-context learning methodologies combined with advanced language models, offering a promising avenue for future research in complex Text-to-SQL conversion tasks.","[{'name': 'Shai Volvovsky, Marco Marcassa, Mustafa Panbiharwala'}]",
1273,Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions,https://arxiv.org/abs/2403.00875,"arXiv:2403.00875v1 Announce Type: cross 
Abstract: Augmentation is an effective alternative to utilize the small amount of labeled protein data. However, most of the existing work focuses on design-ing new architectures or pre-training tasks, and relatively little work has studied data augmentation for proteins. This paper extends data augmentation techniques previously used for images and texts to proteins and then benchmarks these techniques on a variety of protein-related tasks, providing the first comprehensive evaluation of protein augmentation. Furthermore, we propose two novel semantic-level protein augmentation methods, namely Integrated Gradients Substitution and Back Translation Substitution, which enable protein semantic-aware augmentation through saliency detection and biological knowledge. Finally, we integrate extended and proposed augmentations into an augmentation pool and propose a simple but effective framework, namely Automated Protein Augmentation (APA), which can adaptively select the most suitable augmentation combinations for different tasks. Extensive experiments have shown that APA enhances the performance of five protein related tasks by an average of 10.55% across three architectures compared to vanilla implementations without augmentation, highlighting its potential to make a great impact on the field.","[{'name': 'Rui Sun, Lirong Wu, Haitao Lin, Yufei Huang, Stan Z. Li'}]",
1274,Word Order and World Knowledge,https://arxiv.org/abs/2403.00876,"arXiv:2403.00876v1 Announce Type: cross 
Abstract: Word order is an important concept in natural language, and in this work, we study how word order affects the induction of world knowledge from raw text using language models. We use word analogies to probe for such knowledge. Specifically, in addition to the natural word order, we first respectively extract texts of six fixed word orders from five languages and then pretrain the language models on these texts. Finally, we analyze the experimental results of the fixed word orders on word analogies and show that i) certain fixed word orders consistently outperform or underperform others, though the specifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in pre-trained language models, and the natural word order typically yields mediocre results. The source code will be made publicly available at https://github.com/lshowway/probing_by_analogy.","[{'name': 'Qinghua Zhao, Vinit Ravishankar, Nicolas Garneau, Anders S{\\\\o}gaard'}]",
1275,Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models,https://arxiv.org/abs/2403.00878,"arXiv:2403.00878v1 Announce Type: cross 
Abstract: We introduces Crimson, a system that enhances the strategic reasoning capabilities of Large Language Models (LLMs) within the realm of cybersecurity. By correlating CVEs with MITRE ATT&amp;CK techniques, Crimson advances threat anticipation and strategic defense efforts. Our approach includes defining and evaluating cybersecurity strategic tasks, alongside implementing a comprehensive human-in-the-loop data-synthetic workflow to develop the CVE-to-ATT&amp;CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning abilities through a novel Retrieval-Aware Training (RAT) process and its refined iteration, RAT-R.
  Our findings demonstrate that an LLM fine-tuned with our techniques, possessing 7 billion parameters, approaches the performance level of GPT-4, showing markedly lower rates of hallucination and errors, and surpassing other models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of embedding models significantly improves performance within cybersecurity contexts, underscoring the efficacy of our methodology. By leveraging Crimson to convert raw vulnerability data into structured and actionable insights, we bolster proactive cybersecurity defenses.","[{'name': 'Jiandong Jin, Bowen Tang, Mingxuan Ma, Xiao Liu, Yunfei Wang, Qingnan Lai, Jia Yang, Changling Zhou'}]",
1276,Dual-Granularity Medication Recommendation Based on Causal Inference,https://arxiv.org/abs/2403.00880,"arXiv:2403.00880v1 Announce Type: cross 
Abstract: As medical demands grow and machine learning technology advances, AI-based diagnostic and treatment systems are garnering increasing attention. Medication recommendation aims to integrate patients' long-term health records with medical knowledge, recommending accuracy and safe medication combinations for specific conditions. However, most existing researches treat medication recommendation systems merely as variants of traditional recommendation systems, overlooking the heterogeneity between medications and diseases. To address this challenge, we propose DGMed, a framework for medication recommendation. DGMed utilizes causal inference to uncover the connections among medical entities and presents an innovative feature alignment method to tackle heterogeneity issues. Specifically, this study first applies causal inference to analyze the quantified therapeutic effects of medications on specific diseases from historical records, uncovering potential links between medical entities. Subsequently, we integrate molecular-level knowledge, aligning the embeddings of medications and diseases within the molecular space to effectively tackle their heterogeneity. Ultimately, based on relationships at the entity level, we adaptively adjust the recommendation probabilities of medication and recommend medication combinations according to the patient's current health condition. Experimental results on a real-world dataset show that our method surpasses existing state-of-the-art baselines in four evaluation metrics, demonstrating superior performance in both accuracy and safety aspects. Compared to the sub-optimal model, our approach improved accuracy by 4.40%, reduced the risk of side effects by 6.14%, and increased time efficiency by 47.15%.","[{'name': 'Shunpan Liang, Xiang Li, Xiang Li, Chen Li, Yu Lei, Yulei Hou, Tengfei Ma'}]",
1277,Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment,https://arxiv.org/abs/2403.00884,"arXiv:2403.00884v1 Announce Type: cross 
Abstract: Traditional dataset retrieval systems index on metadata information rather than on the data values. Thus relying primarily on manual annotations and high-quality metadata, processes known to be labour-intensive and challenging to automate. We propose a method to support metadata enrichment with topic annotations of column headers using three Large Language Models (LLMs): ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to classify column headers based on domain-specific topics from a controlled vocabulary. We evaluate our approach by assessing the internal consistency of the LLMs, the inter-machine alignment, and the human-machine agreement for the topic classification task. Additionally, we investigate the impact of contextual information (i.e. dataset description) on the classification outcomes. Our results suggest that ChatGPT and GoogleGemini outperform GoogleBard for internal consistency as well as LLM-human-alignment. Interestingly, we found that context had no impact on the LLMs performances. This work proposes a novel approach that leverages LLMs for text classification using a controlled topic vocabulary, which has the potential to facilitate automated metadata enrichment, thereby enhancing dataset retrieval and the Findability, Accessibility, Interoperability and Reusability (FAIR) of research data on the Web.","[{'name': 'Margherita Martorana, Tobias Kuhn, Lise Stork, Jacco van Ossenbruggen'}]",
1278,"SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech",https://arxiv.org/abs/2403.00887,"arXiv:2403.00887v1 Announce Type: cross 
Abstract: The interpretation of human voices holds importance across various applications. This study ventures into predicting age, gender, and emotion from vocal cues, a field with vast applications. Voice analysis tech advancements span domains, from improving customer interactions to enhancing healthcare and retail experiences. Discerning emotions aids mental health, while age and gender detection are vital in various contexts. Exploring deep learning models for these predictions involves comparing single, multi-output, and sequential models highlighted in this paper. Sourcing suitable data posed challenges, resulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work showed promise in individual predictions, but limited research considered all three variables simultaneously. This paper identifies flaws in an individual model approach and advocates for our novel multi-output learning architecture Speech-based Emotion Gender and Age Analysis (SEGAA) model. The experiments suggest that Multi-output models perform comparably to individual models, efficiently capturing the intricate relationships between variables and speech inputs, all while achieving improved runtime.","[{'name': 'Aron R, Indra Sigicharla, Chirag Periwal, Mohanaprasad K, Nithya Darisini P S, Sourabh Tiwari, Shivani Arora'}]",
1279,Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks,https://arxiv.org/abs/2403.00890,"arXiv:2403.00890v1 Announce Type: cross 
Abstract: Generative Adversarial Networks (GANs) have demonstrated their versatility across various applications, including data augmentation and malware detection. This research explores the effectiveness of utilizing GAN-generated data to train a model for the detection of Android malware. Given the considerable storage requirements of Android applications, the study proposes a method to synthetically represent data using GANs, thereby reducing storage demands. The proposed methodology involves creating image representations of features extracted from an existing dataset. A GAN model is then employed to generate a more extensive dataset consisting of realistic synthetic grayscale images. Subsequently, this synthetic dataset is utilized to train a Convolutional Neural Network (CNN) designed to identify previously unseen Android malware applications. The study includes a comparative analysis of the CNN's performance when trained on real images versus synthetic images generated by the GAN. Furthermore, the research explores variations in performance between the Wasserstein Generative Adversarial Network (WGAN) and the Deep Convolutional Generative Adversarial Network (DCGAN). The investigation extends to studying the impact of image size and malware obfuscation on the classification model's effectiveness. The data augmentation approach implemented in this study resulted in a notable performance enhancement of the classification model, ranging from 1.5% to 7%, depending on the dataset. The achieved F1 score reached 97.5%. Keywords--Generative Adversarial Networks, Android Malware, Data Augmentation, Wasserstein Generative Adversarial Network","[{'name': 'Kawana Stalin, Mikias Berhanu Mekoya'}]",
1280,A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder,https://arxiv.org/abs/2403.00891,"arXiv:2403.00891v1 Announce Type: cross 
Abstract: Information extraction (IE) aims to extract complex structured information from the text. Numerous datasets have been constructed for various IE tasks, leading to time-consuming and labor-intensive data annotations. Nevertheless, most prevailing methods focus on training task-specific models, while the common knowledge among different IE tasks is not explicitly modeled. Moreover, the same phrase may have inconsistent labels in different tasks, which poses a big challenge for knowledge transfer using a unified model. In this study, we propose a regularization-based transfer learning method for IE (TIE) via an instructed graph decoder. Specifically, we first construct an instruction pool for datasets from all well-known IE tasks, and then present an instructed graph decoder, which decodes various complex structures into a graph uniformly based on corresponding instructions. In this way, the common knowledge shared with existing datasets can be learned and transferred to a new dataset with new labels. Furthermore, to alleviate the label inconsistency problem among various IE tasks, we introduce a task-specific regularization strategy, which does not update the gradients of two tasks with 'opposite direction'. We conduct extensive experiments on 12 datasets spanning four IE tasks, and the results demonstrate the great advantages of our proposed method","[{'name': 'Kedi Chen, Jie Zhou, Qin Chen, Shunyu Liu, Liang He'}]",
1281,A systematic evaluation of large language models for generating programming code,https://arxiv.org/abs/2403.00894,"arXiv:2403.00894v1 Announce Type: cross 
Abstract: We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.","[{'name': 'Wenpin Hou, Zhicheng Ji'}]",
1282,End-to-end Graph-Sequential Representation Learning for Accurate Recommendations,https://arxiv.org/abs/2403.00895,"arXiv:2403.00895v1 Announce Type: cross 
Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.","[{'name': 'Vladimir Baikalov, Evgeny Frolov'}]",
1283,DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models,https://arxiv.org/abs/2403.00896,"arXiv:2403.00896v1 Announce Type: cross 
Abstract: Since large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, numerous benchmarks are proposed to detect the hallucination. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dialogue-level hallucination evaluation benchmark to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two ChatGPT3.5. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-machine interaction scenarios. Finally, professional scholars annotate all the samples in the dataset. DiaHalu covers four common multi-turn dialogue domains and five hallucination subtypes, extended from factuality and faithfulness hallucination. Experiments through some well-known LLMs and detection methods on the dataset show that DiaHalu is a challenging benchmark, holding significant value for further research.","[{'name': 'Kedi Chen, Qin Chen, Jie Zhou, Yishen He, Liang He'}]",
1284,VisRec: A Semi-Supervised Approach to Radio Interferometric Data Reconstruction,https://arxiv.org/abs/2403.00897,"arXiv:2403.00897v1 Announce Type: cross 
Abstract: Radio telescopes produce visibility data about celestial objects, but these data are sparse and noisy. As a result, images created on raw visibility data are of low quality. Recent studies have used deep learning models to reconstruct visibility data to get cleaner images. However, these methods rely on a substantial amount of labeled training data, which requires significant labeling effort from radio astronomers. Addressing this challenge, we propose VisRec, a model-agnostic semi-supervised learning approach to the reconstruction of visibility data. Specifically, VisRec consists of both a supervised learning module and an unsupervised learning module. In the supervised learning module, we introduce a set of data augmentation functions to produce diverse training examples. In comparison, the unsupervised learning module in VisRec augments unlabeled data and uses reconstructions from non-augmented visibility data as pseudo-labels for training. This hybrid approach allows VisRec to effectively leverage both labeled and unlabeled data. This way, VisRec performs well even when labeled data is scarce. Our evaluation results show that VisRec outperforms all baseline methods in reconstruction quality, robustness against common observation perturbation, and generalizability to different telescope configurations.","[{'name': 'Ruoqi Wang, Haitao Wang, Qiong Luo, Feng Wang, Hejun Wu'}]",
1285,PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning,https://arxiv.org/abs/2403.00929,"arXiv:2403.00929v1 Announce Type: cross 
Abstract: Imitation learning has shown great potential for enabling robots to acquire complex manipulation behaviors. However, these algorithms suffer from high sample complexity in long-horizon tasks, where compounding errors accumulate over the task horizons. We present PRIME (PRimitive-based IMitation with data Efficiency), a behavior primitive-based framework designed for improving the data efficiency of imitation learning. PRIME scaffolds robot tasks by decomposing task demonstrations into primitive sequences, followed by learning a high-level control policy to sequence primitives through imitation learning. Our experiments demonstrate that PRIME achieves a significant performance improvement in multi-stage manipulation tasks, with 10-34% higher success rates in simulation over state-of-the-art baselines and 20-48% on physical hardware.","[{'name': 'Tian Gao, Soroush Nasiriany, Huihan Liu, Quantao Yang, Yuke Zhu'}]",
1286,Scale-free Adversarial Reinforcement Learning,https://arxiv.org/abs/2403.00930,"arXiv:2403.00930v1 Announce Type: cross 
Abstract: This paper initiates the study of scale-free learning in Markov Decision Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We design a generic algorithmic framework, \\underline{S}cale \\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we achieve the first minimax optimal expected regret bound and the first high-probability regret bound in scale-free adversarial MABs, resolving an open problem raised in \\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth to the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ high-probability regret guarantee.","[{'name': 'Mingyu Chen, Xuezhou Zhang'}]",
1287,Resilience of Entropy Model in Distributed Neural Networks,https://arxiv.org/abs/2403.00942,"arXiv:2403.00942v1 Announce Type: cross 
Abstract: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks can increase the communication overhead by up to 95%. By separating compression features in frequency and spatial domain, we propose a new defense mechanism that can reduce the transmission overhead of the attacked input by about 9% compared to unperturbed data, with only about 2% accuracy loss. Importantly, the proposed defense mechanism is a standalone approach which can be applied in conjunction with approaches such as adversarial training to further improve robustness. Code will be shared for reproducibility.","[{'name': 'Milin Zhang, Mohammad Abdi, Shahriar Rifat, Francesco Restuccia'}]",
1288,AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models,https://arxiv.org/abs/2403.00953,"arXiv:2403.00953v1 Announce Type: cross 
Abstract: Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper.
  Materials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction.
  Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, symptom_and_sign: 46.1%, anaphor: 67.5%) and an overall relation extraction F1 score of 38.6% (produces: 34.7%, increases_risk_of: 12.4%, is_a: 37.4%, is_acronym: 44.1%, is_synonym: 16.3%, anaphora: 57.5%). Our qualitative experiment also demonstrates that the performance in constructing the knowledge graph is commendable.
  Discussion: AutoRD demonstrates the potential of LLM applications in rare disease detection. This improvement is attributed to several design, including the integration of ontologies-enhanced LLMs.
  Conclusion: AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs. It uses ontologies-enhanced LLMs for a robust medical knowledge base. The superior performance of AutoRD is validated by experimental evaluations, demonstrating the potential of LLMs in healthcare.","[{'name': 'Lang Cao, Jimeng Sun, Adam Cross'}]",
1289,Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients,https://arxiv.org/abs/2403.00965,"arXiv:2403.00965v1 Announce Type: cross 
Abstract: The Center for Disease Control estimates that over 37 million US adults suffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals are unaware of their condition due to the absence of symptoms in the early stages. It has a significant impact on patients' quality of life, particularly when it progresses to the need for dialysis. Early prediction of dialysis is crucial as it can significantly improve patient outcomes and assist healthcare providers in making timely and informed decisions. However, developing an effective machine learning (ML)-based Clinical Decision Support System (CDSS) for early dialysis prediction poses a key challenge due to the imbalanced nature of data. To address this challenge, this study evaluates various data augmentation techniques to understand their effectiveness on real-world datasets. We propose a new approach named Binary Gaussian Copula Synthesis (BGCS). BGCS is tailored for binary medical datasets and excels in generating synthetic minority data that mirrors the distribution of the original data. BGCS enhances early dialysis prediction by outperforming traditional methods in detecting dialysis patients. For the best ML model, Random Forest, BCGS achieved a 72% improvement, surpassing the state-of-the-art augmentation approaches. Also, we present a ML-based CDSS, designed to aid clinicians in making informed decisions. CDSS, which utilizes decision tree models, is developed to improve patient outcomes, identify critical variables, and thereby enable clinicians to make proactive decisions, and strategize treatment plans effectively for CKD patients who are more likely to require dialysis in the near future. Through comprehensive feature analysis and meticulous data preparation, we ensure that the CDSS's dialysis predictions are not only accurate but also actionable, providing a valuable tool in the management and treatment of CKD.","[{'name': 'Hamed Khosravi, Srinjoy Das, Abdullah Al-Mamun, Imtiaz Ahmed'}]",
1290,Equipment Health Assessment: Time Series Analysis for Wind Turbine Performance,https://arxiv.org/abs/2403.00975,"arXiv:2403.00975v1 Announce Type: cross 
Abstract: In this study, we leverage SCADA data from diverse wind turbines to predict power output, employing advanced time series methods, specifically Functional Neural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key innovation lies in the ensemble of FNN and LSTM models, capitalizing on their collective learning. This ensemble approach outperforms individual models, ensuring stable and accurate power output predictions. Additionally, machine learning techniques are applied to detect wind turbine performance deterioration, enabling proactive maintenance strategies and health assessment. Crucially, our analysis reveals the uniqueness of each wind turbine, necessitating tailored models for optimal predictions. These insight underscores the importance of providing automatized customization for different turbines to keep human modeling effort low. Importantly, the methodologies developed in this analysis are not limited to wind turbines; they can be extended to predict and optimize performance in various machinery, highlighting the versatility and applicability of our research across diverse industrial contexts.","[{'name': 'Jana Backhus, Aniruddha Rajendra Rao, Chandrasekar Venkatraman, Abhishek Padmanabhan, A. Vinoth Kumar, Chetan Gupta'}]",
1291,Merging Text Transformer Models from Different Initializations,https://arxiv.org/abs/2403.00986,"arXiv:2403.00986v1 Announce Type: cross 
Abstract: Recent work on one-shot permutation-based model merging has shown impressive low- or zero-barrier mode connectivity between models from completely different initializations. However, this line of work has not yet extended to the Transformer architecture, despite its dominant popularity in the language domain. Therefore, in this work, we investigate the extent to which separate Transformer minima learn similar features, and propose a model merging technique to investigate the relationship between these minima in the loss landscape. The specifics of the architecture, like its residual connections, multi-headed attention, and discrete, sequential input, require specific interventions in order to compute model permutations that remain within the same functional equivalence class. In merging these models with our method, we consistently find lower loss barriers between minima compared to model averaging for several models trained on a masked-language modeling task or fine-tuned on a language understanding benchmark. Our results show that the minima of these models are less sharp and isolated than previously understood, and provide a basis for future work on merging separately trained Transformer models.","[{'name': 'Neha Verma, Maha Elbayad'}]",
1292,On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games,https://arxiv.org/abs/2403.00993,"arXiv:2403.00993v1 Announce Type: cross 
Abstract: In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.
  In this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing classical models as special cases. We show that this leads to a richer analysis of sequential decision-making problems and enables more tailored algorithm design. In particular, we characterize the \"complexity\" of the observable dynamics of any sequential decision-making problem through a graph-theoretic analysis of the DAG representation of its information structure. The central quantity in this analysis is the minimal set of variables that $d$-separates the past observations from future observations. Furthermore, through constructing a generalization of predictive state representations, we propose tailored reinforcement learning algorithms and prove that the sample complexity is in part determined by the information structure. This recovers known tractability results and gives a novel perspective on reinforcement learning in general sequential decision-making problems, providing a systematic way of identifying new tractable classes of problems.","[{'name': 'Awni Altabaa, Zhuoran Yang'}]",
1293,Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language,https://arxiv.org/abs/2403.00994,"arXiv:2403.00994v1 Announce Type: cross 
Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of gists of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-based LLMs in identifying critical online discussion patterns that can form the basis of public health communication strategies.","[{'name': 'Xiaohan Ding, Buse Carik, Uma Sushmitha Gunturi, Valerie Reyna, Eugenia H. Rho'}]",
1294,Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries,https://arxiv.org/abs/2403.01002,"arXiv:2403.01002v1 Announce Type: cross 
Abstract: Summarizing clinical text is crucial in health decision-support and clinical research. Large language models (LLMs) have shown the potential to generate accurate clinical text summaries, but still struggle with issues regarding grounding and evaluation, especially in safety-critical domains such as health. Holistically evaluating text summaries is challenging because they may contain unsubstantiated information. Here, we explore a general mitigation framework using Attribute Structuring (AS), which structures the summary evaluation process. It decomposes the evaluation process into a grounded procedure that uses an LLM for relatively simple structuring and scoring tasks, rather than the full task of holistic summary evaluation. Experiments show that AS consistently improves the correspondence between human annotations and automated metrics in clinical text summarization. Additionally, AS yields interpretations in the form of a short text span corresponding to each output, which enables efficient human auditing, paving the way towards trustworthy evaluation of clinical information in resource-constrained scenarios. We release our code, prompts, and an open-source benchmark at https://github.com/microsoft/attribute-structuring.","[{'name': 'Zelalem Gero, Chandan Singh, Yiqing Xie, Sheng Zhang, Tristan Naumann, Jianfeng Gao, Hoifung Poon'}]",
1295,FlaKat: A Machine Learning-Based Categorization Framework for Flaky Tests,https://arxiv.org/abs/2403.01003,"arXiv:2403.01003v1 Announce Type: cross 
Abstract: Flaky tests can pass or fail non-deterministically, without alterations to a software system. Such tests are frequently encountered by developers and hinder the credibility of test suites. State-of-the-art research incorporates machine learning solutions into flaky test detection and achieves reasonably good accuracy. Moreover, the majority of automated flaky test repair solutions are designed for specific types of flaky tests. This research work proposes a novel categorization framework, called FlaKat, which uses machine-learning classifiers for fast and accurate prediction of the category of a given flaky test that reflects its root cause. Sampling techniques are applied to address the imbalance between flaky test categories in the International Dataset of Flaky Test (IDoFT). A new evaluation metric, called Flakiness Detection Capacity (FDC), is proposed for measuring the accuracy of classifiers from the perspective of information theory and provides proof for its effectiveness. The final FDC results are also in agreement with F1 score regarding which classifier yields the best flakiness classification.","[{'name': 'Shizhe Lin, Ryan Zheng He Liu, Ladan Tahvildari'}]",
1296,Policy Optimization for PDE Control with a Warm Start,https://arxiv.org/abs/2403.01005,"arXiv:2403.01005v1 Announce Type: cross 
Abstract: Dimensionality reduction is crucial for controlling nonlinear partial differential equations (PDE) through a \"reduce-then-design\" strategy, which identifies a reduced-order model and then implements model-based control solutions. However, inaccuracies in the reduced-order modeling can substantially degrade controller performance, especially in PDEs with chaotic behavior. To address this issue, we augment the reduce-then-design procedure with a policy optimization (PO) step. The PO step fine-tunes the model-based controller to compensate for the modeling error from dimensionality reduction. This augmentation shifts the overall strategy into reduce-then-design-then-adapt, where the model-based controller serves as a warm start for PO. Specifically, we study the state-feedback tracking control of PDEs that aims to align the PDE state with a specific constant target subject to a linear-quadratic cost. Through extensive experiments, we show that a few iterations of PO can significantly improve the model-based controller performance. Our approach offers a cost-effective alternative to PDE control using end-to-end reinforcement learning.","[{'name': 'Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Ba\\\\c{s}ar'}]",
1297,Reservoir Computing Using Measurement-Controlled Quantum Dynamics,https://arxiv.org/abs/2403.01024,"arXiv:2403.01024v1 Announce Type: cross 
Abstract: Physical reservoir computing (RC) is a machine learning algorithm that employs the dynamics of a physical system to forecast highly nonlinear and chaotic phenomena. In this paper, we introduce a quantum RC system that employs the dynamics of a probed atom in a cavity. The atom experiences coherent driving at a particular rate, leading to a measurement-controlled quantum evolution. The proposed quantum reservoir can make fast and reliable forecasts using a small number of artificial neurons compared with the traditional RC algorithm. We theoretically validate the operation of the reservoir, demonstrating its potential to be used in error-tolerant applications, where approximate computing approaches may be used to make feasible forecasts in conditions of limited computational and energy resources.","[{'name': 'A. H. Abbas, Ivan S. Maksymov'}]",
1298,Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks,https://arxiv.org/abs/2403.01031,"arXiv:2403.01031v1 Announce Type: cross 
Abstract: Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic culture, setting the first stone for culturally-aware Arabic MLLMs.The GitHub repository for the \\textit{Peacock} project is available at \\url{https://github.com/UBC-NLP/peacock}.","[{'name': 'Fakhraddin Alwajih, El Moatez Billah Nagoudi, Gagan Bhatia, Abdelrahman Mohamed, Muhammad Abdul-Mageed'}]",
1299,AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks,https://arxiv.org/abs/2403.01038,"arXiv:2403.01038v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated impressive results on natural language tasks, and security researchers are beginning to employ them in both offensive and defensive systems. In cyber-security, there have been multiple research efforts that utilize LLMs focusing on the pre-breach stage of attacks like phishing and malware generation. However, so far there lacks a comprehensive study regarding whether LLM-based systems can be leveraged to simulate the post-breach stage of attacks that are typically human-operated, or \"hands-on-keyboard\" attacks, under various attack techniques and environments.
  As LLMs inevitably advance, they may be able to automate both the pre- and post-breach attack stages. This shift may transform organizational attacks from rare, expert-led events to frequent, automated operations requiring no expertise and executed at automation speed and scale. This risks fundamentally changing global computer security and correspondingly causing substantial economic impacts, and a goal of this work is to better understand these risks now so we can better prepare for these inevitable ever-more-capable LLMs on the horizon. On the immediate impact side, this research serves three purposes. First, an automated LLM-based, post-breach exploitation framework can help analysts quickly test and continually improve their organization's network security posture against previously unseen attacks. Second, an LLM-based penetration test system can extend the effectiveness of red teams with a limited number of human analysts. Finally, this research can help defensive systems and teams learn to detect novel attack behaviors preemptively before their use in the wild....","[{'name': 'Jiacen Xu, Jack W. Stokes, Geoff McDonald, Xuesong Bai, David Marshall, Siyue Wang, Adith Swaminathan, Zhou Li'}]",
1300,A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features,https://arxiv.org/abs/2403.01046,"arXiv:2403.01046v1 Announce Type: cross 
Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.","[{'name': 'Emi Zeger, Yifei Wang, Aaron Mishkin, Tolga Ergen, Emmanuel Cand\\\\`es, Mert Pilanci'}]",
1301,Seeing Unseen: Discover Novel Biomedical Concepts via GeometryConstrained Probabilistic Modeling,https://arxiv.org/abs/2403.01053,"arXiv:2403.01053v1 Announce Type: cross 
Abstract: Machine learning holds tremendous promise for transforming the fundamental practice of scientific discovery by virtue of its data-driven nature. With the ever-increasing stream of research data collection, it would be appealing to autonomously explore patterns and insights from observational data for discovering novel classes of phenotypes and concepts. However, in the biomedical domain, there are several challenges inherently presented in the cumulated data which hamper the progress of novel class discovery. The non-i.i.d. data distribution accompanied by the severe imbalance among different groups of classes essentially leads to ambiguous and biased semantic representations. In this work, we present a geometry-constrained probabilistic modeling treatment to resolve the identified issues. First, we propose to parameterize the approximated posterior of instance embedding as a marginal von MisesFisher distribution to account for the interference of distributional latent bias. Then, we incorporate a suite of critical geometric properties to impose proper constraints on the layout of constructed embedding space, which in turn minimizes the uncontrollable risk for unknown class learning and structuring. Furthermore, a spectral graph-theoretic method is devised to estimate the number of potential novel classes. It inherits two intriguing merits compared to existent approaches, namely high computational efficiency and flexibility for taxonomy-adaptive estimation. Extensive experiments across various biomedical scenarios substantiate the effectiveness and general applicability of our method.","[{'name': 'Jianan Fan, Dongnan Liu, Hang Chang, Heng Huang, Mei Chen, Weidong Cai'}]",
1302,Towards Full Authorship with AI: Supporting Revision with AI-Generated Views,https://arxiv.org/abs/2403.01055,"arXiv:2403.01055v1 Announce Type: cross 
Abstract: Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user's authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals' UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity.","[{'name': 'Jiho Kim, Ray C. Flanagan, Noelle E. Haviland, ZeAi Sun, Souad N. Yakubu, Edom A. Maru, Kenneth C. Arnold'}]",
1303,GraphRCG: Self-conditioned Graph Generation via Bootstrapped Representations,https://arxiv.org/abs/2403.01071,"arXiv:2403.01071v1 Announce Type: cross 
Abstract: Graph generation generally aims to create new graphs that closely align with a specific graph distribution. Existing works often implicitly capture this distribution through the optimization of generators, potentially overlooking the intricacies of the distribution itself. Furthermore, these approaches generally neglect the insights offered by the learned distribution for graph generation. In contrast, in this work, we propose a novel self-conditioned graph generation framework designed to explicitly model graph distributions and employ these distributions to guide the generation process. We first perform self-conditioned modeling to capture the graph distributions by transforming each graph sample into a low-dimensional representation and optimizing a representation generator to create new representations reflective of the learned distribution. Subsequently, we leverage these bootstrapped representations as self-conditioned guidance for the generation process, thereby facilitating the generation of graphs that more accurately reflect the learned distributions. We conduct extensive experiments on generic and molecular graph datasets across various fields. Our framework demonstrates superior performance over existing state-of-the-art graph generation methods in terms of graph quality and fidelity to training data.","[{'name': 'Song Wang, Zhen Tan, Xinyu Zhao, Tianlong Chen, Huan Liu, Jundong Li'}]",
1304,$\\Gamma$-VAE: Curvature regularized variational autoencoders for uncovering emergent low dimensional geometric structure in high dimensional data,https://arxiv.org/abs/2403.01078,"arXiv:2403.01078v1 Announce Type: cross 
Abstract: Natural systems with emergent behaviors often organize along low-dimensional subsets of high-dimensional spaces. For example, despite the tens of thousands of genes in the human genome, the principled study of genomics is fruitful because biological processes rely on coordinated organization that results in lower dimensional phenotypes. To uncover this organization, many nonlinear dimensionality reduction techniques have successfully embedded high-dimensional data into low-dimensional spaces by preserving local similarities between data points. However, the nonlinearities in these methods allow for too much curvature to preserve general trends across multiple non-neighboring data clusters, thereby limiting their interpretability and generalizability to out-of-distribution data. Here, we address both of these limitations by regularizing the curvature of manifolds generated by variational autoencoders, a process we coin ``$\\Gamma$-VAE''. We demonstrate its utility using two example data sets: bulk RNA-seq from the The Cancer Genome Atlas (TCGA) and the Genotype Tissue Expression (GTEx); and single cell RNA-seq from a lineage tracing experiment in hematopoietic stem cell differentiation. We find that the resulting regularized manifolds identify mesoscale structure associated with different cancer cell types, and accurately re-embed tissues from completely unseen, out-of distribution cancers as if they were originally trained on them. Finally, we show that preserving long-range relationships to differentiated cells separates undifferentiated cells -- which have not yet specialized -- according to their eventual fate. Broadly, we anticipate that regularizing the curvature of generative models will enable more consistent, predictive, and generalizable models in any high-dimensional system with emergent low-dimensional behavior.","[{'name': 'Jason Z. Kim, Nicolas Perrin-Gilbert, Erkan Narmanli, Paul Klein, Christopher R. Myers, Itai Cohen, Joshua J. Waterfall, James P. Sethna'}]",
1305,Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework,https://arxiv.org/abs/2403.01079,"arXiv:2403.01079v1 Announce Type: cross 
Abstract: We study the challenging problem for inference tasks on large-scale graph datasets of Graph Neural Networks: huge time and memory consumption, and try to overcome it by reducing reliance on graph structure. Even though distilling graph knowledge to student MLP is an excellent idea, it faces two major problems of positional information loss and low generalization. To solve the problems, we propose a new three-stage multitask distillation framework. In detail, we use Positional Encoding to capture positional information. Also, we introduce Neural Heat Kernels responsible for graph data processing in GNN and utilize hidden layer outputs matching for better performance of student MLP's hidden layers. To the best of our knowledge, it is the first work to include hidden layer distillation for student MLP on graphs and to combine graph Positional Encoding with MLP. We test its performance and robustness with several settings and draw the conclusion that our work can outperform well with good stability.","[{'name': 'Junxian Li, Bin Shi, Erfei Cui, Hua Wei, Qinghua Zheng'}]",
1306,COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for Traffic Forecasting,https://arxiv.org/abs/2403.01091,"arXiv:2403.01091v1 Announce Type: cross 
Abstract: This paper investigates traffic forecasting, which attempts to forecast the future state of traffic based on historical situations. This problem has received ever-increasing attention in various scenarios and facilitated the development of numerous downstream applications such as urban planning and transportation management. However, the efficacy of existing methods remains sub-optimal due to their tendency to model temporal and spatial relationships independently, thereby inadequately accounting for complex high-order interactions of both worlds. Moreover, the diversity of transitional patterns in traffic forecasting makes them challenging to capture for existing approaches, warranting a deeper exploration of their diversity. Toward this end, this paper proposes Conjoint Spatio-Temporal graph neural network (abbreviated as COOL), which models heterogeneous graphs from prior and posterior information to conjointly capture high-order spatio-temporal relationships. On the one hand, heterogeneous graphs connecting sequential observation are constructed to extract composite spatio-temporal relationships via prior message passing. On the other hand, we model dynamic relationships using constructed affinity and penalty graphs, which guide posterior message passing to incorporate complementary semantic information into node representations. Moreover, to capture diverse transitional properties to enhance traffic forecasting, we propose a conjoint self-attention decoder that models diverse temporal patterns from both multi-rank and multi-scale views. Experimental results on four popular benchmark datasets demonstrate that our proposed COOL provides state-of-the-art performance compared with the competitive baselines.","[{'name': 'Wei Ju, Yusheng Zhao, Yifang Qin, Siyu Yi, Jingyang Yuan, Zhiping Xiao, Xiao Luo, Xiting Yan, Ming Zhang'}]",
1307,Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models,https://arxiv.org/abs/2403.01101,"arXiv:2403.01101v1 Announce Type: cross 
Abstract: Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, which may even outweigh the computational cost savings. In this paper, we argue the performance drop stems not only from pre-computed features' inability to distinguish between categories of labeled samples, resulting in the selection of redundant samples but also from the tendency to compromise valuable pre-trained information when fine-tuning with samples selected through the proxy model. To address this issue, we propose a novel method called aligned selection via proxy to update pre-computed features while selecting a proper training method to inherit valuable pre-training information. Extensive experiments validate that our method significantly improves the total cost of efficient active learning while maintaining computational efficiency.","[{'name': 'Ziting Wen, Oscar Pizarro, Stefan Williams'}]",
1308,Distilling Text Style Transfer With Self-Explanation From LLMs,https://arxiv.org/abs/2403.01106,"arXiv:2403.01106v1 Announce Type: cross 
Abstract: Text Style Transfer (TST) seeks to alter the style of text while retaining its core content. Given the constraints of limited parallel datasets for TST, we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills the complex rewriting and reasoning capabilities of LLMs into more streamlined models capable of working with both non-parallel and parallel data. Through experimentation across four TST datasets, CoTeX is shown to surpass traditional supervised fine-tuning and knowledge distillation methods, particularly in low-resource settings. We conduct a comprehensive evaluation, comparing CoTeX against current unsupervised, supervised, in-context learning (ICL) techniques, and instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering transparent explanations for its style transfer process.","[{'name': 'Chiyu ZhangMusic, Honglong CaiMusic,  YuezhangMusic,  Li, Yuexin Wu, Le Hou, Muhammad Abdul-Mageed'}]",
1309,Adversarial Testing for Visual Grounding via Image-Aware Property Reduction,https://arxiv.org/abs/2403.01118,"arXiv:2403.01118v1 Announce Type: cross 
Abstract: Due to the advantages of fusing information from various modalities, multimodal learning is gaining increasing attention. Being a fundamental task of multimodal learning, Visual Grounding (VG), aims to locate objects in images through natural language expressions. Ensuring the quality of VG models presents significant challenges due to the complex nature of the task. In the black box scenario, existing adversarial testing techniques often fail to fully exploit the potential of both modalities of information. They typically apply perturbations based solely on either the image or text information, disregarding the crucial correlation between the two modalities, which would lead to failures in test oracles or an inability to effectively challenge VG models. To this end, we propose PEELING, a text perturbation approach via image-aware property reduction for adversarial testing of the VG model. The core idea is to reduce the property-related information in the original expression meanwhile ensuring the reduced expression can still uniquely describe the original object in the image. To achieve this, PEELING first conducts the object and properties extraction and recombination to generate candidate property reduction expressions. It then selects the satisfied expressions that accurately describe the original object while ensuring no other objects in the image fulfill the expression, through querying the image with a visual understanding technique. We evaluate PEELING on the state-of-the-art VG model, i.e. OFA-VG, involving three commonly used datasets. Results show that the adversarial tests generated by PEELING achieves 21.4% in MultiModal Impact score (MMI), and outperforms state-of-the-art baselines for images and texts by 8.2%--15.1%.","[{'name': 'Zhiyuan Chang, Mingyang Li, Junjie Wang, Cheng Li, Boyu Wu, Fanjiang Xu, Qing Wang'}]",
1310,OpenGraph: Towards Open Graph Foundation Models,https://arxiv.org/abs/2403.01121,"arXiv:2403.01121v1 Announce Type: cross 
Abstract: Graph learning has become indispensable for interpreting and harnessing relational data in diverse fields, ranging from recommendation systems to social network analysis. In this context, a variety of GNNs have emerged as promising methodologies for encoding the structural information of graphs. By effectively capturing the graph's underlying structure, these GNNs have shown great potential in enhancing performance in graph learning tasks, such as link prediction and node classification. However, despite their successes, a significant challenge persists: these advanced methods often face difficulties in generalizing to unseen graph data that significantly differs from the training instances. In this work, our aim is to advance the graph learning paradigm by developing a general graph foundation model. This model is designed to understand the complex topological patterns present in diverse graph data, enabling it to excel in zero-shot graph learning tasks across different downstream datasets. To achieve this goal, we address several key technical challenges in our OpenGraph model. Firstly, we propose a unified graph tokenizer to adapt our graph model to generalize well on unseen graph data, even when the underlying graph properties differ significantly from those encountered during training. Secondly, we develop a scalable graph transformer as the foundational encoder, which effectively captures node-wise dependencies within the global topological context. Thirdly, we introduce a data augmentation mechanism enhanced by a LLM to alleviate the limitations of data scarcity in real-world scenarios. Extensive experiments validate the effectiveness of our framework. By adapting our OpenGraph to new graph characteristics and comprehending the nuances of diverse graphs, our approach achieves remarkable zero-shot graph learning performance across various settings and domains.","[{'name': 'Lianghao Xia, Ben Kao, Chao Huang'}]",
1311,LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation,https://arxiv.org/abs/2403.01131,"arXiv:2403.01131v1 Announce Type: cross 
Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior optimization performance compared to GPT-4 Turbo and the other competitors across both synthetic and realistic problem sets. The fine-tuned model and the usage instructions are available at https://anonymous.4open.science/r/LLaMoCo-722A.","[{'name': 'Zeyuan Ma, Hongshu Guo, Jiacheng Chen, Guojun Peng, Zhiguang Cao, Yining Ma, Yue-Jiao Gong'}]",
1312,LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization,https://arxiv.org/abs/2403.01136,"arXiv:2403.01136v1 Announce Type: cross 
Abstract: Recent breakthroughs in Large-scale language models (LLMs) have demonstrated impressive performance on various tasks. The immense sizes of LLMs have led to very high resource demand and cost for running the models. Though the models are largely served using uniform high-caliber GPUs nowadays, utilizing a heterogeneous cluster with a mix of available high- and low-capacity GPUs can potentially substantially reduce the serving cost. There is a lack of designs to support efficient LLM serving using a heterogeneous cluster, while the current solutions focus on model partition and uniform compression among homogeneous devices. This paper proposes LLM-PQ, a system that advocates adaptive model quantization and phase-aware partition to improve LLM serving efficiency on heterogeneous GPU clusters. We carefully decide on mixed-precision model quantization together with phase-aware model partition and micro-batch sizing in distributed LLM serving with an efficient algorithm, to greatly enhance inference throughput while fulfilling user-specified model quality targets. Extensive experiments on production inference workloads in 11 different clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on average) throughput improvement in inference, showing great advantages over state-of-the-art works.","[{'name': 'Juntao Zhao, Borui Wan, Yanghua Peng, Haibin Lin, Chuan Wu'}]",
1313,ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies,https://arxiv.org/abs/2403.01139,"arXiv:2403.01139v1 Announce Type: cross 
Abstract: Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy. In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes. We publish a gold-set, validated by humans, and a silver-set, generated automatically. We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best models (~13% gap) after a light supervision. We demonstrate that our silver-set is useful for training models. Lastly, we show challenging distractors confuse LLMs, but not humans. We hope our pipeline will encourage research in this emerging field.","[{'name': 'Oren Sultan, Yonatan Bitton, Ron Yosef, Dafna Shahaf'}]",
1314,A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model,https://arxiv.org/abs/2403.01147,"arXiv:2403.01147v1 Announce Type: cross 
Abstract: In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information. This enables the realization of intelligent traffic control and management. Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances. A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges. Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection. Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against the baseline model. The results demonstrate that the proposed model enhances the dataset size, balances the dataset, and improves the performance of traffic incident detection in various aspects.","[{'name': 'Xinying Lu, Doudou Zhang, Jianli Xiao'}]",
1315,"A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization",https://arxiv.org/abs/2403.01152,"arXiv:2403.01152v1 Announce Type: cross 
Abstract: We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furthermore, we explore available resources for AI-generated text forensics research and discuss the evolving challenges and future directions of forensic systems in an AI era.","[{'name': 'Tharindu Kumarage, Garima Agrawal, Paras Sheth, Raha Moraffah, Aman Chadha, Joshua Garland, Huan Liu'}]",
1316,STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models,https://arxiv.org/abs/2403.01165,"arXiv:2403.01165v1 Announce Type: cross 
Abstract: Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning. For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation. Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks.","[{'name': 'Linhai Zhang, Jialong Wu, Deyu Zhou, Guoqiang Xu'}]",
1317,DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference,https://arxiv.org/abs/2403.01166,"arXiv:2403.01166v1 Announce Type: cross 
Abstract: Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review). In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA. In this framework, different types of biases are tackled based on different causal intervention methods. For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is employed for debiasing. For the aspect branch, the bias is described as a direct correlation with labels, where counterfactual reasoning is adopted for debiasing. Extensive experiments demonstrate the effectiveness of the proposed method compared to various baselines on the two widely used real-world aspect robustness test set datasets.","[{'name': 'Jialong Wu, Linhai Zhang, Deyu Zhou, Guoqiang Xu'}]",
1318,Leveraging Self-Supervised Learning for Scene Recognition in Child Sexual Abuse Imagery,https://arxiv.org/abs/2403.01183,"arXiv:2403.01183v1 Announce Type: cross 
Abstract: Crime in the 21st century is split into a virtual and real world. However, the former has become a global menace to people's well-being and security in the latter. The challenges it presents must be faced with unified global cooperation, and we must rely more than ever on automated yet trustworthy tools to combat the ever-growing nature of online offenses. Over 10 million child sexual abuse reports are submitted to the US National Center for Missing & Exploited Children every year, and over 80% originated from online sources. Therefore, investigation centers and clearinghouses cannot manually process and correctly investigate all imagery. In light of that, reliable automated tools that can securely and efficiently deal with this data are paramount. In this sense, the scene recognition task looks for contextual cues in the environment, being able to group and classify child sexual abuse data without requiring to be trained on sensitive material. The scarcity and limitations of working with child sexual abuse images lead to self-supervised learning, a machine-learning methodology that leverages unlabeled data to produce powerful representations that can be more easily transferred to target tasks. This work shows that self-supervised deep learning models pre-trained on scene-centric data can reach 71.6% balanced accuracy on our indoor scene classification task and, on average, 2.2 percentage points better performance than a fully supervised version. We cooperate with Brazilian Federal Police experts to evaluate our indoor classification model on actual child abuse material. The results demonstrate a notable discrepancy between the features observed in widely used scene datasets and those depicted on sensitive materials.","[{'name': 'Pedro H. V. Valois, Jo\\\\~ao Macedo, Leo S. F. Ribeiro, Jefersson A. dos Santos, Sandra Avila'}]",
1319,Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding,https://arxiv.org/abs/2403.01185,"arXiv:2403.01185v1 Announce Type: cross 
Abstract: Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluating its impact on negation understanding. Our experimental results exhibit the effectiveness of balancing exploration and exploitation with RLLF in improving LLMs' negation capabilities. This has implications for the development of more accurate, reliable, and logically consistent language models in high-stakes domains.","[{'name': 'Ha-Thanh Nguyen, Ken Satoh'}]",
1320,RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots,https://arxiv.org/abs/2403.01193,"arXiv:2403.01193v1 Announce Type: cross 
Abstract: Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge. This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings. This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and discuss implications for the development of more trustworthy LLMs.","[{'name': 'Philip Feldman. James R. Foulds, Shimei Pan'}]",
1321,Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021,https://arxiv.org/abs/2403.01196,"arXiv:2403.01196v1 Announce Type: cross 
Abstract: Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points.","[{'name': \"S\\\\'eamus Lankford, Haithem Afli, Andy Way\"}]",
1322,SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters,https://arxiv.org/abs/2403.01210,"arXiv:2403.01210v1 Announce Type: cross 
Abstract: Deep neural network-based Synthetic Aperture Radar (SAR) target recognition models are susceptible to adversarial examples. Current adversarial example generation methods for SAR imagery primarily operate in the 2D digital domain, known as image adversarial examples. Recent work, while considering SAR imaging scatter mechanisms, fails to account for the actual imaging process, rendering attacks in the three-dimensional physical domain infeasible, termed pseudo physics adversarial examples. To address these challenges, this paper proposes SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by altering the scattering feature parameters of target objects. Specifically, we iteratively optimize the coherent energy accumulation of the target echo by perturbing the reflection coefficient and scattering coefficient in the scattering feature parameters of the three-dimensional target object, and obtain the adversarial example after echo signal processing and imaging processing in the RaySAR simulator. Experimental results show that compared to digital adversarial attack methods, SAR-AE-SFP Attack significantly improves attack efficiency on CNN-based models (over 30\\%) and Transformer-based models (over 13\\%), demonstrating significant transferability of attack effects across different models and perspectives.","[{'name': 'Jiahao Cui, Jiale Duan, Binyan Luo, Hang Cao, Wang Guo, Haifeng Li'}]",
1323,API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access,https://arxiv.org/abs/2403.01216,"arXiv:2403.01216v1 Announce Type: cross 
Abstract: This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on both close-ended and open-ended Question Answering tasks show our approach can mostly outperform the logit-based CP baselines.","[{'name': 'Jiayuan Su, Jing Luo, Hongwei Wang, Lu Cheng'}]",
1324,A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations,https://arxiv.org/abs/2403.01221,"arXiv:2403.01221v1 Announce Type: cross 
Abstract: Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.","[{'name': \"Andr\\\\'e Artelt, Andreas Gregoriades\"}]",
1325,REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild,https://arxiv.org/abs/2403.01229,"arXiv:2403.01229v1 Announce Type: cross 
Abstract: Recognizing speaking in humans is a central task towards understanding social interactions. Ideally, speaking would be detected from individual voice recordings, as done previously for meeting scenarios. However, individual voice recordings are hard to obtain in the wild, especially in crowded mingling scenarios due to cost, logistics, and privacy concerns. As an alternative, machine learning models trained on video and wearable sensor data make it possible to recognize speech by detecting its related gestures in an unobtrusive, privacy-preserving way. These models themselves should ideally be trained using labels obtained from the speech signal. However, existing mingling datasets do not contain high quality audio recordings. Instead, speaking status annotations have often been inferred by human annotators from video, without validation of this approach against audio-based ground truth. In this paper we revisit no-audio speaking status estimation by presenting the first publicly available multimodal dataset with high-quality individual speech recordings of 33 subjects in a professional networking event. We present three baselines for no-audio speaking status segmentation: a) from video, b) from body acceleration (chest-worn accelerometer), c) from body pose tracks. In all cases we predict a 20Hz binary speaking status signal extracted from the audio, a time resolution not available in previous datasets. In addition to providing the signals and ground truth necessary to evaluate a wide range of speaking status detection methods, the availability of audio in REWIND makes it suitable for cross-modality studies not feasible with previous mingling datasets. Finally, our flexible data consent setup creates new challenges for multimodal systems under missing modalities.","[{'name': 'Jose Vargas Quiros, Chirag Raman, Stephanie Tan, Ekin Gedik, Laura Cabrera-Quiros, Hayley Hung'}]",
1326,Polynormer: Polynomial-Expressive Graph Transformer in Linear Time,https://arxiv.org/abs/2403.01232,"arXiv:2403.01232v1 Announce Type: cross 
Abstract: Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs). However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs. While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity. To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomial-expressive GT model with linear complexity. Polynormer is built upon a novel base model that learns a high-degree polynomial on input features. To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models. Consequently, Polynormer adopts a linear local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. Polynormer has been evaluated on $13$ homophilic and heterophilic datasets, including large graphs with millions of nodes. Our extensive experiment results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions.","[{'name': 'Chenhui Deng, Zichao Yue, Zhiru Zhang'}]",
1327,IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact,https://arxiv.org/abs/2403.01241,"arXiv:2403.01241v1 Announce Type: cross 
Abstract: Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outlier in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model. The approach is simple and easy to combine with existing quantization solutions. Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further. Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error. Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only INT4 quantization on various downstream tasks, leading to the new state-of-the-art for LLM quantization.","[{'name': 'Ruikang Liu, Haoli Bai, Haokun Lin, Yuening Li, Han Gao, Zhengzhuo Xu, Lu Hou, Jun Yao, Chun Yuan'}]",
1328,Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning,https://arxiv.org/abs/2403.01242,"arXiv:2403.01242v1 Announce Type: cross 
Abstract: Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach in enhancing user experience and expanding the capabilities of electric automation systems. Our work contributes to the advancement of smart technologies by providing a more seamless interaction between users and their environments.","[{'name': 'Lochan Basyal, Bijay Gaudel'}]",
1329,Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal,https://arxiv.org/abs/2403.01244,"arXiv:2403.01244v1 Announce Type: cross 
Abstract: Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in-context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high-quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable performance compared to conventional rehearsal-based approaches while being more data-efficient. Besides, SSR effectively preserves the generalization capabilities of LLMs in general domains.","[{'name': 'Jianheng Huang, Leyang Cui, Ante Wang, Chengyi Yang, Xinting Liao, Linfeng Song, Junfeng Yao, Jinsong Su'}]",
1330,SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code,https://arxiv.org/abs/2403.01248,"arXiv:2403.01248v1 Announce Type: cross 
Abstract: This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments. We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal.","[{'name': 'Ziniu Hu, Ahmet Iscen, Aashi Jain, Thomas Kipf, Yisong Yue, David A. Ross, Cordelia Schmid, Alireza Fathi'}]",
1331,Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey,https://arxiv.org/abs/2403.01255,"arXiv:2403.01255v1 Announce Type: cross 
Abstract: Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, RL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.","[{'name': 'Hamza Kheddar, Mustapha Hemis, Yassine Himeur'}]",
1332,NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention,https://arxiv.org/abs/2403.01273,"arXiv:2403.01273v1 Announce Type: cross 
Abstract: Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations. In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch. We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups. Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning. Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context length. Our results are reproducible at https://github.com/tonyzhang617/nomad-dist.","[{'name': 'Tianyi Zhang, Jonah Wonkyu Yi, Bowen Yao, Zhaozhuo Xu, Anshumali Shrivastava'}]",
1333,Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery,https://arxiv.org/abs/2403.01277,"arXiv:2403.01277v1 Announce Type: cross 
Abstract: We propose a generic multi-robot planning mechanism that combines an optimal task planner and an optimal path planner to provide a scalable solution for complex multi-robot planning problems. The Integrated planner, through the interaction of the task planner and the path planner, produces optimal collision-free trajectories for the robots. We illustrate our general algorithm on an object pick-and-drop planning problem in a warehouse scenario where a group of robots is entrusted with moving objects from one location to another in the workspace. We solve the task planning problem by reducing it into an SMT-solving problem and employing the highly advanced SMT solver Z3 to solve it. To generate collision-free movement of the robots, we extend the state-of-the-art algorithm Conflict Based Search with Precedence Constraints with several domain-specific constraints. We evaluate our integrated task and path planner extensively on various instances of the object pick-and-drop planning problem and compare its performance with a state-of-the-art multi-robot classical planner. Experimental results demonstrate that our planning mechanism can deal with complex planning problems and outperforms a state-of-the-art classical planner both in terms of computation time and the quality of the generated plan.","[{'name': 'Aman Aryan, Manan Modi, Indranil Saha, Rupak Majumdar, Swarup Mohalik'}]",
1334,Fast Low-parameter Video Activity Localization in Collaborative Learning Environments,https://arxiv.org/abs/2403.01281,"arXiv:2403.01281v1 Announce Type: cross 
Abstract: Research on video activity detection has primarily focused on identifying well-defined human activities in short video segments. The majority of the research on video activity recognition is focused on the development of large parameter systems that require training on large video datasets. This paper develops a low-parameter, modular system with rapid inferencing capabilities that can be trained entirely on limited datasets without requiring transfer learning from large-parameter systems. The system can accurately detect and associate specific activities with the students who perform the activities in real-life classroom videos. Additionally, the paper develops an interactive web-based application to visualize human activity maps over long real-life classroom videos.","[{'name': 'Venkatesh Jatla, Sravani Teeparthi, Ugesh Egala, Sylvia Celedon Pattichis, Marios S. Patticis'}]",
1335,Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People,https://arxiv.org/abs/2403.01286,"arXiv:2403.01286v1 Announce Type: cross 
Abstract: This is a summary paper of a use case of a Robotdog dedicated to guide visually impaired people in complex environment like a smart intersection. In such scenarios, the Robotdog has to autonomously decide whether it is safe to cross the intersection or not in order to further guide the human. We leverage data sharing and collaboration between the Robotdog and other autonomous systems operating in the same environment. We propose a system architecture for autonomous systems through a separation of a collaborative decision layer, to enable collective decision making processes, where data about the environment, relevant to the Robotdog decision, together with evidences for trustworthiness about other systems and the environment are shared.","[{'name': 'Aman Malhotra, Selma Saidi'}]",
1336,VBART: The Turkish LLM,https://arxiv.org/abs/2403.01308,"arXiv:2403.01308v1 Announce Type: cross 
Abstract: We present VBART, the first Turkish sequence-to-sequence Large Language Models (LLMs) pre-trained on a large corpus from scratch. VBART are compact LLMs based on good ideas leveraged from BART and mBART models and come in two sizes, Large and XLarge. Fine-tuned VBART models surpass the prior state-of-the-art results in abstractive text summarization, title generation, text paraphrasing, question answering and question generation tasks. They allow fine-tuning for future text generation tasks and datasets, carving a new path for Turkish Natural Language Processing (NLP) research. Our work shows that having a pre-trained LLM for Turkish outperforms up to 3x multilingual models, improving existing results and providing efficient models for training and inference. Moreover, we show that our monolingual tokenizer is 7x more efficient than OpenAI's multilingual tokenizer. Last but not least, we introduce a method to enlarge an existing pre-trained LLM and question the relevancy of Chinchilla Scaling Law to sequence-to-sequence masked language models. Our fine-tuned models, tokenizer and cleaned web corpus of 135 GB are publicly available at huggingface.co/vngrs-ai.","[{'name': 'Meliksah Turker, Mehmet Erdi Ari, Aydin Han'}]",
1337,VNLP: Turkish NLP Package,https://arxiv.org/abs/2403.01309,"arXiv:2403.01309v1 Announce Type: cross 
Abstract: In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language. It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models. Its token classification models are based on \"Context Model\", a novel architecture that is both an encoder and an auto-regressive model. NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and command-line API and a demo page to test all the functionality. Consequently, our main contribution is a complete, compact, easy-to-install and easy-to-use NLP package for Turkish.","[{'name': 'Meliksah Turker, Mehmet Erdi Ari, Aydin Han'}]",
1338,Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models,https://arxiv.org/abs/2403.01329,"arXiv:2403.01329v1 Announce Type: cross 
Abstract: This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver distillation approach to improve sample efficiency of Diffusion and Flow models. BNS solvers are based on a family of non-stationary solvers that provably subsumes existing numerical ODE solvers and consequently demonstrate considerable improvement in sample approximation (PSNR) over these baselines. Compared to model distillation, BNS solvers benefit from a tiny parameter space ($<$200 parameters), fast optimization (two orders of magnitude faster), maintain diversity of samples, and in contrast to previous solver distillation approaches nearly close the gap from standard distillation methods such as Progressive Distillation in the low-medium NFE regime. For example, BNS solver achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We experimented with BNS solvers for conditional image generation, text-to-image generation, and text-2-audio generation showing significant improvement in sample approximation (PSNR) in all.","[{'name': 'Neta Shaul, Uriel Singer, Ricky T. Q. Chen, Matthew Le, Ali Thabet, Albert Pumarola, Yaron Lipman'}]",
1339,Chaining thoughts and LLMs to learn DNA structural biophysics,https://arxiv.org/abs/2403.01332,"arXiv:2403.01332v1 Announce Type: cross 
Abstract: The future development of an AI scientist, a tool that is capable of integrating a variety of experimental data and generating testable hypotheses, holds immense potential. So far, bespoke machine learning models have been created to specialize in singular scientific tasks, but otherwise lack the flexibility of a general purpose model. Here, we show that a general purpose large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the structural biophysics of DNA. We find that both fine-tuning models to return chain-of-thought responses and chaining together models fine-tuned for subtasks have an enhanced ability to analyze and design DNA sequences and their structures.","[{'name': 'Tyler D. Ross, Ashwin Gopinath'}]",
1340,SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization,https://arxiv.org/abs/2403.01348,"arXiv:2403.01348v1 Announce Type: cross 
Abstract: Indoor localization is a critical task in many embedded applications, such as asset tracking, emergency response, and realtime navigation. In this article, we propose a novel fingerprintingbased framework for indoor localization called SANGRIA that uses stacked autoencoder neural networks with gradient boosted trees. Our approach is designed to overcome the device heterogeneity challenge that can create uncertainty in wireless signal measurements across embedded devices used for localization. We compare SANGRIA to several state-of-the-art frameworks and demonstrate 42.96% lower average localization error across diverse indoor locales and heterogeneous devices.","[{'name': 'Danish Gufran, Saideep Tiku, Sudeep Pasricha'}]",
1341,A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement,https://arxiv.org/abs/2403.01369,"arXiv:2403.01369v1 Announce Type: cross 
Abstract: Self-supervised learned models have been found to be very effective for certain speech tasks such as automatic speech recognition, speaker identification, keyword spotting and others. While the features are undeniably useful in speech recognition and associated tasks, their utility in speech enhancement systems is yet to be firmly established, and perhaps not properly understood. In this paper, we investigate the uses of SSL representations for single-channel speech enhancement in challenging conditions and find that they add very little value for the enhancement task. Our constraints are designed around on-device real-time speech enhancement -- model is causal, the compute footprint is small. Additionally, we focus on low SNR conditions where such models struggle to provide good enhancement. In order to systematically examine how SSL representations impact performance of such enhancement models, we propose a variety of techniques to utilize these embeddings which include different forms of knowledge-distillation and pre-training.","[{'name': 'Ravi Shankar, Ke Tan, Buye Xu, Anurag Kumar'}]",
1342,On the Compressibility of Quantized Large Language Models,https://arxiv.org/abs/2403.01384,"arXiv:2403.01384v1 Announce Type: cross 
Abstract: Deploying Large Language Models (LLMs) on edge or mobile devices offers significant benefits, such as enhanced data privacy and real-time processing capabilities. However, it also faces critical challenges due to the substantial memory requirement of LLMs. Quantization is an effective way of reducing the model size while maintaining good performance. However, even after quantization, LLMs may still be too big to fit entirely into the limited memory of edge or mobile devices and have to be partially loaded from the storage to complete the inference. In this case, the I/O latency of model loading becomes the bottleneck of the LLM inference latency. In this work, we take a preliminary step of studying applying data compression techniques to reduce data movement and thus speed up the inference of quantized LLM on memory-constrained devices. In particular, we discussed the compressibility of quantized LLMs, the trade-off between the compressibility and performance of quantized LLMs, and opportunities to optimize both of them jointly.","[{'name': 'Yu Mao, Weilan Wang, Hongchao Du, Nan Guan, Chun Jason Xue'}]",
1343,Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks,https://arxiv.org/abs/2403.01400,"arXiv:2403.01400v1 Announce Type: cross 
Abstract: Recent years have witnessed the great success of graph pre-training for graph representation learning. With hundreds of graph pre-training tasks proposed, integrating knowledge acquired from multiple pre-training tasks has become a popular research topic. In this paper, we identify two important collaborative processes for this topic: (1) select: how to select an optimal task combination from a given task pool based on their compatibility, and (2) weigh: how to weigh the selected tasks based on their importance. While there currently has been a lot of work focused on weighing, comparatively little effort has been devoted to selecting. This paper proposes a novel instance-level framework for integrating multiple graph pre-training tasks, Weigh And Select (WAS), where the two collaborative processes, weighing and selecting, are combined by decoupled siamese networks. Specifically, it first adaptively learns an optimal combination of tasks for each instance from a given task pool, based on which a customized instance-level task weighing strategy is learned. Extensive experiments on 16 graph datasets across node-level and graph-level downstream tasks have demonstrated that by combining a few simple but classical tasks, WAS can achieve comparable performance to other leading counterparts. The code is available at https://github.com/TianyuFan0504/WAS.","[{'name': 'Tianyu Fan, Lirong Wu, Yufei Huang, Haitao Lin, Cheng Tan, Zhangyang Gao, Stan Z. Li'}]",
1344,Region-Transformer: Self-Attention Region Based Class-Agnostic Point Cloud Segmentation,https://arxiv.org/abs/2403.01407,"arXiv:2403.01407v1 Announce Type: cross 
Abstract: Point cloud segmentation, which helps us understand the environment of specific structures and objects, can be performed in class-specific and class-agnostic ways. We propose a novel region-based transformer model called Region-Transformer for performing class-agnostic point cloud segmentation. The model utilizes a region-growth approach and self-attention mechanism to iteratively expand or contract a region by adding or removing points. It is trained on simulated point clouds with instance labels only, avoiding semantic labels. Attention-based networks have succeeded in many previous methods of performing point cloud segmentation. However, a region-growth approach with attention-based networks has yet to be used to explore its performance gain. To our knowledge, we are the first to use a self-attention mechanism in a region-growth approach. With the introduction of self-attention to region-growth that can utilize local contextual information of neighborhood points, our experiments demonstrate that the Region-Transformer model outperforms previous class-agnostic and class-specific methods on indoor datasets regarding clustering metrics. The model generalizes well to large-scale scenes. Key advantages include capturing long-range dependencies through self-attention, avoiding the need for semantic labels during training, and applicability to a variable number of objects. The Region-Transformer model represents a promising approach for flexible point cloud segmentation with applications in robotics, digital twinning, and autonomous vehicles.","[{'name': 'Dipesh Gyawali, Jian Zhang, BB Karki'}]",
1345,Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults,https://arxiv.org/abs/2403.01413,"arXiv:2403.01413v1 Announce Type: cross 
Abstract: Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults' attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.","[{'name': 'Yucheng Jin, Wanling Cai, Li Chen, Yizhe Zhang, Gavin Doherty, Tonglin Jiang'}]",
1346,GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features,https://arxiv.org/abs/2403.01437,"arXiv:2403.01437v1 Announce Type: cross 
Abstract: Moment retrieval (MR) and highlight detection (HD) aim to identify relevant moments and highlights in video from corresponding natural language query. Large language models (LLMs) have demonstrated proficiency in various computer vision tasks. However, existing methods for MR\\&amp;HD have not yet been integrated with LLMs. In this letter, we propose a novel two-stage model that takes the output of LLMs as the input to the second-stage transformer encoder-decoder. First, MiniGPT-4 is employed to generate the detailed description of the video frame and rewrite the query statement, fed into the encoder as new features. Then, semantic similarity is computed between the generated description and the rewritten queries. Finally, continuous high-similarity video frames are converted into span anchors, serving as prior position information for the decoder. Experiments demonstrate that our approach achieves a state-of-the-art result, and by using only span anchors and similarity scores as outputs, positioning accuracy outperforms traditional methods, like Moment-DETR.","[{'name': 'Yunzhuo Sun, Yifang Xu, Zien Xie, Yukun Shu, Sidan Du'}]",
1347,Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment,https://arxiv.org/abs/2403.01456,"arXiv:2403.01456v1 Announce Type: cross 
Abstract: Item difficulty plays a crucial role in adaptive testing. However, few works have focused on generating questions of varying difficulty levels, especially for multiple-choice (MC) cloze tests. We propose training pre-trained language models (PLMs) as surrogate models to enable item response theory (IRT) assessment, avoiding the need for human test subjects. We also propose two strategies to control the difficulty levels of both the gaps and the distractors using ranking rules to reduce invalid distractors. Experimentation on a benchmark dataset demonstrates that our proposed framework and methods can effectively control and evaluate the difficulty levels of MC cloze tests.","[{'name': 'Jingshen Zhang, Jiajun Xie, Xinying Qiu'}]",
1348,Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation,https://arxiv.org/abs/2403.01467,"arXiv:2403.01467v1 Announce Type: cross 
Abstract: Unsupervised Graph Domain Adaptation (UGDA) has emerged as a practical solution to transfer knowledge from a label-rich source graph to a completely unlabelled target graph. However, most methods require a labelled source graph to provide supervision signals, which might not be accessible in the real-world settings due to regulations and privacy concerns. In this paper, we explore the scenario of source-free unsupervised graph domain adaptation, which tries to address the domain adaptation problem without accessing the labelled source graph. Specifically, we present a novel paradigm called GraphCTA, which performs model adaptation and graph adaptation collaboratively through a series of procedures: (1) conduct model adaptation based on node's neighborhood predictions in target graph considering both local and global information; (2) perform graph adaptation by updating graph structure and node attributes via neighborhood contrastive learning; and (3) the updated graph serves as an input to facilitate the subsequent iteration of model adaptation, thereby establishing a collaborative loop between model adaptation and graph adaptation. Comprehensive experiments are conducted on various public datasets. The experimental results demonstrate that our proposed model outperforms recent source-free baselines by large margins.","[{'name': 'Zhen Zhang, Meihan Liu, Anhui Wang, Hongyang Chen, Zhao Li, Jiajun Bu, Bingsheng He'}]",
1349,Representation Learning on Heterophilic Graph with Directional Neighborhood Attention,https://arxiv.org/abs/2403.01475,"arXiv:2403.01475v1 Announce Type: cross 
Abstract: Graph Attention Network (GAT) is one of the most popular Graph Neural Network (GNN) architecture, which employs the attention mechanism to learn edge weights and has demonstrated promising performance in various applications. However, since it only incorporates information from immediate neighborhood, it lacks the ability to capture long-range and global graph information, leading to unsatisfactory performance on some datasets, particularly on heterophilic graphs. To address this limitation, we propose the Directional Graph Attention Network (DGAT) in this paper. DGAT is able to combine the feature-based attention with the global directional information extracted from the graph topology. To this end, a new class of Laplacian matrices is proposed which can provably reduce the diffusion distance between nodes. Based on the new Laplacian, topology-guided neighbour pruning and edge adding mechanisms are proposed to remove the noisy and capture the helpful long-range neighborhood information. Besides, a global directional attention is designed to enable a topological-aware information propagation. The superiority of the proposed DGAT over the baseline GAT has also been verified through experiments on real-world benchmarks and synthetic data sets. It also outperforms the state-of-the-art (SOTA) models on 6 out of 7 real-world benchmark datasets.","[{'name': 'Qincheng Lu, Jiaqi Zhu, Sitao Luan, Xiao-Wen Chang'}]",
1350,Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation,https://arxiv.org/abs/2403.01479,"arXiv:2403.01479v1 Announce Type: cross 
Abstract: The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation. Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb and WMT-2014 En->De, respectively, compared to Transformer baselines.","[{'name': 'Heegon Jin, Seonil Son, Jemin Park, Youngseok Kim, Hyungjong Noh, Yeonsoo Lee'}]",
1351,Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models,https://arxiv.org/abs/2403.01489,"arXiv:2403.01489v1 Announce Type: cross 
Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image generative models. Comprehensive experiments reveal that (1) Our method can effectively attribute fake images to their source models, achieving comparable attribution performance with the state-of-the-art method; (2) Our method has high scalability ability, which is well adapted to real-world attribution scenarios. (3) The proposed method yields satisfactory robustness to common attacks, such as Gaussian blurring, JPEG compression, and Resizing. We also analyze the factors that influence the attribution performance, and explore the boost brought by the proposed method as a plug-in to improve the performance of existing SOTA. We hope our work can shed some light on the solutions to addressing the source of AI-generated images, as well as to prevent the misuse of text-to-image generative models.","[{'name': 'Meiling Li, Zhenxing Qian, Xinpeng Zhang'}]",
1352,End-to-End Human Instance Matting,https://arxiv.org/abs/2403.01510,"arXiv:2403.01510v1 Announce Type: cross 
Abstract: Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspondences of all instances. Finally, an instance matting network decodes the image features and united semantics guidance to predict all instance-level alpha mattes. In addition, we construct a large-scale human instance matting dataset (HIM-100K) comprising over 100,000 human images with instance alpha matte labels. Experiments on HIM-100K demonstrate the proposed E2E-HIM outperforms the existing methods on human instance matting with 50% lower errors and 5X faster speed (6 instances in a 640X640 image). Experiments on the PPM-100, RWP-636, and P3M datasets demonstrate that E2E-HIM also achieves competitive performance on traditional human matting.","[{'name': 'Qinglin Liu, Shengping Zhang, Quanling Meng, Bineng Zhong, Peiqiang Liu, Hongxun Yao'}]",
1353,Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey,https://arxiv.org/abs/2403.01528,"arXiv:2403.01528v1 Announce Type: cross 
Abstract: The integration of biomolecular modeling with natural language (BL) has emerged as a promising interdisciplinary area at the intersection of artificial intelligence, chemistry and biology. This approach leverages the rich, multifaceted descriptions of biomolecules contained within textual data sources to enhance our fundamental understanding and enable downstream computational tasks such as biomolecule property prediction. The fusion of the nuanced narratives expressed through natural language with the structural and functional specifics of biomolecules described via various molecular modeling techniques opens new avenues for comprehensively representing and analyzing biomolecules. By incorporating the contextual language data that surrounds biomolecules into their modeling, BL aims to capture a holistic view encompassing both the symbolic qualities conveyed through language as well as quantitative structural characteristics. In this review, we provide an extensive analysis of recent advancements achieved through cross modeling of biomolecules and natural language. (1) We begin by outlining the technical representations of biomolecules employed, including sequences, 2D graphs, and 3D structures. (2) We then examine in depth the rationale and key objectives underlying effective multi-modal integration of language and molecular data sources. (3) We subsequently survey the practical applications enabled to date in this developing research area. (4) We also compile and summarize the available resources and datasets to facilitate future work. (5) Looking ahead, we identify several promising research directions worthy of further exploration and investment to continue advancing the field. The related resources and contents are updating in \\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.","[{'name': 'Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Yue Wang, Zun Wang, Tao Qin, Rui Yan'}]",
1354,Machine learning predicts long-term mortality after acute myocardial infarction using systolic time intervals and routinely collected clinical data,https://arxiv.org/abs/2403.01533,"arXiv:2403.01533v1 Announce Type: cross 
Abstract: Precise estimation of cardiac patients' current and future comorbidities is an important factor in prioritizing continuous physiological monitoring and new therapies. ML models have shown satisfactory performance in short-term mortality prediction of patients with heart disease, while their utility in long-term predictions is limited. This study aims to investigate the performance of tree-based ML models on long-term mortality prediction and the effect of two recently introduced biomarkers on long-term mortality. This study utilized publicly available data from CCHIA at the Ministry of Health and Welfare, Taiwan, China. Medical records were used to gather demographic and clinical data, including age, gender, BMI, percutaneous coronary intervention (PCI) status, and comorbidities such as hypertension, dyslipidemia, ST-segment elevation myocardial infarction (STEMI), and non-STEMI. Using medical and demographic records as well as two recently introduced biomarkers, brachial pre-ejection period (bPEP) and brachial ejection time (bET), collected from 139 patients with acute myocardial infarction, we investigated the performance of advanced ensemble tree-based ML algorithms (random forest, AdaBoost, and XGBoost) to predict all-cause mortality within 14 years. The developed ML models achieved significantly better performance compared to the baseline LR (C-Statistic, 0.80 for random forest, 0.79 for AdaBoost, and 0.78 for XGBoost, vs 0.77 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). Adding bPEP and bET to our feature set significantly improved the algorithms' performance, leading to an absolute increase in C-Statistic of up to 0.03 (C-Statistic, 0.83 for random forest, 0.82 for AdaBoost, and 0.80 for XGBoost, vs 0.74 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). This advancement may enable better treatment prioritization for high-risk individuals.","[{'name': 'Bijan Roudini, Boshra Khajehpiri, Hamid Abrishami Moghaddam, Mohamad Forouzanfar'}]",
1355,In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation,https://arxiv.org/abs/2403.01548,"arXiv:2403.01548v1 Announce Type: cross 
Abstract: Large language models (LLMs) frequently hallucinate and produce factual errors, yet our understanding of why they make these errors remains limited. In this study, we delve into the underlying mechanisms of LLM hallucinations from the perspective of inner representations, and discover a salient pattern associated with hallucinations: correct generations tend to have sharper context activations in the hidden states of the in-context tokens, compared to the incorrect ones. Leveraging this insight, we propose an entropy-based metric to quantify the ``sharpness'' among the in-context hidden states and incorporate it into the decoding process to formulate a constrained decoding approach. Experiments on various knowledge-seeking and hallucination benchmarks demonstrate our approach's consistent effectiveness, for example, achieving up to an 8.6 point improvement on TruthfulQA. We believe this study can improve our understanding of hallucinations and serve as a practical solution for hallucination mitigation.","[{'name': 'Shiqi Chen, Miao Xiong, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, Junxian He'}]",
1356,ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates,https://arxiv.org/abs/2403.01564,"arXiv:2403.01564v1 Announce Type: cross 
Abstract: Optimal decision-making for trajectory tracking in partially observable, stochastic environments where the number of active localization updates -- the process by which the agent obtains its true state information from the sensors -- are limited, presents a significant challenge. Traditional methods often struggle to balance resource conservation, accurate state estimation and precise tracking, resulting in suboptimal performance. This problem is particularly pronounced in environments with large action spaces, where the need for frequent, accurate state data is paramount, yet the capacity for active localization updates is restricted by external limitations. This paper introduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN) and Model Predictive Control (MPC) to optimize trajectory tracking with constrained active localization updates. The meta-trained DQN ensures adaptive active localization scheduling, while the MPC leverages available state information to improve tracking. The central contribution of this work is their reciprocal interaction: DQN's update decisions inform MPC's control strategy, and MPC's outcomes refine DQN's learning, creating a cohesive, adaptive system. Empirical evaluations in simulated and real-world settings demonstrate that ComTraQ-MPC significantly enhances operational efficiency and accuracy, providing a generalizable and approximately optimal solution for trajectory tracking in complex partially observable environments.","[{'name': 'Gokul Puthumanaillam, Manav Vora, Melkior Ornik'}]",
1357,ReMatch: Retrieval Enhanced Schema Matching with LLMs,https://arxiv.org/abs/2403.01567,"arXiv:2403.01567v1 Announce Type: cross 
Abstract: Schema matching is a crucial task in data integration, involving the alignment of a source database schema with a target schema to establish correspondence between their elements. This task is challenging due to textual and semantic heterogeneity, as well as differences in schema sizes. Although machine-learning-based solutions have been explored in numerous studies, they often suffer from low accuracy, require manual mapping of the schemas for model training, or need access to source schema data which might be unavailable due to privacy concerns. In this paper we present a novel method, named ReMatch, for matching schemas using retrieval-enhanced Large Language Models (LLMs). Our method avoids the need for predefined mapping, any model training, or access to data in the source database. In the ReMatch method the tables of the target schema and the attributes of the source schema are first represented as structured passage-based documents. For each source attribute document, we retrieve $J$ documents, representing target schema tables, according to their semantic relevance. Subsequently, we create a prompt for every source table, comprising all its attributes and their descriptions, alongside all attributes from the set of top $J$ target tables retrieved previously. We employ LLMs using this prompt for the matching task, yielding a ranked list of $K$ potential matches for each source attribute. Our experimental results on large real-world schemas demonstrate that ReMatch significantly improves matching capabilities and outperforms other machine learning approaches. By eliminating the requirement for training data, ReMatch becomes a viable solution for real-world scenarios.","[{'name': 'Eitam Sheetrit, Menachem Brief, Moshik Mishaeli, Oren Elisha'}]",
1358,Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV,https://arxiv.org/abs/2403.01569,"arXiv:2403.01569v1 Announce Type: cross 
Abstract: Self-supervised learning is the key to unlocking generic computer vision systems. By eliminating the reliance on ground-truth annotations, it allows scaling to much larger data quantities. Unfortunately, self-supervised monocular depth estimation (SS-MDE) has been limited by the absence of diverse training data. Existing datasets have focused exclusively on urban driving in densely populated cities, resulting in models that fail to generalize beyond this domain.
  To address these limitations, this paper proposes two novel datasets: SlowTV and CribsTV. These are large-scale datasets curated from publicly available YouTube videos, containing a total of 2M training frames. They offer an incredibly diverse set of environments, ranging from snowy forests to coastal roads, luxury mansions and even underwater coral reefs. We leverage these datasets to tackle the challenging task of zero-shot generalization, outperforming every existing SS-MDE approach and even some state-of-the-art supervised methods.
  The generalization capabilities of our models are further enhanced by a range of components and contributions: 1) learning the camera intrinsics, 2) a stronger augmentation regime targeting aspect ratio changes, 3) support frame randomization, 4) flexible motion estimation, 5) a modern transformer-based architecture. We demonstrate the effectiveness of each component in extensive ablation experiments. To facilitate the development of future research, we make the datasets, code and pretrained models available to the public at https://github.com/jspenmar/slowtv_monodepth.","[{'name': 'Jaime Spencer, Chris Russell, Simon Hadfield, Richard Bowden'}]",
1359,SARD: A Human-AI Collaborative Story Generation,https://arxiv.org/abs/2403.01575,"arXiv:2403.01575v1 Announce Type: cross 
Abstract: Generative artificial intelligence (GenAI) has ushered in a new era for storytellers, providing a powerful tool to ignite creativity and explore uncharted narrative territories. As technology continues to advance, the synergy between human creativity and AI-generated content holds the potential to redefine the landscape of storytelling. In this work, we propose SARD, a drag-and-drop visual interface for generating a multi-chapter story using large language models. Our evaluation of the usability of SARD and its creativity support shows that while node-based visualization of the narrative may help writers build a mental model, it exerts unnecessary mental overhead to the writer and becomes a source of distraction as the story becomes more elaborated. We also found that AI generates stories that are less lexically diverse, irrespective of the complexity of the story. We identified some patterns and limitations of our tool that can guide the development of future human-AI co-writing tools.","[{'name': 'Ahmed Y. Radwan, Khaled M. Alasmari, Omar A. Abdulbagi, Emad A. Alghamdi'}]",
1360,"Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures",https://arxiv.org/abs/2403.01580,"arXiv:2403.01580v1 Announce Type: cross 
Abstract: In the current machine translation (MT) landscape, the Transformer architecture stands out as the gold standard, especially for high-resource language pairs. This research delves into its efficacy for low-resource language pairs including both the English$\\leftrightarrow$Irish and English$\\leftrightarrow$Marathi language pairs. Notably, the study identifies the optimal hyperparameters and subword model type to significantly improve the translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT development. To address this, gaHealth was developed, the first bilingual corpus of health data for the Irish language. Focusing on the health domain, models developed using this in-domain dataset exhibited very significant improvements in BLEU score when compared with models from the LoResMT2021 Shared Task. A subsequent human evaluation using the multidimensional quality metrics error taxonomy showcased the superior performance of the Transformer system in reducing both accuracy and fluency errors compared to an RNN-based counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source applications streamlined for the development, fine-tuning, and deployment of neural machine translation models. These tools considerably simplify the setup and evaluation process, making MT more accessible to both developers and translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes eco-friendly natural language processing research by highlighting the environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM demonstrated advancements in translation performance for two low-resource language pairs: English$\\leftrightarrow$Irish and English$\\leftrightarrow$Marathi, compared to baselines from the LoResMT2021 Shared Task.",[{'name': \"S\\\\'eamus Lankford\"}],
1361,APISR: Anime Production Inspired Real-World Anime Super-Resolution,https://arxiv.org/abs/2403.01598,"arXiv:2403.01598v1 Announce Type: cross 
Abstract: While real-world anime super-resolution (SR) has gained increasing attention in the SR community, existing methods still adopt techniques from the photorealistic domain. In this paper, we analyze the anime production workflow and rethink how to use characteristics of it for the sake of the real-world anime SR. First, we argue that video networks and datasets are not necessary for anime SR due to the repetition use of hand-drawing frames. Instead, we propose an anime image collection pipeline by choosing the least compressed and the most informative frames from the video sources. Based on this pipeline, we introduce the Anime Production-oriented Image (API) dataset. In addition, we identify two anime-specific challenges of distorted and faint hand-drawn lines and unwanted color artifacts. We address the first issue by introducing a prediction-oriented compression module in the image degradation model and a pseudo-ground truth preparation with enhanced hand-drawn lines. In addition, we introduce the balanced twin perceptual loss combining both anime and photorealistic high-level features to mitigate unwanted color artifacts and increase visual clarity. We evaluate our method through extensive experiments on the public benchmark, showing our method outperforms state-of-the-art approaches by a large margin.","[{'name': 'Boyang Wang, Fengyu Yang, Xihang Yu, Chao Zhang, Hanbin Zhao'}]",
1362,SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos,https://arxiv.org/abs/2403.01599,"arXiv:2403.01599v1 Announce Type: cross 
Abstract: We study the problem of procedure planning in instructional videos, which aims to make a goal-oriented sequence of action steps given partial visual state observations. The motivation of this problem is to learn a structured and plannable state and action space. Recent works succeeded in sequence modeling of steps with only sequence-level annotations accessible during training, which overlooked the roles of states in the procedures. In this work, we point out that State CHangEs MAtter (SCHEMA) for procedure planning in instructional videos. We aim to establish a more structured state space by investigating the causal relations between steps and states in procedures. Specifically, we explicitly represent each step as state changes and track the state changes in procedures. For step representation, we leveraged the commonsense knowledge in large language models (LLMs) to describe the state changes of steps via our designed chain-of-thought prompting. For state change tracking, we align visual state observations with language state descriptions via cross-modal contrastive learning, and explicitly model the intermediate states of the procedure using LLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV benchmark datasets demonstrate that our proposed SCHEMA model achieves state-of-the-art performance and obtains explainable visualizations.","[{'name': 'Yulei Niu, Wenliang Guo, Long Chen, Xudong Lin, Shih-Fu Chang'}]",
1363,Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making,https://arxiv.org/abs/2403.01600,"arXiv:2403.01600v1 Announce Type: cross 
Abstract: In the last decades, there has been a deceleration in the rates of poverty reduction, suggesting that traditional redistributive approaches to poverty mitigation could be losing effectiveness, and alternative insights to advance the number one UN Sustainable Development Goal are required. The criminalization of poor people has been denounced by several NGOs, and an increasing number of voices suggest that discrimination against the poor (a phenomenon known as \\emph{aporophobia}) could be an impediment to mitigating poverty. In this paper, we present the novel Aporophobia Agent-Based Model (AABM) to provide evidence of the correlation between aporophobia and poverty computationally. We present our use case built with real-world demographic data and poverty-mitigation public policies (either enforced or under parliamentary discussion) for the city of Barcelona. We classify policies as discriminatory or non-discriminatory against the poor, with the support of specialized NGOs, and we observe the results in the AABM in terms of the impact on wealth inequality. The simulation provides evidence of the relationship between aporophobia and the increase of wealth inequality levels, paving the way for a new generation of poverty reduction policies that act on discrimination and tackle poverty as a societal problem (not only a problem of the poor).","[{'name': 'Alba Aguilera, Nieves Montes, Georgina Curto, Carles Sierra, Nardine Osman'}]",
1364,Towards Provable Log Density Policy Gradient,https://arxiv.org/abs/2403.01605,"arXiv:2403.01605v1 Announce Type: cross 
Abstract: Policy gradient methods are a vital ingredient behind the success of modern reinforcement learning. Modern policy gradient methods, although successful, introduce a residual error in gradient estimation. In this work, we argue that this residual term is significant and correcting for it could potentially improve sample-complexity of reinforcement learning methods. To that end, we propose log density gradient to estimate the policy gradient, which corrects for this residual error term. Log density gradient method computes policy gradient by utilising the state-action discounted distributional formulation. We first present the equations needed to exactly find the log density gradient for a tabular Markov Decision Processes (MDPs). For more complex environments, we propose a temporal difference (TD) method that approximates log density gradient by utilizing backward on-policy samples. Since backward sampling from a Markov chain is highly restrictive we also propose a min-max optimization that can approximate log density gradient using just on-policy samples. We also prove uniqueness, and convergence under linear function approximation, for this min-max optimization. Finally, we show that the sample complexity of our min-max optimization to be of the order of $m^{-1/2}$, where $m$ is the number of on-policy samples. We also demonstrate a proof-of-concept for our log density gradient method on gridworld environment, and observe that our method is able to improve upon the classical policy gradient method by a clear margin, thus indicating a promising novel direction to develop reinforcement learning algorithms that require fewer samples.","[{'name': 'Pulkit Katdare, Anant Joshi, Katherine Driggs-Campbell'}]",
1365,A Unified Model Selection Technique for Spectral Clustering Based Motion Segmentation,https://arxiv.org/abs/2403.01606,"arXiv:2403.01606v1 Announce Type: cross 
Abstract: Motion segmentation is a fundamental problem in computer vision and is crucial in various applications such as robotics, autonomous driving and action recognition. Recently, spectral clustering based methods have shown impressive results on motion segmentation in dynamic environments. These methods perform spectral clustering on motion affinity matrices to cluster objects or point trajectories in the scene into different motion groups. However, existing methods often need the number of motions present in the scene to be known, which significantly reduces their practicality. In this paper, we propose a unified model selection technique to automatically infer the number of motion groups for spectral clustering based motion segmentation methods by combining different existing model selection techniques together. We evaluate our method on the KT3DMoSeg dataset and achieve competitve results comparing to the baseline where the number of clusters is given as ground truth information.","[{'name': 'Yuxiang Huang, John Zelek'}]",
1366,Machine Learning vs Deep Learning: The Generalization Problem,https://arxiv.org/abs/2403.01621,"arXiv:2403.01621v1 Announce Type: cross 
Abstract: The capacity to generalize beyond the range of training data is a pivotal challenge, often synonymous with a model's utility and robustness. This study investigates the comparative abilities of traditional machine learning (ML) models and deep learning (DL) algorithms in terms of extrapolation -- a more challenging aspect of generalization because it requires the model to make inferences about data points that lie outside the domain it has been trained on. We present an empirical analysis where both ML and DL models are trained on an exponentially growing function and then tested on values outside the training domain. The choice of this function allows us to distinctly showcase the divergence in performance when models are required to predict beyond the scope of their training data. Our findings suggest that deep learning models possess inherent capabilities to generalize beyond the training scope, an essential feature for real-world applications where data is often incomplete or extends beyond the observed range. This paper argues for a nuanced understanding of the structural differences between ML and DL models, with an emphasis on the implications for both theoretical research and practical deployment.","[{'name': 'Yong Yi Bay, Kathleen A. Yearick'}]",
1367,You Need to Pay Better Attention,https://arxiv.org/abs/2403.01643,"arXiv:2403.01643v1 Announce Type: cross 
Abstract: We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MNIST, CIFAR100, IMDB Movie Reviews, and Amazon Reviews datasets.","[{'name': 'Mehran Hosseini, Peyman Hosseini'}]",
1368,Recommendations for Government Development and Use of Advanced Automated Systems to Make Decisions about Individuals,https://arxiv.org/abs/2403.01649,"arXiv:2403.01649v1 Announce Type: cross 
Abstract: Contestability -- the ability to effectively challenge a decision -- is critical to the implementation of fairness. In the context of governmental decision making about individuals, contestability is often constitutionally required as an element of due process; specific procedures may be required by state or federal law relevant to a particular program. In addition, contestability can be a valuable way to discover systemic errors, contributing to ongoing assessments and system improvement.
  On January 24-25, 2024, with support from the National Science Foundation and the William and Flora Hewlett Foundation, we convened a diverse group of government officials, representatives of leading technology companies, technology and policy experts from academia and the non-profit sector, advocates, and stakeholders for a workshop on advanced automated decision making, contestability, and the law. Informed by the workshop's rich and wide-ranging discussion, we offer these recommendations. A full report summarizing the discussion is in preparation.","[{'name': 'Susan Landau, James X. Dempsey, Ece Kamar, Steven M. Bellovin'}]",
1369,CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables,https://arxiv.org/abs/2403.01673,"arXiv:2403.01673v1 Announce Type: cross 
Abstract: For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D temporal-contextual attention mechanism, which generates Auxiliary Time Series (ATS) from Original Time Series (OTS) to effectively represent and incorporate inter-series relationships for forecasting. Key principles of ATS - continuity, sparsity, and variability - are identified and implemented through different modules. Even with a basic 2-layer MLP as core predictor, CATS achieves state-of-the-art, significantly reducing complexity and parameters compared to previous multivariate models, marking it an efficient and transferable MTSF solution.","[{'name': 'Jiecheng Lu, Xu Han, Yan Sun, Shihao Yang'}]",
1370,HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances,https://arxiv.org/abs/2403.01693,"arXiv:2403.01693v1 Announce Type: cross 
Abstract: Text-to-image generative models can generate high-quality humans, but realism is lost when generating hands. Common artifacts include irregular hand poses, shapes, incorrect numbers of fingers, and physically implausible finger orientations. To generate images with realistic hands, we propose a novel diffusion-based architecture called HanDiffuser that achieves realism by injecting hand embeddings in the generative process. HanDiffuser consists of two components: a Text-to-Hand-Params diffusion model to generate SMPL-Body and MANO-Hand parameters from input text prompts, and a Text-Guided Hand-Params-to-Image diffusion model to synthesize images by conditioning on the prompts and hand parameters generated by the previous component. We incorporate multiple aspects of hand representation, including 3D shapes and joint-level finger positions, orientations and articulations, for robust learning and reliable performance during inference. We conduct extensive quantitative and qualitative experiments and perform user studies to demonstrate the efficacy of our method in generating images with high-quality hands.","[{'name': 'Supreeth Narasimhaswamy, Uttaran Bhattacharya, Xiang Chen, Ishita Dasgupta, Saayan Mitra, Minh Hoai'}]",
1371,DyCE: Dynamic Configurable Exiting for Deep Learning Compression and Scaling,https://arxiv.org/abs/2403.01695,"arXiv:2403.01695v1 Announce Type: cross 
Abstract: Modern deep learning (DL) models necessitate the employment of scaling and compression techniques for effective deployment in resource-constrained environments. Most existing techniques, such as pruning and quantization are generally static. On the other hand, dynamic compression methods, such as early exits, reduce complexity by recognizing the difficulty of input samples and allocating computation as needed. Dynamic methods, despite their superior flexibility and potential for co-existing with static methods, pose significant challenges in terms of implementation due to any changes in dynamic parts will influence subsequent processes. Moreover, most current dynamic compression designs are monolithic and tightly integrated with base models, thereby complicating the adaptation to novel base models. This paper introduces DyCE, an dynamic configurable early-exit framework that decouples design considerations from each other and from the base model. Utilizing this framework, various types and positions of exits can be organized according to predefined configurations, which can be dynamically switched in real-time to accommodate evolving performance-complexity requirements. We also propose techniques for generating optimized configurations based on any desired trade-off between performance and computational complexity. This empowers future researchers to focus on the improvement of individual exits without latent compromise of overall system performance. The efficacy of this approach is demonstrated through image classification tasks with deep CNNs. DyCE significantly reduces the computational complexity by 23.5% of ResNet152 and 25.9% of ConvNextv2-tiny on ImageNet, with accuracy reductions of less than 0.5%. Furthermore, DyCE offers advantages over existing dynamic methods in terms of real-time configuration and fine-grained performance tuning.","[{'name': \"Qingyuan Wang, Barry Cardiff, Antoine Frapp\\\\'e, Benoit Larras, Deepu John\"}]",
1372,Hypertext Entity Extraction in Webpage,https://arxiv.org/abs/2403.01698,"arXiv:2403.01698v1 Announce Type: cross 
Abstract: Webpage entity extraction is a fundamental natural language processing task in both research and applications. Nowadays, the majority of webpage entity extraction models are trained on structured datasets which strive to retain textual content and its structure information. However, existing datasets all overlook the rich hypertext features (e.g., font color, font size) which show their effectiveness in previous works. To this end, we first collect a \\textbf{H}ypertext \\textbf{E}ntity \\textbf{E}xtraction \\textbf{D}ataset (\\textit{HEED}) from the e-commerce domains, scraping both the text and the corresponding explicit hypertext features with high-quality manual entity annotations. Furthermore, we present the \\textbf{Mo}E-based \\textbf{E}ntity \\textbf{E}xtraction \\textbf{F}ramework (\\textit{MoEEF}), which efficiently integrates multiple features to enhance model performance by Mixture of Experts and outperforms strong baselines, including the state-of-the-art small-scale models and GPT-3.5-turbo. Moreover, the effectiveness of hypertext features in \\textit{HEED} and several model components in \\textit{MoEEF} are analyzed.","[{'name': 'Yifei Yang, Tianqiao Liu, Bo Shao, Hai Zhao, Linjun Shou, Ming Gong, Daxin Jiang'}]",
1373,Brilla AI: AI Contestant for the National Science and Maths Quiz,https://arxiv.org/abs/2403.01699,"arXiv:2403.01699v1 Announce Type: cross 
Abstract: The African continent lacks enough qualified teachers which hampers the provision of adequate learning support. An AI could potentially augment the efforts of the limited number of teachers, leading to better learning outcomes. Towards that end, this work describes and evaluates the first key output for the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for such an AI: \"Build an AI to compete live in Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing better than the best contestants in all rounds and stages of the competition\". The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. In this work, we built Brilla AI, an AI contestant that we deployed to unofficially compete remotely and live in the Riddles round of the 2023 NSMQ Grand Finale, the first of its kind in the 30-year history of the competition. Brilla AI is currently available as a web app that livestreams the Riddles round of the contest, and runs 4 machine learning systems: (1) speech to text (2) question extraction (3) question answering and (4) text to speech that work together in real-time to quickly and accurately provide an answer, and then say it with a Ghanaian accent. In its debut, our AI answered one of the 4 riddles ahead of the 3 human contesting teams, unofficially placing second (tied). Improvements and extensions of this AI could potentially be deployed to offer science tutoring to students and eventually enable millions across Africa to have one-on-one learning interactions, democratizing science education.","[{'name': 'George Boateng, Jonathan Abrefah Mensah, Kevin Takyi Yeboah, William Edor, Andrew Kojo Mensah-Onumah, Naafi Dasana Ibrahim, Nana Sam Yeboah'}]",
1374,Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study,https://arxiv.org/abs/2403.01709,"arXiv:2403.01709v1 Announce Type: cross 
Abstract: Architectural Knowledge Management (AKM) involves the organized handling of information related to architectural decisions and design within a project or organization. An essential artifact of AKM is the Architecture Decision Records (ADR), which documents key design decisions. ADRs are documents that capture decision context, decision made and various aspects related to a design decision, thereby promoting transparency, collaboration, and understanding. Despite their benefits, ADR adoption in software development has been slow due to challenges like time constraints and inconsistent uptake. Recent advancements in Large Language Models (LLMs) may help bridge this adoption gap by facilitating ADR generation. However, the effectiveness of LLM for ADR generation or understanding is something that has not been explored. To this end, in this work, we perform an exploratory study that aims to investigate the feasibility of using LLM for the generation of ADRs given the decision context. In our exploratory study, we utilize GPT and T5-based models with 0-shot, few-shot, and fine-tuning approaches to generate the Decision of an ADR given its Context. Our results indicate that in a 0-shot setting, state-of-the-art models such as GPT-4 generate relevant and accurate Design Decisions, although they fall short of human-level performance. Additionally, we observe that more cost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot setting, and smaller models such as Flan-T5 can yield comparable results after fine-tuning. To conclude, this exploratory study suggests that LLM can generate Design Decisions, but further research is required to attain human-level generation and establish standardized widespread adoption.","[{'name': 'Rudra Dhar, Karthik Vaidhyanathan, Vasudeva Varma'}]",
1375,Offline Goal-Conditioned Reinforcement Learning for Safety-Critical Tasks with Recovery Policy,https://arxiv.org/abs/2403.01734,"arXiv:2403.01734v1 Announce Type: cross 
Abstract: Offline goal-conditioned reinforcement learning (GCRL) aims at solving goal-reaching tasks with sparse rewards from an offline dataset. While prior work has demonstrated various approaches for agents to learn near-optimal policies, these methods encounter limitations when dealing with diverse constraints in complex environments, such as safety constraints. Some of these approaches prioritize goal attainment without considering safety, while others excessively focus on safety at the expense of training efficiency. In this paper, we study the problem of constrained offline GCRL and propose a new method called Recovery-based Supervised Learning (RbSL) to accomplish safety-critical tasks with various goals. To evaluate the method performance, we build a benchmark based on the robot-fetching environment with a randomly positioned obstacle and use expert or random policies to generate an offline dataset. We compare RbSL with three offline GCRL algorithms and one offline safe RL algorithm. As a result, our method outperforms the existing state-of-the-art methods to a large extent. Furthermore, we validate the practicality and effectiveness of RbSL by deploying it on a real Panda manipulator. Code is available at https://github.com/Sunlighted/RbSL.git.","[{'name': 'Chenyang Cao, Zichen Yan, Renhao Lu, Junbo Tan, Xueqian Wang'}]",
1376,Diffusion-TS: Interpretable Diffusion for General Time Series Generation,https://arxiv.org/abs/2403.01742,"arXiv:2403.01742v1 Announce Type: cross 
Abstract: Denoising diffusion probabilistic models (DDPMs) are becoming the leading paradigm for generative models. It has recently shown breakthroughs in audio synthesis, time series imputation and forecasting. In this paper, we propose Diffusion-TS, a novel diffusion-based framework that generates multivariate time series samples of high quality by using an encoder-decoder transformer with disentangled temporal representations, in which the decomposition technique guides Diffusion-TS to capture the semantic meaning of time series while transformers mine detailed sequential information from the noisy model input. Different from existing diffusion-based approaches, we train the model to directly reconstruct the sample instead of the noise in each diffusion step, combining a Fourier-based loss term. Diffusion-TS is expected to generate time series satisfying both interpretablity and realness. In addition, it is shown that the proposed Diffusion-TS can be easily extended to conditional generation tasks, such as forecasting and imputation, without any model changes. This also motivates us to further explore the performance of Diffusion-TS under irregular settings. Finally, through qualitative and quantitative experiments, results show that Diffusion-TS achieves the state-of-the-art results on various realistic analyses of time series.","[{'name': 'Xinyu Yuan, Yan Qiao'}]",
1377,Decode Neural signal as Speech,https://arxiv.org/abs/2403.01748,"arXiv:2403.01748v1 Announce Type: cross 
Abstract: Decoding language from brain dynamics is an important open direction in the realm of brain-computer interface (BCI), especially considering the rapid growth of large language models. Compared to invasive-based signals which require electrode implantation surgery, non-invasive neural signals (e.g. EEG, MEG) have attracted increasing attention considering their safety and generality. However, the exploration is not adequate in three aspects: 1) previous methods mainly focus on EEG but none of the previous works address this problem on MEG with better signal quality; 2) prior works have predominantly used ``teacher-forcing\" during generative decoding, which is impractical; 3) prior works are mostly ``BART-based\" not fully auto-regressive, which performs better in other sequence tasks. In this paper, we explore the brain-to-text translation of MEG signals in a speech-decoding formation. Here we are the first to investigate a cross-attention-based ``whisper\" model for generating text directly from MEG signals without teacher forcing. Our model achieves impressive BLEU-1 scores of 60.30 and 52.89 without pretraining \\& teacher-forcing on two major datasets (\\textit{GWilliams} and \\textit{Schoffelen}). This paper conducts a comprehensive review to understand how speech decoding formation performs on the neural decoding tasks, including pretraining initialization, training \\& evaluation set splitting, augmentation, and scaling law.","[{'name': 'Yiqian Yang, Yiqun Duan, Qiang Zhang, Renjing Xu, Hui Xiong'}]",
1378,Canonical Form of Datatic Description in Control Systems,https://arxiv.org/abs/2403.01768,"arXiv:2403.01768v1 Announce Type: cross 
Abstract: The design of feedback controllers is undergoing a paradigm shift from modelic (i.e., model-driven) control to datatic (i.e., data-driven) control. Canonical form of state space model is an important concept in modelic control systems, exemplified by Jordan form, controllable form and observable form, whose purpose is to facilitate system analysis and controller synthesis. In the realm of datatic control, there is a notable absence in the standardization of data-based system representation. This paper for the first time introduces the concept of canonical data form for the purpose of achieving more effective design of datatic controllers. In a control system, the data sample in canonical form consists of a transition component and an attribute component. The former encapsulates the plant dynamics at the sampling time independently, which is a tuple containing three elements: a state, an action and their corresponding next state. The latter describes one or some artificial characteristics of the current sample, whose calculation must be performed in an online manner. The attribute of each sample must adhere to two requirements: (1) causality, ensuring independence from any future samples; and (2) locality, allowing dependence on historical samples but constrained to a finite neighboring set. The purpose of adding attribute is to offer some kinds of benefits for controller design in terms of effectiveness and efficiency. To provide a more close-up illustration, we present two canonical data forms: temporal form and spatial form, and demonstrate their advantages in reducing instability and enhancing training efficiency in two datatic control systems.","[{'name': 'Guojian Zhan, Ziang Zheng, Shengbo Eben Li'}]",
1379,A Safe Screening Rule with Bi-level Optimization of $\\nu$ Support Vector Machine,https://arxiv.org/abs/2403.01769,"arXiv:2403.01769v1 Announce Type: cross 
Abstract: Support vector machine (SVM) has achieved many successes in machine learning, especially for a small sample problem. As a famous extension of the traditional SVM, the $\\nu$ support vector machine ($\\nu$-SVM) has shown outstanding performance due to its great model interpretability. However, it still faces challenges in training overhead for large-scale problems. To address this issue, we propose a safe screening rule with bi-level optimization for $\\nu$-SVM (SRBO-$\\nu$-SVM) which can screen out inactive samples before training and reduce the computational cost without sacrificing the prediction accuracy. Our SRBO-$\\nu$-SVM is strictly deduced by integrating the Karush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex problems and the $\\nu$-property. Furthermore, we develop an efficient dual coordinate descent method (DCDM) to further improve computational speed. Finally, a unified framework for SRBO is proposed to accelerate many SVM-type models, and it is successfully applied to one-class SVM. Experimental results on 6 artificial data sets and 30 benchmark data sets have verified the effectiveness and safety of our proposed methods in supervised and unsupervised tasks.","[{'name': 'Zhiji Yang, Wanyi Chen, Huan Zhang, Yitian Xu, Lei Shi, Jianhua Zhao'}]",
1380,Improving out-of-distribution generalization in graphs via hierarchical semantic environments,https://arxiv.org/abs/2403.01773,"arXiv:2403.01773v1 Announce Type: cross 
Abstract: Out-of-distribution (OOD) generalization in the graph domain is challenging due to complex distribution shifts and a lack of environmental contexts. Recent methods attempt to enhance graph OOD generalization by generating flat environments. However, such flat environments come with inherent limitations to capture more complex data distributions. Considering the DrugOOD dataset, which contains diverse training environments (e.g., scaffold, size, etc.), flat contexts cannot sufficiently address its high heterogeneity. Thus, a new challenge is posed to generate more semantically enriched environments to enhance graph invariant learning for handling distribution shifts. In this paper, we propose a novel approach to generate hierarchical semantic environments for each graph. Firstly, given an input graph, we explicitly extract variant subgraphs from the input graph to generate proxy predictions on local environments. Then, stochastic attention mechanisms are employed to re-extract the subgraphs for regenerating global environments in a hierarchical manner. In addition, we introduce a new learning objective that guides our model to learn the diversity of environments within the same hierarchy while maintaining consistency across different hierarchies. This approach enables our model to consider the relationships between environments and facilitates robust graph invariant learning. Extensive experiments on real-world graph data have demonstrated the effectiveness of our framework. Particularly, in the challenging dataset DrugOOD, our method achieves up to 1.29\\% and 2.83\\% improvement over the best baselines on IC50 and EC50 prediction tasks, respectively.","[{'name': 'Yinhua Piao, Sangseon Lee, Yijingxiu Lu, Sun Kim'}]",
1381,Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning,https://arxiv.org/abs/2403.01781,"arXiv:2403.01781v1 Announce Type: cross 
Abstract: In the realm of computer vision and graphics, accurately establishing correspondences between geometric 3D shapes is pivotal for applications like object tracking, registration, texture transfer, and statistical shape analysis. Moving beyond traditional hand-crafted and data-driven feature learning methods, we incorporate spectral methods with deep learning, focusing on functional maps (FMs) and optimal transport (OT). Traditional OT-based approaches, often reliant on entropy regularization OT in learning-based framework, face computational challenges due to their quadratic cost. Our key contribution is to employ the sliced Wasserstein distance (SWD) for OT, which is a valid fast optimal transport metric in an unsupervised shape matching framework. This unsupervised framework integrates functional map regularizers with a novel OT-based loss derived from SWD, enhancing feature alignment between shapes treated as discrete probability measures. We also introduce an adaptive refinement process utilizing entropy regularized OT, further refining feature alignments for accurate point-to-point correspondences. Our method demonstrates superior performance in non-rigid shape matching, including near-isometric and non-isometric scenarios, and excels in downstream tasks like segmentation transfer. The empirical results on diverse datasets highlight our framework's effectiveness and generalization capabilities, setting new standards in non-rigid shape matching with efficient OT metrics and an adaptive refinement module.","[{'name': 'Tung Le, Khai Nguyen, Shanlin Sun, Nhat Ho, Xiaohui Xie'}]",
1382,Beyond Recommender: An Exploratory Study of the Effects of Different AI Roles in AI-Assisted Decision Making,https://arxiv.org/abs/2403.01791,"arXiv:2403.01791v1 Announce Type: cross 
Abstract: Artificial Intelligence (AI) is increasingly employed in various decision-making tasks, typically as a Recommender, providing recommendations that the AI deems correct. However, recent studies suggest this may diminish human analytical thinking and lead to humans' inappropriate reliance on AI, impairing the synergy in human-AI teams. In contrast, human advisors in group decision-making perform various roles, such as analyzing alternative options or criticizing decision-makers to encourage their critical thinking. This diversity of roles has not yet been empirically explored in AI assistance. In this paper, we examine three AI roles: Recommender, Analyzer, and Devil's Advocate, and evaluate their effects across two AI performance levels. Our results show each role's distinct strengths and limitations in task performance, reliance appropriateness, and user experience. Notably, the Recommender role is not always the most effective, especially if the AI performance level is low, the Analyzer role may be preferable. These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.","[{'name': 'Shuai Ma, Chenyi Zhang, Xinru Wang, Xiaojuan Ma, Ming Yin'}]",
1383,COLA: Cross-city Mobility Transformer for Human Trajectory Simulation,https://arxiv.org/abs/2403.01801,"arXiv:2403.01801v1 Announce Type: cross 
Abstract: Human trajectory data produced by daily mobile devices has proven its usefulness in various substantial fields such as urban planning and epidemic prevention. In terms of the individual privacy concern, human trajectory simulation has attracted increasing attention from researchers, targeting at offering numerous realistic mobility data for downstream tasks. Nevertheless, the prevalent issue of data scarcity undoubtedly degrades the reliability of existing deep learning models. In this paper, we are motivated to explore the intriguing problem of mobility transfer across cities, grasping the universal patterns of human trajectories to augment the powerful Transformer with external mobility data. There are two crucial challenges arising in the knowledge transfer across cities: 1) how to transfer the Transformer to adapt for domain heterogeneity; 2) how to calibrate the Transformer to adapt for subtly different long-tail frequency distributions of locations. To address these challenges, we have tailored a Cross-city mObiLity trAnsformer (COLA) with a dedicated model-agnostic transfer framework by effectively transferring cross-city knowledge for human trajectory simulation. Firstly, COLA divides the Transformer into the private modules for city-specific characteristics and the shared modules for city-universal mobility patterns. Secondly, COLA leverages a lightweight yet effective post-hoc adjustment strategy for trajectory simulation, without disturbing the complex bi-level optimization of model-agnostic knowledge transfer. Extensive experiments of COLA compared to state-of-the-art single-city baselines and our implemented cross-city baselines have demonstrated its superiority and effectiveness. The code is available at https://github.com/Star607/Cross-city-Mobility-Transformer.","[{'name': 'Yu Wang, Tongya Zheng, Yuxuan Liang, Shunyu Liu, Mingli Song'}]",
1384,AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation,https://arxiv.org/abs/2403.01818,"arXiv:2403.01818v1 Announce Type: cross 
Abstract: Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly complicated training pipeline designs. It can also be regarded as a flexible bottleneck module that can be seamlessly integrated into a general transformer-based segmentation model. The proposed AllSpark outperforms existing methods across all evaluation protocols on Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code and model weights are available at: https://github.com/xmed-lab/AllSpark.","[{'name': 'Haonan Wang, Qixiang Zhang, Yi Li, Xiaomeng Li'}]",
1385,RT-H: Action Hierarchies Using Language,https://arxiv.org/abs/2403.01823,"arXiv:2403.01823v1 Announce Type: cross 
Abstract: Language provides a way to break down complex concepts into digestible pieces. Recent works in robot imitation learning use language-conditioned policies that predict actions given visual observations and the high-level task specified in language. These methods leverage the structure of natural language to share data between semantically similar tasks (e.g., \"pick coke can\" and \"pick an apple\") in multi-task datasets. However, as tasks become more semantically diverse (e.g., \"pick coke can\" and \"pour cup\"), sharing data between tasks becomes harder, so learning to map high-level tasks to actions requires much more demonstration data. To bridge tasks and actions, our insight is to teach the robot the language of actions, describing low-level motions with more fine-grained phrases like \"move arm forward\". Predicting these language motions as an intermediate step between tasks and actions forces the policy to learn the shared structure of low-level motions across seemingly disparate tasks. Furthermore, a policy that is conditioned on language motions can easily be corrected during execution through human-specified language motions. This enables a new paradigm for flexible policies that can learn from human intervention in language. Our method RT-H builds an action hierarchy using language motions: it first learns to predict language motions, and conditioned on this and the high-level task, it predicts actions, using visual context at all stages. We show that RT-H leverages this language-action hierarchy to learn policies that are more robust and flexible by effectively tapping into multi-task datasets. We show that these policies not only allow for responding to language interventions, but can also learn from such interventions and outperform methods that learn from teleoperated interventions. Our website and videos are found at https://rt-hierarchy.github.io.","[{'name': 'Suneel Belkhale, Tianli Ding, Ted Xiao, Pierre Sermanet, Quon Vuong, Jonathan Tompson, Yevgen Chebotar, Debidatta Dwibedi, Dorsa Sadigh'}]",
1386,Analysis and Fully Memristor-based Reservoir Computing for Temporal Data Classification,https://arxiv.org/abs/2403.01827,"arXiv:2403.01827v1 Announce Type: cross 
Abstract: Reservoir computing (RC) offers a neuromorphic framework that is particularly effective for processing spatiotemporal signals. Known for its temporal processing prowess, RC significantly lowers training costs compared to conventional recurrent neural networks. A key component in its hardware deployment is the ability to generate dynamic reservoir states. Our research introduces a novel dual-memory RC system, integrating a short-term memory via a WOx-based memristor, capable of achieving 16 distinct states encoded over 4 bits, and a long-term memory component using a TiOx-based memristor within the readout layer. We thoroughly examine both memristor types and leverage the RC system to process temporal data sets. The performance of the proposed RC system is validated through two benchmark tasks: isolated spoken digit recognition with incomplete inputs and Mackey-Glass time series prediction. The system delivered an impressive 98.84% accuracy in digit recognition and sustained a low normalized root mean square error (NRMSE) of 0.036 in the time series prediction task, underscoring its capability. This study illuminates the adeptness of memristor-based RC systems in managing intricate temporal challenges, laying the groundwork for further innovations in neuromorphic computing.","[{'name': 'Ankur Singh, Sanghyeon Choi, Gunuk Wang, Maryaradhiya Daimari, Byung-Geun Lee'}]",
1387,FreeA: Human-object Interaction Detection using Free Annotation Labels,https://arxiv.org/abs/2403.01840,"arXiv:2403.01840v1 Announce Type: cross 
Abstract: Recent human-object interaction (HOI) detection approaches rely on high cost of manpower and require comprehensive annotated image datasets. In this paper, we propose a novel self-adaption language-driven HOI detection method, termed as FreeA, without labeling by leveraging the adaptability of CLIP to generate latent HOI labels. To be specific, FreeA matches image features of human-object pairs with HOI text templates, and a priori knowledge-based mask method is developed to suppress improbable interactions. In addition, FreeA utilizes the proposed interaction correlation matching method to enhance the likelihood of actions related to a specified action, further refine the generated HOI labels. Experiments on two benchmark datasets show that FreeA achieves state-of-the-art performance among weakly supervised HOI models. Our approach is +8.58 mean Average Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in localizing and classifying the interactive actions than the newest weakly model, and +1.68 mAP and +7.28 mAP than the latest weakly+ model, respectively. Code will be available at https://drliuqi.github.io/.","[{'name': 'Yuxiao Wang, Zhenao Wei, Xinyu Jiang, Yu Lei, Weiying Xue, Jinxiu Liu, Qi Liu'}]",
1388,NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models,https://arxiv.org/abs/2403.01845,"arXiv:2403.01845v1 Announce Type: cross 
Abstract: As machine learning (ML) algorithms get deployed in an ever-increasing number of applications, these algorithms need to achieve better trade-offs between high accuracy, high throughput and low latency. This paper introduces NASH, a novel approach that applies neural architecture search to machine learning hardware. Using NASH, hardware designs can achieve not only high throughput and low latency but also superior accuracy performance. We present four versions of the NASH strategy in this paper, all of which show higher accuracy than the original models. The strategy can be applied to various convolutional neural networks, selecting specific model operations among many to guide the training process toward higher accuracy. Experimental results show that applying NASH on ResNet18 or ResNet34 achieves a top 1 accuracy increase of up to 3.1% and a top 5 accuracy increase of up to 2.2% compared to the non-NASH version when tested on the ImageNet data set. We also integrated this approach into the FINN hardware model synthesis tool to automate the application of our approach and the generation of the hardware model. Results show that using FINN can achieve a maximum throughput of 324.5 fps. In addition, NASH models can also result in a better trade-off between accuracy and hardware resource utilization. The accuracy-hardware (HW) Pareto curve shows that the models with the four NASH versions represent the best trade-offs achieving the highest accuracy for a given HW utilization. The code for our implementation is open-source and publicly available on GitHub at https://github.com/MFJI/NASH.","[{'name': 'Mengfei Ji, Zaid Al-Ars'}]",
1389,One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models,https://arxiv.org/abs/2403.01849,"arXiv:2403.01849v1 Announce Type: cross 
Abstract: Large pre-trained Vision-Language Models (VLMs) like CLIP, despite having remarkable generalization ability, are highly vulnerable to adversarial examples. This work studies the adversarial robustness of VLMs from the novel perspective of the text prompt instead of the extensively studied model weights (frozen in this work). We first show that the effectiveness of both adversarial attack and defense are sensitive to the used text prompt. Inspired by this, we propose a method to improve resilience to adversarial attacks by learning a robust text prompt for VLMs. The proposed method, named Adversarial Prompt Tuning (APT), is effective while being both computationally and data efficient. Extensive experiments are conducted across 15 datasets and 4 data sparsity schemes (from 1-shot to full training data settings) to show APT's superiority over hand-engineered prompts and other state-of-the-art adaption methods. APT demonstrated excellent abilities in terms of the in-distribution performance and the generalization under input distribution shift and across datasets. Surprisingly, by simply adding one learned word to the prompts, APT can significantly boost the accuracy and robustness (epsilon=4/255) over the hand-engineered prompts by +13% and +8.5% on average respectively. The improvement further increases, in our most effective setting, to +26.4% for accuracy and +16.7% for robustness. Code is available at https://github.com/TreeLLi/APT.","[{'name': 'Lin Li, Haoyan Guan, Jianing Qiu, Michael Spratling'}]",
1390,Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral,https://arxiv.org/abs/2403.01851,"arXiv:2403.01851v1 Announce Type: cross 
Abstract: Mixtral, a representative sparse mixture of experts (SMoE) language model, has received significant attention due to its unique model design and superior performance. Based on Mixtral-8x7B-v0.1, in this paper, we propose Chinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language abilities by adopting further pre-training and instruction fine-tuning. Experimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct successfully improve Chinese understanding and generation performance while retaining the original English abilities. Then, we discuss several key questions when performing language adaptation on large language models, including the necessity of extending the language-specific vocabulary and the choice of the initialization model (foundation model v.s. instruction model), by providing empirical results and analysis. We also present the visualizations of each expert to examine their importance on downstream tasks. Our resources are publicly available through \\url{https://github.com/ymcui/Chinese-Mixtral}.","[{'name': 'Yiming Cui, Xin Yao'}]",
1391,AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes,https://arxiv.org/abs/2403.01861,"arXiv:2403.01861v1 Announce Type: cross 
Abstract: Indoor scenes we are living in are visually homogenous or textureless, while they inherently have structural forms and provide enough structural priors for 3D scene reconstruction. Motivated by this fact, we propose a structure-aware online signed distance fields (SDF) reconstruction framework in indoor scenes, especially under the Atlanta world (AW) assumption. Thus, we dub this incremental SDF reconstruction for AW as AiSDF. Within the online framework, we infer the underlying Atlanta structure of a given scene and then estimate planar surfel regions supporting the Atlanta structure. This Atlanta-aware surfel representation provides an explicit planar map for a given scene. In addition, based on these Atlanta planar surfel regions, we adaptively sample and constrain the structural regularity in the SDF reconstruction, which enables us to improve the reconstruction quality by maintaining a high-level structure while enhancing the details of a given scene. We evaluate the proposed AiSDF on the ScanNet and ReplicaCAD datasets, where we demonstrate that the proposed framework is capable of reconstructing fine details of objects implicitly, as well as structures explicitly in room-scale scenes.","[{'name': 'Jaehoon Jang, Inha Lee, Minje Kim, Kyungdon Joo'}]",
1392,ICLN: Input Convex Loss Network for Decision Focused Learning,https://arxiv.org/abs/2403.01875,"arXiv:2403.01875v1 Announce Type: cross 
Abstract: In decision-making problem under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused Learning (DFL) is a task-oriented framework to integrate prediction and optimization by adapting predictive model to give better decision for the corresponding task. Here, an inevitable challenge arises when computing gradients of the optimal decision with respect to the parameters. Existing researches cope this issue by smoothly reforming surrogate optimization or construct surrogate loss function that mimic task loss. However, they are applied to restricted optimization domain or build functions in a local manner leading a large computational time. In this paper, we propose Input Convex Loss Network (ICLN), a novel global surrogate loss which can be implemented in a general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks which is guaranteed to be convex for some inputs, while keeping the global structure for the other inputs. This enables ICLN to admit general DFL through only a single surrogate loss without any sense for choosing appropriate parametric forms. We confirm effectiveness and flexibility of ICLN by evaluating our proposed model with three stochastic decision-making problems.","[{'name': 'Haeun Jeon, Hyunglip Bae, Minsu Park, Chanyeong Kim, Woo Chang Kim'}]",
1393,FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction,https://arxiv.org/abs/2403.01886,"arXiv:2403.01886v1 Announce Type: cross 
Abstract: Document-level Relation Extraction (DocRE) aims to identify relation labels between entities within a single document. It requires handling several sentences and reasoning over them. State-of-the-art DocRE methods use a graph structure to connect entities across the document to capture dependency syntax information. However, this is insufficient to fully exploit the rich syntax information in the document. In this work, we propose to fuse constituency and dependency syntax into DocRE. It uses constituency syntax to aggregate the whole sentence information and select the instructive sentences for the pairs of targets. It exploits the dependency syntax in a graph structure with constituency syntax enhancement and chooses the path between entity pairs based on the dependency graph. The experimental results on datasets from various domains demonstrate the effectiveness of the proposed method. The code is publicly available at this url.","[{'name': 'Xudong Zhu, Zhao Kang, Bei Hui'}]",
1394,Unsupervised Distance Metric Learning for Anomaly Detection Over Multivariate Time Series,https://arxiv.org/abs/2403.01895,"arXiv:2403.01895v1 Announce Type: cross 
Abstract: Distance-based time series anomaly detection methods are prevalent due to their relative non-parametric nature and interpretability. However, the commonly used Euclidean distance is sensitive to noise. While existing works have explored dynamic time warping (DTW) for its robustness, they only support supervised tasks over multivariate time series (MTS), leaving a scarcity of unsupervised methods. In this work, we propose FCM-wDTW, an unsupervised distance metric learning method for anomaly detection over MTS, which encodes raw data into latent space and reveals normal dimension relationships through cluster centers. FCM-wDTW introduces locally weighted DTW into fuzzy C-means clustering and learns the optimal latent space efficiently, enabling anomaly identification via data reconstruction. Experiments with 11 different types of benchmarks demonstrate our method's competitive accuracy and efficiency.","[{'name': 'Hanyang Yuan, Qinglin Cai, Keting Yin'}]",
1395,Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey,https://arxiv.org/abs/2403.01909,"arXiv:2403.01909v1 Announce Type: cross 
Abstract: Semantic segmentation is an important and popular research area in computer vision that focuses on classifying pixels in an image based on their semantics. However, supervised deep learning requires large amounts of data to train models and the process of labeling images pixel by pixel is time-consuming and laborious. This review aims to provide a first comprehensive and organized overview of the state-of-the-art research results on pseudo-label methods in the field of semi-supervised semantic segmentation, which we categorize from different perspectives and present specific methods for specific application areas. In addition, we explore the application of pseudo-label technology in medical and remote-sensing image segmentation. Finally, we also propose some feasible future research directions to address the existing challenges.","[{'name': 'Lingyan Ran, Yali Li, Guoqiang Liang, Yanning Zhang'}]",
1396,xT: Nested Tokenization for Larger Context in Large Images,https://arxiv.org/abs/2403.01915,"arXiv:2403.01915v1 Announce Type: cross 
Abstract: Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in conjunction with long-sequence length models normally used for natural language processing, we are able to increase accuracy by up to 8.6% on challenging classification tasks and $F_1$ score by 11.6 on context-dependent segmentation in large images.","[{'name': 'Ritwik Gupta, Shufan Li, Tyler Zhu, Jitendra Malik, Trevor Darrell, Karttikeya Mangalam'}]",
1397,To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering,https://arxiv.org/abs/2403.01924,"arXiv:2403.01924v1 Announce Type: cross 
Abstract: Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, \"to generate or to retrieve\" is the modern equivalent of Hamlet's dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maximum of 24GB VRAM. MedGENIE sets a new state-of-the-art (SOTA) in the open-book setting of each testbed, even allowing a small-scale reader to outcompete zero-shot closed-book 175B baselines while using up to 706$\\times$ fewer parameters. Overall, our findings reveal that generated passages are more effective than retrieved counterparts in attaining higher accuracy.","[{'name': 'Giacomo Frisoni, Alessio Cocchieri, Alex Presepi, Gianluca Moro, Zaiqiao Meng'}]",
1398,DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory,https://arxiv.org/abs/2403.01954,"arXiv:2403.01954v1 Announce Type: cross 
Abstract: Lexicon-based constrained decoding approaches aim to control the meaning or style of the generated text through certain target concepts. Existing approaches over-focus the targets themselves, leading to a lack of high-level reasoning about how to achieve them. However, human usually tackles tasks by following certain rules that not only focuses on the targets but also on semantically relevant concepts that induce the occurrence of targets. In this work, we present DECIDER, a rule-controllable decoding strategy for constrained language generation inspired by dual-system cognitive theory. Specifically, in DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner that takes high-level rules as input. Then, the DECIDER allows rule signals to flow into the PLM at each decoding step. Extensive experimental results demonstrate that DECIDER can effectively follow given rules to guide generation direction toward the targets in a more human-like manner.","[{'name': 'Chen Xu, Tian Lan, Changlong Yu, Wei Wang, Jun Gao, Yu Ji, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu'}]",
1399,The Heterogeneous Productivity Effects of Generative AI,https://arxiv.org/abs/2403.01964,"arXiv:2403.01964v1 Announce Type: cross 
Abstract: We analyse the individual productivity effects of Italy's ban on ChatGPT, a generative pretrained transformer chatbot. We compile data on the daily coding output quantity and quality of over 36,000 GitHub users in Italy and other European countries and combine these data with the sudden announcement of the ban in a difference-in-differences framework. Among the affected users in Italy, we find a short-term increase in output quantity and quality for less experienced users and a decrease in productivity on more routine tasks for experienced users.","[{'name': 'David Kreitmeir, Paul A. Raschky'}]",
1400,TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions,https://arxiv.org/abs/2403.01977,"arXiv:2403.01977v1 Announce Type: cross 
Abstract: Robot navigation under visual corruption presents a formidable challenge. To address this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav, for point-goal navigation under visual corruptions. Our \"plug-and-play\" method incorporates a top-down decoder to a pre-trained navigation model. Firstly, the pre-trained navigation model gets a corrupted image and extracts features. Secondly, the top-down decoder produces the reconstruction given the high-level features extracted by the pre-trained model. Then, it feeds the reconstruction of a corrupted image back to the pre-trained model. Finally, the pre-trained model does forward pass again to output action. Despite being trained solely on clean images, the top-down decoder can reconstruct cleaner images from corrupted ones without the need for gradient-based adaptation. The pre-trained navigation model with our top-down decoder significantly enhances navigation performance across almost all visual corruptions in our benchmarks. Our method improves the success rate of point-goal navigation from the state-of-the-art result of 46% to 94% on the most severe corruption. This suggests its potential for broader application in robotic visual navigation.","[{'name': 'Maytus Piriyajitakonkij, Mingfei Sun, Mengmi Zhang, Wei Pan'}]",
1401,Transformers for Low-Resource Languages:Is F\\'eidir Linn!,https://arxiv.org/abs/2403.01985,"arXiv:2403.01985v1 Announce Type: cross 
Abstract: The Transformer model is the state-of-the-art in Machine Translation. However, in general, neural translation models often under perform on language pairs with insufficient training data. As a consequence, relatively few experiments have been carried out using this architecture on low-resource language pairs. In this study, hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly, the correct choice of subword model is shown to be the biggest driver of translation performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers, testing various regularisation techniques and evaluating the optimal number of heads for attention. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model. Improvements were observed across a range of metrics, including TER, indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against Google Translate, our translation engines demonstrated significant improvements. The question of whether or not Transformers can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is f\\'eidir linn - yes we can.","[{'name': \"S\\\\'eamus Lankford, Haithem Afli, Andy Way\"}]",
1402,Unveiling Hidden Links Between Unseen Security Entities,https://arxiv.org/abs/2403.02014,"arXiv:2403.02014v1 Announce Type: cross 
Abstract: The proliferation of software vulnerabilities poses a significant challenge for security databases and analysts tasked with their timely identification, classification, and remediation. With the National Vulnerability Database (NVD) reporting an ever-increasing number of vulnerabilities, the traditional manual analysis becomes untenably time-consuming and prone to errors. This paper introduces VulnScopper, an innovative approach that utilizes multi-modal representation learning, combining Knowledge Graphs (KG) and Natural Language Processing (NLP), to automate and enhance the analysis of software vulnerabilities. Leveraging ULTRA, a knowledge graph foundation model, combined with a Large Language Model (LLM), VulnScopper effectively handles unseen entities, overcoming the limitations of previous KG approaches. We evaluate VulnScopper on two major security datasets, the NVD and the Red Hat CVE database. Our method significantly improves the link prediction accuracy between Common Vulnerabilities and Exposures (CVEs), Common Weakness Enumeration (CWEs), and Common Platform Enumerations (CPEs). Our results show that VulnScopper outperforms existing methods, achieving up to 78% Hits@10 accuracy in linking CVEs to CPEs and CWEs and presenting an 11.7% improvement over large language models in predicting CWE labels based on the Red Hat database. Based on the NVD, only 6.37% of the linked CPEs are being published during the first 30 days; many of them are related to critical and high-risk vulnerabilities which, according to multiple compliance frameworks (such as CISA and PCI), should be remediated within 15-30 days. Our model can uncover new products linked to vulnerabilities, reducing remediation time and improving vulnerability management. We analyzed several CVEs from 2023 to showcase this ability.","[{'name': 'Daniel Alfasi, Tal Shapira, Anat Bremler Barr'}]",
1403,Cross Domain Policy Transfer with Effect Cycle-Consistency,https://arxiv.org/abs/2403.02018,"arXiv:2403.02018v1 Announce Type: cross 
Abstract: Training a robotic policy from scratch using deep reinforcement learning methods can be prohibitively expensive due to sample inefficiency. To address this challenge, transferring policies trained in the source domain to the target domain becomes an attractive paradigm. Previous research has typically focused on domains with similar state and action spaces but differing in other aspects. In this paper, our primary focus lies in domains with different state and action spaces, which has broader practical implications, i.e. transfer the policy from robot A to robot B. Unlike prior methods that rely on paired data, we propose a novel approach for learning the mapping functions between state and action spaces across domains using unpaired data. We propose effect cycle consistency, which aligns the effects of transitions across two domains through a symmetrical optimization structure for learning these mapping functions. Once the mapping functions are learned, we can seamlessly transfer the policy from the source domain to the target domain. Our approach has been tested on three locomotion tasks and two robotic manipulation tasks. The empirical results demonstrate that our method can reduce alignment errors significantly and achieve better performance compared to the state-of-the-art method.","[{'name': 'Ruiqi Zhu, Tianhong Dai, Oya Celiktutan'}]",
1404,Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation,https://arxiv.org/abs/2403.02074,"arXiv:2403.02074v1 Announce Type: cross 
Abstract: Combining images from multi-modalities is beneficial to explore various information in computer vision, especially in the medical domain. As an essential part of clinical diagnosis, multi-modal brain tumor segmentation aims to delineate the malignant entity involving multiple modalities. Although existing methods have shown remarkable performance in the task, the information exchange for cross-scale and high-level representations fusion in spatial and modality are limited in these methods. In this paper, we present a novel Modality Aware and Shift Mixer that integrates intra-modality and inter-modality dependencies of multi-modal images for effective and robust brain tumor segmentation. Specifically, we introduce a Modality-Aware module according to neuroimaging studies for modeling the specific modality pair relationships at low levels, and a Modality-Shift module with specific mosaic patterns is developed to explore the complex relationships across modalities at high levels via the self-attention. Experimentally, we outperform previous state-of-the-art approaches on the public Brain Tumor Segmentation (BraTS 2021 segmentation) dataset. Further qualitative experiments demonstrate the efficacy and robustness of MASM.","[{'name': 'Zhongzhen Huang, Linda Wei, Shaoting Zhang, Xiaofan Zhang'}]",
1405,VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT,https://arxiv.org/abs/2403.02076,"arXiv:2403.02076v1 Announce Type: cross 
Abstract: Video temporal grounding (VTG) aims to locate specific temporal segments from an untrimmed video based on a linguistic query. Most existing VTG models are trained on extensive annotated video-text pairs, a process that not only introduces human biases from the queries but also incurs significant computational costs. To tackle these challenges, we propose VTG-GPT, a GPT-based method for zero-shot VTG without training or fine-tuning. To reduce prejudice in the original query, we employ Baichuan2 to generate debiased queries. To lessen redundant information in videos, we apply MiniGPT-v2 to transform visual content into more precise captions. Finally, we devise the proposal generator and post-processing to produce accurate segments from debiased queries and image captions. Extensive experiments demonstrate that VTG-GPT significantly outperforms SOTA methods in zero-shot settings and surpasses unsupervised approaches. More notably, it achieves competitive performance comparable to supervised methods. The code is available on https://github.com/YoucanBaby/VTG-GPT","[{'name': 'Yifang Xu, Yunzhuo Sun, Zien Xie, Benxiang Zhai, Sidan Du'}]",
1406,Iterated $Q$-Network: Beyond the One-Step Bellman Operator,https://arxiv.org/abs/2403.02107,"arXiv:2403.02107v1 Announce Type: cross 
Abstract: Value-based Reinforcement Learning (RL) methods rely on the application of the Bellman operator, which needs to be approximated from samples. Most approaches consist of an iterative scheme alternating the application of the Bellman operator and a subsequent projection step onto a considered function space. However, we observe that these algorithms can be improved by considering multiple iterations of the Bellman operator at once. Thus, we introduce iterated $Q$-Networks (iQN), a novel approach that learns a sequence of $Q$-function approximations where each $Q$-function serves as the target for the next one in a chain of consecutive Bellman iterations. We demonstrate that iQN is theoretically sound and show how it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate its advantages on Atari $2600$ games and in continuous-control MuJoCo environments.","[{'name': \"Th\\\\'eo Vincent, Daniel Palenicek, Boris Belousov, Jan Peters, Carlo D'Eramo\"}]",
1407,Position Paper: Towards Implicit Prompt For Text-To-Image Models,https://arxiv.org/abs/2403.02118,"arXiv:2403.02118v1 Announce Type: cross 
Abstract: Recent text-to-image (T2I) models have had great success, and many benchmarks have been proposed to evaluate their performance and safety. However, they only consider explicit prompts while neglecting implicit prompts (hint at a target without explicitly mentioning it). These prompts may get rid of safety constraints and pose potential threats to the applications of these models. This position paper highlights the current state of T2I models toward implicit prompts. We present a benchmark named ImplicitBench and conduct an investigation on the performance and impacts of implicit prompts with popular T2I models. Specifically, we design and collect more than 2,000 implicit prompts of three aspects: General Symbols, Celebrity Privacy, and Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models' capabilities under these implicit prompts. Experiment results show that (1) T2I models are able to accurately create various target symbols indicated by implicit prompts; (2) Implicit prompts bring potential risks of privacy leakage for T2I models. (3) Constraints of NSFW in most of the evaluated T2I models can be bypassed with implicit prompts. We call for increased attention to the potential and risks of implicit prompts in the T2I community and further investigation into the capabilities and impacts of implicit prompts, advocating for a balanced approach that harnesses their benefits while mitigating their risks.","[{'name': 'Yue Yang, Yuqi lin, Hong Liu, Wenqi Shao, Runjian Chen, Hailong Shang, Yu Wang, Yu Qiao, Kaipeng Zhang, Ping Luo'}]",
1408,Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models,https://arxiv.org/abs/2403.02121,"arXiv:2403.02121v1 Announce Type: cross 
Abstract: The advent of Large Language Models (LLMs) has advanced the benchmark in various Natural Language Processing (NLP) tasks. However, large amounts of labelled training data are required to train LLMs. Furthermore, data annotation and training are computationally expensive and time-consuming. Zero and few-shot learning have recently emerged as viable options for labelling data using large pre-trained models. Hate speech detection in mix-code low-resource languages is an active problem area where the use of LLMs has proven beneficial. In this study, we have compiled a dataset of 100 YouTube comments, and weakly labelled them for coarse and fine-grained misogyny classification in mix-code Hinglish. Weak annotation was applied due to the labor-intensive annotation process. Zero-shot learning, one-shot learning, and few-shot learning and prompting approaches have then been applied to assign labels to the comments and compare them to human-assigned labels. Out of all the approaches, zero-shot classification using the Bidirectional Auto-Regressive Transformers (BART) large model and few-shot prompting using Generative Pre-trained Transformer- 3 (ChatGPT-3) achieve the best results","[{'name': 'Sargam YadavDundalk Institute of Technology, Dundalk, Abhishek KaushikDundalk Institute of Technology, Dundalk, Kevin McDaidDundalk Institute of Technology, Dundalk'}]",
1409,LOCR: Location-Guided Transformer for Optical Character Recognition,https://arxiv.org/abs/2403.02127,"arXiv:2403.02127v1 Announce Type: cross 
Abstract: Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4.4% of pages to 0.5% in the arXiv dataset, from 13.2% to 1.3% in OOD quantum physics documents and from 8.1% to 1.8% in OOD marketing documents. Additionally, LOCR features an interactive OCR mode, facilitating the generation of complex documents through a few location prompts from human.","[{'name': 'Yu Sun, Dongzhan Zhou, Chen Lin, Conghui He, Wanli Ouyang, Han-Sen Zhong'}]",
1410,Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution,https://arxiv.org/abs/2403.02131,"arXiv:2403.02131v1 Announce Type: cross 
Abstract: Evolutionary algorithms, such as Differential Evolution, excel in solving real-parameter optimization challenges. However, the effectiveness of a single algorithm varies across different problem instances, necessitating considerable efforts in algorithm selection or configuration. This paper aims to address the limitation by leveraging the complementary strengths of a group of algorithms and dynamically scheduling them throughout the optimization progress for specific problems. We propose a deep reinforcement learning-based dynamic algorithm selection framework to accomplish this task. Our approach models the dynamic algorithm selection a Markov Decision Process, training an agent in a policy gradient manner to select the most suitable algorithm according to the features observed during the optimization process. To empower the agent with the necessary information, our framework incorporates a thoughtful design of landscape and algorithmic features. Meanwhile, we employ a sophisticated deep neural network model to infer the optimal action, ensuring informed algorithm selections. Additionally, an algorithm context restoration mechanism is embedded to facilitate smooth switching among different algorithms. These mechanisms together enable our framework to seamlessly select and switch algorithms in a dynamic online fashion. Notably, the proposed framework is simple and generic, offering potential improvements across a broad spectrum of evolutionary algorithms. As a proof-of-principle study, we apply this framework to a group of Differential Evolution algorithms. The experimental results showcase the remarkable effectiveness of the proposed framework, not only enhancing the overall optimization performance but also demonstrating favorable generalization ability across different problem classes.","[{'name': 'Hongshu Guo, Yining Ma, Zeyuan Ma, Jiacheng Chen, Xinglin Zhang, Zhiguang Cao, Jun Zhang, Yue-Jiao Gong'}]",
1411,Speech emotion recognition from voice messages recorded in the wild,https://arxiv.org/abs/2403.02167,"arXiv:2403.02167v1 Announce Type: cross 
Abstract: Emotion datasets used for Speech Emotion Recognition (SER) often contain acted or elicited speech, limiting their applicability in real-world scenarios. In this work, we used the Emotional Voice Messages (EMOVOME) database, including spontaneous voice messages from conversations of 100 Spanish speakers on a messaging app, labeled in continuous and discrete emotions by expert and non-expert annotators. We created speaker-independent SER models using the eGeMAPS features, transformer-based models and their combination. We compared the results with reference databases and analyzed the influence of annotators and gender fairness. The pre-trained Unispeech-L model and its combination with eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10% improvement over baseline models. For the emotion categories, 42.58% UA was obtained. EMOVOME performed lower than the acted RAVDESS database. The elicited IEMOCAP database also outperformed EMOVOME in the prediction of emotion categories, while similar results were obtained in valence and arousal. Additionally, EMOVOME outcomes varied with annotator labels, showing superior results and better fairness when combining expert and non-expert annotations. This study significantly contributes to the evaluation of SER models in real-life situations, advancing in the development of applications for analyzing spontaneous voice messages.","[{'name': \"Luc\\\\'ia G\\\\'omez-Zaragoz\\\\'a, \\\\'Oscar Valls, Roc\\\\'io del Amor, Mar\\\\'ia Jos\\\\'e Castro-Bleda, Valery Naranjo, Mariano Alca\\\\~niz Raya, Javier Mar\\\\'in-Morales\"}]",
1412,Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models,https://arxiv.org/abs/2403.02178,"arXiv:2403.02178v1 Announce Type: cross 
Abstract: In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% improvement in GSM8K accuracy and 1% improvement in MATH accuracy across five datasets of various quality and size, as well as two base models. We further investigate the mechanisms behind this improvement through case studies and quantitative analysis, suggesting that our approach may provide superior support for the model in capturing long-distance dependencies, especially those related to questions. This enhancement could deepen understanding of premises in questions and prior steps. Our code is available at Github.","[{'name': 'Changyu Chen, Xiting Wang, Ting-En Lin, Ang Lv, Yuchuan Wu, Xin Gao, Ji-Rong Wen, Rui Yan, Yongbin Li'}]",
1413,Not all Layers of LLMs are Necessary during Inference,https://arxiv.org/abs/2403.02181,"arXiv:2403.02181v1 Announce Type: cross 
Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, \"During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?\" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment tasks, while maintaining comparable performance. Additionally, this method is orthogonal to other model acceleration techniques, potentially boosting inference efficiency further.","[{'name': 'Siqi Fan, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Shuo Shang, Aixin Sun, Yequan Wang, Zhongyuan Wang'}]",
1414,Policy Space Response Oracles: A Survey,https://arxiv.org/abs/2403.02227,"arXiv:2403.02227v1 Announce Type: cross 
Abstract: In game theory, a game refers to a model of interaction among rational decision-makers or players, making choices with the goal of achieving their individual objectives. Understanding their behavior in games is often referred to as game reasoning. This survey provides a comprehensive overview of a fast-developing game-reasoning framework for large games, known as Policy Space Response Oracles (PSRO). We first motivate PSRO, provide historical context, and position PSRO within game-reasoning approaches. We then focus on the strategy exploration issue for PSRO, the challenge of assembling an effective strategy portfolio for modeling the underlying game with minimum computational cost. We also survey current research directions for enhancing the efficiency of PSRO, and explore the applications of PSRO across various domains. We conclude by discussing open questions and future research.","[{'name': 'Ariyan Bighashdel, Yongzhao Wang, Stephen McAleer, Rahul Savani, Frans A. Oliehoek'}]",
1415,Comprehensive evaluation of Mal-API-2019 dataset by machine learning in malware detection,https://arxiv.org/abs/2403.02232,"arXiv:2403.02232v1 Announce Type: cross 
Abstract: This study conducts a thorough examination of malware detection using machine learning techniques, focusing on the evaluation of various classification models using the Mal-API-2019 dataset. The aim is to advance cybersecurity capabilities by identifying and mitigating threats more effectively. Both ensemble and non-ensemble machine learning methods, such as Random Forest, XGBoost, K Nearest Neighbor (KNN), and Neural Networks, are explored. Special emphasis is placed on the importance of data pre-processing techniques, particularly TF-IDF representation and Principal Component Analysis, in improving model performance. Results indicate that ensemble methods, particularly Random Forest and XGBoost, exhibit superior accuracy, precision, and recall compared to others, highlighting their effectiveness in malware detection. The paper also discusses limitations and potential future directions, emphasizing the need for continuous adaptation to address the evolving nature of malware. This research contributes to ongoing discussions in cybersecurity and provides practical insights for developing more robust malware detection systems in the digital era.","[{'name': 'Zhenglin Li, Haibei Zhu, Houze Liu, Jintong Song, Qishuo Cheng'}]",
1416,Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks,https://arxiv.org/abs/2403.02238,"arXiv:2403.02238v1 Announce Type: cross 
Abstract: The integration of Machine Learning and Artificial Intelligence (ML/AI) into fifth-generation (5G) networks has made evident the limitations of network intelligence with ever-increasing, strenuous requirements for current and next-generation devices. This transition to ubiquitous intelligence demands high connectivity, synchronicity, and end-to-end communication between users and network operators, and will pave the way towards full network automation without human intervention. Intent-based networking is a key factor in the reduction of human actions, roles, and responsibilities while shifting towards novel extraction and interpretation of automated network management. This paper presents the development of a custom Large Language Model (LLM) for 5G and next-generation intent-based networking and provides insights into future LLM developments and integrations to realize end-to-end intent-based networking for fully automated network intelligence.","[{'name': 'Dimitrios Michael Manias, Ali Chouman, Abdallah Shami'}]",
1417,Neural Redshift: Random Networks are not Random Functions,https://arxiv.org/abs/2403.02241,"arXiv:2403.02241v1 Announce Type: cross 
Abstract: Our understanding of the generalization capabilities of neural networks (NNs) is still incomplete. Prevailing explanations are based on implicit biases of gradient descent (GD) but they cannot account for the capabilities of models from gradient-free methods nor the simplicity bias recently observed in untrained networks. This paper seeks other sources of generalization in NNs.
  Findings. To understand the inductive biases provided by architectures independently from GD, we examine untrained, random-weight networks. Even simple MLPs show strong inductive biases: uniform sampling in weight space yields a very biased distribution of functions in terms of complexity. But unlike common wisdom, NNs do not have an inherent \"simplicity bias\". This property depends on components such as ReLUs, residual connections, and layer normalizations. Alternative architectures can be built with a bias for any level of complexity. Transformers also inherit all these properties from their building blocks.
  Implications. We provide a fresh explanation for the success of deep learning independent from gradient-based training. It points at promising avenues for controlling the solutions implemented by trained models.","[{'name': 'Damien Teney, Armand Nicolicioiu, Valentin Hartmann, Ehsan Abbasnejad'}]",
1418,Better Schedules for Low Precision Training of Deep Neural Networks,https://arxiv.org/abs/2403.02243,"arXiv:2403.02243v1 Announce Type: cross 
Abstract: Low precision training can significantly reduce the computational overhead of training deep neural networks (DNNs). Though many such techniques exist, cyclic precision training (CPT), which dynamically adjusts precision throughout train- ing according to a cyclic schedule, achieves particularly impressive improvements in training efficiency, while actually improving DNN performance. Existing CPT implementations take common learning rate schedules (e.g., cyclical cosine sched- ules) and use them for low precision training without adequate comparisons to alternative scheduling options. We define a diverse suite of CPT schedules and analyze their performance across a variety of DNN training regimes, some of which are unexplored in the low precision training literature (e.g., node classification with graph neural networks). From these experiments, we discover alternative CPT schedules that offer further improvements in training efficiency and model performance, as well as derive a set of best practices for choosing CPT schedules. Going further, we find that a correlation exists between model performance and training cost, and that changing the underlying CPT schedule can control the tradeoff between these two variables. To explain the direct correlation between model performance and training cost, we draw a connection between quantized training and critical learning periods, suggesting that aggressive quantization is a form of learning impairment that can permanently damage model performance.","[{'name': 'Cameron R. Wolfe, Anastasios Kyrillidis'}]",
1419,Non-autoregressive Sequence-to-Sequence Vision-Language Models,https://arxiv.org/abs/2403.02249,"arXiv:2403.02249v1 Announce Type: cross 
Abstract: Sequence-to-sequence vision-language models are showing promise, but their applicability is limited by their inference latency due to their autoregressive way of generating predictions. We propose a parallel decoding sequence-to-sequence vision-language model, trained with a Query-CTC loss, that marginalizes over multiple inference paths in the decoder. This allows us to model the joint distribution of tokens, rather than restricting to conditional distribution as in an autoregressive model. The resulting model, NARVL, achieves performance on-par with its state-of-the-art autoregressive counterpart, but is faster at inference time, reducing from the linear complexity associated with the sequential generation of tokens to a paradigm of constant time joint inference.","[{'name': 'Kunyu Shi, Qi Dong, Luis Goncalves, Zhuowen Tu, Stefano Soatto'}]",
1420,KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection,https://arxiv.org/abs/2403.02253,"arXiv:2403.02253v1 Announce Type: cross 
Abstract: Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect and release a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML. To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text. Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos. We evaluate KnowPhish and KPD on a manually validated dataset, and on a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines.","[{'name': 'Yuexin Li, Chengyu Huang, Shumin Deng, Mei Lin Lock, Tri Cao, Nay Oo, Bryan Hooi, Hoon Wei Lim'}]",
1421,Subjective $\\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection,https://arxiv.org/abs/2403.02268,"arXiv:2403.02268v1 Announce Type: cross 
Abstract: Natural language processing research has begun to embrace the notion of annotator subjectivity, motivated by variations in labelling. This approach understands each annotator's view as valid, which can be highly suitable for tasks that embed subjectivity, e.g., sentiment analysis. However, this construction may be inappropriate for tasks such as hate speech detection, as it affords equal validity to all positions on e.g., sexism or racism. We argue that the conflation of hate and offence can invalidate findings on hate speech, and call for future work to be situated in theory, disentangling hate from its orthogonal concept, offence.","[{'name': 'Amanda Cercas Curry, Gavin Abercrombie, Zeerak Talat'}]",
1422,Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation,https://arxiv.org/abs/2403.02302,"arXiv:2403.02302v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune the ShareGPT4V model for this specific task, aiming to achieve state-of-the-art results in this particular challenge. Although such a model would not be practical in production, as it is incredibly expensive compared to a specialized model like MiVOLO, it could be very useful in some tasks, like data annotation.","[{'name': 'Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh'}]",
1423,Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training,https://arxiv.org/abs/2403.02325,"arXiv:2403.02325v1 Announce Type: cross 
Abstract: Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a \"visual prompt\", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When region annotations are provided, CRG increases absolute accuracy by up to 11.1% on ViP-Bench, a collection of six diverse region-based tasks such as recognition, math, and object relationship reasoning. We also show CRG's applicability to spatial reasoning, with 10% improvement on What'sUp, as well as to compositional generalization -- improving accuracy by 11.5% and 7.5% on two challenging splits from SugarCrepe -- and to image-text alignment for generated images, where we improve by up to 8.4 AUROC and 6.8 F1 points on SeeTRUE. When reference regions are absent, CRG allows us to re-rank proposed regions in referring expression comprehension and phrase grounding benchmarks like RefCOCO/+/g and Flickr30K Entities, with an average gain of 3.2% in accuracy. Our analysis explores alternative masking strategies for CRG, quantifies CRG's probability shift, and evaluates the role of region guidance strength, empirically validating CRG's design choices.","[{'name': 'David Wan, Jaemin Cho, Elias Stengel-Eskin, Mohit Bansal'}]",
1424,Model Lakes,https://arxiv.org/abs/2403.02327,"arXiv:2403.02327v1 Announce Type: cross 
Abstract: Given a set of deep learning models, it can be hard to find models appropriate to a task, understand the models, and characterize how models are different one from another. Currently, practitioners rely on manually-written documentation to understand and choose models. However, not all models have complete and reliable documentation. As the number of machine learning models increases, this issue of finding, differentiating, and understanding models is becoming more crucial. Inspired from research on data lakes, we introduce and define the concept of model lakes. We discuss fundamental research challenges in the management of large models. And we discuss what principled data management techniques can be brought to bear on the study of large model management.","[{'name': \"Koyena Pal, David Bau, Ren\\\\'ee J. Miller\"}]",
1425,Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning,https://arxiv.org/abs/2403.02333,"arXiv:2403.02333v1 Announce Type: cross 
Abstract: Large language models (LLMs) have shown great potential in complex reasoning tasks, yet their performance is often hampered by the scarcity of high-quality, reasoning-focused training datasets. Addressing this challenge, we propose Key-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that synthesizes question-answer pairs by leveraging key points and exemplar pairs from authentic data sources. KPDDS ensures the generation of novel questions with rigorous quality control and substantial scalability. As a result, we present KPMath, the most extensive synthetic dataset tailored for mathematical reasoning to date, comprising over one million question-answer pairs. Utilizing KPMath and augmenting it with additional reasoning-intensive corpora, we create the comprehensive KPMath-Plus dataset. Fine-tuning the Mistral-7B model on KPMath-Plus yields a zero-shot PASS@1 accuracy of 39.3% on the MATH test set, a performance that not only outpaces other finetuned 7B models but also exceeds that of certain 34B models. Our ablation studies further confirm the substantial enhancement in mathematical reasoning across various subtopics, marking a significant stride in LLMs' reasoning capabilities.","[{'name': 'Yiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, Weizhu Chen'}]",
1426,Gradient Correlation Subspace Learning against Catastrophic Forgetting,https://arxiv.org/abs/2403.02334,"arXiv:2403.02334v1 Announce Type: cross 
Abstract: Efficient continual learning techniques have been a topic of significant research over the last few years. A fundamental problem with such learning is severe degradation of performance on previously learned tasks, known also as catastrophic forgetting. This paper introduces a novel method to reduce catastrophic forgetting in the context of incremental class learning called Gradient Correlation Subspace Learning (GCSL). The method detects a subspace of the weights that is least affected by previous tasks and projects the weights to train for the new task into said subspace. The method can be applied to one or more layers of a given network architectures and the size of the subspace used can be altered from layer to layer and task to task. Code will be available at \\href{https://github.com/vgthengane/GCSL}{https://github.com/vgthengane/GCSL}","[{'name': 'Tammuz Dubnov, Vishal Thengane'}]",
1427,"Brand Visibility in Packaging: A Deep Learning Approach for Logo Detection, Saliency-Map Prediction, and Logo Placement Analysis",https://arxiv.org/abs/2403.02336,"arXiv:2403.02336v1 Announce Type: cross 
Abstract: In the highly competitive area of product marketing, the visibility of brand logos on packaging plays a crucial role in shaping consumer perception, directly influencing the success of the product. This paper introduces a comprehensive framework to measure the brand logo's attention on a packaging design. The proposed method consists of three steps. The first step leverages YOLOv8 for precise logo detection across prominent datasets, FoodLogoDet-1500 and LogoDet-3K. The second step involves modeling the user's visual attention with a novel saliency prediction model tailored for the packaging context. The proposed saliency model combines the visual elements with text maps employing a transformers-based architecture to predict user attention maps. In the third step, by integrating logo detection with a saliency map generation, the framework provides a comprehensive brand attention score. The effectiveness of the proposed method is assessed module by module, ensuring a thorough evaluation of each component. Comparing logo detection and saliency map prediction with state-of-the-art models shows the superiority of the proposed methods. To investigate the robustness of the proposed brand attention score, we collected a unique dataset to examine previous psychophysical hypotheses related to brand visibility. the results show that the brand attention score is in line with all previous studies. Also, we introduced seven new hypotheses to check the impact of position, orientation, presence of person, and other visual elements on brand attention. This research marks a significant stride in the intersection of cognitive psychology, computer vision, and marketing, paving the way for advanced, consumer-centric packaging designs.","[{'name': 'Alireza Hosseini, Kiana Hooshanfar, Pouria Omrani, Reza Toosi, Ramin Toosi, Zahra Ebrahimian, Mohammad Ali Akhaee'}]",
1428,Twisting Lids Off with Two Hands,https://arxiv.org/abs/2403.02338,"arXiv:2403.02338v1 Announce Type: cross 
Abstract: Manipulating objects with two multi-fingered hands has been a long-standing challenge in robotics, attributed to the contact-rich nature of many manipulation tasks and the complexity inherent in coordinating a high-dimensional bimanual system. In this work, we consider the problem of twisting lids of various bottle-like objects with two hands, and demonstrate that policies trained in simulation using deep reinforcement learning can be effectively transferred to the real world. With novel engineering insights into physical modeling, real-time perception, and reward design, the policy demonstrates generalization capabilities across a diverse set of unseen objects, showcasing dynamic and dexterous behaviors. Our findings serve as compelling evidence that deep reinforcement learning combined with sim-to-real transfer remains a promising approach for addressing manipulation problems of unprecedented complexity.","[{'name': 'Toru Lin, Zhao-Heng Yin, Haozhi Qi, Pieter Abbeel, Jitendra Malik'}]",
1429,Similar Cases Recommendation using Legal Knowledge Graphs,https://arxiv.org/abs/2107.04771,"arXiv:2107.04771v2 Announce Type: replace 
Abstract: A legal knowledge graph constructed from court cases, judgments, laws and other legal documents can enable a number of applications like question answering, document similarity, and search. While the use of knowledge graphs for distant supervision in NLP tasks is well researched, using knowledge graphs for applications like case similarity presents challenges. In this work, we describe our solution for predicting similar cases in Indian court judgements. We present our results and also discuss the impact of large language models on this task.","[{'name': 'Jaspreet Singh Dhani, Ruchika Bhatt, Balaji Ganesan, Parikshet Sirohi, Vasudha Bhatnagar'}]",
1430,Retrosynthetic Planning with Dual Value Networks,https://arxiv.org/abs/2301.13755,"arXiv:2301.13755v3 Announce Type: replace 
Abstract: Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro*, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for RetroGraph). Our code is available at \\url{https://github.com/DiXue98/PDVN}.","[{'name': 'Guoqing Liu, Di Xue, Shufang Xie, Yingce Xia, Austin Tripp, Krzysztof Maziarz, Marwin Segler, Tao Qin, Zongzhang Zhang, Tie-Yan Liu'}]",
1431,Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach,https://arxiv.org/abs/2306.03604,"arXiv:2306.03604v5 Announce Type: replace 
Abstract: Large language models (LLMs) encode a vast amount of world knowledge acquired from massive text datasets. Recent studies have demonstrated that LLMs can assist an embodied agent in solving complex sequential decision making tasks by providing high-level instructions. However, interactions with LLMs can be time-consuming. In many practical scenarios, they require a significant amount of storage space that can only be deployed on remote cloud server nodes. Additionally, using commercial LLMs can be costly since they may charge based on usage frequency. In this paper, we explore how to enable intelligent cost-effective interactions between the agent and an LLM. We find that this problem can be naturally formulated by a Markov decision process (MDP), and propose When2Ask, a reinforcement learning based approach that learns when it is necessary to query LLMs for high-level instructions to accomplish a target task. Experiments on MiniGrid and Habitat environments that entail planning sub-goals demonstrate that When2Ask learns to solve target tasks with only a few necessary interactions with an LLM, and significantly reduces interaction costs in testing environments compared with baseline methods. Experiment results also suggest that by learning a mediator model to interact with the LLM, the agent's performance becomes more robust against partial observability of the environment. Our code is available at https://github.com/ZJLAB-AMMI/LLM4RL.","[{'name': 'Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin Xu, Bin Liu'}]",
1432,MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models,https://arxiv.org/abs/2308.09729,"arXiv:2308.09729v5 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named \\method, that leverages knowledge graphs (KGs) to enhance LLMs' inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question \\& answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference. To reproduce our results and extend the framework further, we make our codebase available at https://github.com/wyl-willing/MindMap.","[{'name': 'Yilin Wen, Zifeng Wang, Jimeng Sun'}]",
1433,Safe POMDP Online Planning via Shielding,https://arxiv.org/abs/2309.10216,"arXiv:2309.10216v2 Announce Type: replace 
Abstract: Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees which are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions which would violate the almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored variants designed to improve scalability. Experimental results on a set of benchmark domains demonstrate that the proposed shielding methods successfully guarantee safety (unlike the baseline POMCP without shielding) on large POMDPs, with negligible impact on the runtime for online planning.","[{'name': 'Shili Sheng, David Parker, Lu Feng'}]",
1434,Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding and Fixing Bugs,https://arxiv.org/abs/2312.05588,"arXiv:2312.05588v2 Announce Type: replace 
Abstract: Vision models with high overall accuracy often exhibit systematic errors in specific scenarios, posing potential serious safety concerns. Diagnosing bugs of vision models is gaining increased attention, however traditional diagnostic approaches require annotation efforts (eg rich metadata accompanying each samples of CelebA). To address this issue,We propose a language-assisted diagnostic method that uses texts instead of images to diagnose bugs in vision models based on multi-modal models (eg CLIP). Our approach connects the embedding space of CLIP with the buggy vision model to be diagnosed; meanwhile, utilizing a shared classifier and the cross-modal transferability of embedding space from CLIP, the text-branch of CLIP become a proxy model to find bugs in the buggy model. The proxy model can classify texts paired with images. During the diagnosis, a Large Language Model (LLM) is employed to obtain task-relevant corpora, and this corpora is used to extract keywords. Descriptions constructed with templates containing these keywords serve as input text to probe errors in the proxy model. Finally, we validate the ability to diagnose existing visual models using language on the Waterbirds and CelebA datasets, we can identify bugs comprehensible to human experts, uncovering not only known bugs but also previously unknown ones.","[{'name': 'Chaoquan Jiang, Jinqiang Wang, Rui Hu, Jitao Sang'}]",
1435,Sophisticated Behavioral Simulation: A Possible Solution to Problems of Organized Complexity,https://arxiv.org/abs/2401.09851,"arXiv:2401.09851v2 Announce Type: replace 
Abstract: Simulation technologies have been widely utilized in many scientific research fields such as weather forecasting, fluid mechanics, and biological populations. As a matter of facts, they act as the best tool to handle problems in complex systems where closed-form expressions are unavailable and the target distribution in the representation space is too complex to be fully represented by data-driven learning models, such as deep learning (DL) models. This paper investigates the effectiveness and preference of simulation technologies based on the analyses of scientific paradigms and problems. We revisit the evolution of scientific paradigms from the perspective of data, algorithms, and computational power, and rethink a classic classification of scientific problems which consists of the problems of organized simplicity, problems of disorganized complexity, and problems of organized complexity. These different problems reflect the strengths of different paradigms, indicating that a new simulation technology integrating different paradigms is required to deal with unresolved problems of organized complexity in more complex systems. Therefore, we summarize existent simulation technologies aligning with the scientific paradigms, and propose the concept of behavioral simulation (BS), and further sophisticated behavioral simulation (SBS). They represent a higher degree of paradigms integration based on foundation models to simulate complex social systems involving sophisticated human strategies and behaviors. Beyond the capacity of traditional agent-based modeling simulation (ABMS), BS and further SBS are designed to tackle challenges concerning the complex human system, which can be regarded as a possible next paradigm for science. Through this work, we look forward to more powerful BS and SBS applications in scientific research branches within social science.","[{'name': 'Cheng Wang, Chuwen Wang, Yu Zhao, Wang Zhang, Shirong Zeng, Ronghui Ning, Changjun Jiang'}]",
1436,Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control,https://arxiv.org/abs/2401.12624,"arXiv:2401.12624v2 Announce Type: replace 
Abstract: In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.","[{'name': 'Yongjun Kim, Sejin Seo, Jihong Park, Mehdi Bennis, Seong-Lyun Kim, Junil Choi'}]",
1437,Developing and Evaluating a Design Method for Positive Artificial Intelligence,https://arxiv.org/abs/2402.01499,"arXiv:2402.01499v2 Announce Type: replace 
Abstract: As artificial intelligence (AI) continues advancing, ensuring positive societal impacts becomes critical, especially as AI systems become increasingly ubiquitous in various aspects of life. However, developing \"AI for good\" poses substantial challenges around aligning systems with complex human values. Presently, we lack mature methods for addressing these challenges. This article presents and evaluates the Positive AI design method aimed at addressing this gap. The method provides a human-centered process to translate wellbeing aspirations into concrete practices. First, we explain the method's four key steps: contextualizing, operationalizing, optimizing, and implementing wellbeing supported by continuous measurement for feedback cycles. We then present a multiple case study where novice designers applied the method, revealing strengths and weaknesses related to efficacy and usability. Next, an expert evaluation study assessed the quality of the resulting concepts, rating them moderately high for feasibility, desirability, and plausibility of achieving intended wellbeing benefits. Together, these studies provide preliminary validation of the method's ability to improve AI design, while surfacing areas needing refinement like developing support for complex steps. Proposed adaptations such as examples and evaluation heuristics could address weaknesses. Further research should examine sustained application over multiple projects. This human-centered approach shows promise for realizing the vision of 'AI for Wellbeing' that does not just avoid harm, but actively benefits humanity.","[{'name': 'Willem van der Maden, Derek Lomas, Paul Hekkert'}]",
1438,C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models,https://arxiv.org/abs/2402.03181,"arXiv:2402.03181v3 Announce Type: replace 
Abstract: Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk functions under test distribution shifts. We prove that RAG achieves a lower conformal generation risk than that of a single LLM when the quality of the retrieval model and transformer is non-trivial. Our intensive empirical results demonstrate the soundness and tightness of our conformal generation risk guarantees across four widely-used NLP datasets on four state-of-the-art retrieval models.","[{'name': 'Mintong Kang, Nezihe Merve G\\\\\"urel, Ning Yu, Dawn Song, Bo Li'}]",
1439,CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain,https://arxiv.org/abs/2402.07234,"arXiv:2402.07234v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated significant potential and effectiveness across multiple application domains. To assess the performance of mainstream LLMs in public security tasks, this study aims to construct a specialized evaluation benchmark tailored to the Chinese public security domain--CPSDbench. CPSDbench integrates datasets related to public security collected from real-world scenarios, supporting a comprehensive assessment of LLMs across four key dimensions: text classification, information extraction, question answering, and text generation. Furthermore, this study introduces a set of innovative evaluation metrics designed to more precisely quantify the efficacy of LLMs in executing tasks related to public security. Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the future development of more accurate and customized LLM models targeted at applications in this field.","[{'name': 'Xin Tong, Bo Jin, Zhi Lin, Binjun Wang, Ting Yu, Qiang Cheng'}]",
1440,Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis,https://arxiv.org/abs/2402.07787,"arXiv:2402.07787v3 Announce Type: replace 
Abstract: Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses. Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods.","[{'name': 'Xiaowei Zhao, Yong Zhou, Xiujuan Xu, Yu Liu'}]",
1441,Recursive Joint Simulation in Games,https://arxiv.org/abs/2402.08128,"arXiv:2402.08128v2 Announce Type: replace 
Abstract: Game-theoretic dynamics between AI agents could differ from traditional human-human interactions in various ways. One such difference is that it may be possible to accurately simulate an AI agent, for example because its source code is known. Our aim is to explore ways of leveraging this possibility to achieve more cooperative outcomes in strategic settings. In this paper, we study an interaction between AI agents where the agents run a recursive joint simulation. That is, the agents first jointly observe a simulation of the situation they face. This simulation in turn recursively includes additional simulations (with a small chance of failure, to avoid infinite recursion), and the results of all these nested simulations are observed before an action is chosen. We show that the resulting interaction is strategically equivalent to an infinitely repeated version of the original game, allowing a direct transfer of existing results such as the various folk theorems.","[{'name': 'Vojtech Kovarik, Caspar Oesterheld, Vincent Conitzer'}]",
1442,Premise Order Matters in Reasoning with Large Language Models,https://arxiv.org/abs/2402.08939,"arXiv:2402.08939v2 Announce Type: replace 
Abstract: Large language models (LLMs) have accomplished remarkable reasoning performance in various domains. However, in the domain of reasoning tasks, we discover a frailty: LLMs are surprisingly brittle to the ordering of the premises, despite the fact that such ordering does not alter the underlying task. In particular, we observe that LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps. For example, in deductive reasoning tasks, presenting the premises in the same order as the ground truth proof in the prompt (as opposed to random ordering) drastically increases the model's accuracy. We first examine the effect of premise ordering on deductive reasoning on a variety of LLMs, and our evaluation shows that permuting the premise order can cause a performance drop of over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to examine the ordering effect for mathematical problem-solving, and we again observe a significant drop in accuracy, relative to the original GSM8K benchmark.","[{'name': 'Xinyun Chen, Ryan A. Chi, Xuezhi Wang, Denny Zhou'}]",
1443,Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective,https://arxiv.org/abs/2402.09099,"arXiv:2402.09099v2 Announce Type: replace 
Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of \"self-organization\" and \"multifractal analysis,\" we explore how neuron interactions dynamically evolve during training, leading to \"emergence,\" mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a comprehensive examination of the emergent behavior in LLMs through the lens of both model size and training process, paving new avenues for research into the emergence in large models.","[{'name': 'Xiongye Xiao, Chenyu Zhou, Heng Ping, Defu Cao, Yaxing Li, Yizhuo Zhou, Shixuan Li, Paul Bogdan'}]",
1444,An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection,https://arxiv.org/abs/2402.11403,"arXiv:2402.11403v2 Announce Type: replace 
Abstract: Robots and autonomous systems require an understanding of complex events (CEs) from sensor data to interact with their environments and humans effectively. Traditional end-to-end neural architectures, despite processing sensor data efficiently, struggle with long-duration events due to limited context sizes and reasoning capabilities. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning. We investigate neural and neuro-symbolic architectures' performance in a multimodal CED task, analyzing IMU and acoustic data streams to recognize CE patterns. Our methodology includes (i) end-to-end neural architectures for direct CE detection from sensor embeddings, (ii) two-stage concept-based neural models mapping sensor embeddings to atomic events (AEs) before CE detection, and (iii) a neuro-symbolic approach using a symbolic finite-state machine for CE detection from AEs. Empirically, the neuro-symbolic architecture significantly surpasses purely neural models, demonstrating superior performance in CE recognition, even with extensive training data and ample temporal context for neural approaches.","[{'name': 'Liying Han, Mani B. Srivastava'}]",
1445,A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs,https://arxiv.org/abs/2402.15140,"arXiv:2402.15140v2 Announce Type: replace 
Abstract: Hyper-relational knowledge graphs (KGs) contain additional key-value pairs, providing more information about the relations. In many scenarios, the same relation can have distinct key-value pairs, making the original triple fact more recognizable and specific. Prior studies on hyper-relational KGs have established a solid standard method for hyper-relational graph encoding. In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE. Compared to the prior state-of-the-art approach, ReSaE emphasizes the interaction of relations during message passing process and optimizes the readout structure for link prediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational KGs and ensures stronger performance on downstream link prediction tasks. Our experiments demonstrate that ReSaE achieves state-of-the-art performance on multiple link prediction benchmarks. Furthermore, we also analyze the influence of different model structures on model performance.",[{'name': 'Yonglin Jing'}],
1446,Data Interpreter: An LLM Agent For Data Science,https://arxiv.org/abs/2402.18679,"arXiv:2402.18679v2 Announce Type: replace 
Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated superior performance, exhibiting significant improvements in machine learning tasks, increasing from 0.86 to 0.95. Additionally, it showed a 26% increase in the MATH dataset and a remarkable 112% improvement in open-ended tasks. The solution will be released at https://github.com/geekan/MetaGPT.","[{'name': 'Sirui Hong, Yizhang Lin, Bangbang Liu, Binhao Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Lingyao Zhang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Wenyi Wang, Xiangru Tang, Xiangtao Lu, Xinbing Liang, Yaying Fei, Yuheng Cheng, Zongze Xu, Chenglin Wu, Li Zhang, Min Yang, Xiawu Zheng'}]",
1447,Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound,https://arxiv.org/abs/1907.01743,"arXiv:1907.01743v2 Announce Type: replace-cross 
Abstract: Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of essential importance for image-guided prostate interventions and treatment planning. However, developing such automatic solutions remains very challenging due to the missing/ambiguous boundary and inhomogeneous intensity distribution of the prostate in TRUS, as well as the large variability in prostate shapes. This paper develops a novel 3D deep neural network equipped with attention modules for better prostate segmentation in TRUS by fully exploiting the complementary information encoded in different layers of the convolutional neural network (CNN). Our attention module utilizes the attention mechanism to selectively leverage the multilevel features integrated from different layers to refine the features at each individual layer, suppressing the non-prostate noise at shallow layers of the CNN and increasing more prostate details into features at deep layers. Experimental results on challenging 3D TRUS volumes show that our method attains satisfactory segmentation performance. The proposed attention mechanism is a general strategy to aggregate multi-level deep features and has the potential to be used for other medical image segmentation tasks. The code is publicly available at https://github.com/wulalago/DAF3D.","[{'name': 'Yi Wang, Haoran Dou, Xiaowei Hu, Lei Zhu, Xin Yang, Ming Xu, Jing Qin, Pheng-Ann Heng, Tianfu Wang, Dong Ni'}]",
1448,Private Prediction Sets,https://arxiv.org/abs/2102.06202,"arXiv:2102.06202v3 Announce Type: replace-cross 
Abstract: In real-world settings involving consequential decision-making, the deployment of machine learning systems generally requires both reliable uncertainty quantification and protection of individuals' privacy. We present a framework that treats these two desiderata jointly. Our framework is based on conformal prediction, a methodology that augments predictive models to return prediction sets that provide uncertainty quantification -- they provably cover the true response with a user-specified probability, such as 90%. One might hope that when used with privately-trained models, conformal prediction would yield privacy guarantees for the resulting prediction sets; unfortunately, this is not the case. To remedy this key problem, we develop a method that takes any pre-trained predictive model and outputs differentially private prediction sets. Our method follows the general approach of split conformal prediction; we use holdout data to calibrate the size of the prediction sets but preserve privacy by using a privatized quantile subroutine. This subroutine compensates for the noise introduced to preserve privacy in order to guarantee correct coverage. We evaluate the method on large-scale computer vision datasets.","[{'name': 'Anastasios N. Angelopoulos, Stephen Bates, Tijana Zrnic, Michael I. Jordan'}]",
1449,CMGAN: Conformer-based Metric GAN for Speech Enhancement,https://arxiv.org/abs/2203.15149,"arXiv:2203.15149v4 Announce Type: replace-cross 
Abstract: Recently, convolution-augmented transformer (Conformer) has achieved promising performance in automatic speech recognition (ASR) and time-domain speech enhancement (SE), as it can capture both local and global dependencies in the speech signal. In this paper, we propose a conformer-based metric generative adversarial network (CMGAN) for SE in the time-frequency (TF) domain. In the generator, we utilize two-stage conformer blocks to aggregate all magnitude and complex spectrogram information by modeling both time and frequency dependencies. The estimation of magnitude and complex spectrogram is decoupled in the decoder stage and then jointly incorporated to reconstruct the enhanced speech. In addition, a metric discriminator is employed to further improve the quality of the enhanced estimated speech by optimizing the generator with respect to a corresponding evaluation score. Quantitative analysis on Voice Bank+DEMAND dataset indicates the capability of CMGAN in outperforming various previous models with a margin, i.e., PESQ of 3.41 and SSNR of 11.10 dB.","[{'name': 'Ruizhe Cao, Sherif Abdulatif, Bin Yang'}]",
1450,Multi-View Hypercomplex Learning for Breast Cancer Screening,https://arxiv.org/abs/2204.05798,"arXiv:2204.05798v3 Announce Type: replace-cross 
Abstract: Traditionally, deep learning methods for breast cancer classification perform a single-view analysis. However, radiologists simultaneously analyze all four views that compose a mammography exam, owing to the correlations contained in mammography views, which present crucial information for identifying tumors. In light of this, some studies have started to propose multi-view methods. Nevertheless, in such existing architectures, mammogram views are processed as independent images by separate convolutional branches, thus losing correlations among them. To overcome such limitations, in this paper, we propose a methodological approach for multi-view breast cancer classification based on parameterized hypercomplex neural networks. Thanks to hypercomplex algebra properties, our networks are able to model, and thus leverage, existing correlations between the different views that comprise a mammogram, thus mimicking the reading process performed by clinicians. This happens because hypercomplex networks capture both global properties, as standard neural models, as well as local relations, i.e., inter-view correlations, which real-valued networks fail at modeling. We define architectures designed to process two-view exams, namely PHResNets, and four-view exams, i.e., PHYSEnet and PHYBOnet. Through an extensive experimental evaluation conducted with publicly available datasets, we demonstrate that our proposed models clearly outperform real-valued counterparts and state-of-the-art methods, proving that breast cancer classification benefits from the proposed multi-view architectures. We also assess the method generalizability beyond mammogram analysis by considering different benchmarks, as well as a finer-scaled task such as segmentation. Full code and pretrained models for complete reproducibility of our experiments are freely available at https://github.com/ispamm/PHBreast.","[{'name': 'Eleonora Lopez, Eleonora Grassucci, Martina Valleriani, Danilo Comminiello'}]",
1451,Approximate Nash Equilibrium Learning for n-Player Markov Games in Dynamic Pricing,https://arxiv.org/abs/2207.06492,"arXiv:2207.06492v3 Announce Type: replace-cross 
Abstract: We investigate Nash equilibrium learning in a competitive Markov Game (MG) environment, where multiple agents compete, and multiple Nash equilibria can exist. In particular, for an oligopolistic dynamic pricing environment, exact Nash equilibria are difficult to obtain due to the curse-of-dimensionality. We develop a new model-free method to find approximate Nash equilibria. Gradient-free black box optimization is then applied to estimate $\\epsilon$, the maximum reward advantage of an agent unilaterally deviating from any joint policy, and to also estimate the $\\epsilon$-minimizing policy for any given state. The policy-$\\epsilon$ correspondence and the state to $\\epsilon$-minimizing policy are represented by neural networks, the latter being the Nash Policy Net. During batch update, we perform Nash Q learning on the system, by adjusting the action probabilities using the Nash Policy Net. We demonstrate that an approximate Nash equilibrium can be learned, particularly in the dynamic pricing domain where exact solutions are often intractable.",[{'name': 'Larkin Liu'}],
1452,Using Forwards-Backwards Models to Approximate MDP Homomorphisms,https://arxiv.org/abs/2209.06356,"arXiv:2209.06356v3 Announce Type: replace-cross 
Abstract: Reinforcement learning agents must painstakingly learn through trial and error what sets of state-action pairs are value equivalent -- requiring an often prohibitively large amount of environment experience. MDP homomorphisms have been proposed that reduce the MDP of an environment to an abstract MDP, enabling better sample efficiency. Consequently, impressive improvements have been achieved when a suitable homomorphism can be constructed a priori -- usually by exploiting a practitioner's knowledge of environment symmetries. We propose a novel approach to constructing homomorphisms in discrete action spaces, which uses a learnt model of environment dynamics to infer which state-action pairs lead to the same state -- which can reduce the size of the state-action space by a factor as large as the cardinality of the original action space. In MinAtar, we report an almost 4x improvement over a value-based off-policy baseline in the low sample limit, when averaging over all games and optimizers.","[{'name': 'Augustine N. Mavor-Parker, Matthew J. Sargent, Christian Pehle, Andrea Banino, Lewis D. Griffin, Caswell Barry'}]",
1453,SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction,https://arxiv.org/abs/2210.04870,"arXiv:2210.04870v3 Announce Type: replace-cross 
Abstract: Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. The implementation of SMiLE is available at https://github.com/GKNL/SMiLE.","[{'name': 'Miao Peng, Ben Liu, Qianqian Xie, Wenjie Xu, Hua Wang, Min Peng'}]",
1454,FedTracker: Furnishing Ownership Verification and Traceability for Federated Learning Model,https://arxiv.org/abs/2211.07160,"arXiv:2211.07160v3 Announce Type: replace-cross 
Abstract: Federated learning (FL) is a distributed machine learning paradigm allowing multiple clients to collaboratively train a global model without sharing their local data. However, FL entails exposing the model to various participants. This poses a risk of unauthorized model distribution or resale by the malicious client, compromising the intellectual property rights of the FL group. To deter such misbehavior, it is essential to establish a mechanism for verifying the ownership of the model and as well tracing its origin to the leaker among the FL participants. In this paper, we present FedTracker, the first FL model protection framework that provides both ownership verification and traceability. FedTracker adopts a bi-level protection scheme consisting of global watermark mechanism and local fingerprint mechanism. The former authenticates the ownership of the global model, while the latter identifies which client the model is derived from. FedTracker leverages Continual Learning (CL) principles to embed the watermark in a way that preserves the utility of the FL model on both primitive task and watermark task. FedTracker also devises a novel metric to better discriminate different fingerprints. Experimental results show FedTracker is effective in ownership verification, traceability, and maintains good fidelity and robustness against various watermark removal attacks.","[{'name': 'Shuo Shao, Wenyuan Yang, Hanlin Gu, Zhan Qin, Lixin Fan, Qiang Yang, Kui Ren'}]",
1455,PIP: Positional-encoding Image Prior,https://arxiv.org/abs/2211.14298,"arXiv:2211.14298v3 Announce Type: replace-cross 
Abstract: In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior\" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page https://nimrodshabtay.github.io/PIP/","[{'name': 'Nimrod Shabtay, Eli Schwartz, Raja Giryes'}]",
1456,Discovering Latent Knowledge in Language Models Without Supervision,https://arxiv.org/abs/2212.03827,"arXiv:2212.03827v2 Announce Type: replace-cross 
Abstract: Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels.","[{'name': 'Collin Burns, Haotian Ye, Dan Klein, Jacob Steinhardt'}]",
1457,Complementary Random Masking for RGB-Thermal Semantic Segmentation,https://arxiv.org/abs/2303.17386,"arXiv:2303.17386v2 Announce Type: replace-cross 
Abstract: RGB-thermal semantic segmentation is one potential solution to achieve reliable semantic scene understanding in adverse weather and lighting conditions. However, the previous studies mostly focus on designing a multi-modal fusion module without consideration of the nature of multi-modality inputs. Therefore, the networks easily become over-reliant on a single modality, making it difficult to learn complementary and meaningful representations for each modality. This paper proposes 1) a complementary random masking strategy of RGB-T images and 2) self-distillation loss between clean and masked input modalities. The proposed masking strategy prevents over-reliance on a single modality. It also improves the accuracy and robustness of the neural network by forcing the network to segment and classify objects even when one modality is partially available. Also, the proposed self-distillation loss encourages the network to extract complementary and meaningful representations from a single modality or complementary masked modalities. Based on the proposed method, we achieve state-of-the-art performance over three RGB-T semantic segmentation benchmarks. Our source code is available at https://github.com/UkcheolShin/CRM_RGBTSeg.","[{'name': 'Ukcheol Shin, Kyunghyun Lee, In So Kweon, Jean Oh'}]",
1458,False Claims against Model Ownership Resolution,https://arxiv.org/abs/2304.06607,"arXiv:2304.06607v5 Announce Type: replace-cross 
Abstract: Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.
  In this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our core idea is that a malicious accuser can deviate (without detection) from the specified MOR process by finding (transferable) adversarial examples that successfully serve as evidence against independent suspect models. To this end, we first generalize the procedures of common MOR schemes and show that, under this generalization, defending against false claims is as challenging as preventing (transferable) adversarial examples. Via systematic empirical evaluation, we demonstrate that our false claim attacks always succeed in the MOR schemes that follow our generalization, including against a real-world model: Amazon's Rekognition API.","[{'name': 'Jian Liu, Rui Zhang, Sebastian Szyller, Kui Ren, N. Asokan'}]",
1459,Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion,https://arxiv.org/abs/2305.07912,"arXiv:2305.07912v2 Announce Type: replace-cross 
Abstract: Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that our model has great competitiveness compared to other models with four metrics. Our model can effectively incorporate information from temporal knowledge graphs into the language models.","[{'name': 'Wenjie Xu, Ben Liu, Miao Peng, Xu Jia, Min Peng'}]",
1460,Deep Temporal Graph Clustering,https://arxiv.org/abs/2305.10738,"arXiv:2305.10738v2 Announce Type: replace-cross 
Abstract: Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which introduces deep clustering techniques to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and static graph clustering from several levels. To verify the superiority of the proposed framework TGC, we conduct extensive experiments. The experimental results show that temporal graph clustering enables more flexibility in finding a balance between time and space requirements, and our framework can effectively improve the performance of existing temporal graph learning methods. The code is released: https://github.com/MGitHubL/Deep-Temporal-Graph-Clustering.","[{'name': 'Meng Liu, Yue Liu, Ke Liang, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu'}]",
1461,Unpaired Image-to-Image Translation via Neural Schr\\\"odinger Bridge,https://arxiv.org/abs/2305.15086,"arXiv:2305.15086v3 Announce Type: replace-cross 
Abstract: Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. While diffusion models have achieved remarkable progress, they have limitations in unpaired image-to-image (I2I) translation tasks due to the Gaussian prior assumption. Schr\\\"{o}dinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. Yet, to our best knowledge, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose Unpaired Neural Schr\\\"{o}dinger Bridge (UNSB), which expresses the SB problem as a sequence of adversarial learning problems. This allows us to incorporate advanced discriminators and regularization to learn a SB between unpaired data. We show that UNSB is scalable and successfully solves various unpaired I2I translation tasks. Code: \\url{https://github.com/cyclomon/UNSB}","[{'name': 'Beomsu Kim, Gihyun Kwon, Kwanyoung Kim, Jong Chul Ye'}]",
1462,Learning Safety Constraints from Demonstrations with Unknown Rewards,https://arxiv.org/abs/2305.16147,"arXiv:2305.16147v2 Announce Type: replace-cross 
Abstract: We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in gridworld environments and a driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior. Importantly, we can safely transfer the learned constraints to different tasks and environments. In contrast, alternative methods based on Inverse Reinforcement Learning (IRL) often exhibit poor performance and learn unsafe policies.","[{'name': 'David Lindner, Xin Chen, Sebastian Tschiatschek, Katja Hofmann, Andreas Krause'}]",
1463,Multi-Objective Genetic Algorithm for Multi-View Feature Selection,https://arxiv.org/abs/2305.18352,"arXiv:2305.18352v2 Announce Type: replace-cross 
Abstract: Multi-view datasets offer diverse forms of data that can enhance prediction models by providing complementary information. However, the use of multi-view data leads to an increase in high-dimensional data, which poses significant challenges for the prediction models that can lead to poor generalization. Therefore, relevant feature selection from multi-view datasets is important as it not only addresses the poor generalization but also enhances the interpretability of the models. Despite the success of traditional feature selection methods, they have limitations in leveraging intrinsic information across modalities, lacking generalizability, and being tailored to specific classification tasks. We propose a novel genetic algorithm strategy to overcome these limitations of traditional feature selection methods for multi-view data. Our proposed approach, called the multi-view multi-objective feature selection genetic algorithm (MMFS-GA), simultaneously selects the optimal subset of features within a view and between views under a unified framework. The MMFS-GA framework demonstrates superior performance and interpretability for feature selection on multi-view datasets in both binary and multiclass classification tasks. The results of our evaluations on three benchmark datasets, including synthetic and real data, show improvement over the best baseline methods. This work provides a promising solution for multi-view feature selection and opens up new possibilities for further research in multi-view datasets.","[{'name': 'Vandad Imani, Carlos Sevilla-Salcedo, Elaheh Moradi, Vittorio Fortino, Jussi Tohka'}]",
1464,Safe Offline Reinforcement Learning with Real-Time Budget Constraints,https://arxiv.org/abs/2306.00603,"arXiv:2306.00603v2 Announce Type: replace-cross 
Abstract: Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many real-world applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that models this problem from the perspective of trajectory distribution and solves it through diffusion model planning. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance guarantee for TREBI. Empirical results on a wide range of simulation tasks and a real-world large-scale advertising application demonstrate the capability of TREBI in solving real-time budget constraint problems under offline settings.","[{'name': 'Qian Lin, Bo Tang, Zifan Wu, Chao Yu, Shangqin Mao, Qianlong Xie, Xingxing Wang, Dong Wang'}]",
1465,Prompt Injection attack against LLM-integrated Applications,https://arxiv.org/abs/2306.05499,"arXiv:2306.05499v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and severe attack outcomes, such as unrestricted arbitrary LLM usage and uncomplicated application prompt theft. We deploy HouYi on 36 actual LLM-integrated applications and discern 31 applications susceptible to prompt injection. 10 vendors have validated our discoveries, including Notion, which has the potential to impact millions of users. Our investigation illuminates both the possible risks of prompt injection attacks and the possible tactics for mitigation.","[{'name': 'Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Zihao Wang, Xiaofeng Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, Yang Liu'}]",
1466,Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing,https://arxiv.org/abs/2306.06022,"arXiv:2306.06022v2 Announce Type: replace-cross 
Abstract: The computing in the network (COIN) paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation-demanding applications, such as the metaverse. In this vein, we consider the partial computation offloading problem in the metaverse for multiple subtasks in a COIN environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. The problem is NP-hard, and we transform it into two subproblems: the task-splitting problem (TSP) on the user side and the task-offloading problem (TOP) on the COIN side. We model the TSP as an ordinal potential game and propose a decentralized algorithm to obtain its Nash equilibrium (NE). Then, we model the TOP as a Markov decision process and propose the double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decisions randomly within a certain probability, the COIN agent explores the NE of the TSP and the deep neural network. Finally, the simulation results reveal that the proposed model approach allows the COIN agent to update its policies and make more informed decisions, leading to improved performance over time compared to the traditional baseline","[{'name': 'Ibrahim Aliyu, Seungmin Oh, Namseok Ko, Tai-Won Um, Jinsul Kim'}]",
1467,Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models,https://arxiv.org/abs/2306.08018,"arXiv:2306.08018v5 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.","[{'name': 'Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen'}]",
1468,DCTX-Conformer: Dynamic context carry-over for low latency unified streaming and non-streaming Conformer ASR,https://arxiv.org/abs/2306.08175,"arXiv:2306.08175v2 Announce Type: replace-cross 
Abstract: Conformer-based end-to-end models have become ubiquitous these days and are commonly used in both streaming and non-streaming automatic speech recognition (ASR). Techniques like dual-mode and dynamic chunk training helped unify streaming and non-streaming systems. However, there remains a performance gap between streaming with a full and limited past context. To address this issue, we propose the integration of a novel dynamic contextual carry-over mechanism in a state-of-the-art (SOTA) unified ASR system. Our proposed dynamic context Conformer (DCTX-Conformer) utilizes a non-overlapping contextual carry-over mechanism that takes into account both the left context of a chunk and one or more preceding context embeddings. We outperform the SOTA by a relative 25.0% word error rate, with a negligible latency impact due to the additional context embeddings.","[{'name': 'Goeric Huybrechts, Srikanth Ronanki, Xilai Li, Hadis Nosrati, Sravan Bodapati, Katrin Kirchhoff'}]",
1469,LabelBench: A Comprehensive Framework for Benchmarking Adaptive Label-Efficient Learning,https://arxiv.org/abs/2306.09910,"arXiv:2306.09910v4 Announce Type: replace-cross 
Abstract: Labeled data are critical to modern machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and active learning, aim to be label-efficient: achieving high predictive performance from relatively few labeled examples. While obtaining the best label-efficiency in practice often requires combinations of these techniques, existing benchmark and evaluation frameworks do not capture a concerted combination of all such techniques. This paper addresses this deficiency by introducing LabelBench, a new computationally-efficient framework for joint evaluation of multiple label-efficient learning techniques. As an application of LabelBench, we introduce a novel benchmark of state-of-the-art active learning methods in combination with semi-supervised learning for fine-tuning pretrained vision transformers. Our benchmark demonstrates better label-efficiencies than previously reported in active learning. LabelBench's modular codebase is open-sourced for the broader community to contribute label-efficient learning methods and benchmarks. The repository can be found at: https://github.com/EfficientTraining/LabelBench.","[{'name': 'Jifan Zhang, Yifang Chen, Gregory Canal, Stephen Mussmann, Arnav M. Das, Gantavya Bhatt, Yinglun Zhu, Jeffrey Bilmes, Simon Shaolei Du, Kevin Jamieson, Robert D Nowak'}]",
1470,MATNet: Multi-Level Fusion Transformer-Based Model for Day-Ahead PV Generation Forecasting,https://arxiv.org/abs/2306.10356,"arXiv:2306.10356v2 Announce Type: replace-cross 
Abstract: Accurate forecasting of renewable generation is crucial to facilitate the integration of RES into the power system. Focusing on PV units, forecasting methods can be divided into two main categories: physics-based and data-based strategies, with AI-based models providing state-of-the-art performance. However, while these AI-based models can capture complex patterns and relationships in the data, they ignore the underlying physical prior knowledge of the phenomenon. Therefore, in this paper we propose MATNet, a novel self-attention transformer-based architecture for multivariate multi-step day-ahead PV power generation forecasting. It consists of a hybrid approach that combines the AI paradigm with the prior physical knowledge of PV power generation of physics-based methods. The model is fed with historical PV data and historical and forecast weather data through a multi-level joint fusion approach. The effectiveness of the proposed model is evaluated using the Ausgrid benchmark dataset with different regression performance metrics. The results show that our proposed architecture significantly outperforms the current state-of-the-art methods. These findings demonstrate the potential of MATNet in improving forecasting accuracy and suggest that it could be a promising solution to facilitate the integration of PV energy into the power grid.","[{'name': 'Matteo Tortora, Francesco Conte, Gianluca Natrella, Paolo Soda'}]",
1471,Tackling the Curse of Dimensionality with Physics-Informed Neural Networks,https://arxiv.org/abs/2307.12306,"arXiv:2307.12306v5 Announce Type: replace-cross 
Abstract: The curse-of-dimensionality taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs, as Richard E. Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. We develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and randomly samples a subset of these dimensional pieces in each iteration of training PINNs. We prove theoretically the convergence and other desired properties of the proposed method. We demonstrate in various diverse tests that the proposed method can solve many notoriously hard high-dimensional PDEs, including the Hamilton-Jacobi-Bellman (HJB) and the Schr\\\"{o}dinger equations in tens of thousands of dimensions very fast on a single GPU using the PINNs mesh-free approach. Notably, we solve nonlinear PDEs with nontrivial, anisotropic, and inseparable solutions in 100,000 effective dimensions in 12 hours on a single GPU using SDGD with PINNs. Since SDGD is a general training methodology of PINNs, it can be applied to any current and future variants of PINNs to scale them up for arbitrary high-dimensional PDEs.","[{'name': 'Zheyuan Hu, Khemraj Shukla, George Em Karniadakis, Kenji Kawaguchi'}]",
1472,Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation,https://arxiv.org/abs/2307.15337,"arXiv:2307.15337v3 Announce Type: replace-cross 
Abstract: This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose Skeleton-of-Thought (SoT), which first guides LLMs to generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-ups across 12 LLMs, but it can also potentially improve the answer quality on several question categories. SoT is an initial attempt at data-centric optimization for inference efficiency, and showcases the potential of eliciting high-quality answers by explicitly planning the answer structure in language.","[{'name': 'Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, Yu Wang'}]",
1473,Physically Grounded Vision-Language Models for Robotic Manipulation,https://arxiv.org/abs/2309.02561,"arXiv:2309.02561v4 Announce Type: replace-cross 
Abstract: Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 39.6K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, including generalization to held-out concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically grounded VLM in an interactive framework with a large language model-based robotic planner, and show improved planning performance on tasks that require reasoning about physical object concepts, compared to baselines that do not leverage physically grounded VLMs. We additionally illustrate the benefits of our physically grounded VLM on a real robot, where it improves task success rates. We release our dataset and provide further details and visualizations of our results at https://iliad.stanford.edu/pg-vlm/.","[{'name': 'Jensen Gao, Bidipta Sarkar, Fei Xia, Ted Xiao, Jiajun Wu, Brian Ichter, Anirudha Majumdar, Dorsa Sadigh'}]",
1474,A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism,https://arxiv.org/abs/2309.03720,"arXiv:2309.03720v3 Announce Type: replace-cross 
Abstract: Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.","[{'name': \"Radek Svoboda, Sebastian Basterrech, J\\\\k{e}drzej Kozal, Jan Plato\\\\v{s}, Micha{\\\\l} Wo\\\\'zniak\"}]",
1475,Contrastive Continual Multi-view Clustering with Filtered Structural Fusion,https://arxiv.org/abs/2309.15135,"arXiv:2309.15135v2 Announce Type: replace-cross 
Abstract: Multi-view clustering thrives in applications where views are collected in advance by extracting consistent and complementary information among views. However, it overlooks scenarios where data views are collected sequentially, i.e., real-time data. Due to privacy issues or memory burden, previous views are not available with time in these situations. Some methods are proposed to handle it but are trapped in a stability-plasticity dilemma. In specific, these methods undergo a catastrophic forgetting of prior knowledge when a new view is attained. Such a catastrophic forgetting problem (CFP) would cause the consistent and complementary information hard to get and affect the clustering performance. To tackle this, we propose a novel method termed Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF). Precisely, considering that data correlations play a vital role in clustering and prior knowledge ought to guide the clustering process of a new view, we develop a data buffer with fixed size to store filtered structural information and utilize it to guide the generation of a robust partition matrix via contrastive learning. Furthermore, we theoretically connect CCMVC-FSF with semi-supervised learning and knowledge distillation. Extensive experiments exhibit the excellence of the proposed method.","[{'name': 'Xinhang Wan, Jiyuan Liu, Hao Yu, Ao Li, Xinwang Liu, Ke Liang, Zhibin Dong, En Zhu'}]",
1476,"Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities",https://arxiv.org/abs/2309.16739,"arXiv:2309.16739v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, quantization, and parameter-sharing inference, to facilitate the efficient deployment of LLMs. This article serves as a position paper for thoroughly identifying the motivation, challenges, and pathway for empowering LLMs at the 6G edge.","[{'name': 'Zheng Lin, Guanqiao Qu, Qiyuan Chen, Xianhao Chen, Zhe Chen, Kaibin Huang'}]",
1477,Active-Perceptive Motion Generation for Mobile Manipulation,https://arxiv.org/abs/2310.00433,"arXiv:2310.00433v2 Announce Type: replace-cross 
Abstract: Mobile Manipulation (MoMa) systems incorporate the benefits of mobility and dexterity, due to the enlarged space in which they can move and interact with their environment. However, even when equipped with onboard sensors, e.g., an embodied camera, extracting task-relevant visual information in unstructured and cluttered environments, such as households, remains challenging. In this work, we introduce an active perception pipeline for mobile manipulators to generate motions that are informative toward manipulation tasks, such as grasping in unknown, cluttered scenes. Our proposed approach, ActPerMoMa, generates robot paths in a receding horizon fashion by sampling paths and computing path-wise utilities. These utilities trade-off maximizing the visual Information Gain (IG) for scene reconstruction and the task-oriented objective, e.g., grasp success, by maximizing grasp reachability. We show the efficacy of our method in simulated experiments with a dual-arm TIAGo++ MoMa robot performing mobile grasping in cluttered scenes with obstacles. We empirically analyze the contribution of various utilities and parameters, and compare against representative baselines both with and without active perception objectives. Finally, we demonstrate the transfer of our mobile grasping strategy to the real world, indicating a promising direction for active-perceptive MoMa.","[{'name': 'Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki'}]",
1478,Language Models Represent Space and Time,https://arxiv.org/abs/2310.02207,"arXiv:2310.02207v3 Announce Type: replace-cross 
Abstract: The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual \"space neurons\" and \"time neurons\" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.","[{'name': 'Wes Gurnee, Max Tegmark'}]",
1479,Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization,https://arxiv.org/abs/2310.03234,"arXiv:2310.03234v4 Announce Type: replace-cross 
Abstract: This paper investigates new families of compositional optimization problems, called $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf w}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf c}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\\epsilon$-stationary point of the Moreau envelop of the objective function. Additionally, we also extend the algorithm to solving novel non-smooth weakly-convex tri-level finite-sum coupled compositional optimization problems, which feature a nested arrangement of three functions. Lastly, we explore the applications of our algorithms in deep learning for two-way partial AUC maximization and multi-instance two-way partial AUC maximization, using empirical studies to showcase the effectiveness of the proposed algorithms.","[{'name': 'Quanqi Hu, Dixian Zhu, Tianbao Yang'}]",
1480,Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction,https://arxiv.org/abs/2310.05207,"arXiv:2310.05207v5 Announce Type: replace-cross 
Abstract: Recently how to introduce large amounts of unlabeled facial images in the wild into supervised Facial Action Unit (AU) detection frameworks has become a challenging problem. In this paper, we propose a new AU detection framework where multi-task learning is introduced to jointly learn AU domain separation and reconstruction and facial landmark detection by sharing the parameters of homostructural facial extraction modules. In addition, we propose a new feature alignment scheme based on contrastive learning by simple projectors and an improved contrastive loss, which adds four additional intermediate supervisors to promote the feature reconstruction process. Experimental results on two benchmarks demonstrate our superiority against the state-of-the-art methods for AU detection in the wild.","[{'name': 'Ziqiao Shang, Li Yu'}]",
1481,Reinforcement learning for freeform robot design,https://arxiv.org/abs/2310.05670,"arXiv:2310.05670v2 Announce Type: replace-cross 
Abstract: Inspired by the necessity of morphological adaptation in animals, a growing body of work has attempted to expand robot training to encompass physical aspects of a robot's design. However, reinforcement learning methods capable of optimizing the 3D morphology of a robot have been restricted to reorienting or resizing the limbs of a predetermined and static topological genus. Here we show policy gradients for designing freeform robots with arbitrary external and internal structure. This is achieved through actions that deposit or remove bundles of atomic building blocks to form higher-level nonparametric macrostructures such as appendages, organs and cavities. Although results are provided for open loop control only, we discuss how this method could be adapted for closed loop control and sim2real transfer to physical machines in future.","[{'name': 'Muhan Li, David Matthews, Sam Kriegman'}]",
1482,HIO-SDF: Hierarchical Incremental Online Signed Distance Fields,https://arxiv.org/abs/2310.09463,"arXiv:2310.09463v2 Announce Type: replace-cross 
Abstract: A good representation of a large, complex mobile robot workspace must be space-efficient yet capable of encoding relevant geometric details. When exploring unknown environments, it needs to be updatable incrementally in an online fashion. We introduce HIO-SDF, a new method that represents the environment as a Signed Distance Field (SDF). State of the art representations of SDFs are based on either neural networks or voxel grids. Neural networks are capable of representing the SDF continuously. However, they are hard to update incrementally as neural networks tend to forget previously observed parts of the environment unless an extensive sensor history is stored for training. Voxel-based representations do not have this problem but they are not space-efficient especially in large environments with fine details. HIO-SDF combines the advantages of these representations using a hierarchical approach which employs a coarse voxel grid that captures the observed parts of the environment together with high-resolution local information to train a neural network. HIO-SDF achieves a 46% lower mean global SDF error across all test scenes than a state of the art continuous representation, and a 30% lower error than a discrete representation at the same resolution as our coarse global SDF grid. Videos and code are available at: https://samsunglabs.github.io/HIO-SDF-project-page/","[{'name': 'Vasileios Vasilopoulos, Suveer Garg, Jinwook Huh, Bhoram Lee, Volkan Isler'}]",
1483,Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring,https://arxiv.org/abs/2310.09680,"arXiv:2310.09680v4 Announce Type: replace-cross 
Abstract: Automatic Speech Recognition (ASR) has witnessed a profound research interest. Recent breakthroughs have given ASR systems different prospects such as faithfully transcribing spoken language, which is a pivotal advancement in building conversational agents. However, there is still an imminent challenge of accurately discerning context-dependent words and phrases. In this work, we propose a novel approach for enhancing contextual recognition within ASR systems via semantic lattice processing leveraging the power of deep learning models in accurately delivering spot-on transcriptions across a wide variety of vocabularies and speaking styles. Our solution consists of using Hidden Markov Models and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks (DNN) models integrating both language and acoustic modeling for better accuracy. We infused our network with the use of a transformer-based model to properly rescore the word lattice achieving remarkable capabilities with a palpable reduction in Word Error Rate (WER). We demonstrate the effectiveness of our proposed framework on the LibriSpeech dataset with empirical analyses.","[{'name': 'Ankitha Sudarshan, Vinay Samuel, Parth Patwa, Ibtihel Amara, Aman Chadha'}]",
1484,Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning,https://arxiv.org/abs/2310.11053,"arXiv:2310.11053v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have made unprecedented breakthroughs, yet their increasing integration into everyday life might raise societal risks due to generated unethical content. Despite extensive study on specific issues like bias, the intrinsic values of LLMs remain largely unexplored from a moral philosophy perspective. This work delves into ethical values utilizing Moral Foundation Theory. Moving beyond conventional discriminative evaluations with poor reliability, we propose DeNEVIL, a novel prompt generation algorithm tailored to dynamically exploit LLMs' value vulnerabilities and elicit the violation of ethics in a generative manner, revealing their underlying value inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset comprising 2,397 prompts covering 500+ value principles, and then benchmark the intrinsic values across a spectrum of LLMs. We discovered that most models are essentially misaligned, necessitating further ethical value alignment. In response, we develop VILMO, an in-context alignment method that substantially enhances the value compliance of LLM outputs by learning to generate appropriate value instructions, outperforming existing competitors. Our methods are suitable for black-box and open-source models, offering a promising initial step in studying the ethical values of LLMs.","[{'name': 'Shitong Duan, Xiaoyuan Yi, Peng Zhang, Tun Lu, Xing Xie, Ning Gu'}]",
1485,Quantum Speedups in Regret Analysis of Infinite Horizon Average-Reward Markov Decision Processes,https://arxiv.org/abs/2310.11684,"arXiv:2310.11684v2 Announce Type: replace-cross 
Abstract: This paper investigates the potential of quantum acceleration in addressing infinite horizon Markov Decision Processes (MDPs) to enhance average reward outcomes. We introduce an innovative quantum framework for the agent's engagement with an unknown MDP, extending the conventional interaction paradigm. Our approach involves the design of an optimism-driven tabular Reinforcement Learning algorithm that harnesses quantum signals acquired by the agent through efficient quantum mean estimation techniques. Through thorough theoretical analysis, we demonstrate that the quantum advantage in mean estimation leads to exponential advancements in regret guarantees for infinite horizon Reinforcement Learning. Specifically, the proposed Quantum algorithm achieves a regret bound of $\\tilde{\\mathcal{O}}(1)$, a significant improvement over the $\\tilde{\\mathcal{O}}(\\sqrt{T})$ bound exhibited by classical counterparts.","[{'name': 'Bhargav Ganguly, Yang Xu, Vaneet Aggarwal'}]",
1486,Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments,https://arxiv.org/abs/2311.00123,"arXiv:2311.00123v2 Announce Type: replace-cross 
Abstract: As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of POMDPs under a uniform controlled filter stability (which does not require the knowledge of the model), and (iv) for multi-agent models where convergence of learning dynamics to a new class of equilibria, subjective Q-learning equilibria, will be studied. In addition to the convergence theorem, some implications of the theorem above are new to the literature and others are interpreted as applications of the convergence theorem. Some open problems are noted.","[{'name': 'Ali Devran Kara, Serdar Yuksel'}]",
1487,Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model,https://arxiv.org/abs/2311.00968,"arXiv:2311.00968v2 Announce Type: replace-cross 
Abstract: Numerous studies in the field of music generation have demonstrated impressive performance, yet virtually no models are able to directly generate music to match accompanying videos. In this work, we develop a generative music AI framework, Video2Music, that can match a provided video. We first curated a unique collection of music videos. Then, we analysed the music videos to obtain semantic, scene offset, motion, and emotion features. These distinct features are then employed as guiding input to our music generation model. We transcribe the audio files into MIDI and chords, and extract features such as note density and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on which we train a novel Affective Multimodal Transformer (AMT) model to generate music given a video. This model includes a novel mechanism to enforce affective similarity between video and music. Finally, post-processing is performed based on a biGRU-based regression model to estimate note density and loudness based on the video features. This ensures a dynamic rendering of the generated chords with varying rhythm and volume. In a thorough experiment, we show that our proposed framework can generate music that matches the video content in terms of emotion. The musical quality, along with the quality of music-video matching is confirmed in a user study. The proposed AMT model, along with the new MuVi-Sync dataset, presents a promising step for the new task of music generation for videos.","[{'name': 'Jaeyong Kang, Soujanya Poria, Dorien Herremans'}]",
1488,"A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",https://arxiv.org/abs/2311.05112,"arXiv:2311.05112v4 Announce Type: replace-cross 
Abstract: Large language models (LLMs), such as ChatGPT, have received substantial attention due to their capabilities for understanding and generating human language. While there has been a burgeoning trend in research focusing on the employment of LLMs in supporting different medical tasks (e.g., enhancing clinical diagnostics and providing medical education), a review of these efforts, particularly their development, practical applications, and outcomes in medicine, remains scarce. Therefore, this review aims to provide a detailed overview of the development and deployment of LLMs in medicine, including the challenges and opportunities they face. In terms of development, we provide a detailed introduction to the principles of existing medical LLMs, including their basic model structures, number of parameters, and sources and scales of data used for model development. It serves as a guide for practitioners in developing medical LLMs tailored to their specific needs. In terms of deployment, we offer a comparison of the performance of different LLMs across various medical tasks, and further compare them with state-of-the-art lightweight models, aiming to provide an understanding of the advantages and limitations of LLMs in medicine. Overall, in this review, we address the following questions: 1) What are the practices for developing medical LLMs 2) How to measure the medical task performance of LLMs in a medical setting? 3) How have medical LLMs been employed in real-world practice? 4) What challenges arise from the use of medical LLMs? and 5) How to more effectively develop and deploy medical LLMs? By answering these questions, this review aims to provide insights into the opportunities for LLMs in medicine and serve as a practical resource. We also maintain a regularly updated list of practical guides on medical LLMs at: https://github.com/AI-in-Health/MedLLMsPracticalGuide.","[{'name': 'Hongjian Zhou, Fenglin Liu, Boyang Gu, Xinyu Zou, Jinfa Huang, Jinge Wu, Yiru Li, Sam S. Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Chenyu You, Xian Wu, Yefeng Zheng, Lei Clifton, Zheng Li, Jiebo Luo, David A. Clifton'}]",
1489,MELA: Multilingual Evaluation of Linguistic Acceptability,https://arxiv.org/abs/2311.09033,"arXiv:2311.09033v2 Announce Type: replace-cross 
Abstract: Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families. We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages. Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting. Cross-lingual and multi-task learning experiments show that unlike semantic tasks, in-language training data is crucial in acceptability judgements. Results in layerwise probing indicate that the upper layers of XLM-R become a task-specific but language-agnostic region for multilingual acceptability judgment. We also introduce the concept of conflicting weight, which could be a potential indicator for the difficulty of cross-lingual transfer between languages. Our data will be available at https://github.com/sjtu-compling/MELA.","[{'name': 'Ziyin Zhang, Yikang Liu, Weifang Huang, Junyu Mao, Rui Wang, Hai Hu'}]",
1490,High-fidelity Person-centric Subject-to-Image Synthesis,https://arxiv.org/abs/2311.10329,"arXiv:2311.10329v3 Announce Type: replace-cross 
Abstract: Current subject-driven image generation methods encounter significant challenges in person-centric image generation. The reason is that they learn the semantic scene and person generation by fine-tuning a common pre-trained diffusion, which involves an irreconcilable training imbalance. Precisely, to generate realistic persons, they need to sufficiently tune the pre-trained model, which inevitably causes the model to forget the rich semantic scene prior and makes scene generation over-fit to the training data. Moreover, even with sufficient fine-tuning, these methods can still not generate high-fidelity persons since joint learning of the scene and person generation also lead to quality compromise. In this paper, we propose Face-diffuser, an effective collaborative generation pipeline to eliminate the above training imbalance and quality compromise. Specifically, we first develop two specialized pre-trained diffusion models, i.e., Text-driven Diffusion Model (TDM) and Subject-augmented Diffusion Model (SDM), for scene and person generation, respectively. The sampling process is divided into three sequential stages, i.e., semantic scene construction, subject-scene fusion, and subject enhancement. The first and last stages are performed by TDM and SDM respectively. The subject-scene fusion stage, that is the collaboration achieved through a novel and highly effective mechanism, Saliency-adaptive Noise Fusion (SNF). Specifically, it is based on our key observation that there exists a robust link between classifier-free guidance responses and the saliency of generated images. In each time step, SNF leverages the unique strengths of each model and allows for the spatial blending of predicted noises from both models automatically in a saliency-aware manner. Extensive experiments confirm the impressive effectiveness and robustness of the Face-diffuser.","[{'name': 'Yibin Wang, Weizhong Zhang, Jianwei Zheng, Cheng Jin'}]",
1491,Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition,https://arxiv.org/abs/2311.16119,"arXiv:2311.16119v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts.","[{'name': 'Sander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-Fran\\\\c{c}ois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Liu Kost, Christopher Carnahan, Jordan Boyd-Graber'}]",
1492,MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following,https://arxiv.org/abs/2312.02436,"arXiv:2312.02436v2 Announce Type: replace-cross 
Abstract: In the realm of large language models (LLMs), enhancing instruction-following capability often involves curating expansive training data. This is achieved through two primary schemes: i) Scaling-Inputs: Amplifying (input, output) pairs per task instruction, aiming for better instruction adherence. ii) Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction, output) pair (without requiring a separate input anymore). However, LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs. This work introduces MUFFIN, a new scheme of instruction-following dataset curation. Specifically, we automatically Scale Tasks per Input by diversifying these tasks with various input facets. Experimental results across four zero-shot benchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes, reveal that LLMs, at various scales, trained on MUFFIN generally demonstrate superior instruction-following capabilities compared to those trained on the two aforementioned schemes.","[{'name': 'Renze Lou, Kai Zhang, Jian Xie, Yuxuan Sun, Janice Ahn, Hanzi Xu, Yu Su, Wenpeng Yin'}]",
1493,Reconciling Shared versus Context-Specific Information in a Neural Network Model of Latent Causes,https://arxiv.org/abs/2312.08519,"arXiv:2312.08519v2 Announce Type: replace-cross 
Abstract: It has been proposed that, when processing a stream of events, humans divide their experiences in terms of inferred latent causes (LCs) to support context-dependent learning. However, when shared structure is present across contexts, it is still unclear how the \"splitting\" of LCs and learning of shared structure can be simultaneously achieved. Here, we present the Latent Cause Network (LCNet), a neural network model of LC inference. Through learning, it naturally stores structure that is shared across tasks in the network weights. Additionally, it represents context-specific structure using a context module, controlled by a Bayesian nonparametric inference algorithm, which assigns a unique context vector for each inferred LC. Across three simulations, we found that LCNet could 1) extract shared structure across LCs in a function learning task while avoiding catastrophic interference, 2) capture human data on curriculum effects in schema learning, and 3) infer the underlying event structure when processing naturalistic videos of daily events. Overall, these results demonstrate a computationally feasible approach to reconciling shared structure and context-specific structure in a model of LCs that is scalable from laboratory experiment settings to naturalistic settings.","[{'name': 'Qihong Lu, Tan T. Nguyen, Qiong Zhang, Uri Hasson, Thomas L. Griffiths, Jeffrey M. Zacks, Samuel J. Gershman, Kenneth A. Norman'}]",
1494,Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks,https://arxiv.org/abs/2312.14499,"arXiv:2312.14499v2 Announce Type: replace-cross 
Abstract: Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by seamlessly blending data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the original PINN loss and its unbiased behavior under specific conditions. Comparisons with Stochastic Dimension Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly in scenarios with significant variance among dimensions. We further extend HTE to higher-order and higher-dimensional PDEs, specifically addressing the biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently computes the colossal tensor associated with the fourth-order high-dimensional biharmonic equation, saving memory and enabling rapid computation. The effectiveness of HTE is illustrated through experimental setups, demonstrating comparable convergence rates with SDGD under memory and speed constraints. Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN (gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new capability in scientific machine learning for tackling high-order and high-dimensional PDEs.","[{'name': 'Zheyuan Hu, Zekun Shi, George Em Karniadakis, Kenji Kawaguchi'}]",
1495,BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation,https://arxiv.org/abs/2401.04330,"arXiv:2401.04330v2 Announce Type: replace-cross 
Abstract: The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment metrics and evaluation effects of the model described in this paper on the publicly available datasets DSIFN-CD, S2Looking and WHU-CD are the best when compared to other models.","[{'name': 'Yonghui Tan, Xiaolong Li, Yishu Chen, Jinquan Ai'}]",
1496,Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study,https://arxiv.org/abs/2401.04331,"arXiv:2401.04331v2 Announce Type: replace-cross 
Abstract: In this work, we rigorously investigate the robustness of graph neural fractional-order differential equation (FDE) models. This framework extends beyond traditional graph neural (integer-order) ordinary differential equation (ODE) models by implementing the time-fractional Caputo derivative. Utilizing fractional calculus allows our model to consider long-term memory during the feature updating process, diverging from the memoryless Markovian updates seen in traditional graph neural ODE models. The superiority of graph neural FDE models over graph neural ODE models has been established in environments free from attacks or perturbations. While traditional graph neural ODE models have been verified to possess a degree of stability and resilience in the presence of adversarial attacks in existing literature, the robustness of graph neural FDE models, especially under adversarial conditions, remains largely unexplored. This paper undertakes a detailed assessment of the robustness of graph neural FDE models. We establish a theoretical foundation outlining the robustness characteristics of graph neural FDE models, highlighting that they maintain more stringent output perturbation bounds in the face of input and graph topology disturbances, compared to their integer-order counterparts. Our empirical evaluations further confirm the enhanced robustness of graph neural FDE models, highlighting their potential in adversarially robust applications.","[{'name': 'Qiyu Kang, Kai Zhao, Yang Song, Yihang Xie, Yanan Zhao, Sijie Wang, Rui She, Wee Peng Tay'}]",
1497,DocFinQA: A Long-Context Financial Reasoning Dataset,https://arxiv.org/abs/2401.06915,"arXiv:2401.06915v2 Announce Type: replace-cross 
Abstract: For large language models (LLMs) to be effective in the financial domain -- where each decision can have a significant impact -- it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents that are hundreds of pages long, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with the full-document context, extending the average context length from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments over retrieval-based QA pipelines and long-context language models. DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case-study on the longest documents in DocFinQA and find that models particularly struggle on these documents. Addressing these challenges may have a wide reaching impact across applications where specificity and long-range contexts are critical, like gene sequences and legal document contract analysis.","[{'name': 'Varshini Reddy, Rik Koncel-Kedziorski, Viet Dac Lai, Michael Krumdick, Charles Lovering, Chris Tanner'}]",
1498,Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility,https://arxiv.org/abs/2401.13782,"arXiv:2401.13782v2 Announce Type: replace-cross 
Abstract: As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.","[{'name': 'Iain Xie Weissburg, Mehir Arora, Xinyi Wang, Liangming Pan, William Yang Wang'}]",
1499,FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design,https://arxiv.org/abs/2401.14112,"arXiv:2401.14112v2 Announce Type: replace-cross 
Abstract: Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality consistently across varied applications. However, existing systems do not provide Tensor Core support for FP6 quantization and struggle to achieve practical performance improvements during LLM inference. It is challenging to support FP6 quantization on GPUs due to (1) unfriendly memory access of model weights with irregular bit-width and (2) high runtime overhead of weight de-quantization. To address these problems, we propose TC-FPx, the first full-stack GPU kernel design scheme with unified Tensor Core support of float-point weights for various quantization bit-width. We integrate TC-FPx kernel into an existing inference system, providing new end-to-end support (called FP6-LLM) for quantized LLM inference, where better trade-offs between inference cost and model quality are achieved. Experiments show that FP6-LLM enables the inference of LLaMA-70b using only a single GPU, achieving 1.69x-2.65x higher normalized inference throughput than the FP16 baseline. The source code is publicly available at https://github.com/usyd-fsalab/fp6_llm.","[{'name': 'Haojun Xia, Zhen Zheng, Xiaoxia Wu, Shiyang Chen, Zhewei Yao, Stephen Youn, Arash Bakhtiari, Michael Wyatt, Donglin Zhuang, Zhongzhu Zhou, Olatunji Ruwase, Yuxiong He, Shuaiwen Leon Song'}]",
1500,On Prompt-Driven Safeguarding for Large Language Models,https://arxiv.org/abs/2401.18018,"arXiv:2401.18018v2 Announce Type: replace-cross 
Abstract: Prepending model inputs with safety prompts is a common practice for safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not been revealed yet, which hinders the potential for automatically optimizing them to improve LLM safety. To this end, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by safety prompts in similar directions where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. It treats safety prompts as continuous, trainable embeddings and learns to move the representations of harmful/harmless queries along/opposite the direction in which the model's refusal probability increases. Experiments with eight LLMs on out-of-domain benchmarks demonstrate that DRO remarkably improves the safeguarding performance of human-crafted safety prompts and outperforms strong baselines, without compromising the general model capability.","[{'name': 'Chujie Zheng, Fan Yin, Hao Zhou, Fandong Meng, Jie Zhou, Kai-Wei Chang, Minlie Huang, Nanyun Peng'}]",
1501,Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting,https://arxiv.org/abs/2402.01440,"arXiv:2402.01440v3 Announce Type: replace-cross 
Abstract: Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to catalyze continued innovation in this field.","[{'name': 'Xingtong Yu, Yuan Fang, Zemin Liu, Yuxia Wu, Zhihao Wen, Jianyuan Bo, Xinming Zhang, Steven C. H. Hoi'}]",
1502,Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm,https://arxiv.org/abs/2402.02042,"arXiv:2402.02042v2 Announce Type: replace-cross 
Abstract: This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDP). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, we demonstrate that our proposed algorithm achieves $\\tilde{\\mathcal{O}}({T}^{4/5})$ objective regret and $\\tilde{\\mathcal{O}}({T}^{4/5})$ constraint violation bounds.","[{'name': 'Qinbo Bai, Washim Uddin Mondal, Vaneet Aggarwal'}]",
1503,A Truly Joint Neural Architecture for Segmentation and Parsing,https://arxiv.org/abs/2402.02564,"arXiv:2402.02564v2 Announce Type: replace-cross 
Abstract: Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.","[{'name': 'Danit Yshaayahu Levi, Reut Tsarfaty'}]",
1504,ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer,https://arxiv.org/abs/2402.02733,"arXiv:2402.02733v2 Announce Type: replace-cross 
Abstract: Face re-aging is a prominent field in computer vision and graphics, with significant applications in photorealistic domains such as movies, advertising, and live streaming. Recently, the need to apply face re-aging to non-photorealistic images, like comics, illustrations, and animations, has emerged as an extension in various entertainment sectors. However, the absence of a network capable of seamlessly editing the apparent age on NPR images means that these tasks have been confined to a naive approach, applying each task sequentially. This often results in unpleasant artifacts and a loss of facial attributes due to domain discrepancies. In this paper, we introduce a novel one-stage method for face re-aging combined with portrait style transfer, executed in a single generative step. We leverage existing face re-aging and style transfer networks, both trained within the same PR domain. Our method uniquely fuses distinct latent vectors, each responsible for managing aging-related attributes and NPR appearance. Adopting an exemplar-based approach, our method offers greater flexibility than domain-level fine-tuning approaches, which typically require separate training or fine-tuning for each domain. This effectively addresses the limitation of requiring paired datasets for re-aging and domain-level, data-driven approaches for stylization. Our experiments show that our model can effortlessly generate re-aged images while simultaneously transferring the style of examples, maintaining both natural appearance and controllability.","[{'name': 'Bumsoo Kim, Abdul Muqeet, Kyuchul Lee, Sanghyun Seo'}]",
1505,SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM,https://arxiv.org/abs/2402.03246,"arXiv:2402.03246v3 Announce Type: replace-cross 
Abstract: Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM). Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings. Building on this progress, we propose SGS-SLAM which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation. It outperforms existing methods by a large margin meanwhile preserving real-time rendering ability.","[{'name': 'Mingrui Li, Shuhong Liu, Heng Zhou, Guohao Zhu, Na Cheng, Hongyu Wang'}]",
1506,RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback,https://arxiv.org/abs/2402.03681,"arXiv:2402.03681v3 Announce Type: replace-cross 
Abstract: Reward engineering has long been a challenge in Reinforcement Learning (RL) research, as it often requires extensive human effort and iterative processes of trial-and-error to design effective reward functions. In this paper, we propose RL-VLM-F, a method that automatically generates reward functions for agents to learn new tasks, using only a text description of the task goal and the agent's visual observations, by leveraging feedbacks from vision language foundation models (VLMs). The key to our approach is to query these models to give preferences over pairs of the agent's image observations based on the text description of the task goal, and then learn a reward function from the preference labels, rather than directly prompting these models to output a raw reward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F successfully produces effective rewards and policies across various domains - including classic control, as well as manipulation of rigid, articulated, and deformable objects - without the need for human supervision, outperforming prior methods that use large pretrained models for reward generation under the same assumptions. Videos can be found on our project website: https://rlvlmf2024.github.io/","[{'name': 'Yufei Wang, Zhanyi Sun, Jesse Zhang, Zhou Xian, Erdem Biyik, David Held, Zackory Erickson'}]",
1507,SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models,https://arxiv.org/abs/2402.05044,"arXiv:2402.05044v3 Announce Type: replace-cross 
Abstract: In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our extensive experiments shed light on the resilience of LLMs against emerging threats and the efficacy of contemporary defense tactics. Data and evaluator are released under https://github.com/OpenSafetyLab/SALAD-BENCH.","[{'name': 'Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu Qiao, Jing Shao'}]",
1508,Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application,https://arxiv.org/abs/2402.05448,"arXiv:2402.05448v2 Announce Type: replace-cross 
Abstract: In this paper, we first present the character texture generation system \\textit{Minecraft-ify}, specified to Minecraft video game toward in-game application. Ours can generate face-focused image for texture mapping tailored to 3D virtual character having cube manifold. While existing projects or works only generate texture, proposed system can inverse the user-provided real image, or generate average/random appearance from learned distribution. Moreover, it can be manipulated with text-guidance using StyleGAN and StyleCLIP. These features provide a more extended user experience with enlarged freedom as a user-friendly AI-tool. Project page can be found at https://gh-bumsookim.github.io/Minecraft-ify/","[{'name': 'Bumsoo Kim, Sanghyun Byun, Yonghoon Jung, Wonseop Shin, Sareer UI Amin, Sanghyun Seo'}]",
1509,Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction,https://arxiv.org/abs/2402.05663,"arXiv:2402.05663v2 Announce Type: replace-cross 
Abstract: Accurate real-time traffic state forecasting plays a pivotal role in traffic control research. In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays. After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment. In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting. We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time.","[{'name': 'Raphael Chekroun, Han Wang, Jonathan Lee, Marin Toromanoff, Sascha Hornauer, Fabien Moutarde, Maria Laura Delle Monache'}]",
1510,The last Dance : Robust backdoor attack via diffusion models and bayesian approach,https://arxiv.org/abs/2402.05967,"arXiv:2402.05967v2 Announce Type: replace-cross 
Abstract: Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we aim to fool audio-based DNN models, such as those from the Hugging Face framework, primarily those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and achieve results faster and more efficiently. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence research. The backdoor attack developed in this paper is based on poisoning model training data uniquely by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data.",[{'name': 'Orson Mengara'}],
1511,Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data,https://arxiv.org/abs/2402.06104,"arXiv:2402.06104v2 Announce Type: replace-cross 
Abstract: Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 benchmark datasets with other 8 competitive baselines. The code is open-sourced at \\url{https://github.com/DixianZhu/FAR}.","[{'name': 'Dixian Zhu, Livnat Jerby'}]",
1512,Forecasting high-impact research topics via machine learning on evolving knowledge graphs,https://arxiv.org/abs/2402.08640,"arXiv:2402.08640v2 Announce Type: replace-cross 
Abstract: The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas.","[{'name': 'Xuemei Gu, Mario Krenn'}]",
1513,MC-DBN: A Deep Belief Network-Based Model for Modality Completion,https://arxiv.org/abs/2402.09782,"arXiv:2402.09782v2 Announce Type: replace-cross 
Abstract: Recent advancements in multi-modal artificial intelligence (AI) have revolutionized the fields of stock market forecasting and heart rate monitoring. Utilizing diverse data sources can substantially improve prediction accuracy. Nonetheless, additional data may not always align with the original dataset. Interpolation methods are commonly utilized for handling missing values in modal data, though they may exhibit limitations in the context of sparse information. Addressing this challenge, we propose a Modality Completion Deep Belief Network-Based Model (MC-DBN). This approach utilizes implicit features of complete data to compensate for gaps between itself and additional incomplete data. It ensures that the enhanced multi-modal data closely aligns with the dynamic nature of the real world to enhance the effectiveness of the model. We conduct evaluations of the MC-DBN model in two datasets from the stock market forecasting and heart rate monitoring domains. Comprehensive experiments showcase the model's capacity to bridge the semantic divide present in multi-modal data, subsequently enhancing its performance. The source code is available at: https://github.com/logan-0623/DBN-generate","[{'name': 'Zihong Luo, Kexin He, Chengzhi Liu, Zheng Tao'}]",
1514,Enhancing Convergence in Federated Learning: A Contribution-Aware Asynchronous Approach,https://arxiv.org/abs/2402.10991,"arXiv:2402.10991v4 Announce Type: replace-cross 
Abstract: Federated Learning (FL) is a distributed machine learning paradigm that allows clients to train models on their data while preserving their privacy. FL algorithms, such as Federated Averaging (FedAvg) and its variants, have been shown to converge well in many scenarios. However, these methods require clients to upload their local updates to the server in a synchronous manner, which can be slow and unreliable in realistic FL settings. To address this issue, researchers have developed asynchronous FL methods that allow clients to continue training on their local data using a stale global model. However, most of these methods simply aggregate all of the received updates without considering their relative contributions, which can slow down convergence. In this paper, we propose a contribution-aware asynchronous FL method that takes into account the staleness and statistical heterogeneity of the received updates. Our method dynamically adjusts the contribution of each update based on these factors, which can speed up convergence compared to existing methods.","[{'name': 'Changxin Xu, Yuxin Qiao, Zhanxin Zhou, Fanghao Ni, Jize Xiong'}]",
1515,Aligning Large Language Models by On-Policy Self-Judgment,https://arxiv.org/abs/2402.11253,"arXiv:2402.11253v2 Announce Type: replace-cross 
Abstract: Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning. In this paper, we present a novel alignment framework, \\method{} that (1) does on-policy learning and 2) is parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning. To this end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a single model to act as both a policy and a judge. Specifically, we view the pairwise judgment task, choosing the better response from a response pair, as a special case of the instruction-following task. The resulting model can judge preferences of on-the-fly responses from current policy initialized from itself. Experimental results show the efficacy of \\method{}, outperforming baselines in preference benchmarks. We also show that the rejecting sampling by itself can improve performance further without an additional evaluator.","[{'name': 'Sangkyu Lee, Sungdong Kim, Ashkan Yousefpour, Minjoon Seo, Kang Min Yoo, Youngjae Yu'}]",
1516,"From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions, and Models for Planning from Raw Data",https://arxiv.org/abs/2402.11871,"arXiv:2402.11871v4 Announce Type: replace-cross 
Abstract: Hand-crafted, logic-based state and action representations have been widely used to overcome the intractable computational complexity of long-horizon robot planning problems, including task and motion planning problems. However, creating such representations requires experts with strong intuitions and detailed knowledge about the robot and the tasks it may need to accomplish in a given setting. Removing this dependency on human intuition is a highly active research area.
  This paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories. The learned representations constitute auto-invented PDDL-like domain models. Empirical results in deterministic settings show that powerful abstract representations can be learned from just a handful of robot trajectories; the learned relational representations include but go beyond classical, intuitive notions of high-level actions; and that the learned models allow planning algorithms to scale to tasks that were previously beyond the scope of planning without hand-crafted abstractions.","[{'name': 'Naman Shah, Jayesh Nagpal, Pulkit Verma, Siddharth Srivastava'}]",
1517,Transformer-based Causal Language Models Perform Clustering,https://arxiv.org/abs/2402.12151,"arXiv:2402.12151v2 Announce Type: replace-cross 
Abstract: Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements in the instruction-following capability via additional training for instruction-following tasks. However, the mechanisms responsible for effective instruction-following capabilities remain inadequately understood. Here, we introduce a simplified instruction-following task and use synthetic datasets to analyze a Transformer-based causal language model. Our findings suggest that the model learns task-specific information by clustering data within its hidden space, with this clustering process evolving dynamically during learning. We also demonstrate how this phenomenon assists the model in handling unseen instances, and validate our results in a more realistic setting. Furthermore, we present inspired applications regarding pre-training and alignment.","[{'name': 'Xinbo Wu, Lav R. Varshney'}]",
1518,PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images,https://arxiv.org/abs/2402.12721,"arXiv:2402.12721v2 Announce Type: replace-cross 
Abstract: A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the original, downstream model. Moreover, the proposed PAC-FNO is ready to work with existing image recognition models. Extensively evaluating methods with seven image recognition benchmarks, we show that the proposed PAC-FNO improves the performance of existing baseline models on images with various resolutions by up to 77.1% and various types of natural variations in the images at inference.","[{'name': 'Jinsung Jeon, Hyundong Jin, Jonghyun Choi, Sanghyun Hong, Dongeun Lee, Kookjin Lee, Noseong Park'}]",
1519,Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering,https://arxiv.org/abs/2402.12728,"arXiv:2402.12728v2 Announce Type: replace-cross 
Abstract: Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designed for sufficient multimodal fusion. We utilize the shared mentioned entities in two graphs as mediums to bridge a tight inter-modal exchange, while maximally preserving insightful intra-modal learning by constraining the fusion within mediums. Extensive experiments on two benchmark datasets show the superiority of MAIL with 24x less resources.","[{'name': 'Junnan Dong, Qinggang Zhang, Huachi Zhou, Daochen Zha, Pai Zheng, Xiao Huang'}]",
1520,NeRF Solves Undersampled MRI Reconstruction,https://arxiv.org/abs/2402.13226,"arXiv:2402.13226v2 Announce Type: replace-cross 
Abstract: This article presents a novel undersampled magnetic resonance imaging (MRI) technique that leverages the concept of Neural Radiance Field (NeRF). With radial undersampling, the corresponding imaging problem can be reformulated into an image modeling task from sparse-view rendered data; therefore, a high dimensional MR image is obtainable from undersampled k-space data by taking advantage of implicit neural representation. A multi-layer perceptron, which is designed to output an image intensity from a spatial coordinate, learns the MR physics-driven rendering relation between given measurement data and desired image. Effective undersampling strategies for high-quality neural representation are investigated. The proposed method serves two benefits: (i) The learning is based fully on single undersampled k-space data, not a bunch of measured data and target image sets. It can be used potentially for diagnostic MR imaging, such as fetal MRI, where data acquisition is relatively rare or limited against diversity of clinical images while undersampled reconstruction is highly demanded. (ii) A reconstructed MR image is a scan-specific representation highly adaptive to the given k-space measurement. Numerous experiments validate the feasibility and capability of the proposed approach.","[{'name': 'Tae Jun Jang, Chang Min Hyun'}]",
1521,DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning,https://arxiv.org/abs/2402.13711,"arXiv:2402.13711v4 Announce Type: replace-cross 
Abstract: We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD) approach to consider both the class representativeness and the diversity within each class of the replayed nodes. Moreover, we adopt graph structure learning (GSL) to ensure that the replayed nodes are connected to truly informative neighbors. Extensive experimental results demonstrate the effectiveness and efficiency of DSLR. Our source code is available at https://github.com/seungyoon-Choi/DSLR_official.","[{'name': 'Seungyoon Choi, Wonjoong Kim, Sungwon Kim, Yeonjun In, Sein Kim, Chanyoung Park'}]",
1522,NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion,https://arxiv.org/abs/2402.13809,"arXiv:2402.13809v2 Announce Type: replace-cross 
Abstract: Reconstructing visual stimuli from functional Magnetic Resonance Imaging (fMRI) based on Latent Diffusion Models (LDM) provides a fine-grained retrieval of the brain. A challenge persists in reconstructing a cohesive alignment of details (such as structure, background, texture, color, etc.). Moreover, LDMs would generate different image results even under the same conditions. For these, we first uncover the neuroscientific perspective of LDM-based methods that is top-down creation based on pre-trained knowledge from massive images but lack of detail-driven bottom-up perception resulting in unfaithful details. We propose NeuralDiffuser which introduces primary visual feature guidance to provide detail cues in the form of gradients, extending the bottom-up process for LDM-based methods to achieve faithful semantics and details. We also developed a novel guidance strategy to ensure the consistency of repeated reconstructions rather than a variety of results. We obtain the state-of-the-art performance of NeuralDiffuser on the Natural Senses Dataset (NSD), which offers more faithful details and consistent results.","[{'name': 'Haoyu Li, Hao Wu, Badong Chen'}]",
1523,SDXL-Lightning: Progressive Adversarial Diffusion Distillation,https://arxiv.org/abs/2402.13929,"arXiv:2402.13929v3 Announce Type: replace-cross 
Abstract: We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights.","[{'name': 'Shanchuan Lin, Anran Wang, Xiao Yang'}]",
1524,E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series,https://arxiv.org/abs/2402.14041,"arXiv:2402.14041v4 Announce Type: replace-cross 
Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead.","[{'name': 'Zhichen Lai, Huan Li, Dalin Zhang, Yan Zhao, Weizhu Qian, Christian S. Jensen'}]",
1525,A Collision-Aware Cable Grasping Method in Cluttered Environment,https://arxiv.org/abs/2402.14498,"arXiv:2402.14498v2 Announce Type: replace-cross 
Abstract: We introduce a Cable Grasping-Convolutional Neural Network designed to facilitate robust cable grasping in cluttered environments. Utilizing physics simulations, we generate an extensive dataset that mimics the intricacies of cable grasping, factoring in potential collisions between cables and robotic grippers. We employ the Approximate Convex Decomposition technique to dissect the non-convex cable model, with grasp quality autonomously labeled based on simulated grasping attempts. The CG-CNN is refined using this simulated dataset and enhanced through domain randomization techniques. Subsequently, the trained model predicts grasp quality, guiding the optimal grasp pose to the robot controller for execution. Grasping efficacy is assessed across both synthetic and real-world settings. Given our model implicit collision sensitivity, we achieved commendable success rates of 92.3% for known cables and 88.4% for unknown cables, surpassing contemporary state-of-the-art approaches. Supplementary materials can be found at https://leizhang-public.github.io/cg-cnn/ .","[{'name': 'Lei Zhang, Kaixin Bai, Qiang Li, Zhaopeng Chen, Jianwei Zhang'}]",
1526,OmniPred: Language Models as Universal Regressors,https://arxiv.org/abs/2402.14547,"arXiv:2402.14547v3 Announce Type: replace-cross 
Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.","[{'name': 'Xingyou Song, Oscar Li, Chansoo Lee, Bangding Yang, Daiyi Peng, Sagi Perel, Yutian Chen'}]",
1527,Query Augmentation by Decoding Semantics from Brain Signals,https://arxiv.org/abs/2402.15708,"arXiv:2402.15708v2 Announce Type: replace-cross 
Abstract: Query augmentation is a crucial technique for refining semantically imprecise queries. Traditionally, query augmentation relies on extracting information from initially retrieved, potentially relevant documents. If the quality of the initially retrieved documents is low, then the effectiveness of query augmentation would be limited as well. We propose Brain-Aug, which enhances a query by incorporating semantic information decoded from brain signals. BrainAug generates the continuation of the original query with a prompt constructed with brain signal information and a ranking-oriented inference approach. Experimental results on fMRI (functional magnetic resonance imaging) datasets show that Brain-Aug produces semantically more accurate queries, leading to improved document ranking performance. Such improvement brought by brain signals is particularly notable for ambiguous queries.","[{'name': 'Ziyi Ye, Jingtao Zhan, Qingyao Ai, Yiqun Liu, Maarten de Rijke, Christina Lioma, Tuukka Ruotsalo'}]",
1528,LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper,https://arxiv.org/abs/2402.15727,"arXiv:2402.15727v2 Announce Type: replace-cross 
Abstract: Jailbreaking is an emerging adversarial attack that bypasses the safety alignment deployed in off-the-shelf large language models (LLMs). A considerable amount of research exists proposing more effective jailbreak attacks, including the recent Greedy Coordinate Gradient (GCG) attack, jailbreak template-based attacks such as using \"Do-Anything-Now\" (DAN), and multilingual jailbreak. In contrast, the defensive side has been relatively less explored. This paper proposes a lightweight yet practical defense called SELFDEFEND, which can defend against all existing jailbreak attacks with minimal delay for jailbreak prompts and negligible delay for normal user prompts. Our key insight is that regardless of the kind of jailbreak strategies employed, they eventually need to include a harmful prompt (e.g., \"how to make a bomb\") in the prompt sent to LLMs, and we found that existing LLMs can effectively recognize such harmful prompts that violate their safety policies. Based on this insight, we design a shadow stack that concurrently checks whether a harmful prompt exists in the user prompt and triggers a checkpoint in the normal stack once a token of \"No\" or a harmful prompt is output. The latter could also generate an explainable LLM response to adversarial prompts. We demonstrate our idea of SELFDEFEND works in various jailbreak scenarios through manual analysis in GPT-3.5/4. We also list three future directions to further enhance SELFDEFEND.","[{'name': 'Daoyuan Wu, Shuai Wang, Yang Liu, Ning Liu'}]",
1529,Rethinking Software Engineering in the Foundation Model Era: A Curated Catalogue of Challenges in the Development of Trustworthy FMware,https://arxiv.org/abs/2402.15943,"arXiv:2402.15943v2 Announce Type: replace-cross 
Abstract: Foundation models (FMs), such as Large Language Models (LLMs), have revolutionized software development by enabling new use cases and business models. We refer to software built using FMs as FMware. The unique properties of FMware (e.g., prompts, agents, and the need for orchestration), coupled with the intrinsic limitations of FMs (e.g., hallucination) lead to a completely new set of software engineering challenges. Based on our industrial experience, we identified 10 key SE4FMware challenges that have caused enterprise FMware development to be unproductive, costly, and risky. In this paper, we discuss these challenges in detail and state the path for innovation that we envision. Next, we present FMArts, which is our long-term effort towards creating a cradle-to-grave platform for the engineering of trustworthy FMware. Finally, we (i) show how the unique properties of FMArts enabled us to design and develop a complex FMware for a large customer in a timely manner and (ii) discuss the lessons that we learned in doing so. We hope that the disclosure of the aforementioned challenges and our associated efforts to tackle them will not only raise awareness but also promote deeper and further discussions, knowledge sharing, and innovative solutions across the software engineering discipline.","[{'name': 'Ahmed E. Hassan, Dayi Lin, Gopi Krishnan Rajbahadur, Keheliya Gallaba, Filipe R. Cogo, Boyuan Chen, Haoxiang Zhang, Kishanthan Thangarajah, Gustavo Ansaldi Oliva, Jiahuei Lin, Wali Mohammad Abdullah, Zhen Ming Jiang'}]",
1530,Citation-Enhanced Generation for LLM-based Chatbots,https://arxiv.org/abs/2402.16063,"arXiv:2402.16063v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc Citation-Enhanced Generation (CEG) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-based citation generation module. Once the statements in the generated content lack of reference, our model can regenerate responses until all statements are supported by citations. Note that our method is a training-free plug-and-play plugin that is capable of various LLMs. Experiments on various hallucination-related datasets show our framework outperforms state-of-the-art methods in both hallucination detection and response regeneration on three benchmarks. Our codes and dataset will be publicly available.","[{'name': 'Weitao Li, Junkai Li, Weizhi Ma, Yang Liu'}]",
1531,Improving LLM-based Machine Translation with Systematic Self-Correction,https://arxiv.org/abs/2402.16379,"arXiv:2402.16379v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3) different estimation strategies yield varied impacts on AI feedback, directly affecting the effectiveness of the final corrections. We further compare different LLMs and conduct various experiments involving self-correction and cross-model correction to investigate the potential relationship between the translation and evaluation capabilities of LLMs. Our code and data are available at https://github.com/fzp0424/self_correct_mt","[{'name': 'Zhaopeng Feng, Yan Zhang, Hao Li, Wenqiang Liu, Jun Lang, Yang Feng, Jian Wu, Zuozhu Liu'}]",
1532,LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step,https://arxiv.org/abs/2402.16906,"arXiv:2402.16906v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifically, LDB segments the programs into basic blocks and tracks the values of intermediate variables after each block throughout the runtime execution. This allows LLMs to concentrate on simpler code units within the overall execution flow, verify their correctness against the task description block by block, and efficiently pinpoint any potential errors. Experiments demonstrate that LDB consistently enhances the baseline performance by up to 9.8% across the HumanEval, MBPP, and TransCoder benchmarks, archiving new state-of-the-art performance in code debugging for various LLM selections.","[{'name': 'Li Zhong, Zilong Wang, Jingbo Shang'}]",
1533,When Your AIs Deceive You: Challenges with Partial Observability of Human Evaluators in Reward Learning,https://arxiv.org/abs/2402.17747,"arXiv:2402.17747v2 Announce Type: replace-cross 
Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observable settings and propose research directions to help tackle these challenges.","[{'name': 'Leon Lang, Davis Foote, Stuart Russell, Anca Dragan, Erik Jenner, Scott Emmons'}]",
1534,REPrune: Channel Pruning via Kernel Representative Selection,https://arxiv.org/abs/2402.17862,"arXiv:2402.17862v2 Announce Type: replace-cross 
Abstract: Channel pruning is widely accepted to accelerate modern convolutional neural networks (CNNs). The resulting pruned model benefits from its immediate deployment on general-purpose software and hardware resources. However, its large pruning granularity, specifically at the unit of a convolution filter, often leads to undesirable accuracy drops due to the inflexibility of deciding how and where to introduce sparsity to the CNNs. In this paper, we propose REPrune, a novel channel pruning technique that emulates kernel pruning, fully exploiting the finer but structured granularity. REPrune identifies similar kernels within each channel using agglomerative clustering. Then, it selects filters that maximize the incorporation of kernel representatives while optimizing the maximum cluster coverage problem. By integrating with a simultaneous training-pruning paradigm, REPrune promotes efficient, progressive pruning throughout training CNNs, avoiding the conventional train-prune-finetune sequence. Experimental results highlight that REPrune performs better in computer vision tasks than existing methods, effectively achieving a balance between acceleration ratio and performance retention.","[{'name': 'Mincheol Park, Dongjin Kim, Cheonjun Park, Yuna Park, Gyeong Eun Gong, Won Woo Ro, Suhyun Kim'}]",
1535,Mixer is more than just a model,https://arxiv.org/abs/2402.18007,"arXiv:2402.18007v2 Announce Type: replace-cross 
Abstract: Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example. In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information. Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information. The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of \"mixing\" in the realm of neural network architectures. Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements. This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and frequency domains. Experimental results demonstrate that ASM-RH is particularly well-suited for audio data and yields promising outcomes across multiple classification tasks. The models and optimal weights files will be published.","[{'name': 'Qingfeng Ji, Yuxin Wang, Letong Sun'}]",
1536,Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging,https://arxiv.org/abs/2402.18205,"arXiv:2402.18205v2 Announce Type: replace-cross 
Abstract: Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \\textbf{L}og parsing framework with \\textbf{E}ntropy sampling and Chain-of-Thought \\textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method for large language models (LLMs). LLMs exhibit exceptional semantic comprehension, deftly distinguishing between parameters and invariant tokens. We have conducted experiments on large-scale public datasets. Extensive evaluation demonstrates that Lemur achieves the state-of-the-art performance and impressive efficiency.","[{'name': 'Wei Zhang, Hongcheng Guo, Anjie Le, Jian Yang, Jiaheng Liu, Zhoujun Li, Tieqiao Zheng, Shi Xu, Runqiang Zang, Liangfan Zheng, Bo Zhang'}]",
1537,Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization,https://arxiv.org/abs/2402.18284,"arXiv:2402.18284v2 Announce Type: replace-cross 
Abstract: Wide usage of ChatGPT has highlighted the potential of reinforcement learning from human feedback. However, its training pipeline relies on manual ranking, a resource-intensive process. To reduce labor costs, we propose a self-supervised text ranking approach for applying Proximal-Policy-Optimization to fine-tune language models while eliminating the need for human annotators. Our method begins with probabilistic sampling to encourage a language model to generate diverse responses for each input. We then employ TextRank and ISODATA algorithms to rank and cluster these responses based on their semantics. Subsequently, we construct a reward model to learn the rank and optimize our generative policy. Our experimental results, conducted using two language models on three tasks, demonstrate that the models trained by our method considerably outperform baselines regarding BLEU, GLEU, and METEOR scores. Furthermore, our manual evaluation shows that our ranking results exhibit a remarkably high consistency with that of humans. This research significantly reduces training costs of proximal policy-guided models and demonstrates the potential for self-correction of language models.","[{'name': 'Shuo Yang, Gjergji Kasneci'}]",
1538,Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review,https://arxiv.org/abs/2402.18590,"arXiv:2402.18590v2 Announce Type: replace-cross 
Abstract: The paper underscores the significance of Large Language Models (LLMs) in reshaping recommender systems, attributing their value to unique reasoning abilities absent in traditional recommenders. Unlike conventional systems lacking direct user interaction data, LLMs exhibit exceptional proficiency in recommending items, showcasing their adeptness in comprehending intricacies of language. This marks a fundamental paradigm shift in the realm of recommendations. Amidst the dynamic research landscape, researchers actively harness the language comprehension and generation capabilities of LLMs to redefine the foundations of recommendation tasks. The investigation thoroughly explores the inherent strengths of LLMs within recommendation frameworks, encompassing nuanced contextual comprehension, seamless transitions across diverse domains, adoption of unified approaches, holistic learning strategies leveraging shared data reservoirs, transparent decision-making, and iterative improvements. Despite their transformative potential, challenges persist, including sensitivity to input prompts, occasional misinterpretations, and unforeseen recommendations, necessitating continuous refinement and evolution in LLM-driven recommender systems.","[{'name': 'Arpita Vats, Vinija Jain, Rahul Raja, Aman Chadha'}]",
1539,Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective,https://arxiv.org/abs/2402.18607,"arXiv:2402.18607v2 Announce Type: replace-cross 
Abstract: Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.
  In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execute fairness poisoning attacks to undermine the receiver's downstream models by manipulating the training data distribution of the diffusion model. Meanwhile, the receiver can perform property inference attacks to reveal the distribution of sensitive features in the sharer's dataset. Our experiments conducted on real-world datasets demonstrate remarkable attack performance on different types of diffusion models, which highlights the critical importance of robust data auditing and privacy protection protocols in pertinent applications.","[{'name': 'Xinjian Luo, Yangfan Jiang, Fei Wei, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi'}]",
1540,Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation,https://arxiv.org/abs/2402.18920,"arXiv:2402.18920v2 Announce Type: replace-cross 
Abstract: Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both pose-dominant and shape-dominant deformations. Using different challenging datasets, we demonstrate that our method outperforms previous state-of-the-art methods for both shape matching and interpolation, even compared to supervised approaches.","[{'name': 'Dongliang Cao, Marvin Eisenberger, Nafie El Amrani, Daniel Cremers, Florian Bernard'}]",
1541,How to Understand \"Support\"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding,https://arxiv.org/abs/2402.19116,"arXiv:2402.19116v2 Announce Type: replace-cross 
Abstract: Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep multimodal semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and counterfactual techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting finding that IECI outperforms the advanced multimodal LLMs by a large margin on this implicit-enhanced dataset, which may facilitate more research to evaluate the multimodal LLMs in this direction.","[{'name': 'Jiamin Luo, Jianing Zhao, Jingjing Wang, Guodong Zhou'}]",
1542,On the Scaling Laws of Geographical Representation in Language Models,https://arxiv.org/abs/2402.19406,"arXiv:2402.19406v2 Announce Type: replace-cross 
Abstract: Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.","[{'name': \"Nathan Godey, \\\\'Eric de la Clergerie, Beno\\\\^it Sagot\"}]",
1543,"ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models",https://arxiv.org/abs/2403.00510,"arXiv:2403.00510v2 Announce Type: replace-cross 
Abstract: Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and variance, just to name a few.","[{'name': 'Bo Li, Qinghua Zhao, Lijie Wen'}]",
1544,Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks,https://arxiv.org/abs/2403.00692,"arXiv:2403.00692v2 Announce Type: replace-cross 
Abstract: The upcoming landscape of Earth Observation missions will defined by networked heterogeneous nanosatellite constellations required to meet strict mission requirements, such as revisit times and spatial resolution. However, scheduling satellite communications in these satellite networks through efficiently creating a global satellite Contact Plan (CP) is a complex task, with current solutions requiring ground-based coordination or being limited by onboard computational resources. The paper proposes a novel approach to overcome these challenges by modeling the constellations and CP as dynamic networks and employing graph-based techniques. The proposed method utilizes a state-of-the-art dynamic graph neural network to evaluate the performance of a given CP and update it using a heuristic algorithm based on simulated annealing. The trained neural network can predict the network delay with a mean absolute error of 3.6 minutes. Simulation results show that the proposed method can successfully design a contact plan for large satellite networks, improving the delay by 29.1%, similar to a traditional approach, while performing the objective evaluations 20x faster.","[{'name': 'Guillem Casadesus-Vila, Joan-Adria Ruiz-de-Azua, Eduard Alarcon'}]",
1545,On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs,https://arxiv.org/abs/2403.00783,"arXiv:2403.00783v1 Announce Type: new 
Abstract: Plan synthesis aims to generate a course of actions or policies to transit given initial states to goal states, provided domain models that could be designed by experts or learnt from training data or interactions with the world. Intrigued by the claims of emergent planning capabilities in large language models (LLMs), works have been proposed to investigate the planning effectiveness of LLMs, without considering any utilization of off-the-shelf planning techniques in LLMs. In this paper, we aim to further study the insight of the planning capability of LLMs by investigating the roles of LLMs in off-the-shelf planning frameworks. To do this, we investigate the effectiveness of embedding LLMs into one of the well-known planning frameworks, graph-based planning, proposing a novel LLMs-based planning framework with LLMs embedded in two levels of planning graphs, i.e., mutual constraints generation level and constraints solving level. We empirically exhibit the effectiveness of our proposed framework in various planning domains.","[{'name': 'Hankz Hankui Zhuo, Xin Chen, Rong Pan'}]",
1546,A New Dynamic Distributed Planning Approach: Application to DPDP Problems,https://arxiv.org/abs/2403.00805,"arXiv:2403.00805v1 Announce Type: new 
Abstract: In this work, we proposed a new dynamic distributed planning approach that is able to take into account the changes that the agent introduces on his set of actions to be planned in order to take into account the changes that occur in his environment. Our approach fits into the context of distributed planning for distributed plans where each agent can produce its own plans. According to our approach the generation of the plans is based on the satisfaction of the constraints by the use of the genetic algorithms. Our approach is to generate, a new plan by each agent, whenever there is a change in its set of actions to plan. This in order to take into account the new actions introduced in its new plan. In this new plan, the agent takes, each time, as a new action set to plan all the old un-executed actions of the old plan and the new actions engendered by the changes and as a new initial state; the state in which the set of actions of the agent undergoes a change. In our work, we used a concrete case to illustrate and demonstrate the utility of our approach.",[{'name': 'Zakaria Tolba'}],
1547,Bootstrapping Cognitive Agents with a Large Language Model,https://arxiv.org/abs/2403.00810,"arXiv:2403.00810v1 Announce Type: new 
Abstract: Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. On the other hand cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent based entirely on large language models. Our experiments indicate that large language models are a good source of information for cognitive architectures, and the cognitive architecture in turn can verify and update the knowledge of large language models to a specific domain.","[{'name': 'Feiyu Zhu, Reid Simmons'}]",
1548,Cognitive Bias in High-Stakes Decision-Making with LLMs,https://arxiv.org/abs/2403.00811,"arXiv:2403.00811v1 Announce Type: new 
Abstract: Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across different commercial and open-source models. We demonstrate that our self-help debiasing effectively mitigate cognitive bias without having to manually craft examples for each bias type.","[{'name': 'Jessica Echterhoff, Yao Liu, Abeer Alessa, Julian McAuley, Zexue He'}]",
1549,Adapting to Teammates in a Cooperative Language Game,https://arxiv.org/abs/2403.00823,"arXiv:2403.00823v1 Announce Type: new 
Abstract: The game of Codenames has recently emerged as a domain of interest for intelligent agent design. The game is unique due to the way that language and coordination between teammates play important roles. Previous approaches to designing agents for this game have utilized a single internal language model to determine action choices. This often leads to good performance with some teammates and inferior performance with other teammates, as the agent cannot adapt to any specific teammate. In this paper we present the first adaptive agent for playing Codenames. We adopt an ensemble approach with the goal of determining, during the course of interacting with a specific teammate, which of our internal expert agents, each potentially with its own language model, is the best match. One difficulty faced in this approach is the lack of a single numerical metric that accurately captures the performance of a Codenames team. Prior Codenames research has utilized a handful of different metrics to evaluate agent teams. We propose a novel single metric to evaluate the performance of a Codenames team, whether playing a single team (solitaire) game, or a competitive game against another team. We then present and analyze an ensemble agent which selects an internal expert on each turn in order to maximize this proposed metric. Experimental analysis shows that this ensemble approach adapts to individual teammates and often performs nearly as well as the best internal expert with a teammate. Crucially, this success does not depend on any previous knowledge about the teammates, the ensemble agents, or their compatibility. This research represents an important step to making language-based agents for cooperative language settings like Codenames more adaptable to individual teammates.","[{'name': 'Christopher Archibald, Spencer Brosnahan'}]",
1550,TroubleLLM: Align to Red Team Expert,https://arxiv.org/abs/2403.00829,"arXiv:2403.00829v1 Announce Type: new 
Abstract: Large Language Models (LLMs) become the start-of-the-art solutions for a variety of natural language tasks and are integrated into real-world applications. However, LLMs can be potentially harmful in manifesting undesirable safety issues like social biases and toxic content. It is imperative to assess its safety issues before deployment. However, the quality and diversity of test prompts generated by existing methods are still far from satisfactory. Not only are these methods labor-intensive and require large budget costs, but the controllability of test prompt generation is lacking for the specific testing domain of LLM applications. With the idea of LLM for LLM testing, we propose the first LLM, called TroubleLLM, to generate controllable test prompts on LLM safety issues. Extensive experiments and human evaluation illustrate the superiority of TroubleLLM on generation quality and generation controllability.","[{'name': 'Zhuoer Xu, Jianping Zhang, Shiwen Cui, Changhua Meng, Weiqiang Wang'}]",
1551,MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices,https://arxiv.org/abs/2403.00830,"arXiv:2403.00830v1 Announce Type: new 
Abstract: Large language models (LLMs) are revolutionizing various domains with their remarkable natural language processing (NLP) abilities. However, deploying LLMs in resource-constrained edge computing and embedded systems presents significant challenges. Another challenge lies in delivering medical assistance in remote areas with limited healthcare facilities and infrastructure. To address this, we introduce MedAide, an on-premise healthcare chatbot. It leverages tiny-LLMs integrated with LangChain, providing efficient edge-based preliminary medical diagnostics and support. MedAide employs model optimizations for minimal memory footprint and latency on embedded edge devices without server infrastructure. The training process is optimized using low-rank adaptation (LoRA). Additionally, the model is trained on diverse medical datasets, employing reinforcement learning from human feedback (RLHF) to enhance its domain-specific capabilities. The system is implemented on various consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\\% accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an energy-efficient healthcare assistance platform that alleviates privacy concerns due to edge-based deployment, thereby empowering the community.","[{'name': 'Abdul Basit, Khizar Hussain, Muhammad Abdullah Hanif, Muhammad Shafique'}]",
1552,Position Paper: Agent AI Towards a Holistic Intelligence,https://arxiv.org/abs/2403.00833,"arXiv:2403.00833v1 Announce Type: new 
Abstract: Recent advancements in large foundation models have remarkably enhanced our understanding of sensory information in open-world environments. In leveraging the power of foundation models, it is crucial for AI research to pivot away from excessive reductionism and toward an emphasis on systems that function as cohesive wholes. Specifically, we emphasize developing Agent AI -- an embodied system that integrates large foundation models into agent actions. The emerging field of Agent AI spans a wide range of existing embodied and agent-based multimodal interactions, including robotics, gaming, and healthcare systems, etc. In this paper, we propose a novel large action model to achieve embodied intelligent behavior, the Agent Foundation Model. On top of this idea, we discuss how agent AI exhibits remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Furthermore, we discuss the potential of Agent AI from an interdisciplinary perspective, underscoring AI cognition and consciousness within scientific discourse. We believe that those discussions serve as a basis for future research directions and encourage broader societal engagement.","[{'name': 'Qiuyuan Huang, Naoki Wake, Bidipta Sarkar, Zane Durante, Ran Gong, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Noboru Kuno, Ade Famoti, Ashley Llorens, John Langford, Hoi Vo, Li Fei-Fei, Katsu Ikeuchi, Jianfeng Gao'}]",
1553,ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph,https://arxiv.org/abs/2403.00839,"arXiv:2403.00839v1 Announce Type: new 
Abstract: While achieving remarkable progress in a broad range of tasks, large language models (LLMs) remain significantly limited in properly using massive external tools. Existing in-context learning approaches simply format tools into a list of plain text descriptions and input them to LLMs, from which, LLMs generate a sequence of tool calls to solve problems step by step. Such a paradigm ignores the intrinsic dependency between tools and offloads all reasoning loads to LLMs, making them restricted to a limited number of specifically designed tools. It thus remains challenging for LLMs to operate on a library of massive tools, casting a great limitation when confronted with real-world scenarios. This paper proposes ToolNet, a plug-and-play framework that scales up the number of tools to thousands with a moderate increase in token consumption. ToolNet organizes tools into a directed graph. Each node represents a tool, and weighted edges denote tool transition. Starting from an initial tool node, an LLM navigates in the graph by iteratively choosing the next one from its successors until the task is resolved. Extensive experiments show that ToolNet can achieve impressive results in challenging multi-hop tool learning datasets and is resilient to tool failures.","[{'name': 'Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang, Yuchen Liu, Dongkuan Xu'}]",
1554,Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning,https://arxiv.org/abs/2403.00854,"arXiv:2403.00854v1 Announce Type: new 
Abstract: Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of dysarthric speech. We evaluated on the Universal Access Speech dataset using leave-one-speaker-out cross-validation, our model demonstrated superior performance over traditional machine learning approaches, with an accuracy of $70.48\\%$ and an F1 score of $59.23\\%$. Our SALR model also exceeded the previous benchmark for AI-based classification, which used support vector machines, by $16.58\\%$. We open the black box of our model by visualising the latent space where we can observe how the model substantially reduces speaker-specific cues and amplifies task-specific ones, thereby showing its robustness. In conclusion, SALR establishes a new benchmark in speaker-independent multi-class dysarthria severity classification using generative AI. The potential implications of our findings for broader clinical applications in automated dysarthria severity assessments.","[{'name': 'Lauren Stumpf, Balasundaram Kadirvelu, Sigourney Waibel, A. Aldo Faisal'}]",
1555,Team Formation amidst Conflicts,https://arxiv.org/abs/2403.00859,"arXiv:2403.00859v1 Announce Type: new 
Abstract: In this work, we formulate the problem of team formation amidst conflicts. The goal is to assign individuals to tasks, with given capacities, taking into account individuals' task preferences and the conflicts between them. Using dependent rounding schemes as our main toolbox, we provide efficient approximation algorithms. Our framework is extremely versatile and can model many different real-world scenarios as they arise in educational settings and human-resource management. We test and deploy our algorithms on real-world datasets and we show that our algorithms find assignments that are better than those found by natural baselines. In the educational setting we also show how our assignments are far better than those done manually by human experts. In the human resource management application we show how our assignments increase the diversity of teams. Finally, using a synthetic dataset we demonstrate that our algorithms scale very well in practice.","[{'name': 'Iasonas Nikolaou, Evimaria Terzi'}]",
1556,"Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights",https://arxiv.org/abs/2403.00861,"arXiv:2403.00861v1 Announce Type: new 
Abstract: Generative AI applications, such as ChatGPT or DALL-E, have shown the world their impressive capabilities in generating human-like text or image. Diving deeper, the science stakeholder for those AI applications are Deep Generative Models, a.k.a DGMs, which are designed to learn the underlying distribution of the data and generate new data points that are statistically similar to the original dataset. One critical question is raised: how can we leverage DGMs into morden retail supply chain realm? To address this question, this paper expects to provide a comprehensive review of DGMs and discuss their existing and potential usecases in retail supply chain, by (1) providing a taxonomy and overview of state-of-the-art DGMs and their variants, (2) reviewing existing DGM applications in retail supply chain from a end-to-end view of point, and (3) discussing insights and potential directions on how DGMs can be further utilized on solving retail supply chain problems.","[{'name': 'Yuan Wang, Lokesh Kumar Sambasivan, Mingang Fu, Prakhar Mehrotra'}]",
1557,The Algorithm Configuration Problem,https://arxiv.org/abs/2403.00898,"arXiv:2403.00898v1 Announce Type: new 
Abstract: The field of algorithmic optimization has significantly advanced with the development of methods for the automatic configuration of algorithmic parameters. This article delves into the Algorithm Configuration Problem, focused on optimizing parametrized algorithms for solving specific instances of decision/optimization problems. We present a comprehensive framework that not only formalizes the Algorithm Configuration Problem, but also outlines different approaches for its resolution, leveraging machine learning models and heuristic strategies. The article categorizes existing methodologies into per-instance and per-problem approaches, distinguishing between offline and online strategies for model construction and deployment. By synthesizing these approaches, we aim to provide a clear pathway for both understanding and addressing the complexities inherent in algorithm configuration.","[{'name': \"Gabriele Iommazzo, Claudia D'Ambrosio, Antonio Frangioni, Leo Liberti\"}]",
1558,History-dependence shapes causal inference of brain-behaviour relationships,https://arxiv.org/abs/2403.00947,"arXiv:2403.00947v1 Announce Type: new 
Abstract: Behavioural and neural time series are often correlated with the past. This history-dependence may represent a fundamental property of the measured variables, or may arise from how confounding variables change over time. Here we argue that undecidability about the ground-truth of history-dependence is a general computational property of systems that exchange information with its environment, and show that the resulting uncertainty has a direct impact on causal inference. We first argue that uncertainty in the ground truth of history-dependence is an inherent property of open systems that cannot be explicitly falsified. Simple model systems are then simulated to show how different assumptions about history-dependence can lead to spurious correlations and statistical properties of data distributions that are typically unaccounted for. We then consider this problem from an interventionist perspective, showing that interventions can only be guaranteed to remedy the spurious correlation problem when the latent dynamics between the intervention and measured processes are known a priori, and the effect of the intervention is invariant at the chosen level of analysis. We conclude that uncertainty about history-dependence is a fundamental property of the study of neural systems, and in light of this discuss how causality should be assessed in neuroscience.","[{'name': 'Brandon Caie, Gunnar Blohm'}]",
1559,An internal sensory model allows for balance control based on non-actionable proprioceptive feedback,https://arxiv.org/abs/2403.00951,"arXiv:2403.00951v1 Announce Type: new 
Abstract: All motor tasks with a mechanical system (a human body, a rider on a bicycle) that is approximately linear in the part of the state space where it stays most of the time (e.g., upright balance control) have the following property: actionable sensory feedback allows for optimal control actions that are a simple linear combination of the sensory feedback. When only non-actionable sensory feedback is available, optimal control for these approximately linear mechanical systems is based on an internal dynamical system that estimates the states, and that can be implemented as a recurrent neural network (RNN). It uses a sensory model to update the state estimates with the non-actionable sensory feedback, and the weights of this RNN are fully specified by results from optimal feedback control. This is highly relevant for muscle spindle afferent firing rates which, under perfectly coordinated fusimotor and skeletomotor control, scale with the exafferent joint acceleration component. The resulting control mechanism balances a standing body and a rider-bicycle combination using realistic parameter values and with forcing torques that are feasible for humans.",[{'name': 'Eric Maris'}],
1560,Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using Counterfactuals As Guides?,https://arxiv.org/abs/2403.00980,"arXiv:2403.00980v1 Announce Type: new 
Abstract: Recently, counterfactuals using \"if-only\" explanations have become very popular in eXplainable AI (XAI), as they describe which changes to feature-inputs of a black-box AI system result in changes to a (usually negative) decision-outcome. Even more recently, semi-factuals using \"even-if\" explanations have gained more attention. They elucidate the feature-input changes that do \\textit{not} change the decision-outcome of the AI system, with a potential to suggest more beneficial recourses. Some semi-factual methods use counterfactuals to the query-instance to guide semi-factual production (so-called counterfactual-guided methods), whereas others do not (so-called counterfactual-free methods). In this work, we perform comprehensive tests of 8 semi-factual methods on 7 datasets using 5 key metrics, to determine whether counterfactual guidance is necessary to find the best semi-factuals. The results of these tests suggests not, but rather that computing other aspects of the decision space lead to better semi-factual XAI.","[{'name': 'Saugat Aryal, Mark T. Keane'}]",
1561,The Case for Animal-Friendly AI,https://arxiv.org/abs/2403.01199,"arXiv:2403.01199v1 Announce Type: new 
Abstract: Artificial intelligence is seen as increasingly important, and potentially profoundly so, but the fields of AI ethics and AI engineering have not fully recognized that these technologies, including large language models (LLMs), will have massive impacts on animals. We argue that this impact matters, because animals matter morally.
  As a first experiment in evaluating animal consideration in LLMs, we constructed a proof-of-concept Evaluation System, which assesses LLM responses and biases from multiple perspectives. This system evaluates LLM outputs by two criteria: their truthfulness, and the degree of consideration they give to the interests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using a set of structured queries and predefined normative perspectives. Preliminary results suggest that the outcomes of the tested models can be benchmarked regarding the consideration they give to animals, and that generated positions and biases might be addressed and mitigated with more developed and validated systems.
  Our research contributes one possible approach to integrating animal ethics in AI, opening pathways for future studies and practical applications in various fields, including education, public policy, and regulation, that involve or relate to animals and society. Overall, this study serves as a step towards more useful and responsible AI systems that better recognize and respect the vital interests and perspectives of all sentient beings.","[{'name': 'Sankalpa Ghose, Yip Fai Tse, Kasra Rasaee, Jeff Sebo, Peter Singer'}]",
1562,Soft Reasoning on Uncertain Knowledge Graphs,https://arxiv.org/abs/2403.01508,"arXiv:2403.01508v1 Announce Type: new 
Abstract: The study of machine learning-based logical query-answering enables reasoning with large-scale and incomplete knowledge graphs. This paper further advances this line of research by considering the uncertainty in the knowledge. The uncertain nature of knowledge is widely observed in the real world, but \\textit{does not} align seamlessly with the first-order logic underpinning existing studies. To bridge this gap, we study the setting of soft queries on uncertain knowledge, which is motivated by the establishment of soft constraint programming. We further propose an ML-based approach with both forward inference and backward calibration to answer soft queries on large-scale, incomplete, and uncertain knowledge graphs. Theoretical discussions present that our methods share the same complexity as state-of-the-art inference algorithms for first-order queries. Empirical results justify the superior performance of our approach against previous ML-based methods with number embedding extensions.","[{'name': 'Weizhi Fei, Zihao Wang, Hang Yin, Yang Duan, Hanghang Tong, Yangqiu Song'}]",
1563,How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems,https://arxiv.org/abs/2403.01757,"arXiv:2403.01757v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through extensive empirical studies focused on a well-known combinatorial optimization problem, i.e., capacitated vehicle routing problem. The results are compared against those obtained from the LLM-based optimization algorithms that rely solely on textual prompts, demonstrating the significant advantages of our multimodal approach.","[{'name': 'Yuxiao Huang, Wenjie Zhang, Liang Feng, Xingyu Wu, Kay Chen Tan'}]",
1564,CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text,https://arxiv.org/abs/2403.01784,"arXiv:2403.01784v1 Announce Type: new 
Abstract: Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. Evaluation based on such $\\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems. However, in this context, current evaluation methods are either limited in task coverage or lack standardization. To address this issue, we propose using category theory as a framework for evaluation. Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. We present an automatic evaluation framework called $\\textbf{CatCode}$ ($\\textbf{Cat}$egory $\\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, Text-Davinci, and CodeGeeX.","[{'name': 'Zhenru Lin, Yiqun Yao, Yang Yuan'}]",
1565,SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for Adaptive Real-Time Subtask Recognition,https://arxiv.org/abs/2403.01816,"arXiv:2403.01816v1 Announce Type: new 
Abstract: Instead of making behavioral decisions directly from the exponentially expanding joint observational-action space, subtask-based multi-agent reinforcement learning (MARL) methods enable agents to learn how to tackle different subtasks. Most existing subtask-based MARL methods are based on hierarchical reinforcement learning (HRL). However, these approaches often limit the number of subtasks, perform subtask recognition periodically, and can only identify and execute a specific subtask within the predefined fixed time period, which makes them inflexible and not suitable for diverse and dynamic scenarios with constantly changing subtasks. To break through above restrictions, a \\textbf{S}liding \\textbf{M}ultidimensional t\\textbf{A}sk window based m\\textbf{U}ti-agent reinforcement learnin\\textbf{G} framework (SMAUG) is proposed for adaptive real-time subtask recognition. It leverages a sliding multidimensional task window to extract essential information of subtasks from trajectory segments concatenated based on observed and predicted trajectories in varying lengths. An inference network is designed to iteratively predict future trajectories with the subtask-oriented policy network. Furthermore, intrinsic motivation rewards are defined to promote subtask exploration and behavior diversity. SMAUG can be integrated with any Q-learning-based approach. Experiments on StarCraft II show that SMAUG not only demonstrates performance superiority in comparison with all baselines but also presents a more prominent and swift rise in rewards during the initial training stage.","[{'name': 'Wenjing Zhang, Wei Zhang'}]",
1566,Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism,https://arxiv.org/abs/2403.01832,"arXiv:2403.01832v1 Announce Type: new 
Abstract: This paper delves into the contrasting roles of data within academic and industrial spheres, highlighting the divergence between Data-Centric AI and Model-Agnostic AI approaches. We argue that while Data-Centric AI focuses on the primacy of high-quality data for model performance, Model-Agnostic AI prioritizes algorithmic flexibility, often at the expense of data quality considerations. This distinction reveals that academic standards for data quality frequently do not meet the rigorous demands of industrial applications, leading to potential pitfalls in deploying academic models in real-world settings. Through a comprehensive analysis, we address these disparities, presenting both the challenges they pose and strategies for bridging the gap. Furthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which aims to reconcile these differences by integrating model considerations into data optimization processes. This approach underscores the necessity for evolving data requirements that are sensitive to the nuances of both academic research and industrial deployment. By exploring these discrepancies, we aim to foster a more nuanced understanding of data's role in AI development and encourage a convergence of academic and industrial standards to enhance AI's real-world applicability.","[{'name': 'Chanjun Park, Minsoo Khang, Dahyun Kim'}]",
1567,Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost Benchmarks,https://arxiv.org/abs/2403.01888,"arXiv:2403.01888v1 Announce Type: new 
Abstract: While deep learning has celebrated many successes, its results often hinge on the meticulous selection of hyperparameters (HPs). However, the time-consuming nature of deep learning training makes HP optimization (HPO) a costly endeavor, slowing down the development of efficient HPO tools. While zero-cost benchmarks, which provide performance and runtime without actual training, offer a solution for non-parallel setups, they fall short in parallel setups as each worker must communicate its queried runtime to return its evaluation in the exact order. This work addresses this challenge by introducing a user-friendly Python package that facilitates efficient parallel HPO with zero-cost benchmarks. Our approach calculates the exact return order based on the information stored in file system, eliminating the need for long waiting times and enabling much faster HPO evaluations. We first verify the correctness of our approach through extensive testing and the experiments with 6 popular HPO libraries show its applicability to diverse libraries and its ability to achieve over 1000x speedup compared to a traditional approach. Our package can be installed via pip install mfhpo-simulator.","[{'name': 'Shuhei Watanabe, Neeratyoy Mallik, Edward Bergman, Frank Hutter'}]",
1568,A Scoping Review of Energy-Efficient Driving Behaviors and Applied State-of-the-Art AI Methods,https://arxiv.org/abs/2403.02053,"arXiv:2403.02053v1 Announce Type: new 
Abstract: The transportation sector remains a major contributor to greenhouse gas emissions. The understanding of energy-efficient driving behaviors and utilization of energy-efficient driving strategies are essential to reduce vehicles' fuel consumption. However, there is no comprehensive investigation into energy-efficient driving behaviors and strategies. Furthermore, many state-of-the-art AI models have been applied for the analysis of eco-friendly driving styles, but no overview is available. To fill the gap, this paper conducts a thorough literature review on ecological driving behaviors and styles and analyzes the driving factors influencing energy consumption and state-of-the-art methodologies. With a thorough scoping review process, the methodological and related data are compared. The results show that the factors that impact driving behaviors can be summarized into eleven features including speed, acceleration, deceleration, pedal, and so on. This paper finds that supervised/unsupervised learning algorithms and reinforcement learning frameworks have been popularly used to model the vehicle's energy consumption with multi-dimensional data. Furthermore, the literature shows that the driving data are collected from either simulators or real-world experiments, and the real-world data are mainly stored and transmitted by meters, controller area networks, onboard data services, smartphones, and additional sensors installed in the vehicle. Based on driving behavior factors, driver characteristics, and safety rules, this paper recommends nine energy-efficient driving styles including four guidelines for the drivers' selection and adjustment of the vehicle parameters, three recommendations for the energy-efficient driving styles in different driving scenarios, and two subjective suggestions for different types of drivers and employers.","[{'name': 'Zhipeng Ma, Bo N{\\\\o}rregaard J{\\\\o}rgensen, Zheng Ma'}]",
1569,Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism,https://arxiv.org/abs/2403.02054,"arXiv:2403.02054v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers from LLMs and discuss method limitations and potential research directions.","[{'name': 'Shuvayan Brahmachary, Subodh M. Joshi, Aniruddha Panda, Kaushik Koneripalli, Arun Kumar Sagotra, Harshil Patel, Ankush Sharma, Ameya D. Jagtap, Kaushic Kalyanaraman'}]",
1570,Cognition is All You Need - The Next Layer of AI Above Large Language Models,https://arxiv.org/abs/2403.02164,"arXiv:2403.02164v1 Announce Type: new 
Abstract: Recent studies of the applications of conversational AI tools, such as chatbots powered by large language models, to complex real-world knowledge work have shown limitations related to reasoning and multi-step problem solving. Specifically, while existing chatbots simulate shallow reasoning and understanding they are prone to errors as problem complexity increases. The failure of these systems to address complex knowledge work is due to the fact that they do not perform any actual cognition. In this position paper, we present Cognitive AI, a higher-level framework for implementing programmatically defined neuro-symbolic cognition above and outside of large language models. Specifically, we propose a dual-layer functional architecture for Cognitive AI that serves as a roadmap for AI systems that can perform complex multi-step knowledge work. We propose that Cognitive AI is a necessary precursor for the evolution of higher forms of AI, such as AGI, and specifically claim that AGI cannot be achieved by probabilistic approaches on their own. We conclude with a discussion of the implications for large language models, adoption cycles in AI, and commercial Cognitive AI development.","[{'name': 'Nova Spivack, Sam Douglas, Michelle Crames, Tim Connors'}]",
1571,Koopman-Assisted Reinforcement Learning,https://arxiv.org/abs/2403.02290,"arXiv:2403.02290v1 Announce Type: new 
Abstract: The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman (HJB) equation, are ubiquitous in reinforcement learning (RL) and control theory. However, these equations quickly become intractable for systems with high-dimensional states and nonlinearity. This paper explores the connection between the data-driven Koopman operator and Markov Decision Processes (MDPs), resulting in the development of two new RL algorithms to address these limitations. We leverage Koopman operator techniques to lift a nonlinear system into new coordinates where the dynamics become approximately linear, and where HJB-based methods are more tractable. In particular, the Koopman operator is able to capture the expectation of the time evolution of the value function of a given system via linear dynamics in the lifted coordinates. By parameterizing the Koopman operator with the control actions, we construct a ``Koopman tensor'' that facilitates the estimation of the optimal value function. Then, a transformation of Bellman's framework in terms of the Koopman tensor enables us to reformulate two max-entropy RL algorithms: soft value iteration and soft actor-critic (SAC). This highly flexible framework can be used for deterministic or stochastic systems as well as for discrete or continuous-time dynamics. Finally, we show that these Koopman Assisted Reinforcement Learning (KARL) algorithms attain state-of-the-art (SOTA) performance with respect to traditional neural network-based SAC and linear quadratic regulator (LQR) baselines on four controlled dynamical systems: a linear state-space system, the Lorenz system, fluid flow past a cylinder, and a double-well potential with non-isotropic stochastic forcing.","[{'name': 'Preston Rozwood, Edward Mehrez, Ludger Paehler, Wen Sun, Steven L. Brunton'}]",
1572,An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots,https://arxiv.org/abs/2403.00765,"arXiv:2403.00765v1 Announce Type: cross 
Abstract: As data science applications gain adoption across industries, the tooling landscape matures to facilitate the life cycle of such applications and provide solutions to the challenges involved to boost the productivity of the people involved. Reinforcement learning with agents in a 3D world could still face challenges: the knowledge required to use a simulation software as well as the utilization of a standalone simulation software in unattended training pipelines.
  In this paper we review tools and approaches to train reinforcement learning agents for robots in 3D worlds with respect to the robot Robotino and argue that the separation of the simulation environment for creators of virtual worlds and the model development environment for data scientists is not a well covered topic. Often both are the same and data scientists require knowledge of the simulation software to work directly with their APIs. Moreover, sometimes creators of virtual worlds and data scientists even work on the same files. We want to contribute to that topic by describing an approach where data scientists don't require knowledge about the simulation software. Our approach uses the standalone simulation software Webots, the Robot Operating System to communicate with simulated robots as well as the simulation software itself and container technology to separate the simulation from the model development environment. We put emphasize on the APIs the data scientists work with and the use of a standalone simulation software in unattended training pipelines. We show the parts that are specific to the Robotino and the robot task to learn.","[{'name': 'Tobias Haubold, Petra Linke'}]",
1573,Do Weibo platform experts perform better at predicting stock market?,https://arxiv.org/abs/2403.00772,"arXiv:2403.00772v1 Announce Type: cross 
Abstract: Sentiment analysis can be used for stock market prediction. However, existing research has not studied the impact of a user's financial background on sentiment-based forecasting of the stock market using artificial neural networks. In this work, a novel combination of neural networks is used for the assessment of sentiment-based stock market prediction, based on the financial background of the population that generated the sentiment. The state-of-the-art language processing model Bidirectional Encoder Representations from Transformers (BERT) is used to classify the sentiment and a Long-Short Term Memory (LSTM) model is used for time-series based stock market prediction. For evaluation, the Weibo social networking platform is used as a sentiment data collection source. Weibo users (and their comments respectively) are divided into Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor (UFA) groups according to their background information, as collected by Weibo. The Hong Kong Hang Seng index is used to extract historical stock market change data. The results indicate that stock market prediction learned from the AFA group users is 39.67% more precise than that learned from the UFA group users and shows the highest accuracy (87%) when compared to existing approaches.","[{'name': 'Ziyuan Ma, Conor Ryan, Jim Buckley, Muslim Chochlov'}]",
1574,Empirical and Experimental Insights into Data Mining Techniques for Crime Prediction: A Comprehensive Survey,https://arxiv.org/abs/2403.00780,"arXiv:2403.00780v1 Announce Type: cross 
Abstract: This survey paper presents a comprehensive analysis of crime prediction methodologies, exploring the various techniques and technologies utilized in this area. The paper covers the statistical methods, machine learning algorithms, and deep learning techniques employed to analyze crime data, while also examining their effectiveness and limitations. We propose a methodological taxonomy that classifies crime prediction algorithms into specific techniques. This taxonomy is structured into four tiers, including methodology category, methodology sub-category, methodology techniques, and methodology sub-techniques. Empirical and experimental evaluations are provided to rank the different techniques. The empirical evaluation assesses the crime prediction techniques based on four criteria, while the experimental evaluation ranks the algorithms that employ the same sub-technique, the different sub-techniques that employ the same technique, the different techniques that employ the same methodology sub-category, the different methodology sub-categories within the same category, and the different methodology categories. The combination of methodological taxonomy, empirical evaluations, and experimental comparisons allows for a nuanced and comprehensive understanding of crime prediction algorithms, aiding researchers in making informed decisions. Finally, the paper provides a glimpse into the future of crime prediction techniques, highlighting potential advancements and opportunities for further research in this field",[{'name': 'Kamal Taha'}],
1575,ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework,https://arxiv.org/abs/2403.00781,"arXiv:2403.00781v1 Announce Type: cross 
Abstract: The profound impact of food on health necessitates advanced nutrition-oriented food recommendation services. Conventional methods often lack the crucial elements of personalization, explainability, and interactivity. While Large Language Models (LLMs) bring interpretability and explainability, their standalone use falls short of achieving true personalization. In this paper, we introduce ChatDiet, a novel LLM-powered framework designed specifically for personalized nutrition-oriented food recommendation chatbots. ChatDiet integrates personal and population models, complemented by an orchestrator, to seamlessly retrieve and process pertinent information. The result is a dynamic delivery of personalized and explainable food recommendations, tailored to individual user preferences. Our evaluation of ChatDiet includes a compelling case study, where we establish a causal personal model to estimate individual nutrition effects. Our assessments, including a food recommendation test showcasing a 92\\% effectiveness rate, coupled with illustrative dialogue examples, underscore ChatDiet's strengths in explainability, personalization, and interactivity.","[{'name': 'Zhongqi Yang, Elahe Khatibi, Nitish Nagesh, Mahyar Abbasian, Iman Azimi, Ramesh Jain, Amir M. Rahmani'}]",
1576,Ploutos: Towards interpretable stock movement prediction with financial large language model,https://arxiv.org/abs/2403.00782,"arXiv:2403.00782v1 Announce Type: cross 
Abstract: Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverage rearview-mirror prompting mechanism to guide GPT-4 to generate rationales, and a dynamic token weighting mechanism to finetune LLM by increasing key tokens weight. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and interpretability.","[{'name': 'Hanshuang Tong, Jun Li, Ning Wu, Ming Gong, Dongmei Zhang, Qi Zhang'}]",
1577,"Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges",https://arxiv.org/abs/2403.00784,"arXiv:2403.00784v1 Announce Type: cross 
Abstract: Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. A key highlight of our survey is the comparison between BERT's encoder-based models and the latest generative Large Language Models (LLMs), such as ChatGPT, which rely on decoders. Despite the popularity of LLMs, we find that for specific tasks, finely tuned BERT encoders still outperform, and at a lower deployment cost. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.","[{'name': 'Jiajia Wang, Jimmy X. Huang, Xinhui Tu, Junmei Wang, Angela J. Huang, Md Tahmid Rahman Laskar, Amran Bhuiyan'}]",
1578,"PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care",https://arxiv.org/abs/2403.00788,"arXiv:2403.00788v1 Announce Type: cross 
Abstract: This study introduces and evaluates the PRECISE framework, utilizing OpenAI's GPT-4 to enhance patient engagement by providing clearer and more accessible chest X-ray reports at a sixth-grade reading level. The framework was tested on 500 reports, demonstrating significant improvements in readability, reliability, and understandability. Statistical analyses confirmed the effectiveness of the PRECISE approach, highlighting its potential to foster patient-centric care delivery in healthcare decision-making.","[{'name': 'Satvik Tripathi, Liam Mutter, Meghana Muppuri, Suhani Dheer, Emiliano Garza-Frias, Komal Awan, Aakash Jha, Michael Dezube, Azadeh Tabari, Christopher P. Bridge, Dania Daye'}]",
1579,Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations,https://arxiv.org/abs/2403.00790,"arXiv:2403.00790v1 Announce Type: cross 
Abstract: In this paper, we explore the intriguing similarities between the structure of a discrete neural network, such as a spiking network, and the composition of a piano piece. While both involve nodes or notes that are activated sequentially or in parallel, the latter benefits from the rich body of music theory to guide meaningful combinations. We propose a novel approach that leverages musical grammar to regulate activations in a spiking neural network, allowing for the representation of symbols as attractors. By applying rules for chord progressions from music theory, we demonstrate how certain activations naturally follow others, akin to the concept of attraction. Furthermore, we introduce the concept of modulating keys to navigate different basins of attraction within the network. Ultimately, we show that the map of concepts in our model is structured by the musical circle of fifths, highlighting the potential for leveraging music theory principles in deep learning algorithms.",[{'name': 'Tofara Moyo'}],
1580,$\\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024,https://arxiv.org/abs/2403.00791,"arXiv:2403.00791v1 Announce Type: cross 
Abstract: Language-molecule models have emerged as an exciting direction for molecular discovery and understanding. However, training these models is challenging due to the scarcity of molecule-language pair datasets. At this point, datasets have been released which are 1) small and scraped from existing databases, 2) large but noisy and constructed by performing entity linking on the scientific literature, and 3) built by converting property prediction datasets to natural language using templates. In this document, we detail the $\\textit{L+M-24}$ dataset, which has been created for the Language + Molecules Workshop shared task at ACL 2024. In particular, $\\textit{L+M-24}$ is designed to focus on three key benefits of natural language in molecule design: compositionality, functionality, and abstraction.","[{'name': 'Carl Edwards, Qingyun Wang, Lawrence Zhao, Heng Ji'}]",
1581,Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models,https://arxiv.org/abs/2403.00794,"arXiv:2403.00794v1 Announce Type: cross 
Abstract: Humor is a fundamental facet of human cognition and interaction. Yet, despite recent advances in natural language processing, humor detection remains a challenging task that is complicated by the scarcity of datasets that pair humorous texts with similar non-humorous counterparts. In our work, we investigate whether large language models (LLMs), can generate synthetic data for humor detection via editing texts. We benchmark LLMs on an existing human dataset and show that current LLMs display an impressive ability to `unfun' jokes, as judged by humans and as measured on the downstream task of humor detection. We extend our approach to a code-mixed English-Hindi humor dataset, where we find that GPT-4's synthetic data is highly rated by bilingual annotators and provides challenging adversarial examples for humor classifiers.","[{'name': 'Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen McKeown'}]",
1582,Executing Natural Language-Described Algorithms with Large Language Models: An Investigation,https://arxiv.org/abs/2403.00795,"arXiv:2403.00795v1 Announce Type: cross 
Abstract: Executing computer programs described in natural language has long been a pursuit of computer science. With the advent of enhanced natural language understanding capabilities exhibited by large language models (LLMs), the path toward this goal has been illuminated. In this paper, we seek to examine the capacity of present-day LLMs to comprehend and execute algorithms outlined in natural language. We established an algorithm test set sourced from Introduction to Algorithm, a well-known textbook that contains many representative widely-used algorithms. To systematically assess LLMs' code execution abilities, we selected 30 algorithms, generated 300 random-sampled instances in total, and evaluated whether popular LLMs can understand and execute these algorithms. Our findings reveal that LLMs, notably GPT-4, can effectively execute programs described in natural language, as long as no heavy numeric computation is involved. We believe our findings contribute to evaluating LLMs' code execution abilities and would encourage further investigation and application for the computation power of LLMs.","[{'name': 'Xin Zheng, Qiming Zhu, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun'}]",
1583,Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes: Functional and Augmented Data Structures in Financial Forecasting,https://arxiv.org/abs/2403.00796,"arXiv:2403.00796v1 Announce Type: cross 
Abstract: In this paper, we explore the application of Gaussian Processes (GPs) for predicting mean-reverting time series with an underlying structure, using relatively unexplored functional and augmented data structures. While many conventional forecasting methods concentrate on the short-term dynamics of time series data, GPs offer the potential to forecast not just the average prediction but the entire probability distribution over a future trajectory. This is particularly beneficial in financial contexts, where accurate predictions alone may not suffice if incorrect volatility assessments lead to capital losses. Moreover, in trade selection, GPs allow for the forecasting of multiple Sharpe ratios adjusted for transaction costs, aiding in decision-making. The functional data representation utilized in this study enables longer-term predictions by leveraging information from previous years, even as the forecast moves away from the current year's training data. Additionally, the augmented representation enriches the training set by incorporating multiple targets for future points in time, facilitating long-term predictions. Our implementation closely aligns with the methodology outlined in, which assessed effectiveness on commodity futures. However, our testing methodology differs. Instead of real data, we employ simulated data with similar characteristics. We construct a testing environment to evaluate both data representations and models under conditions of increasing noise, fat tails, and inappropriate kernels-conditions commonly encountered in practice. By simulating data, we can compare our forecast distribution over time against a full simulation of the actual distribution of our test set, thereby reducing the inherent uncertainty in testing time series models on real data. We enable feature prediction through augmentation and employ sub-sampling to ensure the feasibility of GPs.",[{'name': 'Narayan Tondapu'}],
1584,An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning,https://arxiv.org/abs/2403.00799,"arXiv:2403.00799v1 Announce Type: cross 
Abstract: Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available at https://github.com/cyzhh/MMOS.","[{'name': 'Zui Chen, Yezeng Chen, Jiaqi Han, Zhijie Huang, Ji Qi, Yi Zhou'}]",
1585,Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes,https://arxiv.org/abs/2403.00800,"arXiv:2403.00800v1 Announce Type: cross 
Abstract: Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at https://github.com/cyzhh/Brain.","[{'name': 'Yezeng Chen, Zui Chen, Yi Zhou'}]",
1586,Towards a Theoretical Understanding of Two-Stage Recommender Systems,https://arxiv.org/abs/2403.00802,"arXiv:2403.00802v1 Announce Type: cross 
Abstract: Production-grade recommender systems rely heavily on a large-scale corpus used by online media services, including Netflix, Pinterest, and Amazon. These systems enrich recommendations by learning users' and items' embeddings projected in a low-dimensional space with two-stage models (two deep neural networks), which facilitate their embedding constructs to predict users' feedback associated with items. Despite its popularity for recommendations, its theoretical behaviors remain comprehensively unexplored. We study the asymptotic behaviors of the two-stage recommender that entail a strong convergence to the optimal recommender system. We establish certain theoretical properties and statistical assurance of the two-stage recommender. In addition to asymptotic behaviors, we demonstrate that the two-stage recommender system attains faster convergence by relying on the intrinsic dimensions of the input features. Finally, we show numerically that the two-stage recommender enables encapsulating the impacts of items' and users' attributes on ratings, resulting in better performance compared to existing methods conducted using synthetic and real-world data experiments.",[{'name': 'Amit Kumar Jaiswal'}],
1587,LiMAML: Personalization of Deep Recommender Models via Meta Learning,https://arxiv.org/abs/2403.00803,"arXiv:2403.00803v1 Announce Type: cross 
Abstract: In the realm of recommender systems, the ubiquitous adoption of deep neural networks has emerged as a dominant paradigm for modeling diverse business objectives. As user bases continue to expand, the necessity of personalization and frequent model updates have assumed paramount significance to ensure the delivery of relevant and refreshed experiences to a diverse array of members. In this work, we introduce an innovative meta-learning solution tailored to the personalization of models for individual members and other entities, coupled with the frequent updates based on the latest user interaction signals. Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to adapt per-task sub-networks using recent user interaction data. Given the near infeasibility of productionizing original MAML-based models in online recommendation systems, we propose an efficient strategy to operationalize meta-learned sub-networks in production, which involves transforming them into fixed-sized vectors, termed meta embeddings, thereby enabling the seamless deployment of models with hundreds of billions of parameters for online serving. Through extensive experimentation on production data drawn from various applications at LinkedIn, we demonstrate that the proposed solution consistently outperforms the baseline models of those applications, including strong baselines such as using wide-and-deep ID based personalization approach. Our approach has enabled the deployment of a range of highly personalized AI models across diverse LinkedIn applications, leading to substantial improvements in business metrics as well as refreshed experience for our members.","[{'name': 'Ruofan Wang, Prakruthi Prabhakar, Gaurav Srivastava, Tianqi Wang, Zeinab S. Jalali, Varun Bharill, Yunbo Ouyang, Aastha Nigam, Divya Venugopalan, Aman Gupta, Fedor Borisyuk, Sathiya Keerthi, Ajith Muralidharan'}]",
1588,Uncovering Customer Issues through Topological Natural Language Analysis,https://arxiv.org/abs/2403.00804,"arXiv:2403.00804v1 Announce Type: cross 
Abstract: E-commerce companies deal with a high volume of customer service requests daily. While a simple annotation system is often used to summarize the topics of customer contacts, thoroughly exploring each specific issue can be challenging. This presents a critical concern, especially during an emerging outbreak where companies must quickly identify and address specific issues. To tackle this challenge, we propose a novel machine learning algorithm that leverages natural language techniques and topological data analysis to monitor emerging and trending customer issues. Our approach involves an end-to-end deep learning framework that simultaneously tags the primary question sentence of each customer's transcript and generates sentence embedding vectors. We then whiten the embedding vectors and use them to construct an undirected graph. From there, we define trending and emerging issues based on the topological properties of each transcript. We have validated our results through various methods and found that they are highly consistent with news sources.","[{'name': 'Shu-Ting Pi, Sidarth Srinivasan, Yuying Zhu, Michael Yang, Qun Liu'}]",
1589,IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model,https://arxiv.org/abs/2403.00808,"arXiv:2403.00808v1 Announce Type: cross 
Abstract: Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model (IPED), an innovative approach for extracting relational triples. Our classifier-free solution adopts an implicit strategy using block coverage to complete the tables, avoiding the limitations of explicit tagging methods. Additionally, we introduce a generative model structure, the block-denoising diffusion model, to collaborate with our implicit perspective and effectively circumvent redundant information disruptions. Experimental results on two popular datasets demonstrate that IPED achieves state-of-the-art performance while gaining superior inference speed and low computational complexity. To support future research, we have made our source code publicly available online.","[{'name': 'Jianli Zhao, Changhao Xu, Bin Jiang'}]",
1590,"Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT",https://arxiv.org/abs/2403.00809,"arXiv:2403.00809v1 Announce Type: cross 
Abstract: This study introduces a dedicated model aimed at solving the BRAINTEASER task 9 , a novel challenge designed to assess models lateral thinking capabilities through sentence and word puzzles. Our model demonstrates remarkable efficacy, securing Rank 1 in sentence puzzle solving during the test phase with an overall score of 0.98. Additionally, we explore the comparative performance of ChatGPT, specifically analyzing how variations in temperature settings affect its ability to engage in lateral thinking and problem-solving. Our findings indicate a notable performance disparity between the dedicated model and ChatGPT, underscoring the potential of specialized approaches in enhancing creative reasoning in AI.","[{'name': 'Abdelhak Kelious, Mounir Okirim'}]",
1591,LoRA Meets Dropout under a Unified Framework,https://arxiv.org/abs/2403.00812,"arXiv:2403.00812v1 Announce Type: cross 
Abstract: With the remarkable capabilities, large language models (LLMs) have emerged as essential elements in numerous NLP applications, while parameter-efficient finetuning, especially LoRA, has gained popularity as a lightweight approach for model customization. Meanwhile, various dropout methods, initially designed for full finetuning with all the parameters updated, alleviates overfitting associated with excessive parameter redundancy. Hence, a possible contradiction arises from negligible trainable parameters of LoRA and the effectiveness of previous dropout methods, which has been largely overlooked. To fill this gap, we first confirm that parameter-efficient LoRA is also overfitting-prone. We then revisit transformer-specific dropout methods, and establish their equivalence and distinctions mathematically and empirically. Building upon this comparative analysis, we introduce a unified framework for a comprehensive investigation, which instantiates these methods based on dropping position, structural pattern and compensation measure. Through this framework, we reveal the new preferences and performance comparisons of them when involved with limited trainable parameters. This framework also allows us to amalgamate the most favorable aspects into a novel dropout method named HiddenKey. Extensive experiments verify the remarkable superiority and sufficiency of HiddenKey across multiple models and tasks, which highlights it as the preferred approach for high-performance and parameter-efficient finetuning of LLMs.","[{'name': 'Sheng Wang, Liheng Chen, Jiyue Jiang, Boyang Xue, Lingpeng Kong, Chuan Wu'}]",
1592,UrbanGPT: Spatio-Temporal Large Language Models,https://arxiv.org/abs/2403.00813,"arXiv:2403.00813v1 Announce Type: cross 
Abstract: Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. Consequently, it becomes necessary to build a spatio-temporal model with strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce.","[{'name': 'Zhonghang Li, Lianghao Xia, Jiabin Tang, Yong Xu, Lei Shi, Long Xia, Dawei Yin, Chao Huang'}]",
1593,RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records,https://arxiv.org/abs/2403.00815,"arXiv:2403.00815v1 Announce Type: cross 
Abstract: We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \\url{https://github.com/ritaranx/RAM-EHR}.","[{'name': 'Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Bowen Jin, May D. Wang, Joyce C. Ho, Carl Yang'}]",
1594,CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering,https://arxiv.org/abs/2403.00816,"arXiv:2403.00816v1 Announce Type: cross 
Abstract: Document Visual Question Answering (DVQA) is a task that involves responding to queries based on the content of images. Existing work is limited to locating information within a single page and does not facilitate cross-page question-and-answer interaction. Furthermore, the token length limitation imposed on inputs to the model may lead to truncation of segments pertinent to the answer. In this study, we introduce a simple but effective methodology called CFRet-DVQA, which focuses on retrieval and efficient tuning to address this critical issue effectively. For that, we initially retrieve multiple segments from the document that correlate with the question at hand. Subsequently, we leverage the advanced reasoning abilities of the large language model (LLM), further augmenting its performance through instruction tuning. This approach enables the generation of answers that align with the style of the document labels. The experiments demonstrate that our methodology achieved state-of-the-art or competitive results with both single-page and multi-page documents in various fields.","[{'name': 'Jinxu Zhang, Yongqi Yu, Yu Zhang'}]",
1595,InteraRec: Interactive Recommendations Using Multimodal Large Language Models,https://arxiv.org/abs/2403.00822,"arXiv:2403.00822v1 Announce Type: cross 
Abstract: Weblogs, comprised of records detailing user activities on any website, offer valuable insights into user preferences, behavior, and interests. Numerous recommendation algorithms, employing strategies such as collaborative filtering, content-based filtering, and hybrid methods, leverage the data mined through these weblogs to provide personalized recommendations to users. Despite the abundance of information available in these weblogs, identifying and extracting pertinent information and key features necessitates extensive engineering endeavors. The intricate nature of the data also poses a challenge for interpretation, especially for non-experts. In this study, we introduce a sophisticated and interactive recommendation framework denoted as InteraRec, which diverges from conventional approaches that exclusively depend on weblogs for recommendation generation. This framework captures high-frequency screenshots of web pages as users navigate through a website. Leveraging state-of-the-art multimodal large language models (MLLMs), it extracts valuable insights into user preferences from these screenshots by generating a user behavioral summary based on predefined keywords. Subsequently, this summary is utilized as input to an LLM-integrated optimization setup to generate tailored recommendations. Through our experiments, we demonstrate the effectiveness of InteraRec in providing users with valuable and personalized offerings.","[{'name': 'Saketh Reddy Karra, Theja Tulabandhula'}]",
1596,Information Flow Routes: Automatically Interpreting Language Models at Scale,https://arxiv.org/abs/2403.00824,"arXiv:2403.00824v1 Announce Type: cross 
Abstract: Information flows by routes inside the network via mechanisms implemented in the model. These routes can be represented as graphs where nodes correspond to token representations and edges to operations inside the network. We automatically build these graphs in a top-down manner, for each prediction leaving only the most important nodes and edges. In contrast to the existing workflows relying on activation patching, we do this through attribution: this allows us to efficiently uncover existing circuits with just a single forward pass. Additionally, the applicability of our method is far beyond patching: we do not need a human to carefully design prediction templates, and we can extract information flow routes for any prediction (not just the ones among the allowed templates). As a result, we can talk about model behavior in general, for specific types of predictions, or different domains. We experiment with Llama 2 and show that the role of some attention heads is overall important, e.g. previous token heads and subword merging heads. Next, we find similarities in Llama 2 behavior when handling tokens of the same part of speech. Finally, we show that some model components can be specialized on domains such as coding or multilingual texts.","[{'name': 'Javier Ferrando, Elena Voita'}]",
1597,Self-Refinement of Language Models from External Proxy Metrics Feedback,https://arxiv.org/abs/2403.00827,"arXiv:2403.00827v1 Announce Type: cross 
Abstract: It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning Llama-2-13B-Chat on the synthetic dialogue data generated by ProMiSe yields significant performance improvements over the zero-shot baseline as well as a supervised fine-tuned model on human annotated data.","[{'name': \"Keshav Ramji, Young-Suk Lee, Ram\\\\'on Fernandez Astudillo, Md Arafat Sultan, Tahira Naseem, Asim Munawar, Radu Florian, Salim Roukos\"}]",
1598,Deep Learning Detection Method for Large Language Models-Generated Scientific Content,https://arxiv.org/abs/2403.00828,"arXiv:2403.00828v1 Announce Type: cross 
Abstract: Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models have the potential to generate scientific content that is indistinguishable from that written by humans. Hence, LLMs carry severe consequences for the scientific community, which relies on the integrity and reliability of publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. AI-Catcher is a multimodal model that fuses hidden patterns derived from MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset is collected to enhance AI-generated text detection tools, AIGTxt. AIGTxt contains 3000 records collected from published academic articles across ten domains and divided into three classes: Human-written, ChatGPT-generated, and Mixed text. Several experiments are conducted to evaluate the performance of AI-Catcher. The comparative results demonstrate the capability of AI-Catcher to distinguish between human-written and ChatGPT-generated scientific text more accurately than alternative methods. On average, AI-Catcher improved accuracy by 37.4%.","[{'name': 'Bushra Alhijawi, Rawan Jarrar, Aseel AbuAlRub, Arwa Bader'}]",
1599,Explainable Session-based Recommendation via Path Reasoning,https://arxiv.org/abs/2403.00832,"arXiv:2403.00832v1 Announce Type: cross 
Abstract: This paper explores providing explainability for session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting point for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR, and introduce path midpoint reward to enhance the exploration efficiency in knowledge graphs. To improve the completeness of the knowledge graph and to diversify the paths of explanation, we incorporate extracted feature information from images into the knowledge graph. We instantiate PR4SR in five state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and compare it with other explainable SR frameworks, to demonstrate the effectiveness of PR4SR for recommendation and explanation tasks through extensive experiments with these approaches on four datasets.","[{'name': 'Yang Cao, Shuo Shang, Jun Wang, Wei Zhang'}]",
1600,Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics,https://arxiv.org/abs/2403.00834,"arXiv:2403.00834v1 Announce Type: cross 
Abstract: Generative Artificial Intelligence (AI) models can propose solutions to scientific problems beyond human capability. To truly make conceptual contributions, researchers need to be capable of understanding the AI-generated structures and extracting the underlying concepts and ideas. When algorithms provide little explanatory reasoning alongside the output, scientists have to reverse-engineer the fundamental insights behind proposals based solely on examples. This task can be challenging as the output is often highly complex and thus not immediately accessible to humans. In this work we show how transferring part of the analysis process into an immersive Virtual Reality (VR) environment can assist researchers in developing an understanding of AI-generated solutions. We demonstrate the usefulness of VR in finding interpretable configurations of abstract graphs, representing Quantum Optics experiments. Thereby, we can manually discover new generalizations of AI-discoveries as well as new understanding in experimental quantum optics. Furthermore, it allows us to customize the search space in an informed way - as a human-in-the-loop - to achieve significantly faster subsequent discovery iterations. As concrete examples, with this technology, we discover a new resource-efficient 3-dimensional entanglement swapping scheme, as well as a 3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our results show the potential of VR for increasing a human researcher's ability to derive knowledge from graph-based generative AI that, which is a common abstract data representation used in diverse fields of science.","[{'name': 'Philipp Schmidt, S\\\\\"oren Arlt, Carlos Ruiz-Gonzalez, Xuemei Gu, Carla Rodr\\\\\\'iguez, Mario Krenn'}]",
1601,CLLMs: Consistency Large Language Models,https://arxiv.org/abs/2403.00835,"arXiv:2403.00835v1 Announce Type: cross 
Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\\times$ to 3.4$\\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.","[{'name': 'Siqi Kou, Lanxiang Hu, Zhezhi He, Zhijie Deng, Hao Zhang'}]",
1602,EyeGPT: Ophthalmic Assistant with Large Language Models,https://arxiv.org/abs/2403.00840,"arXiv:2403.00840v1 Announce Type: cross 
Abstract: Artificial intelligence (AI) has gained significant attention in healthcare consultation due to its potential to improve clinical workflow and enhance medical communication. However, owing to the complex nature of medical information, large language models (LLM) trained with general world knowledge might not possess the capability to tackle medical-related tasks at an expert level. Here, we introduce EyeGPT, a specialized LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In particular, we proposed a comprehensive evaluation framework that encompasses a diverse dataset, covering various subspecialties of ophthalmology, different users, and diverse inquiry intents. Moreover, we considered multiple evaluation metrics, including accuracy, understandability, trustworthiness, empathy, and the proportion of hallucinations. By assessing the performance of different EyeGPT variants, we identify the most effective one, which exhibits comparable levels of understandability, trustworthiness, and empathy to human ophthalmologists (all Ps>0.05). Overall, ur study provides valuable insights for future research, facilitating comprehensive comparisons and evaluations of different strategies for developing specialized LLMs in ophthalmology. The potential benefits include enhancing the patient experience in eye care and optimizing ophthalmologists' services.","[{'name': 'Xiaolan Chen, Ziwei Zhao, Weiyi Zhang, Pusheng Xu, Le Gao, Mingpu Xu, Yue Wu, Yinwen Li, Danli Shi, Mingguang He'}]",
1603,Offline Fictitious Self-Play for Competitive Games,https://arxiv.org/abs/2403.00841,"arXiv:2403.00841v1 Announce Type: cross 
Abstract: Offline Reinforcement Learning (RL) has received significant interest due to its ability to improve policies in previously collected datasets without online interactions. Despite its success in the single-agent setting, offline multi-agent RL remains a challenge, especially in competitive games. Firstly, unaware of the game structure, it is impossible to interact with the opponents and conduct a major learning paradigm, self-play, for competitive games. Secondly, real-world datasets cannot cover all the state and action space in the game, resulting in barriers to identifying Nash equilibrium (NE). To address these issues, this paper introduces Off-FSP, the first practical model-free offline RL algorithm for competitive games. We start by simulating interactions with various opponents by adjusting the weights of the fixed dataset with importance sampling. This technique allows us to learn best responses to different opponents and employ the Offline Self-Play learning framework. In this framework, we further implement Fictitious Self-Play (FSP) to approximate NE. In partially covered real-world datasets, our methods show the potential to approach NE by incorporating any single-agent offline RL method. Experimental results in Leduc Hold'em Poker show that our method significantly improves performances compared with state-of-the-art baselines.","[{'name': 'Jingxiao Chen, Weiji Xie, Weinan Zhang, Yong yu, Ying Wen'}]",
1604,Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning,https://arxiv.org/abs/2403.00843,"arXiv:2403.00843v1 Announce Type: cross 
Abstract: Traditional recommendation setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the recommendation decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite Reinforcement Learning (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of recommendation data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch.
  In this context, we propose to leverage the remarkable planning capabilities over sparse data of Large Language Models (LLMs) for long-term recommendation. The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized recommendation scenarios, as the model's pre-training may not naturally encompass these principles, necessitating the need to inspire or teach the model. To achieve this, we propose a Bi-level Learnable LLM Planner framework, which combines macro-learning and micro-learning through a hierarchical mechanism. The framework includes a Planner and Reflector for acquiring high-level guiding principles and an Actor-Critic component for planning personalization. Extensive experiments validate the superiority of the framework in learning to plan for long-term recommendations.","[{'name': 'Wentao Shi, Xiangnan He, Yang Zhang, Chongming Gao, Xinyue Li, Jizhi Zhang, Qifan Wang, Fuli Feng'}]",
1605,Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs,https://arxiv.org/abs/2403.00858,"arXiv:2403.00858v1 Announce Type: cross 
Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional alignment procedure. For the finetuning step, we use instruction-response pairs generated by target model for distillation in plausible data distribution, and propose a new Total Variation Distance++ (TVD++) loss that incorporates variance reduction techniques inspired from the policy gradient method in reinforcement learning. Our empirical results show that Llama 2 Chat Drafter 115M with speculative decoding achieves up to 2.3 block efficiency and 2.4$\\times$ speed-up relative to autoregressive decoding on various tasks with no further task-specific fine-tuning.","[{'name': 'Raghavv Goel, Mukul Gagrani, Wonseok Jeon, Junyoung Park, Mingu Lee, Christopher Lott'}]",
1606,Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions,https://arxiv.org/abs/2403.00860,"arXiv:2403.00860v1 Announce Type: cross 
Abstract: A feedforward neural network using rectified linear units constructs a mapping from inputs to outputs by partitioning its input space into a set of convex regions where points within a region share a single affine transformation. In order to understand how neural networks work, when and why they fail, and how they compare to biological intelligence, we need to understand the organization and formation of these regions. Step one is to design and implement algorithms for exact region enumeration in networks beyond toy examples.
  In this work, we present parallel algorithms for exact enumeration in deep (and shallow) neural networks. Our work has three main contributions: (1) we present a novel algorithm framework and parallel algorithms for region enumeration; (2) we implement one of our algorithms on a variety of network architectures and experimentally show how the number of regions dictates runtime; and (3) we show, using our algorithm's output, how the dimension of a region's affine transformation impacts further partitioning of the region by deeper layers.
  To our knowledge, we run our implemented algorithm on networks larger than all of the networks used in the existing region enumeration literature. Further, we experimentally demonstrate the importance of parallelism for region enumeration of any reasonably sized network.","[{'name': 'Sabrina Drammis, Bowen Zheng, Karthik Srinivasan, Robert C. Berwick, Nancy A. Lynch, Robert Ajemian'}]",
1607,NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications,https://arxiv.org/abs/2403.00862,"arXiv:2403.00862v1 Announce Type: cross 
Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 11 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safety considerations.","[{'name': 'Miao Li, Ming-Bin Chen, Bo Tang, Shengbin Hou, Pengyu Wang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Keming Mao, Peng Cheng, Yi Luo'}]",
1608,LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction,https://arxiv.org/abs/2403.00863,"arXiv:2403.00863v1 Announce Type: cross 
Abstract: Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality recommendations and enhancing customer satisfaction. The recently emerging Large Language Models (LLMs) have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different LLMs due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single LLM dominating all others. Considering the diverse strengths and weaknesses of LLMs, it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called LLM-ensemble to ensemble different LLMs' outputs for attribute value extraction. We iteratively learn the weights for different LLMs to aggregate the labels with weights to predict the final attribute value. Not only can our proposed method be proven theoretically optimal, but it also ensures efficient computation, fast convergence, and safe deployment. We have also conducted extensive experiments with various state-of-the-art LLMs, including Llama2-13B, Llama2-70B, PaLM-2, GPT-3.5, and GPT-4, on Walmart's internal data. Our offline metrics demonstrate that the LLM-ensemble method outperforms all the state-of-the-art single LLMs on Walmart's internal dataset. This method has been launched in several production models, leading to improved Gross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate (CVR), and Add-to-Cart Rate (ATC).","[{'name': 'Chenhao Fang, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Kaushiki Nag, Evren Korpeoglu, Sushant Kumar, Kannan Achan'}]",
1609,Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning,https://arxiv.org/abs/2403.00865,"arXiv:2403.00865v1 Announce Type: cross 
Abstract: In this paper, we develop upon the topic of loss function learning, an emergent meta-learning paradigm that aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for task and model-agnostic loss function learning via a hybrid search approach. The framework first uses genetic programming to find a set of symbolic loss functions. Second, the set of learned loss functions is subsequently parameterized and optimized via unrolled differentiation. The versatility and performance of the proposed framework are empirically validated on a diverse set of supervised learning tasks. Results show that the learned loss functions bring improved convergence, sample efficiency, and inference performance on tabulated, computer vision, and natural language processing problems, using a variety of task-specific neural network architectures.","[{'name': 'Christian Raymond, Qi Chen, Bing Xue, Mengjie Zhang'}]",
1610,Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes,https://arxiv.org/abs/2403.00867,"arXiv:2403.00867v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can significantly improve the LLM's rejection capability for malicious jailbreak queries, while maintaining the model's performance for benign user queries by adjusting the detection threshold.","[{'name': 'Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho'}]",
1611,SoftTiger: A Clinical Foundation Model for Healthcare Workflows,https://arxiv.org/abs/2403.00868,"arXiv:2403.00868v1 Announce Type: cross 
Abstract: We release and introduce SoftTiger, a clinical large language model (CLaM) designed as a foundation model for healthcare workflows. The narrative and unstructured nature of clinical notes is a major obstacle for healthcare intelligentization. We address a critical problem of structuring clinical notes into clinical data, according to international interoperability standards. We collect and annotate data for three critical subtasks, namely, international patient summary, clinical impression and medical encounter. We then supervised fine-tuned a state-of-the-art LLM using public and credentialed clinical data. The training is orchestrated in a way that the target model can first support basic clinical tasks such as abbreviation expansion and temporal information extraction, and then learn to perform more complex downstream clinical tasks such as impression and encounter summary. Moreover, we address, several modeling challenges in the healthcare context, e.g., extra long context window. Our blind pairwise evaluation shows that SoftTiger outperforms other popular open-source models and GPT-3.5, comparable to Gemini-pro, and only has a mild gap from GPT-4. We believe that LLMs may become a step-stone towards healthcare digitalization and democratization. Therefore, we publicly release SoftTiger models at scales of 13 billion and 70 billion parameters, as well as datasets and code for our innovative scalable evaluation, hopefully, making a significant contribution to the healthcare industry.","[{'name': 'Ye Chen, Igor Couto, Wei Cai, Cong Fu, Bruno Dorneles'}]",
1612,Teach LLMs to Phish: Stealing Private Information from Language Models,https://arxiv.org/abs/2403.00871,"arXiv:2403.00871v1 Announce Type: cross 
Abstract: When large language models are trained on private data, it can be a significant privacy risk for them to memorize and regurgitate sensitive information. In this work, we propose a new practical data extraction attack that we call \"neural phishing\". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%. Our attack assumes only that an adversary can insert as few as 10s of benign-appearing sentences into the training dataset using only vague priors on the structure of the user data.","[{'name': 'Ashwinee Panda, Christopher A. Choquette-Choo, Zhengming Zhang, Yaoqing Yang, Prateek Mittal'}]",
1613,DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases,https://arxiv.org/abs/2403.00872,"arXiv:2403.00872v1 Announce Type: cross 
Abstract: The task of converting natural language queries into SQL queries is intricate, necessitating a blend of precise techniques for an accurate translation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a significant development in this domain. This paper introduces DFIN (Decomposed Focused-In-Context), an innovative extension of DIN-SQL that enhances Text-to-SQL conversion by addressing schema linking errors, which are a major source of inaccuracies. DFIN uniquely alternates between prompting techniques and Retrieval-Augmented Generation (RAG), adapting to the size and complexity of the database schema. A preprocessing phase embeds database definitions and leverages annotated files, akin to those in the BIRD dataset, facilitating the runtime retrieval of pertinent schema information. This strategy significantly reduces the token count for schema linking prompts, enabling the use of a standard GPT-4 model over its larger context variant, thus handling large-scale databases more effectively and economically. Our evaluation on the BIRD dataset, a challenging real-world benchmark, demonstrates that DFIN not only scales efficiently but also improves accuracy, achieving a score of 51.69. This improvement surpasses DIN-SQL method (the current third-place), which is the highest-ranked model employing in-context learning rather than fine-tuning, previously scoring 50.72. The advancement of DFIN underscores the evolving capabilities of in-context learning methodologies combined with advanced language models, offering a promising avenue for future research in complex Text-to-SQL conversion tasks.","[{'name': 'Shai Volvovsky, Marco Marcassa, Mustafa Panbiharwala'}]",
1614,Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions,https://arxiv.org/abs/2403.00875,"arXiv:2403.00875v1 Announce Type: cross 
Abstract: Augmentation is an effective alternative to utilize the small amount of labeled protein data. However, most of the existing work focuses on design-ing new architectures or pre-training tasks, and relatively little work has studied data augmentation for proteins. This paper extends data augmentation techniques previously used for images and texts to proteins and then benchmarks these techniques on a variety of protein-related tasks, providing the first comprehensive evaluation of protein augmentation. Furthermore, we propose two novel semantic-level protein augmentation methods, namely Integrated Gradients Substitution and Back Translation Substitution, which enable protein semantic-aware augmentation through saliency detection and biological knowledge. Finally, we integrate extended and proposed augmentations into an augmentation pool and propose a simple but effective framework, namely Automated Protein Augmentation (APA), which can adaptively select the most suitable augmentation combinations for different tasks. Extensive experiments have shown that APA enhances the performance of five protein related tasks by an average of 10.55% across three architectures compared to vanilla implementations without augmentation, highlighting its potential to make a great impact on the field.","[{'name': 'Rui Sun, Lirong Wu, Haitao Lin, Yufei Huang, Stan Z. Li'}]",
1615,Word Order and World Knowledge,https://arxiv.org/abs/2403.00876,"arXiv:2403.00876v1 Announce Type: cross 
Abstract: Word order is an important concept in natural language, and in this work, we study how word order affects the induction of world knowledge from raw text using language models. We use word analogies to probe for such knowledge. Specifically, in addition to the natural word order, we first respectively extract texts of six fixed word orders from five languages and then pretrain the language models on these texts. Finally, we analyze the experimental results of the fixed word orders on word analogies and show that i) certain fixed word orders consistently outperform or underperform others, though the specifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in pre-trained language models, and the natural word order typically yields mediocre results. The source code will be made publicly available at https://github.com/lshowway/probing_by_analogy.","[{'name': 'Qinghua Zhao, Vinit Ravishankar, Nicolas Garneau, Anders S{\\\\o}gaard'}]",
1616,Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models,https://arxiv.org/abs/2403.00878,"arXiv:2403.00878v1 Announce Type: cross 
Abstract: We introduces Crimson, a system that enhances the strategic reasoning capabilities of Large Language Models (LLMs) within the realm of cybersecurity. By correlating CVEs with MITRE ATT&amp;CK techniques, Crimson advances threat anticipation and strategic defense efforts. Our approach includes defining and evaluating cybersecurity strategic tasks, alongside implementing a comprehensive human-in-the-loop data-synthetic workflow to develop the CVE-to-ATT&amp;CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning abilities through a novel Retrieval-Aware Training (RAT) process and its refined iteration, RAT-R.
  Our findings demonstrate that an LLM fine-tuned with our techniques, possessing 7 billion parameters, approaches the performance level of GPT-4, showing markedly lower rates of hallucination and errors, and surpassing other models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of embedding models significantly improves performance within cybersecurity contexts, underscoring the efficacy of our methodology. By leveraging Crimson to convert raw vulnerability data into structured and actionable insights, we bolster proactive cybersecurity defenses.","[{'name': 'Jiandong Jin, Bowen Tang, Mingxuan Ma, Xiao Liu, Yunfei Wang, Qingnan Lai, Jia Yang, Changling Zhou'}]",
1617,Dual-Granularity Medication Recommendation Based on Causal Inference,https://arxiv.org/abs/2403.00880,"arXiv:2403.00880v1 Announce Type: cross 
Abstract: As medical demands grow and machine learning technology advances, AI-based diagnostic and treatment systems are garnering increasing attention. Medication recommendation aims to integrate patients' long-term health records with medical knowledge, recommending accuracy and safe medication combinations for specific conditions. However, most existing researches treat medication recommendation systems merely as variants of traditional recommendation systems, overlooking the heterogeneity between medications and diseases. To address this challenge, we propose DGMed, a framework for medication recommendation. DGMed utilizes causal inference to uncover the connections among medical entities and presents an innovative feature alignment method to tackle heterogeneity issues. Specifically, this study first applies causal inference to analyze the quantified therapeutic effects of medications on specific diseases from historical records, uncovering potential links between medical entities. Subsequently, we integrate molecular-level knowledge, aligning the embeddings of medications and diseases within the molecular space to effectively tackle their heterogeneity. Ultimately, based on relationships at the entity level, we adaptively adjust the recommendation probabilities of medication and recommend medication combinations according to the patient's current health condition. Experimental results on a real-world dataset show that our method surpasses existing state-of-the-art baselines in four evaluation metrics, demonstrating superior performance in both accuracy and safety aspects. Compared to the sub-optimal model, our approach improved accuracy by 4.40%, reduced the risk of side effects by 6.14%, and increased time efficiency by 47.15%.","[{'name': 'Shunpan Liang, Xiang Li, Xiang Li, Chen Li, Yu Lei, Yulei Hou, Tengfei Ma'}]",
1618,Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment,https://arxiv.org/abs/2403.00884,"arXiv:2403.00884v1 Announce Type: cross 
Abstract: Traditional dataset retrieval systems index on metadata information rather than on the data values. Thus relying primarily on manual annotations and high-quality metadata, processes known to be labour-intensive and challenging to automate. We propose a method to support metadata enrichment with topic annotations of column headers using three Large Language Models (LLMs): ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to classify column headers based on domain-specific topics from a controlled vocabulary. We evaluate our approach by assessing the internal consistency of the LLMs, the inter-machine alignment, and the human-machine agreement for the topic classification task. Additionally, we investigate the impact of contextual information (i.e. dataset description) on the classification outcomes. Our results suggest that ChatGPT and GoogleGemini outperform GoogleBard for internal consistency as well as LLM-human-alignment. Interestingly, we found that context had no impact on the LLMs performances. This work proposes a novel approach that leverages LLMs for text classification using a controlled topic vocabulary, which has the potential to facilitate automated metadata enrichment, thereby enhancing dataset retrieval and the Findability, Accessibility, Interoperability and Reusability (FAIR) of research data on the Web.","[{'name': 'Margherita Martorana, Tobias Kuhn, Lise Stork, Jacco van Ossenbruggen'}]",
1619,"SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech",https://arxiv.org/abs/2403.00887,"arXiv:2403.00887v1 Announce Type: cross 
Abstract: The interpretation of human voices holds importance across various applications. This study ventures into predicting age, gender, and emotion from vocal cues, a field with vast applications. Voice analysis tech advancements span domains, from improving customer interactions to enhancing healthcare and retail experiences. Discerning emotions aids mental health, while age and gender detection are vital in various contexts. Exploring deep learning models for these predictions involves comparing single, multi-output, and sequential models highlighted in this paper. Sourcing suitable data posed challenges, resulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work showed promise in individual predictions, but limited research considered all three variables simultaneously. This paper identifies flaws in an individual model approach and advocates for our novel multi-output learning architecture Speech-based Emotion Gender and Age Analysis (SEGAA) model. The experiments suggest that Multi-output models perform comparably to individual models, efficiently capturing the intricate relationships between variables and speech inputs, all while achieving improved runtime.","[{'name': 'Aron R, Indra Sigicharla, Chirag Periwal, Mohanaprasad K, Nithya Darisini P S, Sourabh Tiwari, Shivani Arora'}]",
1620,Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks,https://arxiv.org/abs/2403.00890,"arXiv:2403.00890v1 Announce Type: cross 
Abstract: Generative Adversarial Networks (GANs) have demonstrated their versatility across various applications, including data augmentation and malware detection. This research explores the effectiveness of utilizing GAN-generated data to train a model for the detection of Android malware. Given the considerable storage requirements of Android applications, the study proposes a method to synthetically represent data using GANs, thereby reducing storage demands. The proposed methodology involves creating image representations of features extracted from an existing dataset. A GAN model is then employed to generate a more extensive dataset consisting of realistic synthetic grayscale images. Subsequently, this synthetic dataset is utilized to train a Convolutional Neural Network (CNN) designed to identify previously unseen Android malware applications. The study includes a comparative analysis of the CNN's performance when trained on real images versus synthetic images generated by the GAN. Furthermore, the research explores variations in performance between the Wasserstein Generative Adversarial Network (WGAN) and the Deep Convolutional Generative Adversarial Network (DCGAN). The investigation extends to studying the impact of image size and malware obfuscation on the classification model's effectiveness. The data augmentation approach implemented in this study resulted in a notable performance enhancement of the classification model, ranging from 1.5% to 7%, depending on the dataset. The achieved F1 score reached 97.5%. Keywords--Generative Adversarial Networks, Android Malware, Data Augmentation, Wasserstein Generative Adversarial Network","[{'name': 'Kawana Stalin, Mikias Berhanu Mekoya'}]",
1621,A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder,https://arxiv.org/abs/2403.00891,"arXiv:2403.00891v1 Announce Type: cross 
Abstract: Information extraction (IE) aims to extract complex structured information from the text. Numerous datasets have been constructed for various IE tasks, leading to time-consuming and labor-intensive data annotations. Nevertheless, most prevailing methods focus on training task-specific models, while the common knowledge among different IE tasks is not explicitly modeled. Moreover, the same phrase may have inconsistent labels in different tasks, which poses a big challenge for knowledge transfer using a unified model. In this study, we propose a regularization-based transfer learning method for IE (TIE) via an instructed graph decoder. Specifically, we first construct an instruction pool for datasets from all well-known IE tasks, and then present an instructed graph decoder, which decodes various complex structures into a graph uniformly based on corresponding instructions. In this way, the common knowledge shared with existing datasets can be learned and transferred to a new dataset with new labels. Furthermore, to alleviate the label inconsistency problem among various IE tasks, we introduce a task-specific regularization strategy, which does not update the gradients of two tasks with 'opposite direction'. We conduct extensive experiments on 12 datasets spanning four IE tasks, and the results demonstrate the great advantages of our proposed method","[{'name': 'Kedi Chen, Jie Zhou, Qin Chen, Shunyu Liu, Liang He'}]",
1622,A systematic evaluation of large language models for generating programming code,https://arxiv.org/abs/2403.00894,"arXiv:2403.00894v1 Announce Type: cross 
Abstract: We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.","[{'name': 'Wenpin Hou, Zhicheng Ji'}]",
1623,End-to-end Graph-Sequential Representation Learning for Accurate Recommendations,https://arxiv.org/abs/2403.00895,"arXiv:2403.00895v1 Announce Type: cross 
Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.","[{'name': 'Vladimir Baikalov, Evgeny Frolov'}]",
1624,DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models,https://arxiv.org/abs/2403.00896,"arXiv:2403.00896v1 Announce Type: cross 
Abstract: Since large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, numerous benchmarks are proposed to detect the hallucination. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dialogue-level hallucination evaluation benchmark to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two ChatGPT3.5. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-machine interaction scenarios. Finally, professional scholars annotate all the samples in the dataset. DiaHalu covers four common multi-turn dialogue domains and five hallucination subtypes, extended from factuality and faithfulness hallucination. Experiments through some well-known LLMs and detection methods on the dataset show that DiaHalu is a challenging benchmark, holding significant value for further research.","[{'name': 'Kedi Chen, Qin Chen, Jie Zhou, Yishen He, Liang He'}]",
1625,VisRec: A Semi-Supervised Approach to Radio Interferometric Data Reconstruction,https://arxiv.org/abs/2403.00897,"arXiv:2403.00897v1 Announce Type: cross 
Abstract: Radio telescopes produce visibility data about celestial objects, but these data are sparse and noisy. As a result, images created on raw visibility data are of low quality. Recent studies have used deep learning models to reconstruct visibility data to get cleaner images. However, these methods rely on a substantial amount of labeled training data, which requires significant labeling effort from radio astronomers. Addressing this challenge, we propose VisRec, a model-agnostic semi-supervised learning approach to the reconstruction of visibility data. Specifically, VisRec consists of both a supervised learning module and an unsupervised learning module. In the supervised learning module, we introduce a set of data augmentation functions to produce diverse training examples. In comparison, the unsupervised learning module in VisRec augments unlabeled data and uses reconstructions from non-augmented visibility data as pseudo-labels for training. This hybrid approach allows VisRec to effectively leverage both labeled and unlabeled data. This way, VisRec performs well even when labeled data is scarce. Our evaluation results show that VisRec outperforms all baseline methods in reconstruction quality, robustness against common observation perturbation, and generalizability to different telescope configurations.","[{'name': 'Ruoqi Wang, Haitao Wang, Qiong Luo, Feng Wang, Hejun Wu'}]",
1626,PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning,https://arxiv.org/abs/2403.00929,"arXiv:2403.00929v1 Announce Type: cross 
Abstract: Imitation learning has shown great potential for enabling robots to acquire complex manipulation behaviors. However, these algorithms suffer from high sample complexity in long-horizon tasks, where compounding errors accumulate over the task horizons. We present PRIME (PRimitive-based IMitation with data Efficiency), a behavior primitive-based framework designed for improving the data efficiency of imitation learning. PRIME scaffolds robot tasks by decomposing task demonstrations into primitive sequences, followed by learning a high-level control policy to sequence primitives through imitation learning. Our experiments demonstrate that PRIME achieves a significant performance improvement in multi-stage manipulation tasks, with 10-34% higher success rates in simulation over state-of-the-art baselines and 20-48% on physical hardware.","[{'name': 'Tian Gao, Soroush Nasiriany, Huihan Liu, Quantao Yang, Yuke Zhu'}]",
1627,Scale-free Adversarial Reinforcement Learning,https://arxiv.org/abs/2403.00930,"arXiv:2403.00930v1 Announce Type: cross 
Abstract: This paper initiates the study of scale-free learning in Markov Decision Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We design a generic algorithmic framework, \\underline{S}cale \\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we achieve the first minimax optimal expected regret bound and the first high-probability regret bound in scale-free adversarial MABs, resolving an open problem raised in \\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth to the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ high-probability regret guarantee.","[{'name': 'Mingyu Chen, Xuezhou Zhang'}]",
1628,Resilience of Entropy Model in Distributed Neural Networks,https://arxiv.org/abs/2403.00942,"arXiv:2403.00942v1 Announce Type: cross 
Abstract: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks can increase the communication overhead by up to 95%. By separating compression features in frequency and spatial domain, we propose a new defense mechanism that can reduce the transmission overhead of the attacked input by about 9% compared to unperturbed data, with only about 2% accuracy loss. Importantly, the proposed defense mechanism is a standalone approach which can be applied in conjunction with approaches such as adversarial training to further improve robustness. Code will be shared for reproducibility.","[{'name': 'Milin Zhang, Mohammad Abdi, Shahriar Rifat, Francesco Restuccia'}]",
1629,AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models,https://arxiv.org/abs/2403.00953,"arXiv:2403.00953v1 Announce Type: cross 
Abstract: Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper.
  Materials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction.
  Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, symptom_and_sign: 46.1%, anaphor: 67.5%) and an overall relation extraction F1 score of 38.6% (produces: 34.7%, increases_risk_of: 12.4%, is_a: 37.4%, is_acronym: 44.1%, is_synonym: 16.3%, anaphora: 57.5%). Our qualitative experiment also demonstrates that the performance in constructing the knowledge graph is commendable.
  Discussion: AutoRD demonstrates the potential of LLM applications in rare disease detection. This improvement is attributed to several design, including the integration of ontologies-enhanced LLMs.
  Conclusion: AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs. It uses ontologies-enhanced LLMs for a robust medical knowledge base. The superior performance of AutoRD is validated by experimental evaluations, demonstrating the potential of LLMs in healthcare.","[{'name': 'Lang Cao, Jimeng Sun, Adam Cross'}]",
1630,Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients,https://arxiv.org/abs/2403.00965,"arXiv:2403.00965v1 Announce Type: cross 
Abstract: The Center for Disease Control estimates that over 37 million US adults suffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals are unaware of their condition due to the absence of symptoms in the early stages. It has a significant impact on patients' quality of life, particularly when it progresses to the need for dialysis. Early prediction of dialysis is crucial as it can significantly improve patient outcomes and assist healthcare providers in making timely and informed decisions. However, developing an effective machine learning (ML)-based Clinical Decision Support System (CDSS) for early dialysis prediction poses a key challenge due to the imbalanced nature of data. To address this challenge, this study evaluates various data augmentation techniques to understand their effectiveness on real-world datasets. We propose a new approach named Binary Gaussian Copula Synthesis (BGCS). BGCS is tailored for binary medical datasets and excels in generating synthetic minority data that mirrors the distribution of the original data. BGCS enhances early dialysis prediction by outperforming traditional methods in detecting dialysis patients. For the best ML model, Random Forest, BCGS achieved a 72% improvement, surpassing the state-of-the-art augmentation approaches. Also, we present a ML-based CDSS, designed to aid clinicians in making informed decisions. CDSS, which utilizes decision tree models, is developed to improve patient outcomes, identify critical variables, and thereby enable clinicians to make proactive decisions, and strategize treatment plans effectively for CKD patients who are more likely to require dialysis in the near future. Through comprehensive feature analysis and meticulous data preparation, we ensure that the CDSS's dialysis predictions are not only accurate but also actionable, providing a valuable tool in the management and treatment of CKD.","[{'name': 'Hamed Khosravi, Srinjoy Das, Abdullah Al-Mamun, Imtiaz Ahmed'}]",
1631,Equipment Health Assessment: Time Series Analysis for Wind Turbine Performance,https://arxiv.org/abs/2403.00975,"arXiv:2403.00975v1 Announce Type: cross 
Abstract: In this study, we leverage SCADA data from diverse wind turbines to predict power output, employing advanced time series methods, specifically Functional Neural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key innovation lies in the ensemble of FNN and LSTM models, capitalizing on their collective learning. This ensemble approach outperforms individual models, ensuring stable and accurate power output predictions. Additionally, machine learning techniques are applied to detect wind turbine performance deterioration, enabling proactive maintenance strategies and health assessment. Crucially, our analysis reveals the uniqueness of each wind turbine, necessitating tailored models for optimal predictions. These insight underscores the importance of providing automatized customization for different turbines to keep human modeling effort low. Importantly, the methodologies developed in this analysis are not limited to wind turbines; they can be extended to predict and optimize performance in various machinery, highlighting the versatility and applicability of our research across diverse industrial contexts.","[{'name': 'Jana Backhus, Aniruddha Rajendra Rao, Chandrasekar Venkatraman, Abhishek Padmanabhan, A. Vinoth Kumar, Chetan Gupta'}]",
1632,Merging Text Transformer Models from Different Initializations,https://arxiv.org/abs/2403.00986,"arXiv:2403.00986v1 Announce Type: cross 
Abstract: Recent work on one-shot permutation-based model merging has shown impressive low- or zero-barrier mode connectivity between models from completely different initializations. However, this line of work has not yet extended to the Transformer architecture, despite its dominant popularity in the language domain. Therefore, in this work, we investigate the extent to which separate Transformer minima learn similar features, and propose a model merging technique to investigate the relationship between these minima in the loss landscape. The specifics of the architecture, like its residual connections, multi-headed attention, and discrete, sequential input, require specific interventions in order to compute model permutations that remain within the same functional equivalence class. In merging these models with our method, we consistently find lower loss barriers between minima compared to model averaging for several models trained on a masked-language modeling task or fine-tuned on a language understanding benchmark. Our results show that the minima of these models are less sharp and isolated than previously understood, and provide a basis for future work on merging separately trained Transformer models.","[{'name': 'Neha Verma, Maha Elbayad'}]",
1633,On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games,https://arxiv.org/abs/2403.00993,"arXiv:2403.00993v1 Announce Type: cross 
Abstract: In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.
  In this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing classical models as special cases. We show that this leads to a richer analysis of sequential decision-making problems and enables more tailored algorithm design. In particular, we characterize the \"complexity\" of the observable dynamics of any sequential decision-making problem through a graph-theoretic analysis of the DAG representation of its information structure. The central quantity in this analysis is the minimal set of variables that $d$-separates the past observations from future observations. Furthermore, through constructing a generalization of predictive state representations, we propose tailored reinforcement learning algorithms and prove that the sample complexity is in part determined by the information structure. This recovers known tractability results and gives a novel perspective on reinforcement learning in general sequential decision-making problems, providing a systematic way of identifying new tractable classes of problems.","[{'name': 'Awni Altabaa, Zhuoran Yang'}]",
1634,Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language,https://arxiv.org/abs/2403.00994,"arXiv:2403.00994v1 Announce Type: cross 
Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of gists of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-based LLMs in identifying critical online discussion patterns that can form the basis of public health communication strategies.","[{'name': 'Xiaohan Ding, Buse Carik, Uma Sushmitha Gunturi, Valerie Reyna, Eugenia H. Rho'}]",
1635,Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries,https://arxiv.org/abs/2403.01002,"arXiv:2403.01002v1 Announce Type: cross 
Abstract: Summarizing clinical text is crucial in health decision-support and clinical research. Large language models (LLMs) have shown the potential to generate accurate clinical text summaries, but still struggle with issues regarding grounding and evaluation, especially in safety-critical domains such as health. Holistically evaluating text summaries is challenging because they may contain unsubstantiated information. Here, we explore a general mitigation framework using Attribute Structuring (AS), which structures the summary evaluation process. It decomposes the evaluation process into a grounded procedure that uses an LLM for relatively simple structuring and scoring tasks, rather than the full task of holistic summary evaluation. Experiments show that AS consistently improves the correspondence between human annotations and automated metrics in clinical text summarization. Additionally, AS yields interpretations in the form of a short text span corresponding to each output, which enables efficient human auditing, paving the way towards trustworthy evaluation of clinical information in resource-constrained scenarios. We release our code, prompts, and an open-source benchmark at https://github.com/microsoft/attribute-structuring.","[{'name': 'Zelalem Gero, Chandan Singh, Yiqing Xie, Sheng Zhang, Tristan Naumann, Jianfeng Gao, Hoifung Poon'}]",
1636,FlaKat: A Machine Learning-Based Categorization Framework for Flaky Tests,https://arxiv.org/abs/2403.01003,"arXiv:2403.01003v1 Announce Type: cross 
Abstract: Flaky tests can pass or fail non-deterministically, without alterations to a software system. Such tests are frequently encountered by developers and hinder the credibility of test suites. State-of-the-art research incorporates machine learning solutions into flaky test detection and achieves reasonably good accuracy. Moreover, the majority of automated flaky test repair solutions are designed for specific types of flaky tests. This research work proposes a novel categorization framework, called FlaKat, which uses machine-learning classifiers for fast and accurate prediction of the category of a given flaky test that reflects its root cause. Sampling techniques are applied to address the imbalance between flaky test categories in the International Dataset of Flaky Test (IDoFT). A new evaluation metric, called Flakiness Detection Capacity (FDC), is proposed for measuring the accuracy of classifiers from the perspective of information theory and provides proof for its effectiveness. The final FDC results are also in agreement with F1 score regarding which classifier yields the best flakiness classification.","[{'name': 'Shizhe Lin, Ryan Zheng He Liu, Ladan Tahvildari'}]",
1637,Policy Optimization for PDE Control with a Warm Start,https://arxiv.org/abs/2403.01005,"arXiv:2403.01005v1 Announce Type: cross 
Abstract: Dimensionality reduction is crucial for controlling nonlinear partial differential equations (PDE) through a \"reduce-then-design\" strategy, which identifies a reduced-order model and then implements model-based control solutions. However, inaccuracies in the reduced-order modeling can substantially degrade controller performance, especially in PDEs with chaotic behavior. To address this issue, we augment the reduce-then-design procedure with a policy optimization (PO) step. The PO step fine-tunes the model-based controller to compensate for the modeling error from dimensionality reduction. This augmentation shifts the overall strategy into reduce-then-design-then-adapt, where the model-based controller serves as a warm start for PO. Specifically, we study the state-feedback tracking control of PDEs that aims to align the PDE state with a specific constant target subject to a linear-quadratic cost. Through extensive experiments, we show that a few iterations of PO can significantly improve the model-based controller performance. Our approach offers a cost-effective alternative to PDE control using end-to-end reinforcement learning.","[{'name': 'Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Ba\\\\c{s}ar'}]",
1638,Reservoir Computing Using Measurement-Controlled Quantum Dynamics,https://arxiv.org/abs/2403.01024,"arXiv:2403.01024v1 Announce Type: cross 
Abstract: Physical reservoir computing (RC) is a machine learning algorithm that employs the dynamics of a physical system to forecast highly nonlinear and chaotic phenomena. In this paper, we introduce a quantum RC system that employs the dynamics of a probed atom in a cavity. The atom experiences coherent driving at a particular rate, leading to a measurement-controlled quantum evolution. The proposed quantum reservoir can make fast and reliable forecasts using a small number of artificial neurons compared with the traditional RC algorithm. We theoretically validate the operation of the reservoir, demonstrating its potential to be used in error-tolerant applications, where approximate computing approaches may be used to make feasible forecasts in conditions of limited computational and energy resources.","[{'name': 'A. H. Abbas, Ivan S. Maksymov'}]",
1639,Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks,https://arxiv.org/abs/2403.01031,"arXiv:2403.01031v1 Announce Type: cross 
Abstract: Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic culture, setting the first stone for culturally-aware Arabic MLLMs.The GitHub repository for the \\textit{Peacock} project is available at \\url{https://github.com/UBC-NLP/peacock}.","[{'name': 'Fakhraddin Alwajih, El Moatez Billah Nagoudi, Gagan Bhatia, Abdelrahman Mohamed, Muhammad Abdul-Mageed'}]",
1640,AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks,https://arxiv.org/abs/2403.01038,"arXiv:2403.01038v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated impressive results on natural language tasks, and security researchers are beginning to employ them in both offensive and defensive systems. In cyber-security, there have been multiple research efforts that utilize LLMs focusing on the pre-breach stage of attacks like phishing and malware generation. However, so far there lacks a comprehensive study regarding whether LLM-based systems can be leveraged to simulate the post-breach stage of attacks that are typically human-operated, or \"hands-on-keyboard\" attacks, under various attack techniques and environments.
  As LLMs inevitably advance, they may be able to automate both the pre- and post-breach attack stages. This shift may transform organizational attacks from rare, expert-led events to frequent, automated operations requiring no expertise and executed at automation speed and scale. This risks fundamentally changing global computer security and correspondingly causing substantial economic impacts, and a goal of this work is to better understand these risks now so we can better prepare for these inevitable ever-more-capable LLMs on the horizon. On the immediate impact side, this research serves three purposes. First, an automated LLM-based, post-breach exploitation framework can help analysts quickly test and continually improve their organization's network security posture against previously unseen attacks. Second, an LLM-based penetration test system can extend the effectiveness of red teams with a limited number of human analysts. Finally, this research can help defensive systems and teams learn to detect novel attack behaviors preemptively before their use in the wild....","[{'name': 'Jiacen Xu, Jack W. Stokes, Geoff McDonald, Xuesong Bai, David Marshall, Siyue Wang, Adith Swaminathan, Zhou Li'}]",
1641,A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features,https://arxiv.org/abs/2403.01046,"arXiv:2403.01046v1 Announce Type: cross 
Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.","[{'name': 'Emi Zeger, Yifei Wang, Aaron Mishkin, Tolga Ergen, Emmanuel Cand\\\\`es, Mert Pilanci'}]",
1642,Seeing Unseen: Discover Novel Biomedical Concepts via GeometryConstrained Probabilistic Modeling,https://arxiv.org/abs/2403.01053,"arXiv:2403.01053v1 Announce Type: cross 
Abstract: Machine learning holds tremendous promise for transforming the fundamental practice of scientific discovery by virtue of its data-driven nature. With the ever-increasing stream of research data collection, it would be appealing to autonomously explore patterns and insights from observational data for discovering novel classes of phenotypes and concepts. However, in the biomedical domain, there are several challenges inherently presented in the cumulated data which hamper the progress of novel class discovery. The non-i.i.d. data distribution accompanied by the severe imbalance among different groups of classes essentially leads to ambiguous and biased semantic representations. In this work, we present a geometry-constrained probabilistic modeling treatment to resolve the identified issues. First, we propose to parameterize the approximated posterior of instance embedding as a marginal von MisesFisher distribution to account for the interference of distributional latent bias. Then, we incorporate a suite of critical geometric properties to impose proper constraints on the layout of constructed embedding space, which in turn minimizes the uncontrollable risk for unknown class learning and structuring. Furthermore, a spectral graph-theoretic method is devised to estimate the number of potential novel classes. It inherits two intriguing merits compared to existent approaches, namely high computational efficiency and flexibility for taxonomy-adaptive estimation. Extensive experiments across various biomedical scenarios substantiate the effectiveness and general applicability of our method.","[{'name': 'Jianan Fan, Dongnan Liu, Hang Chang, Heng Huang, Mei Chen, Weidong Cai'}]",
1643,Towards Full Authorship with AI: Supporting Revision with AI-Generated Views,https://arxiv.org/abs/2403.01055,"arXiv:2403.01055v1 Announce Type: cross 
Abstract: Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user's authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals' UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity.","[{'name': 'Jiho Kim, Ray C. Flanagan, Noelle E. Haviland, ZeAi Sun, Souad N. Yakubu, Edom A. Maru, Kenneth C. Arnold'}]",
1644,GraphRCG: Self-conditioned Graph Generation via Bootstrapped Representations,https://arxiv.org/abs/2403.01071,"arXiv:2403.01071v1 Announce Type: cross 
Abstract: Graph generation generally aims to create new graphs that closely align with a specific graph distribution. Existing works often implicitly capture this distribution through the optimization of generators, potentially overlooking the intricacies of the distribution itself. Furthermore, these approaches generally neglect the insights offered by the learned distribution for graph generation. In contrast, in this work, we propose a novel self-conditioned graph generation framework designed to explicitly model graph distributions and employ these distributions to guide the generation process. We first perform self-conditioned modeling to capture the graph distributions by transforming each graph sample into a low-dimensional representation and optimizing a representation generator to create new representations reflective of the learned distribution. Subsequently, we leverage these bootstrapped representations as self-conditioned guidance for the generation process, thereby facilitating the generation of graphs that more accurately reflect the learned distributions. We conduct extensive experiments on generic and molecular graph datasets across various fields. Our framework demonstrates superior performance over existing state-of-the-art graph generation methods in terms of graph quality and fidelity to training data.","[{'name': 'Song Wang, Zhen Tan, Xinyu Zhao, Tianlong Chen, Huan Liu, Jundong Li'}]",
1645,$\\Gamma$-VAE: Curvature regularized variational autoencoders for uncovering emergent low dimensional geometric structure in high dimensional data,https://arxiv.org/abs/2403.01078,"arXiv:2403.01078v1 Announce Type: cross 
Abstract: Natural systems with emergent behaviors often organize along low-dimensional subsets of high-dimensional spaces. For example, despite the tens of thousands of genes in the human genome, the principled study of genomics is fruitful because biological processes rely on coordinated organization that results in lower dimensional phenotypes. To uncover this organization, many nonlinear dimensionality reduction techniques have successfully embedded high-dimensional data into low-dimensional spaces by preserving local similarities between data points. However, the nonlinearities in these methods allow for too much curvature to preserve general trends across multiple non-neighboring data clusters, thereby limiting their interpretability and generalizability to out-of-distribution data. Here, we address both of these limitations by regularizing the curvature of manifolds generated by variational autoencoders, a process we coin ``$\\Gamma$-VAE''. We demonstrate its utility using two example data sets: bulk RNA-seq from the The Cancer Genome Atlas (TCGA) and the Genotype Tissue Expression (GTEx); and single cell RNA-seq from a lineage tracing experiment in hematopoietic stem cell differentiation. We find that the resulting regularized manifolds identify mesoscale structure associated with different cancer cell types, and accurately re-embed tissues from completely unseen, out-of distribution cancers as if they were originally trained on them. Finally, we show that preserving long-range relationships to differentiated cells separates undifferentiated cells -- which have not yet specialized -- according to their eventual fate. Broadly, we anticipate that regularizing the curvature of generative models will enable more consistent, predictive, and generalizable models in any high-dimensional system with emergent low-dimensional behavior.","[{'name': 'Jason Z. Kim, Nicolas Perrin-Gilbert, Erkan Narmanli, Paul Klein, Christopher R. Myers, Itai Cohen, Joshua J. Waterfall, James P. Sethna'}]",
1646,Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework,https://arxiv.org/abs/2403.01079,"arXiv:2403.01079v1 Announce Type: cross 
Abstract: We study the challenging problem for inference tasks on large-scale graph datasets of Graph Neural Networks: huge time and memory consumption, and try to overcome it by reducing reliance on graph structure. Even though distilling graph knowledge to student MLP is an excellent idea, it faces two major problems of positional information loss and low generalization. To solve the problems, we propose a new three-stage multitask distillation framework. In detail, we use Positional Encoding to capture positional information. Also, we introduce Neural Heat Kernels responsible for graph data processing in GNN and utilize hidden layer outputs matching for better performance of student MLP's hidden layers. To the best of our knowledge, it is the first work to include hidden layer distillation for student MLP on graphs and to combine graph Positional Encoding with MLP. We test its performance and robustness with several settings and draw the conclusion that our work can outperform well with good stability.","[{'name': 'Junxian Li, Bin Shi, Erfei Cui, Hua Wei, Qinghua Zheng'}]",
1647,COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for Traffic Forecasting,https://arxiv.org/abs/2403.01091,"arXiv:2403.01091v1 Announce Type: cross 
Abstract: This paper investigates traffic forecasting, which attempts to forecast the future state of traffic based on historical situations. This problem has received ever-increasing attention in various scenarios and facilitated the development of numerous downstream applications such as urban planning and transportation management. However, the efficacy of existing methods remains sub-optimal due to their tendency to model temporal and spatial relationships independently, thereby inadequately accounting for complex high-order interactions of both worlds. Moreover, the diversity of transitional patterns in traffic forecasting makes them challenging to capture for existing approaches, warranting a deeper exploration of their diversity. Toward this end, this paper proposes Conjoint Spatio-Temporal graph neural network (abbreviated as COOL), which models heterogeneous graphs from prior and posterior information to conjointly capture high-order spatio-temporal relationships. On the one hand, heterogeneous graphs connecting sequential observation are constructed to extract composite spatio-temporal relationships via prior message passing. On the other hand, we model dynamic relationships using constructed affinity and penalty graphs, which guide posterior message passing to incorporate complementary semantic information into node representations. Moreover, to capture diverse transitional properties to enhance traffic forecasting, we propose a conjoint self-attention decoder that models diverse temporal patterns from both multi-rank and multi-scale views. Experimental results on four popular benchmark datasets demonstrate that our proposed COOL provides state-of-the-art performance compared with the competitive baselines.","[{'name': 'Wei Ju, Yusheng Zhao, Yifang Qin, Siyu Yi, Jingyang Yuan, Zhiping Xiao, Xiao Luo, Xiting Yan, Ming Zhang'}]",
1648,Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models,https://arxiv.org/abs/2403.01101,"arXiv:2403.01101v1 Announce Type: cross 
Abstract: Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, which may even outweigh the computational cost savings. In this paper, we argue the performance drop stems not only from pre-computed features' inability to distinguish between categories of labeled samples, resulting in the selection of redundant samples but also from the tendency to compromise valuable pre-trained information when fine-tuning with samples selected through the proxy model. To address this issue, we propose a novel method called aligned selection via proxy to update pre-computed features while selecting a proper training method to inherit valuable pre-training information. Extensive experiments validate that our method significantly improves the total cost of efficient active learning while maintaining computational efficiency.","[{'name': 'Ziting Wen, Oscar Pizarro, Stefan Williams'}]",
1649,Distilling Text Style Transfer With Self-Explanation From LLMs,https://arxiv.org/abs/2403.01106,"arXiv:2403.01106v1 Announce Type: cross 
Abstract: Text Style Transfer (TST) seeks to alter the style of text while retaining its core content. Given the constraints of limited parallel datasets for TST, we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills the complex rewriting and reasoning capabilities of LLMs into more streamlined models capable of working with both non-parallel and parallel data. Through experimentation across four TST datasets, CoTeX is shown to surpass traditional supervised fine-tuning and knowledge distillation methods, particularly in low-resource settings. We conduct a comprehensive evaluation, comparing CoTeX against current unsupervised, supervised, in-context learning (ICL) techniques, and instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering transparent explanations for its style transfer process.","[{'name': 'Chiyu ZhangMusic, Honglong CaiMusic,  YuezhangMusic,  Li, Yuexin Wu, Le Hou, Muhammad Abdul-Mageed'}]",
1650,Adversarial Testing for Visual Grounding via Image-Aware Property Reduction,https://arxiv.org/abs/2403.01118,"arXiv:2403.01118v1 Announce Type: cross 
Abstract: Due to the advantages of fusing information from various modalities, multimodal learning is gaining increasing attention. Being a fundamental task of multimodal learning, Visual Grounding (VG), aims to locate objects in images through natural language expressions. Ensuring the quality of VG models presents significant challenges due to the complex nature of the task. In the black box scenario, existing adversarial testing techniques often fail to fully exploit the potential of both modalities of information. They typically apply perturbations based solely on either the image or text information, disregarding the crucial correlation between the two modalities, which would lead to failures in test oracles or an inability to effectively challenge VG models. To this end, we propose PEELING, a text perturbation approach via image-aware property reduction for adversarial testing of the VG model. The core idea is to reduce the property-related information in the original expression meanwhile ensuring the reduced expression can still uniquely describe the original object in the image. To achieve this, PEELING first conducts the object and properties extraction and recombination to generate candidate property reduction expressions. It then selects the satisfied expressions that accurately describe the original object while ensuring no other objects in the image fulfill the expression, through querying the image with a visual understanding technique. We evaluate PEELING on the state-of-the-art VG model, i.e. OFA-VG, involving three commonly used datasets. Results show that the adversarial tests generated by PEELING achieves 21.4% in MultiModal Impact score (MMI), and outperforms state-of-the-art baselines for images and texts by 8.2%--15.1%.","[{'name': 'Zhiyuan Chang, Mingyang Li, Junjie Wang, Cheng Li, Boyu Wu, Fanjiang Xu, Qing Wang'}]",
1651,OpenGraph: Towards Open Graph Foundation Models,https://arxiv.org/abs/2403.01121,"arXiv:2403.01121v1 Announce Type: cross 
Abstract: Graph learning has become indispensable for interpreting and harnessing relational data in diverse fields, ranging from recommendation systems to social network analysis. In this context, a variety of GNNs have emerged as promising methodologies for encoding the structural information of graphs. By effectively capturing the graph's underlying structure, these GNNs have shown great potential in enhancing performance in graph learning tasks, such as link prediction and node classification. However, despite their successes, a significant challenge persists: these advanced methods often face difficulties in generalizing to unseen graph data that significantly differs from the training instances. In this work, our aim is to advance the graph learning paradigm by developing a general graph foundation model. This model is designed to understand the complex topological patterns present in diverse graph data, enabling it to excel in zero-shot graph learning tasks across different downstream datasets. To achieve this goal, we address several key technical challenges in our OpenGraph model. Firstly, we propose a unified graph tokenizer to adapt our graph model to generalize well on unseen graph data, even when the underlying graph properties differ significantly from those encountered during training. Secondly, we develop a scalable graph transformer as the foundational encoder, which effectively captures node-wise dependencies within the global topological context. Thirdly, we introduce a data augmentation mechanism enhanced by a LLM to alleviate the limitations of data scarcity in real-world scenarios. Extensive experiments validate the effectiveness of our framework. By adapting our OpenGraph to new graph characteristics and comprehending the nuances of diverse graphs, our approach achieves remarkable zero-shot graph learning performance across various settings and domains.","[{'name': 'Lianghao Xia, Ben Kao, Chao Huang'}]",
1652,LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation,https://arxiv.org/abs/2403.01131,"arXiv:2403.01131v1 Announce Type: cross 
Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior optimization performance compared to GPT-4 Turbo and the other competitors across both synthetic and realistic problem sets. The fine-tuned model and the usage instructions are available at https://anonymous.4open.science/r/LLaMoCo-722A.","[{'name': 'Zeyuan Ma, Hongshu Guo, Jiacheng Chen, Guojun Peng, Zhiguang Cao, Yining Ma, Yue-Jiao Gong'}]",
1653,LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization,https://arxiv.org/abs/2403.01136,"arXiv:2403.01136v1 Announce Type: cross 
Abstract: Recent breakthroughs in Large-scale language models (LLMs) have demonstrated impressive performance on various tasks. The immense sizes of LLMs have led to very high resource demand and cost for running the models. Though the models are largely served using uniform high-caliber GPUs nowadays, utilizing a heterogeneous cluster with a mix of available high- and low-capacity GPUs can potentially substantially reduce the serving cost. There is a lack of designs to support efficient LLM serving using a heterogeneous cluster, while the current solutions focus on model partition and uniform compression among homogeneous devices. This paper proposes LLM-PQ, a system that advocates adaptive model quantization and phase-aware partition to improve LLM serving efficiency on heterogeneous GPU clusters. We carefully decide on mixed-precision model quantization together with phase-aware model partition and micro-batch sizing in distributed LLM serving with an efficient algorithm, to greatly enhance inference throughput while fulfilling user-specified model quality targets. Extensive experiments on production inference workloads in 11 different clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on average) throughput improvement in inference, showing great advantages over state-of-the-art works.","[{'name': 'Juntao Zhao, Borui Wan, Yanghua Peng, Haibin Lin, Chuan Wu'}]",
1654,ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies,https://arxiv.org/abs/2403.01139,"arXiv:2403.01139v1 Announce Type: cross 
Abstract: Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy. In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes. We publish a gold-set, validated by humans, and a silver-set, generated automatically. We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best models (~13% gap) after a light supervision. We demonstrate that our silver-set is useful for training models. Lastly, we show challenging distractors confuse LLMs, but not humans. We hope our pipeline will encourage research in this emerging field.","[{'name': 'Oren Sultan, Yonatan Bitton, Ron Yosef, Dafna Shahaf'}]",
1655,A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model,https://arxiv.org/abs/2403.01147,"arXiv:2403.01147v1 Announce Type: cross 
Abstract: In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information. This enables the realization of intelligent traffic control and management. Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances. A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges. Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection. Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against the baseline model. The results demonstrate that the proposed model enhances the dataset size, balances the dataset, and improves the performance of traffic incident detection in various aspects.","[{'name': 'Xinying Lu, Doudou Zhang, Jianli Xiao'}]",
1656,"A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization",https://arxiv.org/abs/2403.01152,"arXiv:2403.01152v1 Announce Type: cross 
Abstract: We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furthermore, we explore available resources for AI-generated text forensics research and discuss the evolving challenges and future directions of forensic systems in an AI era.","[{'name': 'Tharindu Kumarage, Garima Agrawal, Paras Sheth, Raha Moraffah, Aman Chadha, Joshua Garland, Huan Liu'}]",
1657,STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models,https://arxiv.org/abs/2403.01165,"arXiv:2403.01165v1 Announce Type: cross 
Abstract: Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning. For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation. Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks.","[{'name': 'Linhai Zhang, Jialong Wu, Deyu Zhou, Guoqiang Xu'}]",
1658,DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference,https://arxiv.org/abs/2403.01166,"arXiv:2403.01166v1 Announce Type: cross 
Abstract: Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review). In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA. In this framework, different types of biases are tackled based on different causal intervention methods. For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is employed for debiasing. For the aspect branch, the bias is described as a direct correlation with labels, where counterfactual reasoning is adopted for debiasing. Extensive experiments demonstrate the effectiveness of the proposed method compared to various baselines on the two widely used real-world aspect robustness test set datasets.","[{'name': 'Jialong Wu, Linhai Zhang, Deyu Zhou, Guoqiang Xu'}]",
1659,Leveraging Self-Supervised Learning for Scene Recognition in Child Sexual Abuse Imagery,https://arxiv.org/abs/2403.01183,"arXiv:2403.01183v1 Announce Type: cross 
Abstract: Crime in the 21st century is split into a virtual and real world. However, the former has become a global menace to people's well-being and security in the latter. The challenges it presents must be faced with unified global cooperation, and we must rely more than ever on automated yet trustworthy tools to combat the ever-growing nature of online offenses. Over 10 million child sexual abuse reports are submitted to the US National Center for Missing & Exploited Children every year, and over 80% originated from online sources. Therefore, investigation centers and clearinghouses cannot manually process and correctly investigate all imagery. In light of that, reliable automated tools that can securely and efficiently deal with this data are paramount. In this sense, the scene recognition task looks for contextual cues in the environment, being able to group and classify child sexual abuse data without requiring to be trained on sensitive material. The scarcity and limitations of working with child sexual abuse images lead to self-supervised learning, a machine-learning methodology that leverages unlabeled data to produce powerful representations that can be more easily transferred to target tasks. This work shows that self-supervised deep learning models pre-trained on scene-centric data can reach 71.6% balanced accuracy on our indoor scene classification task and, on average, 2.2 percentage points better performance than a fully supervised version. We cooperate with Brazilian Federal Police experts to evaluate our indoor classification model on actual child abuse material. The results demonstrate a notable discrepancy between the features observed in widely used scene datasets and those depicted on sensitive materials.","[{'name': 'Pedro H. V. Valois, Jo\\\\~ao Macedo, Leo S. F. Ribeiro, Jefersson A. dos Santos, Sandra Avila'}]",
1660,Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding,https://arxiv.org/abs/2403.01185,"arXiv:2403.01185v1 Announce Type: cross 
Abstract: Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluating its impact on negation understanding. Our experimental results exhibit the effectiveness of balancing exploration and exploitation with RLLF in improving LLMs' negation capabilities. This has implications for the development of more accurate, reliable, and logically consistent language models in high-stakes domains.","[{'name': 'Ha-Thanh Nguyen, Ken Satoh'}]",
1661,RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots,https://arxiv.org/abs/2403.01193,"arXiv:2403.01193v1 Announce Type: cross 
Abstract: Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge. This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings. This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and discuss implications for the development of more trustworthy LLMs.","[{'name': 'Philip Feldman. James R. Foulds, Shimei Pan'}]",
1662,Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021,https://arxiv.org/abs/2403.01196,"arXiv:2403.01196v1 Announce Type: cross 
Abstract: Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points.","[{'name': \"S\\\\'eamus Lankford, Haithem Afli, Andy Way\"}]",
1663,SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters,https://arxiv.org/abs/2403.01210,"arXiv:2403.01210v1 Announce Type: cross 
Abstract: Deep neural network-based Synthetic Aperture Radar (SAR) target recognition models are susceptible to adversarial examples. Current adversarial example generation methods for SAR imagery primarily operate in the 2D digital domain, known as image adversarial examples. Recent work, while considering SAR imaging scatter mechanisms, fails to account for the actual imaging process, rendering attacks in the three-dimensional physical domain infeasible, termed pseudo physics adversarial examples. To address these challenges, this paper proposes SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by altering the scattering feature parameters of target objects. Specifically, we iteratively optimize the coherent energy accumulation of the target echo by perturbing the reflection coefficient and scattering coefficient in the scattering feature parameters of the three-dimensional target object, and obtain the adversarial example after echo signal processing and imaging processing in the RaySAR simulator. Experimental results show that compared to digital adversarial attack methods, SAR-AE-SFP Attack significantly improves attack efficiency on CNN-based models (over 30\\%) and Transformer-based models (over 13\\%), demonstrating significant transferability of attack effects across different models and perspectives.","[{'name': 'Jiahao Cui, Jiale Duan, Binyan Luo, Hang Cao, Wang Guo, Haifeng Li'}]",
1664,API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access,https://arxiv.org/abs/2403.01216,"arXiv:2403.01216v1 Announce Type: cross 
Abstract: This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on both close-ended and open-ended Question Answering tasks show our approach can mostly outperform the logit-based CP baselines.","[{'name': 'Jiayuan Su, Jing Luo, Hongwei Wang, Lu Cheng'}]",
1665,A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations,https://arxiv.org/abs/2403.01221,"arXiv:2403.01221v1 Announce Type: cross 
Abstract: Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.","[{'name': \"Andr\\\\'e Artelt, Andreas Gregoriades\"}]",
1666,REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild,https://arxiv.org/abs/2403.01229,"arXiv:2403.01229v1 Announce Type: cross 
Abstract: Recognizing speaking in humans is a central task towards understanding social interactions. Ideally, speaking would be detected from individual voice recordings, as done previously for meeting scenarios. However, individual voice recordings are hard to obtain in the wild, especially in crowded mingling scenarios due to cost, logistics, and privacy concerns. As an alternative, machine learning models trained on video and wearable sensor data make it possible to recognize speech by detecting its related gestures in an unobtrusive, privacy-preserving way. These models themselves should ideally be trained using labels obtained from the speech signal. However, existing mingling datasets do not contain high quality audio recordings. Instead, speaking status annotations have often been inferred by human annotators from video, without validation of this approach against audio-based ground truth. In this paper we revisit no-audio speaking status estimation by presenting the first publicly available multimodal dataset with high-quality individual speech recordings of 33 subjects in a professional networking event. We present three baselines for no-audio speaking status segmentation: a) from video, b) from body acceleration (chest-worn accelerometer), c) from body pose tracks. In all cases we predict a 20Hz binary speaking status signal extracted from the audio, a time resolution not available in previous datasets. In addition to providing the signals and ground truth necessary to evaluate a wide range of speaking status detection methods, the availability of audio in REWIND makes it suitable for cross-modality studies not feasible with previous mingling datasets. Finally, our flexible data consent setup creates new challenges for multimodal systems under missing modalities.","[{'name': 'Jose Vargas Quiros, Chirag Raman, Stephanie Tan, Ekin Gedik, Laura Cabrera-Quiros, Hayley Hung'}]",
1667,Polynormer: Polynomial-Expressive Graph Transformer in Linear Time,https://arxiv.org/abs/2403.01232,"arXiv:2403.01232v1 Announce Type: cross 
Abstract: Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs). However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs. While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity. To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomial-expressive GT model with linear complexity. Polynormer is built upon a novel base model that learns a high-degree polynomial on input features. To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models. Consequently, Polynormer adopts a linear local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. Polynormer has been evaluated on $13$ homophilic and heterophilic datasets, including large graphs with millions of nodes. Our extensive experiment results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions.","[{'name': 'Chenhui Deng, Zichao Yue, Zhiru Zhang'}]",
1668,IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact,https://arxiv.org/abs/2403.01241,"arXiv:2403.01241v1 Announce Type: cross 
Abstract: Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outlier in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model. The approach is simple and easy to combine with existing quantization solutions. Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further. Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error. Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only INT4 quantization on various downstream tasks, leading to the new state-of-the-art for LLM quantization.","[{'name': 'Ruikang Liu, Haoli Bai, Haokun Lin, Yuening Li, Han Gao, Zhengzhuo Xu, Lu Hou, Jun Yao, Chun Yuan'}]",
1669,Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning,https://arxiv.org/abs/2403.01242,"arXiv:2403.01242v1 Announce Type: cross 
Abstract: Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach in enhancing user experience and expanding the capabilities of electric automation systems. Our work contributes to the advancement of smart technologies by providing a more seamless interaction between users and their environments.","[{'name': 'Lochan Basyal, Bijay Gaudel'}]",
1670,Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal,https://arxiv.org/abs/2403.01244,"arXiv:2403.01244v1 Announce Type: cross 
Abstract: Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in-context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high-quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable performance compared to conventional rehearsal-based approaches while being more data-efficient. Besides, SSR effectively preserves the generalization capabilities of LLMs in general domains.","[{'name': 'Jianheng Huang, Leyang Cui, Ante Wang, Chengyi Yang, Xinting Liao, Linfeng Song, Junfeng Yao, Jinsong Su'}]",
1671,SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code,https://arxiv.org/abs/2403.01248,"arXiv:2403.01248v1 Announce Type: cross 
Abstract: This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments. We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal.","[{'name': 'Ziniu Hu, Ahmet Iscen, Aashi Jain, Thomas Kipf, Yisong Yue, David A. Ross, Cordelia Schmid, Alireza Fathi'}]",
1672,Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey,https://arxiv.org/abs/2403.01255,"arXiv:2403.01255v1 Announce Type: cross 
Abstract: Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, RL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.","[{'name': 'Hamza Kheddar, Mustapha Hemis, Yassine Himeur'}]",
1673,NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention,https://arxiv.org/abs/2403.01273,"arXiv:2403.01273v1 Announce Type: cross 
Abstract: Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations. In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch. We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups. Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning. Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context length. Our results are reproducible at https://github.com/tonyzhang617/nomad-dist.","[{'name': 'Tianyi Zhang, Jonah Wonkyu Yi, Bowen Yao, Zhaozhuo Xu, Anshumali Shrivastava'}]",
1674,Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery,https://arxiv.org/abs/2403.01277,"arXiv:2403.01277v1 Announce Type: cross 
Abstract: We propose a generic multi-robot planning mechanism that combines an optimal task planner and an optimal path planner to provide a scalable solution for complex multi-robot planning problems. The Integrated planner, through the interaction of the task planner and the path planner, produces optimal collision-free trajectories for the robots. We illustrate our general algorithm on an object pick-and-drop planning problem in a warehouse scenario where a group of robots is entrusted with moving objects from one location to another in the workspace. We solve the task planning problem by reducing it into an SMT-solving problem and employing the highly advanced SMT solver Z3 to solve it. To generate collision-free movement of the robots, we extend the state-of-the-art algorithm Conflict Based Search with Precedence Constraints with several domain-specific constraints. We evaluate our integrated task and path planner extensively on various instances of the object pick-and-drop planning problem and compare its performance with a state-of-the-art multi-robot classical planner. Experimental results demonstrate that our planning mechanism can deal with complex planning problems and outperforms a state-of-the-art classical planner both in terms of computation time and the quality of the generated plan.","[{'name': 'Aman Aryan, Manan Modi, Indranil Saha, Rupak Majumdar, Swarup Mohalik'}]",
1675,Fast Low-parameter Video Activity Localization in Collaborative Learning Environments,https://arxiv.org/abs/2403.01281,"arXiv:2403.01281v1 Announce Type: cross 
Abstract: Research on video activity detection has primarily focused on identifying well-defined human activities in short video segments. The majority of the research on video activity recognition is focused on the development of large parameter systems that require training on large video datasets. This paper develops a low-parameter, modular system with rapid inferencing capabilities that can be trained entirely on limited datasets without requiring transfer learning from large-parameter systems. The system can accurately detect and associate specific activities with the students who perform the activities in real-life classroom videos. Additionally, the paper develops an interactive web-based application to visualize human activity maps over long real-life classroom videos.","[{'name': 'Venkatesh Jatla, Sravani Teeparthi, Ugesh Egala, Sylvia Celedon Pattichis, Marios S. Patticis'}]",
1676,Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People,https://arxiv.org/abs/2403.01286,"arXiv:2403.01286v1 Announce Type: cross 
Abstract: This is a summary paper of a use case of a Robotdog dedicated to guide visually impaired people in complex environment like a smart intersection. In such scenarios, the Robotdog has to autonomously decide whether it is safe to cross the intersection or not in order to further guide the human. We leverage data sharing and collaboration between the Robotdog and other autonomous systems operating in the same environment. We propose a system architecture for autonomous systems through a separation of a collaborative decision layer, to enable collective decision making processes, where data about the environment, relevant to the Robotdog decision, together with evidences for trustworthiness about other systems and the environment are shared.","[{'name': 'Aman Malhotra, Selma Saidi'}]",
1677,VBART: The Turkish LLM,https://arxiv.org/abs/2403.01308,"arXiv:2403.01308v1 Announce Type: cross 
Abstract: We present VBART, the first Turkish sequence-to-sequence Large Language Models (LLMs) pre-trained on a large corpus from scratch. VBART are compact LLMs based on good ideas leveraged from BART and mBART models and come in two sizes, Large and XLarge. Fine-tuned VBART models surpass the prior state-of-the-art results in abstractive text summarization, title generation, text paraphrasing, question answering and question generation tasks. They allow fine-tuning for future text generation tasks and datasets, carving a new path for Turkish Natural Language Processing (NLP) research. Our work shows that having a pre-trained LLM for Turkish outperforms up to 3x multilingual models, improving existing results and providing efficient models for training and inference. Moreover, we show that our monolingual tokenizer is 7x more efficient than OpenAI's multilingual tokenizer. Last but not least, we introduce a method to enlarge an existing pre-trained LLM and question the relevancy of Chinchilla Scaling Law to sequence-to-sequence masked language models. Our fine-tuned models, tokenizer and cleaned web corpus of 135 GB are publicly available at huggingface.co/vngrs-ai.","[{'name': 'Meliksah Turker, Mehmet Erdi Ari, Aydin Han'}]",
1678,VNLP: Turkish NLP Package,https://arxiv.org/abs/2403.01309,"arXiv:2403.01309v1 Announce Type: cross 
Abstract: In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language. It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models. Its token classification models are based on \"Context Model\", a novel architecture that is both an encoder and an auto-regressive model. NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and command-line API and a demo page to test all the functionality. Consequently, our main contribution is a complete, compact, easy-to-install and easy-to-use NLP package for Turkish.","[{'name': 'Meliksah Turker, Mehmet Erdi Ari, Aydin Han'}]",
1679,Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models,https://arxiv.org/abs/2403.01329,"arXiv:2403.01329v1 Announce Type: cross 
Abstract: This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver distillation approach to improve sample efficiency of Diffusion and Flow models. BNS solvers are based on a family of non-stationary solvers that provably subsumes existing numerical ODE solvers and consequently demonstrate considerable improvement in sample approximation (PSNR) over these baselines. Compared to model distillation, BNS solvers benefit from a tiny parameter space ($<$200 parameters), fast optimization (two orders of magnitude faster), maintain diversity of samples, and in contrast to previous solver distillation approaches nearly close the gap from standard distillation methods such as Progressive Distillation in the low-medium NFE regime. For example, BNS solver achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We experimented with BNS solvers for conditional image generation, text-to-image generation, and text-2-audio generation showing significant improvement in sample approximation (PSNR) in all.","[{'name': 'Neta Shaul, Uriel Singer, Ricky T. Q. Chen, Matthew Le, Ali Thabet, Albert Pumarola, Yaron Lipman'}]",
1680,Chaining thoughts and LLMs to learn DNA structural biophysics,https://arxiv.org/abs/2403.01332,"arXiv:2403.01332v1 Announce Type: cross 
Abstract: The future development of an AI scientist, a tool that is capable of integrating a variety of experimental data and generating testable hypotheses, holds immense potential. So far, bespoke machine learning models have been created to specialize in singular scientific tasks, but otherwise lack the flexibility of a general purpose model. Here, we show that a general purpose large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the structural biophysics of DNA. We find that both fine-tuning models to return chain-of-thought responses and chaining together models fine-tuned for subtasks have an enhanced ability to analyze and design DNA sequences and their structures.","[{'name': 'Tyler D. Ross, Ashwin Gopinath'}]",
1681,SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization,https://arxiv.org/abs/2403.01348,"arXiv:2403.01348v1 Announce Type: cross 
Abstract: Indoor localization is a critical task in many embedded applications, such as asset tracking, emergency response, and realtime navigation. In this article, we propose a novel fingerprintingbased framework for indoor localization called SANGRIA that uses stacked autoencoder neural networks with gradient boosted trees. Our approach is designed to overcome the device heterogeneity challenge that can create uncertainty in wireless signal measurements across embedded devices used for localization. We compare SANGRIA to several state-of-the-art frameworks and demonstrate 42.96% lower average localization error across diverse indoor locales and heterogeneous devices.","[{'name': 'Danish Gufran, Saideep Tiku, Sudeep Pasricha'}]",
1682,A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement,https://arxiv.org/abs/2403.01369,"arXiv:2403.01369v1 Announce Type: cross 
Abstract: Self-supervised learned models have been found to be very effective for certain speech tasks such as automatic speech recognition, speaker identification, keyword spotting and others. While the features are undeniably useful in speech recognition and associated tasks, their utility in speech enhancement systems is yet to be firmly established, and perhaps not properly understood. In this paper, we investigate the uses of SSL representations for single-channel speech enhancement in challenging conditions and find that they add very little value for the enhancement task. Our constraints are designed around on-device real-time speech enhancement -- model is causal, the compute footprint is small. Additionally, we focus on low SNR conditions where such models struggle to provide good enhancement. In order to systematically examine how SSL representations impact performance of such enhancement models, we propose a variety of techniques to utilize these embeddings which include different forms of knowledge-distillation and pre-training.","[{'name': 'Ravi Shankar, Ke Tan, Buye Xu, Anurag Kumar'}]",
1683,On the Compressibility of Quantized Large Language Models,https://arxiv.org/abs/2403.01384,"arXiv:2403.01384v1 Announce Type: cross 
Abstract: Deploying Large Language Models (LLMs) on edge or mobile devices offers significant benefits, such as enhanced data privacy and real-time processing capabilities. However, it also faces critical challenges due to the substantial memory requirement of LLMs. Quantization is an effective way of reducing the model size while maintaining good performance. However, even after quantization, LLMs may still be too big to fit entirely into the limited memory of edge or mobile devices and have to be partially loaded from the storage to complete the inference. In this case, the I/O latency of model loading becomes the bottleneck of the LLM inference latency. In this work, we take a preliminary step of studying applying data compression techniques to reduce data movement and thus speed up the inference of quantized LLM on memory-constrained devices. In particular, we discussed the compressibility of quantized LLMs, the trade-off between the compressibility and performance of quantized LLMs, and opportunities to optimize both of them jointly.","[{'name': 'Yu Mao, Weilan Wang, Hongchao Du, Nan Guan, Chun Jason Xue'}]",
1684,Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks,https://arxiv.org/abs/2403.01400,"arXiv:2403.01400v1 Announce Type: cross 
Abstract: Recent years have witnessed the great success of graph pre-training for graph representation learning. With hundreds of graph pre-training tasks proposed, integrating knowledge acquired from multiple pre-training tasks has become a popular research topic. In this paper, we identify two important collaborative processes for this topic: (1) select: how to select an optimal task combination from a given task pool based on their compatibility, and (2) weigh: how to weigh the selected tasks based on their importance. While there currently has been a lot of work focused on weighing, comparatively little effort has been devoted to selecting. This paper proposes a novel instance-level framework for integrating multiple graph pre-training tasks, Weigh And Select (WAS), where the two collaborative processes, weighing and selecting, are combined by decoupled siamese networks. Specifically, it first adaptively learns an optimal combination of tasks for each instance from a given task pool, based on which a customized instance-level task weighing strategy is learned. Extensive experiments on 16 graph datasets across node-level and graph-level downstream tasks have demonstrated that by combining a few simple but classical tasks, WAS can achieve comparable performance to other leading counterparts. The code is available at https://github.com/TianyuFan0504/WAS.","[{'name': 'Tianyu Fan, Lirong Wu, Yufei Huang, Haitao Lin, Cheng Tan, Zhangyang Gao, Stan Z. Li'}]",
1685,Region-Transformer: Self-Attention Region Based Class-Agnostic Point Cloud Segmentation,https://arxiv.org/abs/2403.01407,"arXiv:2403.01407v1 Announce Type: cross 
Abstract: Point cloud segmentation, which helps us understand the environment of specific structures and objects, can be performed in class-specific and class-agnostic ways. We propose a novel region-based transformer model called Region-Transformer for performing class-agnostic point cloud segmentation. The model utilizes a region-growth approach and self-attention mechanism to iteratively expand or contract a region by adding or removing points. It is trained on simulated point clouds with instance labels only, avoiding semantic labels. Attention-based networks have succeeded in many previous methods of performing point cloud segmentation. However, a region-growth approach with attention-based networks has yet to be used to explore its performance gain. To our knowledge, we are the first to use a self-attention mechanism in a region-growth approach. With the introduction of self-attention to region-growth that can utilize local contextual information of neighborhood points, our experiments demonstrate that the Region-Transformer model outperforms previous class-agnostic and class-specific methods on indoor datasets regarding clustering metrics. The model generalizes well to large-scale scenes. Key advantages include capturing long-range dependencies through self-attention, avoiding the need for semantic labels during training, and applicability to a variable number of objects. The Region-Transformer model represents a promising approach for flexible point cloud segmentation with applications in robotics, digital twinning, and autonomous vehicles.","[{'name': 'Dipesh Gyawali, Jian Zhang, BB Karki'}]",
1686,Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults,https://arxiv.org/abs/2403.01413,"arXiv:2403.01413v1 Announce Type: cross 
Abstract: Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults' attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.","[{'name': 'Yucheng Jin, Wanling Cai, Li Chen, Yizhe Zhang, Gavin Doherty, Tonglin Jiang'}]",
1687,BrainMass: Advancing Brain Network Analysis for Diagnosis with Large-scale Self-Supervised Learning,https://arxiv.org/abs/2403.01433,"arXiv:2403.01433v1 Announce Type: cross 
Abstract: Foundation models pretrained on large-scale datasets via self-supervised learning demonstrate exceptional versatility across various tasks. Due to the heterogeneity and hard-to-collect medical data, this approach is especially beneficial for medical image analysis and neuroscience research, as it streamlines broad downstream tasks without the need for numerous costly annotations. However, there has been limited investigation into brain network foundation models, limiting their adaptability and generalizability for broad neuroscience studies. In this study, we aim to bridge this gap. In particular, (1) we curated a comprehensive dataset by collating images from 30 datasets, which comprises 70,781 samples of 46,686 participants. Moreover, we introduce pseudo-functional connectivity (pFC) to further generates millions of augmented brain networks by randomly dropping certain timepoints of the BOLD signal. (2) We propose the BrainMass framework for brain network self-supervised learning via mask modeling and feature alignment. BrainMass employs Mask-ROI Modeling (MRM) to bolster intra-network dependencies and regional specificity. Furthermore, Latent Representation Alignment (LRA) module is utilized to regularize augmented brain networks of the same participant with similar topological properties to yield similar latent representations by aligning their latent embeddings. Extensive experiments on eight internal tasks and seven external brain disorder diagnosis tasks show BrainMass's superior performance, highlighting its significant generalizability and adaptability. Nonetheless, BrainMass demonstrates powerful few/zero-shot learning abilities and exhibits meaningful interpretation to various diseases, showcasing its potential use for clinical applications.","[{'name': 'Yanwu Yang, Chenfei Ye, Guinan Su, Ziyao Zhang, Zhikai Chang, Hairui Chen, Piu Chan, Yue Yu, Ting Ma'}]",
1688,GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features,https://arxiv.org/abs/2403.01437,"arXiv:2403.01437v1 Announce Type: cross 
Abstract: Moment retrieval (MR) and highlight detection (HD) aim to identify relevant moments and highlights in video from corresponding natural language query. Large language models (LLMs) have demonstrated proficiency in various computer vision tasks. However, existing methods for MR\\&amp;HD have not yet been integrated with LLMs. In this letter, we propose a novel two-stage model that takes the output of LLMs as the input to the second-stage transformer encoder-decoder. First, MiniGPT-4 is employed to generate the detailed description of the video frame and rewrite the query statement, fed into the encoder as new features. Then, semantic similarity is computed between the generated description and the rewritten queries. Finally, continuous high-similarity video frames are converted into span anchors, serving as prior position information for the decoder. Experiments demonstrate that our approach achieves a state-of-the-art result, and by using only span anchors and similarity scores as outputs, positioning accuracy outperforms traditional methods, like Moment-DETR.","[{'name': 'Yunzhuo Sun, Yifang Xu, Zien Xie, Yukun Shu, Sidan Du'}]",
1689,Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment,https://arxiv.org/abs/2403.01456,"arXiv:2403.01456v1 Announce Type: cross 
Abstract: Item difficulty plays a crucial role in adaptive testing. However, few works have focused on generating questions of varying difficulty levels, especially for multiple-choice (MC) cloze tests. We propose training pre-trained language models (PLMs) as surrogate models to enable item response theory (IRT) assessment, avoiding the need for human test subjects. We also propose two strategies to control the difficulty levels of both the gaps and the distractors using ranking rules to reduce invalid distractors. Experimentation on a benchmark dataset demonstrates that our proposed framework and methods can effectively control and evaluate the difficulty levels of MC cloze tests.","[{'name': 'Jingshen Zhang, Jiajun Xie, Xinying Qiu'}]",
1690,Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation,https://arxiv.org/abs/2403.01467,"arXiv:2403.01467v1 Announce Type: cross 
Abstract: Unsupervised Graph Domain Adaptation (UGDA) has emerged as a practical solution to transfer knowledge from a label-rich source graph to a completely unlabelled target graph. However, most methods require a labelled source graph to provide supervision signals, which might not be accessible in the real-world settings due to regulations and privacy concerns. In this paper, we explore the scenario of source-free unsupervised graph domain adaptation, which tries to address the domain adaptation problem without accessing the labelled source graph. Specifically, we present a novel paradigm called GraphCTA, which performs model adaptation and graph adaptation collaboratively through a series of procedures: (1) conduct model adaptation based on node's neighborhood predictions in target graph considering both local and global information; (2) perform graph adaptation by updating graph structure and node attributes via neighborhood contrastive learning; and (3) the updated graph serves as an input to facilitate the subsequent iteration of model adaptation, thereby establishing a collaborative loop between model adaptation and graph adaptation. Comprehensive experiments are conducted on various public datasets. The experimental results demonstrate that our proposed model outperforms recent source-free baselines by large margins.","[{'name': 'Zhen Zhang, Meihan Liu, Anhui Wang, Hongyang Chen, Zhao Li, Jiajun Bu, Bingsheng He'}]",
1691,Representation Learning on Heterophilic Graph with Directional Neighborhood Attention,https://arxiv.org/abs/2403.01475,"arXiv:2403.01475v1 Announce Type: cross 
Abstract: Graph Attention Network (GAT) is one of the most popular Graph Neural Network (GNN) architecture, which employs the attention mechanism to learn edge weights and has demonstrated promising performance in various applications. However, since it only incorporates information from immediate neighborhood, it lacks the ability to capture long-range and global graph information, leading to unsatisfactory performance on some datasets, particularly on heterophilic graphs. To address this limitation, we propose the Directional Graph Attention Network (DGAT) in this paper. DGAT is able to combine the feature-based attention with the global directional information extracted from the graph topology. To this end, a new class of Laplacian matrices is proposed which can provably reduce the diffusion distance between nodes. Based on the new Laplacian, topology-guided neighbour pruning and edge adding mechanisms are proposed to remove the noisy and capture the helpful long-range neighborhood information. Besides, a global directional attention is designed to enable a topological-aware information propagation. The superiority of the proposed DGAT over the baseline GAT has also been verified through experiments on real-world benchmarks and synthetic data sets. It also outperforms the state-of-the-art (SOTA) models on 6 out of 7 real-world benchmark datasets.","[{'name': 'Qincheng Lu, Jiaqi Zhu, Sitao Luan, Xiao-Wen Chang'}]",
1692,Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation,https://arxiv.org/abs/2403.01479,"arXiv:2403.01479v1 Announce Type: cross 
Abstract: The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation. Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb and WMT-2014 En->De, respectively, compared to Transformer baselines.","[{'name': 'Heegon Jin, Seonil Son, Jemin Park, Youngseok Kim, Hyungjong Noh, Yeonsoo Lee'}]",
1693,Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models,https://arxiv.org/abs/2403.01489,"arXiv:2403.01489v1 Announce Type: cross 
Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image generative models. Comprehensive experiments reveal that (1) Our method can effectively attribute fake images to their source models, achieving comparable attribution performance with the state-of-the-art method; (2) Our method has high scalability ability, which is well adapted to real-world attribution scenarios. (3) The proposed method yields satisfactory robustness to common attacks, such as Gaussian blurring, JPEG compression, and Resizing. We also analyze the factors that influence the attribution performance, and explore the boost brought by the proposed method as a plug-in to improve the performance of existing SOTA. We hope our work can shed some light on the solutions to addressing the source of AI-generated images, as well as to prevent the misuse of text-to-image generative models.","[{'name': 'Meiling Li, Zhenxing Qian, Xinpeng Zhang'}]",
1694,End-to-End Human Instance Matting,https://arxiv.org/abs/2403.01510,"arXiv:2403.01510v1 Announce Type: cross 
Abstract: Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspondences of all instances. Finally, an instance matting network decodes the image features and united semantics guidance to predict all instance-level alpha mattes. In addition, we construct a large-scale human instance matting dataset (HIM-100K) comprising over 100,000 human images with instance alpha matte labels. Experiments on HIM-100K demonstrate the proposed E2E-HIM outperforms the existing methods on human instance matting with 50% lower errors and 5X faster speed (6 instances in a 640X640 image). Experiments on the PPM-100, RWP-636, and P3M datasets demonstrate that E2E-HIM also achieves competitive performance on traditional human matting.","[{'name': 'Qinglin Liu, Shengping Zhang, Quanling Meng, Bineng Zhong, Peiqiang Liu, Hongxun Yao'}]",
1695,Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey,https://arxiv.org/abs/2403.01528,"arXiv:2403.01528v1 Announce Type: cross 
Abstract: The integration of biomolecular modeling with natural language (BL) has emerged as a promising interdisciplinary area at the intersection of artificial intelligence, chemistry and biology. This approach leverages the rich, multifaceted descriptions of biomolecules contained within textual data sources to enhance our fundamental understanding and enable downstream computational tasks such as biomolecule property prediction. The fusion of the nuanced narratives expressed through natural language with the structural and functional specifics of biomolecules described via various molecular modeling techniques opens new avenues for comprehensively representing and analyzing biomolecules. By incorporating the contextual language data that surrounds biomolecules into their modeling, BL aims to capture a holistic view encompassing both the symbolic qualities conveyed through language as well as quantitative structural characteristics. In this review, we provide an extensive analysis of recent advancements achieved through cross modeling of biomolecules and natural language. (1) We begin by outlining the technical representations of biomolecules employed, including sequences, 2D graphs, and 3D structures. (2) We then examine in depth the rationale and key objectives underlying effective multi-modal integration of language and molecular data sources. (3) We subsequently survey the practical applications enabled to date in this developing research area. (4) We also compile and summarize the available resources and datasets to facilitate future work. (5) Looking ahead, we identify several promising research directions worthy of further exploration and investment to continue advancing the field. The related resources and contents are updating in \\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.","[{'name': 'Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Yue Wang, Zun Wang, Tao Qin, Rui Yan'}]",
1696,Machine learning predicts long-term mortality after acute myocardial infarction using systolic time intervals and routinely collected clinical data,https://arxiv.org/abs/2403.01533,"arXiv:2403.01533v1 Announce Type: cross 
Abstract: Precise estimation of cardiac patients' current and future comorbidities is an important factor in prioritizing continuous physiological monitoring and new therapies. ML models have shown satisfactory performance in short-term mortality prediction of patients with heart disease, while their utility in long-term predictions is limited. This study aims to investigate the performance of tree-based ML models on long-term mortality prediction and the effect of two recently introduced biomarkers on long-term mortality. This study utilized publicly available data from CCHIA at the Ministry of Health and Welfare, Taiwan, China. Medical records were used to gather demographic and clinical data, including age, gender, BMI, percutaneous coronary intervention (PCI) status, and comorbidities such as hypertension, dyslipidemia, ST-segment elevation myocardial infarction (STEMI), and non-STEMI. Using medical and demographic records as well as two recently introduced biomarkers, brachial pre-ejection period (bPEP) and brachial ejection time (bET), collected from 139 patients with acute myocardial infarction, we investigated the performance of advanced ensemble tree-based ML algorithms (random forest, AdaBoost, and XGBoost) to predict all-cause mortality within 14 years. The developed ML models achieved significantly better performance compared to the baseline LR (C-Statistic, 0.80 for random forest, 0.79 for AdaBoost, and 0.78 for XGBoost, vs 0.77 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). Adding bPEP and bET to our feature set significantly improved the algorithms' performance, leading to an absolute increase in C-Statistic of up to 0.03 (C-Statistic, 0.83 for random forest, 0.82 for AdaBoost, and 0.80 for XGBoost, vs 0.74 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). This advancement may enable better treatment prioritization for high-risk individuals.","[{'name': 'Bijan Roudini, Boshra Khajehpiri, Hamid Abrishami Moghaddam, Mohamad Forouzanfar'}]",
1697,In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation,https://arxiv.org/abs/2403.01548,"arXiv:2403.01548v1 Announce Type: cross 
Abstract: Large language models (LLMs) frequently hallucinate and produce factual errors, yet our understanding of why they make these errors remains limited. In this study, we delve into the underlying mechanisms of LLM hallucinations from the perspective of inner representations, and discover a salient pattern associated with hallucinations: correct generations tend to have sharper context activations in the hidden states of the in-context tokens, compared to the incorrect ones. Leveraging this insight, we propose an entropy-based metric to quantify the ``sharpness'' among the in-context hidden states and incorporate it into the decoding process to formulate a constrained decoding approach. Experiments on various knowledge-seeking and hallucination benchmarks demonstrate our approach's consistent effectiveness, for example, achieving up to an 8.6 point improvement on TruthfulQA. We believe this study can improve our understanding of hallucinations and serve as a practical solution for hallucination mitigation.","[{'name': 'Shiqi Chen, Miao Xiong, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, Junxian He'}]",
1698,ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates,https://arxiv.org/abs/2403.01564,"arXiv:2403.01564v1 Announce Type: cross 
Abstract: Optimal decision-making for trajectory tracking in partially observable, stochastic environments where the number of active localization updates -- the process by which the agent obtains its true state information from the sensors -- are limited, presents a significant challenge. Traditional methods often struggle to balance resource conservation, accurate state estimation and precise tracking, resulting in suboptimal performance. This problem is particularly pronounced in environments with large action spaces, where the need for frequent, accurate state data is paramount, yet the capacity for active localization updates is restricted by external limitations. This paper introduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN) and Model Predictive Control (MPC) to optimize trajectory tracking with constrained active localization updates. The meta-trained DQN ensures adaptive active localization scheduling, while the MPC leverages available state information to improve tracking. The central contribution of this work is their reciprocal interaction: DQN's update decisions inform MPC's control strategy, and MPC's outcomes refine DQN's learning, creating a cohesive, adaptive system. Empirical evaluations in simulated and real-world settings demonstrate that ComTraQ-MPC significantly enhances operational efficiency and accuracy, providing a generalizable and approximately optimal solution for trajectory tracking in complex partially observable environments.","[{'name': 'Gokul Puthumanaillam, Manav Vora, Melkior Ornik'}]",
1699,ReMatch: Retrieval Enhanced Schema Matching with LLMs,https://arxiv.org/abs/2403.01567,"arXiv:2403.01567v1 Announce Type: cross 
Abstract: Schema matching is a crucial task in data integration, involving the alignment of a source database schema with a target schema to establish correspondence between their elements. This task is challenging due to textual and semantic heterogeneity, as well as differences in schema sizes. Although machine-learning-based solutions have been explored in numerous studies, they often suffer from low accuracy, require manual mapping of the schemas for model training, or need access to source schema data which might be unavailable due to privacy concerns. In this paper we present a novel method, named ReMatch, for matching schemas using retrieval-enhanced Large Language Models (LLMs). Our method avoids the need for predefined mapping, any model training, or access to data in the source database. In the ReMatch method the tables of the target schema and the attributes of the source schema are first represented as structured passage-based documents. For each source attribute document, we retrieve $J$ documents, representing target schema tables, according to their semantic relevance. Subsequently, we create a prompt for every source table, comprising all its attributes and their descriptions, alongside all attributes from the set of top $J$ target tables retrieved previously. We employ LLMs using this prompt for the matching task, yielding a ranked list of $K$ potential matches for each source attribute. Our experimental results on large real-world schemas demonstrate that ReMatch significantly improves matching capabilities and outperforms other machine learning approaches. By eliminating the requirement for training data, ReMatch becomes a viable solution for real-world scenarios.","[{'name': 'Eitam Sheetrit, Menachem Brief, Moshik Mishaeli, Oren Elisha'}]",
1700,Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV,https://arxiv.org/abs/2403.01569,"arXiv:2403.01569v1 Announce Type: cross 
Abstract: Self-supervised learning is the key to unlocking generic computer vision systems. By eliminating the reliance on ground-truth annotations, it allows scaling to much larger data quantities. Unfortunately, self-supervised monocular depth estimation (SS-MDE) has been limited by the absence of diverse training data. Existing datasets have focused exclusively on urban driving in densely populated cities, resulting in models that fail to generalize beyond this domain.
  To address these limitations, this paper proposes two novel datasets: SlowTV and CribsTV. These are large-scale datasets curated from publicly available YouTube videos, containing a total of 2M training frames. They offer an incredibly diverse set of environments, ranging from snowy forests to coastal roads, luxury mansions and even underwater coral reefs. We leverage these datasets to tackle the challenging task of zero-shot generalization, outperforming every existing SS-MDE approach and even some state-of-the-art supervised methods.
  The generalization capabilities of our models are further enhanced by a range of components and contributions: 1) learning the camera intrinsics, 2) a stronger augmentation regime targeting aspect ratio changes, 3) support frame randomization, 4) flexible motion estimation, 5) a modern transformer-based architecture. We demonstrate the effectiveness of each component in extensive ablation experiments. To facilitate the development of future research, we make the datasets, code and pretrained models available to the public at https://github.com/jspenmar/slowtv_monodepth.","[{'name': 'Jaime Spencer, Chris Russell, Simon Hadfield, Richard Bowden'}]",
1701,SARD: A Human-AI Collaborative Story Generation,https://arxiv.org/abs/2403.01575,"arXiv:2403.01575v1 Announce Type: cross 
Abstract: Generative artificial intelligence (GenAI) has ushered in a new era for storytellers, providing a powerful tool to ignite creativity and explore uncharted narrative territories. As technology continues to advance, the synergy between human creativity and AI-generated content holds the potential to redefine the landscape of storytelling. In this work, we propose SARD, a drag-and-drop visual interface for generating a multi-chapter story using large language models. Our evaluation of the usability of SARD and its creativity support shows that while node-based visualization of the narrative may help writers build a mental model, it exerts unnecessary mental overhead to the writer and becomes a source of distraction as the story becomes more elaborated. We also found that AI generates stories that are less lexically diverse, irrespective of the complexity of the story. We identified some patterns and limitations of our tool that can guide the development of future human-AI co-writing tools.","[{'name': 'Ahmed Y. Radwan, Khaled M. Alasmari, Omar A. Abdulbagi, Emad A. Alghamdi'}]",
1702,"Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures",https://arxiv.org/abs/2403.01580,"arXiv:2403.01580v1 Announce Type: cross 
Abstract: In the current machine translation (MT) landscape, the Transformer architecture stands out as the gold standard, especially for high-resource language pairs. This research delves into its efficacy for low-resource language pairs including both the English$\\leftrightarrow$Irish and English$\\leftrightarrow$Marathi language pairs. Notably, the study identifies the optimal hyperparameters and subword model type to significantly improve the translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT development. To address this, gaHealth was developed, the first bilingual corpus of health data for the Irish language. Focusing on the health domain, models developed using this in-domain dataset exhibited very significant improvements in BLEU score when compared with models from the LoResMT2021 Shared Task. A subsequent human evaluation using the multidimensional quality metrics error taxonomy showcased the superior performance of the Transformer system in reducing both accuracy and fluency errors compared to an RNN-based counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source applications streamlined for the development, fine-tuning, and deployment of neural machine translation models. These tools considerably simplify the setup and evaluation process, making MT more accessible to both developers and translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes eco-friendly natural language processing research by highlighting the environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM demonstrated advancements in translation performance for two low-resource language pairs: English$\\leftrightarrow$Irish and English$\\leftrightarrow$Marathi, compared to baselines from the LoResMT2021 Shared Task.",[{'name': \"S\\\\'eamus Lankford\"}],
1703,APISR: Anime Production Inspired Real-World Anime Super-Resolution,https://arxiv.org/abs/2403.01598,"arXiv:2403.01598v1 Announce Type: cross 
Abstract: While real-world anime super-resolution (SR) has gained increasing attention in the SR community, existing methods still adopt techniques from the photorealistic domain. In this paper, we analyze the anime production workflow and rethink how to use characteristics of it for the sake of the real-world anime SR. First, we argue that video networks and datasets are not necessary for anime SR due to the repetition use of hand-drawing frames. Instead, we propose an anime image collection pipeline by choosing the least compressed and the most informative frames from the video sources. Based on this pipeline, we introduce the Anime Production-oriented Image (API) dataset. In addition, we identify two anime-specific challenges of distorted and faint hand-drawn lines and unwanted color artifacts. We address the first issue by introducing a prediction-oriented compression module in the image degradation model and a pseudo-ground truth preparation with enhanced hand-drawn lines. In addition, we introduce the balanced twin perceptual loss combining both anime and photorealistic high-level features to mitigate unwanted color artifacts and increase visual clarity. We evaluate our method through extensive experiments on the public benchmark, showing our method outperforms state-of-the-art approaches by a large margin.","[{'name': 'Boyang Wang, Fengyu Yang, Xihang Yu, Chao Zhang, Hanbin Zhao'}]",
1704,SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos,https://arxiv.org/abs/2403.01599,"arXiv:2403.01599v1 Announce Type: cross 
Abstract: We study the problem of procedure planning in instructional videos, which aims to make a goal-oriented sequence of action steps given partial visual state observations. The motivation of this problem is to learn a structured and plannable state and action space. Recent works succeeded in sequence modeling of steps with only sequence-level annotations accessible during training, which overlooked the roles of states in the procedures. In this work, we point out that State CHangEs MAtter (SCHEMA) for procedure planning in instructional videos. We aim to establish a more structured state space by investigating the causal relations between steps and states in procedures. Specifically, we explicitly represent each step as state changes and track the state changes in procedures. For step representation, we leveraged the commonsense knowledge in large language models (LLMs) to describe the state changes of steps via our designed chain-of-thought prompting. For state change tracking, we align visual state observations with language state descriptions via cross-modal contrastive learning, and explicitly model the intermediate states of the procedure using LLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV benchmark datasets demonstrate that our proposed SCHEMA model achieves state-of-the-art performance and obtains explainable visualizations.","[{'name': 'Yulei Niu, Wenliang Guo, Long Chen, Xudong Lin, Shih-Fu Chang'}]",
1705,Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making,https://arxiv.org/abs/2403.01600,"arXiv:2403.01600v1 Announce Type: cross 
Abstract: In the last decades, there has been a deceleration in the rates of poverty reduction, suggesting that traditional redistributive approaches to poverty mitigation could be losing effectiveness, and alternative insights to advance the number one UN Sustainable Development Goal are required. The criminalization of poor people has been denounced by several NGOs, and an increasing number of voices suggest that discrimination against the poor (a phenomenon known as \\emph{aporophobia}) could be an impediment to mitigating poverty. In this paper, we present the novel Aporophobia Agent-Based Model (AABM) to provide evidence of the correlation between aporophobia and poverty computationally. We present our use case built with real-world demographic data and poverty-mitigation public policies (either enforced or under parliamentary discussion) for the city of Barcelona. We classify policies as discriminatory or non-discriminatory against the poor, with the support of specialized NGOs, and we observe the results in the AABM in terms of the impact on wealth inequality. The simulation provides evidence of the relationship between aporophobia and the increase of wealth inequality levels, paving the way for a new generation of poverty reduction policies that act on discrimination and tackle poverty as a societal problem (not only a problem of the poor).","[{'name': 'Alba Aguilera, Nieves Montes, Georgina Curto, Carles Sierra, Nardine Osman'}]",
1706,Towards Provable Log Density Policy Gradient,https://arxiv.org/abs/2403.01605,"arXiv:2403.01605v1 Announce Type: cross 
Abstract: Policy gradient methods are a vital ingredient behind the success of modern reinforcement learning. Modern policy gradient methods, although successful, introduce a residual error in gradient estimation. In this work, we argue that this residual term is significant and correcting for it could potentially improve sample-complexity of reinforcement learning methods. To that end, we propose log density gradient to estimate the policy gradient, which corrects for this residual error term. Log density gradient method computes policy gradient by utilising the state-action discounted distributional formulation. We first present the equations needed to exactly find the log density gradient for a tabular Markov Decision Processes (MDPs). For more complex environments, we propose a temporal difference (TD) method that approximates log density gradient by utilizing backward on-policy samples. Since backward sampling from a Markov chain is highly restrictive we also propose a min-max optimization that can approximate log density gradient using just on-policy samples. We also prove uniqueness, and convergence under linear function approximation, for this min-max optimization. Finally, we show that the sample complexity of our min-max optimization to be of the order of $m^{-1/2}$, where $m$ is the number of on-policy samples. We also demonstrate a proof-of-concept for our log density gradient method on gridworld environment, and observe that our method is able to improve upon the classical policy gradient method by a clear margin, thus indicating a promising novel direction to develop reinforcement learning algorithms that require fewer samples.","[{'name': 'Pulkit Katdare, Anant Joshi, Katherine Driggs-Campbell'}]",
1707,A Unified Model Selection Technique for Spectral Clustering Based Motion Segmentation,https://arxiv.org/abs/2403.01606,"arXiv:2403.01606v1 Announce Type: cross 
Abstract: Motion segmentation is a fundamental problem in computer vision and is crucial in various applications such as robotics, autonomous driving and action recognition. Recently, spectral clustering based methods have shown impressive results on motion segmentation in dynamic environments. These methods perform spectral clustering on motion affinity matrices to cluster objects or point trajectories in the scene into different motion groups. However, existing methods often need the number of motions present in the scene to be known, which significantly reduces their practicality. In this paper, we propose a unified model selection technique to automatically infer the number of motion groups for spectral clustering based motion segmentation methods by combining different existing model selection techniques together. We evaluate our method on the KT3DMoSeg dataset and achieve competitve results comparing to the baseline where the number of clusters is given as ground truth information.","[{'name': 'Yuxiang Huang, John Zelek'}]",
1708,Machine Learning vs Deep Learning: The Generalization Problem,https://arxiv.org/abs/2403.01621,"arXiv:2403.01621v1 Announce Type: cross 
Abstract: The capacity to generalize beyond the range of training data is a pivotal challenge, often synonymous with a model's utility and robustness. This study investigates the comparative abilities of traditional machine learning (ML) models and deep learning (DL) algorithms in terms of extrapolation -- a more challenging aspect of generalization because it requires the model to make inferences about data points that lie outside the domain it has been trained on. We present an empirical analysis where both ML and DL models are trained on an exponentially growing function and then tested on values outside the training domain. The choice of this function allows us to distinctly showcase the divergence in performance when models are required to predict beyond the scope of their training data. Our findings suggest that deep learning models possess inherent capabilities to generalize beyond the training scope, an essential feature for real-world applications where data is often incomplete or extends beyond the observed range. This paper argues for a nuanced understanding of the structural differences between ML and DL models, with an emphasis on the implications for both theoretical research and practical deployment.","[{'name': 'Yong Yi Bay, Kathleen A. Yearick'}]",
1709,You Need to Pay Better Attention,https://arxiv.org/abs/2403.01643,"arXiv:2403.01643v1 Announce Type: cross 
Abstract: We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MNIST, CIFAR100, IMDB Movie Reviews, and Amazon Reviews datasets.","[{'name': 'Mehran Hosseini, Peyman Hosseini'}]",
1710,Recommendations for Government Development and Use of Advanced Automated Systems to Make Decisions about Individuals,https://arxiv.org/abs/2403.01649,"arXiv:2403.01649v1 Announce Type: cross 
Abstract: Contestability -- the ability to effectively challenge a decision -- is critical to the implementation of fairness. In the context of governmental decision making about individuals, contestability is often constitutionally required as an element of due process; specific procedures may be required by state or federal law relevant to a particular program. In addition, contestability can be a valuable way to discover systemic errors, contributing to ongoing assessments and system improvement.
  On January 24-25, 2024, with support from the National Science Foundation and the William and Flora Hewlett Foundation, we convened a diverse group of government officials, representatives of leading technology companies, technology and policy experts from academia and the non-profit sector, advocates, and stakeholders for a workshop on advanced automated decision making, contestability, and the law. Informed by the workshop's rich and wide-ranging discussion, we offer these recommendations. A full report summarizing the discussion is in preparation.","[{'name': 'Susan Landau, James X. Dempsey, Ece Kamar, Steven M. Bellovin'}]",
1711,CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables,https://arxiv.org/abs/2403.01673,"arXiv:2403.01673v1 Announce Type: cross 
Abstract: For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D temporal-contextual attention mechanism, which generates Auxiliary Time Series (ATS) from Original Time Series (OTS) to effectively represent and incorporate inter-series relationships for forecasting. Key principles of ATS - continuity, sparsity, and variability - are identified and implemented through different modules. Even with a basic 2-layer MLP as core predictor, CATS achieves state-of-the-art, significantly reducing complexity and parameters compared to previous multivariate models, marking it an efficient and transferable MTSF solution.","[{'name': 'Jiecheng Lu, Xu Han, Yan Sun, Shihao Yang'}]",
1712,HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances,https://arxiv.org/abs/2403.01693,"arXiv:2403.01693v1 Announce Type: cross 
Abstract: Text-to-image generative models can generate high-quality humans, but realism is lost when generating hands. Common artifacts include irregular hand poses, shapes, incorrect numbers of fingers, and physically implausible finger orientations. To generate images with realistic hands, we propose a novel diffusion-based architecture called HanDiffuser that achieves realism by injecting hand embeddings in the generative process. HanDiffuser consists of two components: a Text-to-Hand-Params diffusion model to generate SMPL-Body and MANO-Hand parameters from input text prompts, and a Text-Guided Hand-Params-to-Image diffusion model to synthesize images by conditioning on the prompts and hand parameters generated by the previous component. We incorporate multiple aspects of hand representation, including 3D shapes and joint-level finger positions, orientations and articulations, for robust learning and reliable performance during inference. We conduct extensive quantitative and qualitative experiments and perform user studies to demonstrate the efficacy of our method in generating images with high-quality hands.","[{'name': 'Supreeth Narasimhaswamy, Uttaran Bhattacharya, Xiang Chen, Ishita Dasgupta, Saayan Mitra, Minh Hoai'}]",
1713,DyCE: Dynamic Configurable Exiting for Deep Learning Compression and Scaling,https://arxiv.org/abs/2403.01695,"arXiv:2403.01695v1 Announce Type: cross 
Abstract: Modern deep learning (DL) models necessitate the employment of scaling and compression techniques for effective deployment in resource-constrained environments. Most existing techniques, such as pruning and quantization are generally static. On the other hand, dynamic compression methods, such as early exits, reduce complexity by recognizing the difficulty of input samples and allocating computation as needed. Dynamic methods, despite their superior flexibility and potential for co-existing with static methods, pose significant challenges in terms of implementation due to any changes in dynamic parts will influence subsequent processes. Moreover, most current dynamic compression designs are monolithic and tightly integrated with base models, thereby complicating the adaptation to novel base models. This paper introduces DyCE, an dynamic configurable early-exit framework that decouples design considerations from each other and from the base model. Utilizing this framework, various types and positions of exits can be organized according to predefined configurations, which can be dynamically switched in real-time to accommodate evolving performance-complexity requirements. We also propose techniques for generating optimized configurations based on any desired trade-off between performance and computational complexity. This empowers future researchers to focus on the improvement of individual exits without latent compromise of overall system performance. The efficacy of this approach is demonstrated through image classification tasks with deep CNNs. DyCE significantly reduces the computational complexity by 23.5% of ResNet152 and 25.9% of ConvNextv2-tiny on ImageNet, with accuracy reductions of less than 0.5%. Furthermore, DyCE offers advantages over existing dynamic methods in terms of real-time configuration and fine-grained performance tuning.","[{'name': \"Qingyuan Wang, Barry Cardiff, Antoine Frapp\\\\'e, Benoit Larras, Deepu John\"}]",
1714,Hypertext Entity Extraction in Webpage,https://arxiv.org/abs/2403.01698,"arXiv:2403.01698v1 Announce Type: cross 
Abstract: Webpage entity extraction is a fundamental natural language processing task in both research and applications. Nowadays, the majority of webpage entity extraction models are trained on structured datasets which strive to retain textual content and its structure information. However, existing datasets all overlook the rich hypertext features (e.g., font color, font size) which show their effectiveness in previous works. To this end, we first collect a \\textbf{H}ypertext \\textbf{E}ntity \\textbf{E}xtraction \\textbf{D}ataset (\\textit{HEED}) from the e-commerce domains, scraping both the text and the corresponding explicit hypertext features with high-quality manual entity annotations. Furthermore, we present the \\textbf{Mo}E-based \\textbf{E}ntity \\textbf{E}xtraction \\textbf{F}ramework (\\textit{MoEEF}), which efficiently integrates multiple features to enhance model performance by Mixture of Experts and outperforms strong baselines, including the state-of-the-art small-scale models and GPT-3.5-turbo. Moreover, the effectiveness of hypertext features in \\textit{HEED} and several model components in \\textit{MoEEF} are analyzed.","[{'name': 'Yifei Yang, Tianqiao Liu, Bo Shao, Hai Zhao, Linjun Shou, Ming Gong, Daxin Jiang'}]",
1715,Brilla AI: AI Contestant for the National Science and Maths Quiz,https://arxiv.org/abs/2403.01699,"arXiv:2403.01699v1 Announce Type: cross 
Abstract: The African continent lacks enough qualified teachers which hampers the provision of adequate learning support. An AI could potentially augment the efforts of the limited number of teachers, leading to better learning outcomes. Towards that end, this work describes and evaluates the first key output for the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for such an AI: \"Build an AI to compete live in Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing better than the best contestants in all rounds and stages of the competition\". The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. In this work, we built Brilla AI, an AI contestant that we deployed to unofficially compete remotely and live in the Riddles round of the 2023 NSMQ Grand Finale, the first of its kind in the 30-year history of the competition. Brilla AI is currently available as a web app that livestreams the Riddles round of the contest, and runs 4 machine learning systems: (1) speech to text (2) question extraction (3) question answering and (4) text to speech that work together in real-time to quickly and accurately provide an answer, and then say it with a Ghanaian accent. In its debut, our AI answered one of the 4 riddles ahead of the 3 human contesting teams, unofficially placing second (tied). Improvements and extensions of this AI could potentially be deployed to offer science tutoring to students and eventually enable millions across Africa to have one-on-one learning interactions, democratizing science education.","[{'name': 'George Boateng, Jonathan Abrefah Mensah, Kevin Takyi Yeboah, William Edor, Andrew Kojo Mensah-Onumah, Naafi Dasana Ibrahim, Nana Sam Yeboah'}]",
1716,Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study,https://arxiv.org/abs/2403.01709,"arXiv:2403.01709v1 Announce Type: cross 
Abstract: Architectural Knowledge Management (AKM) involves the organized handling of information related to architectural decisions and design within a project or organization. An essential artifact of AKM is the Architecture Decision Records (ADR), which documents key design decisions. ADRs are documents that capture decision context, decision made and various aspects related to a design decision, thereby promoting transparency, collaboration, and understanding. Despite their benefits, ADR adoption in software development has been slow due to challenges like time constraints and inconsistent uptake. Recent advancements in Large Language Models (LLMs) may help bridge this adoption gap by facilitating ADR generation. However, the effectiveness of LLM for ADR generation or understanding is something that has not been explored. To this end, in this work, we perform an exploratory study that aims to investigate the feasibility of using LLM for the generation of ADRs given the decision context. In our exploratory study, we utilize GPT and T5-based models with 0-shot, few-shot, and fine-tuning approaches to generate the Decision of an ADR given its Context. Our results indicate that in a 0-shot setting, state-of-the-art models such as GPT-4 generate relevant and accurate Design Decisions, although they fall short of human-level performance. Additionally, we observe that more cost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot setting, and smaller models such as Flan-T5 can yield comparable results after fine-tuning. To conclude, this exploratory study suggests that LLM can generate Design Decisions, but further research is required to attain human-level generation and establish standardized widespread adoption.","[{'name': 'Rudra Dhar, Karthik Vaidhyanathan, Vasudeva Varma'}]",
1717,Offline Goal-Conditioned Reinforcement Learning for Safety-Critical Tasks with Recovery Policy,https://arxiv.org/abs/2403.01734,"arXiv:2403.01734v1 Announce Type: cross 
Abstract: Offline goal-conditioned reinforcement learning (GCRL) aims at solving goal-reaching tasks with sparse rewards from an offline dataset. While prior work has demonstrated various approaches for agents to learn near-optimal policies, these methods encounter limitations when dealing with diverse constraints in complex environments, such as safety constraints. Some of these approaches prioritize goal attainment without considering safety, while others excessively focus on safety at the expense of training efficiency. In this paper, we study the problem of constrained offline GCRL and propose a new method called Recovery-based Supervised Learning (RbSL) to accomplish safety-critical tasks with various goals. To evaluate the method performance, we build a benchmark based on the robot-fetching environment with a randomly positioned obstacle and use expert or random policies to generate an offline dataset. We compare RbSL with three offline GCRL algorithms and one offline safe RL algorithm. As a result, our method outperforms the existing state-of-the-art methods to a large extent. Furthermore, we validate the practicality and effectiveness of RbSL by deploying it on a real Panda manipulator. Code is available at https://github.com/Sunlighted/RbSL.git.","[{'name': 'Chenyang Cao, Zichen Yan, Renhao Lu, Junbo Tan, Xueqian Wang'}]",
1718,Diffusion-TS: Interpretable Diffusion for General Time Series Generation,https://arxiv.org/abs/2403.01742,"arXiv:2403.01742v1 Announce Type: cross 
Abstract: Denoising diffusion probabilistic models (DDPMs) are becoming the leading paradigm for generative models. It has recently shown breakthroughs in audio synthesis, time series imputation and forecasting. In this paper, we propose Diffusion-TS, a novel diffusion-based framework that generates multivariate time series samples of high quality by using an encoder-decoder transformer with disentangled temporal representations, in which the decomposition technique guides Diffusion-TS to capture the semantic meaning of time series while transformers mine detailed sequential information from the noisy model input. Different from existing diffusion-based approaches, we train the model to directly reconstruct the sample instead of the noise in each diffusion step, combining a Fourier-based loss term. Diffusion-TS is expected to generate time series satisfying both interpretablity and realness. In addition, it is shown that the proposed Diffusion-TS can be easily extended to conditional generation tasks, such as forecasting and imputation, without any model changes. This also motivates us to further explore the performance of Diffusion-TS under irregular settings. Finally, through qualitative and quantitative experiments, results show that Diffusion-TS achieves the state-of-the-art results on various realistic analyses of time series.","[{'name': 'Xinyu Yuan, Yan Qiao'}]",
1719,Decode Neural signal as Speech,https://arxiv.org/abs/2403.01748,"arXiv:2403.01748v1 Announce Type: cross 
Abstract: Decoding language from brain dynamics is an important open direction in the realm of brain-computer interface (BCI), especially considering the rapid growth of large language models. Compared to invasive-based signals which require electrode implantation surgery, non-invasive neural signals (e.g. EEG, MEG) have attracted increasing attention considering their safety and generality. However, the exploration is not adequate in three aspects: 1) previous methods mainly focus on EEG but none of the previous works address this problem on MEG with better signal quality; 2) prior works have predominantly used ``teacher-forcing\" during generative decoding, which is impractical; 3) prior works are mostly ``BART-based\" not fully auto-regressive, which performs better in other sequence tasks. In this paper, we explore the brain-to-text translation of MEG signals in a speech-decoding formation. Here we are the first to investigate a cross-attention-based ``whisper\" model for generating text directly from MEG signals without teacher forcing. Our model achieves impressive BLEU-1 scores of 60.30 and 52.89 without pretraining \\& teacher-forcing on two major datasets (\\textit{GWilliams} and \\textit{Schoffelen}). This paper conducts a comprehensive review to understand how speech decoding formation performs on the neural decoding tasks, including pretraining initialization, training \\& evaluation set splitting, augmentation, and scaling law.","[{'name': 'Yiqian Yang, Yiqun Duan, Qiang Zhang, Renjing Xu, Hui Xiong'}]",
1720,Canonical Form of Datatic Description in Control Systems,https://arxiv.org/abs/2403.01768,"arXiv:2403.01768v1 Announce Type: cross 
Abstract: The design of feedback controllers is undergoing a paradigm shift from modelic (i.e., model-driven) control to datatic (i.e., data-driven) control. Canonical form of state space model is an important concept in modelic control systems, exemplified by Jordan form, controllable form and observable form, whose purpose is to facilitate system analysis and controller synthesis. In the realm of datatic control, there is a notable absence in the standardization of data-based system representation. This paper for the first time introduces the concept of canonical data form for the purpose of achieving more effective design of datatic controllers. In a control system, the data sample in canonical form consists of a transition component and an attribute component. The former encapsulates the plant dynamics at the sampling time independently, which is a tuple containing three elements: a state, an action and their corresponding next state. The latter describes one or some artificial characteristics of the current sample, whose calculation must be performed in an online manner. The attribute of each sample must adhere to two requirements: (1) causality, ensuring independence from any future samples; and (2) locality, allowing dependence on historical samples but constrained to a finite neighboring set. The purpose of adding attribute is to offer some kinds of benefits for controller design in terms of effectiveness and efficiency. To provide a more close-up illustration, we present two canonical data forms: temporal form and spatial form, and demonstrate their advantages in reducing instability and enhancing training efficiency in two datatic control systems.","[{'name': 'Guojian Zhan, Ziang Zheng, Shengbo Eben Li'}]",
1721,A Safe Screening Rule with Bi-level Optimization of $\\nu$ Support Vector Machine,https://arxiv.org/abs/2403.01769,"arXiv:2403.01769v1 Announce Type: cross 
Abstract: Support vector machine (SVM) has achieved many successes in machine learning, especially for a small sample problem. As a famous extension of the traditional SVM, the $\\nu$ support vector machine ($\\nu$-SVM) has shown outstanding performance due to its great model interpretability. However, it still faces challenges in training overhead for large-scale problems. To address this issue, we propose a safe screening rule with bi-level optimization for $\\nu$-SVM (SRBO-$\\nu$-SVM) which can screen out inactive samples before training and reduce the computational cost without sacrificing the prediction accuracy. Our SRBO-$\\nu$-SVM is strictly deduced by integrating the Karush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex problems and the $\\nu$-property. Furthermore, we develop an efficient dual coordinate descent method (DCDM) to further improve computational speed. Finally, a unified framework for SRBO is proposed to accelerate many SVM-type models, and it is successfully applied to one-class SVM. Experimental results on 6 artificial data sets and 30 benchmark data sets have verified the effectiveness and safety of our proposed methods in supervised and unsupervised tasks.","[{'name': 'Zhiji Yang, Wanyi Chen, Huan Zhang, Yitian Xu, Lei Shi, Jianhua Zhao'}]",
1722,Improving out-of-distribution generalization in graphs via hierarchical semantic environments,https://arxiv.org/abs/2403.01773,"arXiv:2403.01773v1 Announce Type: cross 
Abstract: Out-of-distribution (OOD) generalization in the graph domain is challenging due to complex distribution shifts and a lack of environmental contexts. Recent methods attempt to enhance graph OOD generalization by generating flat environments. However, such flat environments come with inherent limitations to capture more complex data distributions. Considering the DrugOOD dataset, which contains diverse training environments (e.g., scaffold, size, etc.), flat contexts cannot sufficiently address its high heterogeneity. Thus, a new challenge is posed to generate more semantically enriched environments to enhance graph invariant learning for handling distribution shifts. In this paper, we propose a novel approach to generate hierarchical semantic environments for each graph. Firstly, given an input graph, we explicitly extract variant subgraphs from the input graph to generate proxy predictions on local environments. Then, stochastic attention mechanisms are employed to re-extract the subgraphs for regenerating global environments in a hierarchical manner. In addition, we introduce a new learning objective that guides our model to learn the diversity of environments within the same hierarchy while maintaining consistency across different hierarchies. This approach enables our model to consider the relationships between environments and facilitates robust graph invariant learning. Extensive experiments on real-world graph data have demonstrated the effectiveness of our framework. Particularly, in the challenging dataset DrugOOD, our method achieves up to 1.29\\% and 2.83\\% improvement over the best baselines on IC50 and EC50 prediction tasks, respectively.","[{'name': 'Yinhua Piao, Sangseon Lee, Yijingxiu Lu, Sun Kim'}]",
1723,Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning,https://arxiv.org/abs/2403.01781,"arXiv:2403.01781v1 Announce Type: cross 
Abstract: In the realm of computer vision and graphics, accurately establishing correspondences between geometric 3D shapes is pivotal for applications like object tracking, registration, texture transfer, and statistical shape analysis. Moving beyond traditional hand-crafted and data-driven feature learning methods, we incorporate spectral methods with deep learning, focusing on functional maps (FMs) and optimal transport (OT). Traditional OT-based approaches, often reliant on entropy regularization OT in learning-based framework, face computational challenges due to their quadratic cost. Our key contribution is to employ the sliced Wasserstein distance (SWD) for OT, which is a valid fast optimal transport metric in an unsupervised shape matching framework. This unsupervised framework integrates functional map regularizers with a novel OT-based loss derived from SWD, enhancing feature alignment between shapes treated as discrete probability measures. We also introduce an adaptive refinement process utilizing entropy regularized OT, further refining feature alignments for accurate point-to-point correspondences. Our method demonstrates superior performance in non-rigid shape matching, including near-isometric and non-isometric scenarios, and excels in downstream tasks like segmentation transfer. The empirical results on diverse datasets highlight our framework's effectiveness and generalization capabilities, setting new standards in non-rigid shape matching with efficient OT metrics and an adaptive refinement module.","[{'name': 'Tung Le, Khai Nguyen, Shanlin Sun, Nhat Ho, Xiaohui Xie'}]",
1724,Beyond Recommender: An Exploratory Study of the Effects of Different AI Roles in AI-Assisted Decision Making,https://arxiv.org/abs/2403.01791,"arXiv:2403.01791v1 Announce Type: cross 
Abstract: Artificial Intelligence (AI) is increasingly employed in various decision-making tasks, typically as a Recommender, providing recommendations that the AI deems correct. However, recent studies suggest this may diminish human analytical thinking and lead to humans' inappropriate reliance on AI, impairing the synergy in human-AI teams. In contrast, human advisors in group decision-making perform various roles, such as analyzing alternative options or criticizing decision-makers to encourage their critical thinking. This diversity of roles has not yet been empirically explored in AI assistance. In this paper, we examine three AI roles: Recommender, Analyzer, and Devil's Advocate, and evaluate their effects across two AI performance levels. Our results show each role's distinct strengths and limitations in task performance, reliance appropriateness, and user experience. Notably, the Recommender role is not always the most effective, especially if the AI performance level is low, the Analyzer role may be preferable. These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.","[{'name': 'Shuai Ma, Chenyi Zhang, Xinru Wang, Xiaojuan Ma, Ming Yin'}]",
1725,COLA: Cross-city Mobility Transformer for Human Trajectory Simulation,https://arxiv.org/abs/2403.01801,"arXiv:2403.01801v1 Announce Type: cross 
Abstract: Human trajectory data produced by daily mobile devices has proven its usefulness in various substantial fields such as urban planning and epidemic prevention. In terms of the individual privacy concern, human trajectory simulation has attracted increasing attention from researchers, targeting at offering numerous realistic mobility data for downstream tasks. Nevertheless, the prevalent issue of data scarcity undoubtedly degrades the reliability of existing deep learning models. In this paper, we are motivated to explore the intriguing problem of mobility transfer across cities, grasping the universal patterns of human trajectories to augment the powerful Transformer with external mobility data. There are two crucial challenges arising in the knowledge transfer across cities: 1) how to transfer the Transformer to adapt for domain heterogeneity; 2) how to calibrate the Transformer to adapt for subtly different long-tail frequency distributions of locations. To address these challenges, we have tailored a Cross-city mObiLity trAnsformer (COLA) with a dedicated model-agnostic transfer framework by effectively transferring cross-city knowledge for human trajectory simulation. Firstly, COLA divides the Transformer into the private modules for city-specific characteristics and the shared modules for city-universal mobility patterns. Secondly, COLA leverages a lightweight yet effective post-hoc adjustment strategy for trajectory simulation, without disturbing the complex bi-level optimization of model-agnostic knowledge transfer. Extensive experiments of COLA compared to state-of-the-art single-city baselines and our implemented cross-city baselines have demonstrated its superiority and effectiveness. The code is available at https://github.com/Star607/Cross-city-Mobility-Transformer.","[{'name': 'Yu Wang, Tongya Zheng, Yuxuan Liang, Shunyu Liu, Mingli Song'}]",
1726,AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation,https://arxiv.org/abs/2403.01818,"arXiv:2403.01818v1 Announce Type: cross 
Abstract: Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly complicated training pipeline designs. It can also be regarded as a flexible bottleneck module that can be seamlessly integrated into a general transformer-based segmentation model. The proposed AllSpark outperforms existing methods across all evaluation protocols on Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code and model weights are available at: https://github.com/xmed-lab/AllSpark.","[{'name': 'Haonan Wang, Qixiang Zhang, Yi Li, Xiaomeng Li'}]",
1727,RT-H: Action Hierarchies Using Language,https://arxiv.org/abs/2403.01823,"arXiv:2403.01823v1 Announce Type: cross 
Abstract: Language provides a way to break down complex concepts into digestible pieces. Recent works in robot imitation learning use language-conditioned policies that predict actions given visual observations and the high-level task specified in language. These methods leverage the structure of natural language to share data between semantically similar tasks (e.g., \"pick coke can\" and \"pick an apple\") in multi-task datasets. However, as tasks become more semantically diverse (e.g., \"pick coke can\" and \"pour cup\"), sharing data between tasks becomes harder, so learning to map high-level tasks to actions requires much more demonstration data. To bridge tasks and actions, our insight is to teach the robot the language of actions, describing low-level motions with more fine-grained phrases like \"move arm forward\". Predicting these language motions as an intermediate step between tasks and actions forces the policy to learn the shared structure of low-level motions across seemingly disparate tasks. Furthermore, a policy that is conditioned on language motions can easily be corrected during execution through human-specified language motions. This enables a new paradigm for flexible policies that can learn from human intervention in language. Our method RT-H builds an action hierarchy using language motions: it first learns to predict language motions, and conditioned on this and the high-level task, it predicts actions, using visual context at all stages. We show that RT-H leverages this language-action hierarchy to learn policies that are more robust and flexible by effectively tapping into multi-task datasets. We show that these policies not only allow for responding to language interventions, but can also learn from such interventions and outperform methods that learn from teleoperated interventions. Our website and videos are found at https://rt-hierarchy.github.io.","[{'name': 'Suneel Belkhale, Tianli Ding, Ted Xiao, Pierre Sermanet, Quon Vuong, Jonathan Tompson, Yevgen Chebotar, Debidatta Dwibedi, Dorsa Sadigh'}]",
1728,Analysis and Fully Memristor-based Reservoir Computing for Temporal Data Classification,https://arxiv.org/abs/2403.01827,"arXiv:2403.01827v1 Announce Type: cross 
Abstract: Reservoir computing (RC) offers a neuromorphic framework that is particularly effective for processing spatiotemporal signals. Known for its temporal processing prowess, RC significantly lowers training costs compared to conventional recurrent neural networks. A key component in its hardware deployment is the ability to generate dynamic reservoir states. Our research introduces a novel dual-memory RC system, integrating a short-term memory via a WOx-based memristor, capable of achieving 16 distinct states encoded over 4 bits, and a long-term memory component using a TiOx-based memristor within the readout layer. We thoroughly examine both memristor types and leverage the RC system to process temporal data sets. The performance of the proposed RC system is validated through two benchmark tasks: isolated spoken digit recognition with incomplete inputs and Mackey-Glass time series prediction. The system delivered an impressive 98.84% accuracy in digit recognition and sustained a low normalized root mean square error (NRMSE) of 0.036 in the time series prediction task, underscoring its capability. This study illuminates the adeptness of memristor-based RC systems in managing intricate temporal challenges, laying the groundwork for further innovations in neuromorphic computing.","[{'name': 'Ankur Singh, Sanghyeon Choi, Gunuk Wang, Maryaradhiya Daimari, Byung-Geun Lee'}]",
1729,FreeA: Human-object Interaction Detection using Free Annotation Labels,https://arxiv.org/abs/2403.01840,"arXiv:2403.01840v1 Announce Type: cross 
Abstract: Recent human-object interaction (HOI) detection approaches rely on high cost of manpower and require comprehensive annotated image datasets. In this paper, we propose a novel self-adaption language-driven HOI detection method, termed as FreeA, without labeling by leveraging the adaptability of CLIP to generate latent HOI labels. To be specific, FreeA matches image features of human-object pairs with HOI text templates, and a priori knowledge-based mask method is developed to suppress improbable interactions. In addition, FreeA utilizes the proposed interaction correlation matching method to enhance the likelihood of actions related to a specified action, further refine the generated HOI labels. Experiments on two benchmark datasets show that FreeA achieves state-of-the-art performance among weakly supervised HOI models. Our approach is +8.58 mean Average Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in localizing and classifying the interactive actions than the newest weakly model, and +1.68 mAP and +7.28 mAP than the latest weakly+ model, respectively. Code will be available at https://drliuqi.github.io/.","[{'name': 'Yuxiao Wang, Zhenao Wei, Xinyu Jiang, Yu Lei, Weiying Xue, Jinxiu Liu, Qi Liu'}]",
1730,NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models,https://arxiv.org/abs/2403.01845,"arXiv:2403.01845v1 Announce Type: cross 
Abstract: As machine learning (ML) algorithms get deployed in an ever-increasing number of applications, these algorithms need to achieve better trade-offs between high accuracy, high throughput and low latency. This paper introduces NASH, a novel approach that applies neural architecture search to machine learning hardware. Using NASH, hardware designs can achieve not only high throughput and low latency but also superior accuracy performance. We present four versions of the NASH strategy in this paper, all of which show higher accuracy than the original models. The strategy can be applied to various convolutional neural networks, selecting specific model operations among many to guide the training process toward higher accuracy. Experimental results show that applying NASH on ResNet18 or ResNet34 achieves a top 1 accuracy increase of up to 3.1% and a top 5 accuracy increase of up to 2.2% compared to the non-NASH version when tested on the ImageNet data set. We also integrated this approach into the FINN hardware model synthesis tool to automate the application of our approach and the generation of the hardware model. Results show that using FINN can achieve a maximum throughput of 324.5 fps. In addition, NASH models can also result in a better trade-off between accuracy and hardware resource utilization. The accuracy-hardware (HW) Pareto curve shows that the models with the four NASH versions represent the best trade-offs achieving the highest accuracy for a given HW utilization. The code for our implementation is open-source and publicly available on GitHub at https://github.com/MFJI/NASH.","[{'name': 'Mengfei Ji, Zaid Al-Ars'}]",
1731,One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models,https://arxiv.org/abs/2403.01849,"arXiv:2403.01849v1 Announce Type: cross 
Abstract: Large pre-trained Vision-Language Models (VLMs) like CLIP, despite having remarkable generalization ability, are highly vulnerable to adversarial examples. This work studies the adversarial robustness of VLMs from the novel perspective of the text prompt instead of the extensively studied model weights (frozen in this work). We first show that the effectiveness of both adversarial attack and defense are sensitive to the used text prompt. Inspired by this, we propose a method to improve resilience to adversarial attacks by learning a robust text prompt for VLMs. The proposed method, named Adversarial Prompt Tuning (APT), is effective while being both computationally and data efficient. Extensive experiments are conducted across 15 datasets and 4 data sparsity schemes (from 1-shot to full training data settings) to show APT's superiority over hand-engineered prompts and other state-of-the-art adaption methods. APT demonstrated excellent abilities in terms of the in-distribution performance and the generalization under input distribution shift and across datasets. Surprisingly, by simply adding one learned word to the prompts, APT can significantly boost the accuracy and robustness (epsilon=4/255) over the hand-engineered prompts by +13% and +8.5% on average respectively. The improvement further increases, in our most effective setting, to +26.4% for accuracy and +16.7% for robustness. Code is available at https://github.com/TreeLLi/APT.","[{'name': 'Lin Li, Haoyan Guan, Jianing Qiu, Michael Spratling'}]",
1732,Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral,https://arxiv.org/abs/2403.01851,"arXiv:2403.01851v1 Announce Type: cross 
Abstract: Mixtral, a representative sparse mixture of experts (SMoE) language model, has received significant attention due to its unique model design and superior performance. Based on Mixtral-8x7B-v0.1, in this paper, we propose Chinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language abilities by adopting further pre-training and instruction fine-tuning. Experimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct successfully improve Chinese understanding and generation performance while retaining the original English abilities. Then, we discuss several key questions when performing language adaptation on large language models, including the necessity of extending the language-specific vocabulary and the choice of the initialization model (foundation model v.s. instruction model), by providing empirical results and analysis. We also present the visualizations of each expert to examine their importance on downstream tasks. Our resources are publicly available through \\url{https://github.com/ymcui/Chinese-Mixtral}.","[{'name': 'Yiming Cui, Xin Yao'}]",
1733,AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes,https://arxiv.org/abs/2403.01861,"arXiv:2403.01861v1 Announce Type: cross 
Abstract: Indoor scenes we are living in are visually homogenous or textureless, while they inherently have structural forms and provide enough structural priors for 3D scene reconstruction. Motivated by this fact, we propose a structure-aware online signed distance fields (SDF) reconstruction framework in indoor scenes, especially under the Atlanta world (AW) assumption. Thus, we dub this incremental SDF reconstruction for AW as AiSDF. Within the online framework, we infer the underlying Atlanta structure of a given scene and then estimate planar surfel regions supporting the Atlanta structure. This Atlanta-aware surfel representation provides an explicit planar map for a given scene. In addition, based on these Atlanta planar surfel regions, we adaptively sample and constrain the structural regularity in the SDF reconstruction, which enables us to improve the reconstruction quality by maintaining a high-level structure while enhancing the details of a given scene. We evaluate the proposed AiSDF on the ScanNet and ReplicaCAD datasets, where we demonstrate that the proposed framework is capable of reconstructing fine details of objects implicitly, as well as structures explicitly in room-scale scenes.","[{'name': 'Jaehoon Jang, Inha Lee, Minje Kim, Kyungdon Joo'}]",
1734,ICLN: Input Convex Loss Network for Decision Focused Learning,https://arxiv.org/abs/2403.01875,"arXiv:2403.01875v1 Announce Type: cross 
Abstract: In decision-making problem under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused Learning (DFL) is a task-oriented framework to integrate prediction and optimization by adapting predictive model to give better decision for the corresponding task. Here, an inevitable challenge arises when computing gradients of the optimal decision with respect to the parameters. Existing researches cope this issue by smoothly reforming surrogate optimization or construct surrogate loss function that mimic task loss. However, they are applied to restricted optimization domain or build functions in a local manner leading a large computational time. In this paper, we propose Input Convex Loss Network (ICLN), a novel global surrogate loss which can be implemented in a general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks which is guaranteed to be convex for some inputs, while keeping the global structure for the other inputs. This enables ICLN to admit general DFL through only a single surrogate loss without any sense for choosing appropriate parametric forms. We confirm effectiveness and flexibility of ICLN by evaluating our proposed model with three stochastic decision-making problems.","[{'name': 'Haeun Jeon, Hyunglip Bae, Minsu Park, Chanyeong Kim, Woo Chang Kim'}]",
1735,FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction,https://arxiv.org/abs/2403.01886,"arXiv:2403.01886v1 Announce Type: cross 
Abstract: Document-level Relation Extraction (DocRE) aims to identify relation labels between entities within a single document. It requires handling several sentences and reasoning over them. State-of-the-art DocRE methods use a graph structure to connect entities across the document to capture dependency syntax information. However, this is insufficient to fully exploit the rich syntax information in the document. In this work, we propose to fuse constituency and dependency syntax into DocRE. It uses constituency syntax to aggregate the whole sentence information and select the instructive sentences for the pairs of targets. It exploits the dependency syntax in a graph structure with constituency syntax enhancement and chooses the path between entity pairs based on the dependency graph. The experimental results on datasets from various domains demonstrate the effectiveness of the proposed method. The code is publicly available at this url.","[{'name': 'Xudong Zhu, Zhao Kang, Bei Hui'}]",
1736,Unsupervised Distance Metric Learning for Anomaly Detection Over Multivariate Time Series,https://arxiv.org/abs/2403.01895,"arXiv:2403.01895v1 Announce Type: cross 
Abstract: Distance-based time series anomaly detection methods are prevalent due to their relative non-parametric nature and interpretability. However, the commonly used Euclidean distance is sensitive to noise. While existing works have explored dynamic time warping (DTW) for its robustness, they only support supervised tasks over multivariate time series (MTS), leaving a scarcity of unsupervised methods. In this work, we propose FCM-wDTW, an unsupervised distance metric learning method for anomaly detection over MTS, which encodes raw data into latent space and reveals normal dimension relationships through cluster centers. FCM-wDTW introduces locally weighted DTW into fuzzy C-means clustering and learns the optimal latent space efficiently, enabling anomaly identification via data reconstruction. Experiments with 11 different types of benchmarks demonstrate our method's competitive accuracy and efficiency.","[{'name': 'Hanyang Yuan, Qinglin Cai, Keting Yin'}]",
1737,Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey,https://arxiv.org/abs/2403.01909,"arXiv:2403.01909v1 Announce Type: cross 
Abstract: Semantic segmentation is an important and popular research area in computer vision that focuses on classifying pixels in an image based on their semantics. However, supervised deep learning requires large amounts of data to train models and the process of labeling images pixel by pixel is time-consuming and laborious. This review aims to provide a first comprehensive and organized overview of the state-of-the-art research results on pseudo-label methods in the field of semi-supervised semantic segmentation, which we categorize from different perspectives and present specific methods for specific application areas. In addition, we explore the application of pseudo-label technology in medical and remote-sensing image segmentation. Finally, we also propose some feasible future research directions to address the existing challenges.","[{'name': 'Lingyan Ran, Yali Li, Guoqiang Liang, Yanning Zhang'}]",
1738,xT: Nested Tokenization for Larger Context in Large Images,https://arxiv.org/abs/2403.01915,"arXiv:2403.01915v1 Announce Type: cross 
Abstract: Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in conjunction with long-sequence length models normally used for natural language processing, we are able to increase accuracy by up to 8.6% on challenging classification tasks and $F_1$ score by 11.6 on context-dependent segmentation in large images.","[{'name': 'Ritwik Gupta, Shufan Li, Tyler Zhu, Jitendra Malik, Trevor Darrell, Karttikeya Mangalam'}]",
1739,To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering,https://arxiv.org/abs/2403.01924,"arXiv:2403.01924v1 Announce Type: cross 
Abstract: Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, \"to generate or to retrieve\" is the modern equivalent of Hamlet's dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maximum of 24GB VRAM. MedGENIE sets a new state-of-the-art (SOTA) in the open-book setting of each testbed, even allowing a small-scale reader to outcompete zero-shot closed-book 175B baselines while using up to 706$\\times$ fewer parameters. Overall, our findings reveal that generated passages are more effective than retrieved counterparts in attaining higher accuracy.","[{'name': 'Giacomo Frisoni, Alessio Cocchieri, Alex Presepi, Gianluca Moro, Zaiqiao Meng'}]",
1740,DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory,https://arxiv.org/abs/2403.01954,"arXiv:2403.01954v1 Announce Type: cross 
Abstract: Lexicon-based constrained decoding approaches aim to control the meaning or style of the generated text through certain target concepts. Existing approaches over-focus the targets themselves, leading to a lack of high-level reasoning about how to achieve them. However, human usually tackles tasks by following certain rules that not only focuses on the targets but also on semantically relevant concepts that induce the occurrence of targets. In this work, we present DECIDER, a rule-controllable decoding strategy for constrained language generation inspired by dual-system cognitive theory. Specifically, in DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner that takes high-level rules as input. Then, the DECIDER allows rule signals to flow into the PLM at each decoding step. Extensive experimental results demonstrate that DECIDER can effectively follow given rules to guide generation direction toward the targets in a more human-like manner.","[{'name': 'Chen Xu, Tian Lan, Changlong Yu, Wei Wang, Jun Gao, Yu Ji, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu'}]",
1741,The Heterogeneous Productivity Effects of Generative AI,https://arxiv.org/abs/2403.01964,"arXiv:2403.01964v1 Announce Type: cross 
Abstract: We analyse the individual productivity effects of Italy's ban on ChatGPT, a generative pretrained transformer chatbot. We compile data on the daily coding output quantity and quality of over 36,000 GitHub users in Italy and other European countries and combine these data with the sudden announcement of the ban in a difference-in-differences framework. Among the affected users in Italy, we find a short-term increase in output quantity and quality for less experienced users and a decrease in productivity on more routine tasks for experienced users.","[{'name': 'David Kreitmeir, Paul A. Raschky'}]",
1742,TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions,https://arxiv.org/abs/2403.01977,"arXiv:2403.01977v1 Announce Type: cross 
Abstract: Robot navigation under visual corruption presents a formidable challenge. To address this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav, for point-goal navigation under visual corruptions. Our \"plug-and-play\" method incorporates a top-down decoder to a pre-trained navigation model. Firstly, the pre-trained navigation model gets a corrupted image and extracts features. Secondly, the top-down decoder produces the reconstruction given the high-level features extracted by the pre-trained model. Then, it feeds the reconstruction of a corrupted image back to the pre-trained model. Finally, the pre-trained model does forward pass again to output action. Despite being trained solely on clean images, the top-down decoder can reconstruct cleaner images from corrupted ones without the need for gradient-based adaptation. The pre-trained navigation model with our top-down decoder significantly enhances navigation performance across almost all visual corruptions in our benchmarks. Our method improves the success rate of point-goal navigation from the state-of-the-art result of 46% to 94% on the most severe corruption. This suggests its potential for broader application in robotic visual navigation.","[{'name': 'Maytus Piriyajitakonkij, Mingfei Sun, Mengmi Zhang, Wei Pan'}]",
1743,Transformers for Low-Resource Languages:Is F\\'eidir Linn!,https://arxiv.org/abs/2403.01985,"arXiv:2403.01985v1 Announce Type: cross 
Abstract: The Transformer model is the state-of-the-art in Machine Translation. However, in general, neural translation models often under perform on language pairs with insufficient training data. As a consequence, relatively few experiments have been carried out using this architecture on low-resource language pairs. In this study, hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly, the correct choice of subword model is shown to be the biggest driver of translation performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers, testing various regularisation techniques and evaluating the optimal number of heads for attention. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model. Improvements were observed across a range of metrics, including TER, indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against Google Translate, our translation engines demonstrated significant improvements. The question of whether or not Transformers can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is f\\'eidir linn - yes we can.","[{'name': \"S\\\\'eamus Lankford, Haithem Afli, Andy Way\"}]",
1744,Unveiling Hidden Links Between Unseen Security Entities,https://arxiv.org/abs/2403.02014,"arXiv:2403.02014v1 Announce Type: cross 
Abstract: The proliferation of software vulnerabilities poses a significant challenge for security databases and analysts tasked with their timely identification, classification, and remediation. With the National Vulnerability Database (NVD) reporting an ever-increasing number of vulnerabilities, the traditional manual analysis becomes untenably time-consuming and prone to errors. This paper introduces VulnScopper, an innovative approach that utilizes multi-modal representation learning, combining Knowledge Graphs (KG) and Natural Language Processing (NLP), to automate and enhance the analysis of software vulnerabilities. Leveraging ULTRA, a knowledge graph foundation model, combined with a Large Language Model (LLM), VulnScopper effectively handles unseen entities, overcoming the limitations of previous KG approaches. We evaluate VulnScopper on two major security datasets, the NVD and the Red Hat CVE database. Our method significantly improves the link prediction accuracy between Common Vulnerabilities and Exposures (CVEs), Common Weakness Enumeration (CWEs), and Common Platform Enumerations (CPEs). Our results show that VulnScopper outperforms existing methods, achieving up to 78% Hits@10 accuracy in linking CVEs to CPEs and CWEs and presenting an 11.7% improvement over large language models in predicting CWE labels based on the Red Hat database. Based on the NVD, only 6.37% of the linked CPEs are being published during the first 30 days; many of them are related to critical and high-risk vulnerabilities which, according to multiple compliance frameworks (such as CISA and PCI), should be remediated within 15-30 days. Our model can uncover new products linked to vulnerabilities, reducing remediation time and improving vulnerability management. We analyzed several CVEs from 2023 to showcase this ability.","[{'name': 'Daniel Alfasi, Tal Shapira, Anat Bremler Barr'}]",
1745,Cross Domain Policy Transfer with Effect Cycle-Consistency,https://arxiv.org/abs/2403.02018,"arXiv:2403.02018v1 Announce Type: cross 
Abstract: Training a robotic policy from scratch using deep reinforcement learning methods can be prohibitively expensive due to sample inefficiency. To address this challenge, transferring policies trained in the source domain to the target domain becomes an attractive paradigm. Previous research has typically focused on domains with similar state and action spaces but differing in other aspects. In this paper, our primary focus lies in domains with different state and action spaces, which has broader practical implications, i.e. transfer the policy from robot A to robot B. Unlike prior methods that rely on paired data, we propose a novel approach for learning the mapping functions between state and action spaces across domains using unpaired data. We propose effect cycle consistency, which aligns the effects of transitions across two domains through a symmetrical optimization structure for learning these mapping functions. Once the mapping functions are learned, we can seamlessly transfer the policy from the source domain to the target domain. Our approach has been tested on three locomotion tasks and two robotic manipulation tasks. The empirical results demonstrate that our method can reduce alignment errors significantly and achieve better performance compared to the state-of-the-art method.","[{'name': 'Ruiqi Zhu, Tianhong Dai, Oya Celiktutan'}]",
1746,Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation,https://arxiv.org/abs/2403.02074,"arXiv:2403.02074v1 Announce Type: cross 
Abstract: Combining images from multi-modalities is beneficial to explore various information in computer vision, especially in the medical domain. As an essential part of clinical diagnosis, multi-modal brain tumor segmentation aims to delineate the malignant entity involving multiple modalities. Although existing methods have shown remarkable performance in the task, the information exchange for cross-scale and high-level representations fusion in spatial and modality are limited in these methods. In this paper, we present a novel Modality Aware and Shift Mixer that integrates intra-modality and inter-modality dependencies of multi-modal images for effective and robust brain tumor segmentation. Specifically, we introduce a Modality-Aware module according to neuroimaging studies for modeling the specific modality pair relationships at low levels, and a Modality-Shift module with specific mosaic patterns is developed to explore the complex relationships across modalities at high levels via the self-attention. Experimentally, we outperform previous state-of-the-art approaches on the public Brain Tumor Segmentation (BraTS 2021 segmentation) dataset. Further qualitative experiments demonstrate the efficacy and robustness of MASM.","[{'name': 'Zhongzhen Huang, Linda Wei, Shaoting Zhang, Xiaofan Zhang'}]",
1747,VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT,https://arxiv.org/abs/2403.02076,"arXiv:2403.02076v1 Announce Type: cross 
Abstract: Video temporal grounding (VTG) aims to locate specific temporal segments from an untrimmed video based on a linguistic query. Most existing VTG models are trained on extensive annotated video-text pairs, a process that not only introduces human biases from the queries but also incurs significant computational costs. To tackle these challenges, we propose VTG-GPT, a GPT-based method for zero-shot VTG without training or fine-tuning. To reduce prejudice in the original query, we employ Baichuan2 to generate debiased queries. To lessen redundant information in videos, we apply MiniGPT-v2 to transform visual content into more precise captions. Finally, we devise the proposal generator and post-processing to produce accurate segments from debiased queries and image captions. Extensive experiments demonstrate that VTG-GPT significantly outperforms SOTA methods in zero-shot settings and surpasses unsupervised approaches. More notably, it achieves competitive performance comparable to supervised methods. The code is available on https://github.com/YoucanBaby/VTG-GPT","[{'name': 'Yifang Xu, Yunzhuo Sun, Zien Xie, Benxiang Zhai, Sidan Du'}]",
1748,Iterated $Q$-Network: Beyond the One-Step Bellman Operator,https://arxiv.org/abs/2403.02107,"arXiv:2403.02107v1 Announce Type: cross 
Abstract: Value-based Reinforcement Learning (RL) methods rely on the application of the Bellman operator, which needs to be approximated from samples. Most approaches consist of an iterative scheme alternating the application of the Bellman operator and a subsequent projection step onto a considered function space. However, we observe that these algorithms can be improved by considering multiple iterations of the Bellman operator at once. Thus, we introduce iterated $Q$-Networks (iQN), a novel approach that learns a sequence of $Q$-function approximations where each $Q$-function serves as the target for the next one in a chain of consecutive Bellman iterations. We demonstrate that iQN is theoretically sound and show how it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate its advantages on Atari $2600$ games and in continuous-control MuJoCo environments.","[{'name': \"Th\\\\'eo Vincent, Daniel Palenicek, Boris Belousov, Jan Peters, Carlo D'Eramo\"}]",
1749,Position Paper: Towards Implicit Prompt For Text-To-Image Models,https://arxiv.org/abs/2403.02118,"arXiv:2403.02118v1 Announce Type: cross 
Abstract: Recent text-to-image (T2I) models have had great success, and many benchmarks have been proposed to evaluate their performance and safety. However, they only consider explicit prompts while neglecting implicit prompts (hint at a target without explicitly mentioning it). These prompts may get rid of safety constraints and pose potential threats to the applications of these models. This position paper highlights the current state of T2I models toward implicit prompts. We present a benchmark named ImplicitBench and conduct an investigation on the performance and impacts of implicit prompts with popular T2I models. Specifically, we design and collect more than 2,000 implicit prompts of three aspects: General Symbols, Celebrity Privacy, and Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models' capabilities under these implicit prompts. Experiment results show that (1) T2I models are able to accurately create various target symbols indicated by implicit prompts; (2) Implicit prompts bring potential risks of privacy leakage for T2I models. (3) Constraints of NSFW in most of the evaluated T2I models can be bypassed with implicit prompts. We call for increased attention to the potential and risks of implicit prompts in the T2I community and further investigation into the capabilities and impacts of implicit prompts, advocating for a balanced approach that harnesses their benefits while mitigating their risks.","[{'name': 'Yue Yang, Yuqi lin, Hong Liu, Wenqi Shao, Runjian Chen, Hailong Shang, Yu Wang, Yu Qiao, Kaipeng Zhang, Ping Luo'}]",
1750,Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models,https://arxiv.org/abs/2403.02121,"arXiv:2403.02121v1 Announce Type: cross 
Abstract: The advent of Large Language Models (LLMs) has advanced the benchmark in various Natural Language Processing (NLP) tasks. However, large amounts of labelled training data are required to train LLMs. Furthermore, data annotation and training are computationally expensive and time-consuming. Zero and few-shot learning have recently emerged as viable options for labelling data using large pre-trained models. Hate speech detection in mix-code low-resource languages is an active problem area where the use of LLMs has proven beneficial. In this study, we have compiled a dataset of 100 YouTube comments, and weakly labelled them for coarse and fine-grained misogyny classification in mix-code Hinglish. Weak annotation was applied due to the labor-intensive annotation process. Zero-shot learning, one-shot learning, and few-shot learning and prompting approaches have then been applied to assign labels to the comments and compare them to human-assigned labels. Out of all the approaches, zero-shot classification using the Bidirectional Auto-Regressive Transformers (BART) large model and few-shot prompting using Generative Pre-trained Transformer- 3 (ChatGPT-3) achieve the best results","[{'name': 'Sargam YadavDundalk Institute of Technology, Dundalk, Abhishek KaushikDundalk Institute of Technology, Dundalk, Kevin McDaidDundalk Institute of Technology, Dundalk'}]",
1751,LOCR: Location-Guided Transformer for Optical Character Recognition,https://arxiv.org/abs/2403.02127,"arXiv:2403.02127v1 Announce Type: cross 
Abstract: Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4.4% of pages to 0.5% in the arXiv dataset, from 13.2% to 1.3% in OOD quantum physics documents and from 8.1% to 1.8% in OOD marketing documents. Additionally, LOCR features an interactive OCR mode, facilitating the generation of complex documents through a few location prompts from human.","[{'name': 'Yu Sun, Dongzhan Zhou, Chen Lin, Conghui He, Wanli Ouyang, Han-Sen Zhong'}]",
1752,Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution,https://arxiv.org/abs/2403.02131,"arXiv:2403.02131v1 Announce Type: cross 
Abstract: Evolutionary algorithms, such as Differential Evolution, excel in solving real-parameter optimization challenges. However, the effectiveness of a single algorithm varies across different problem instances, necessitating considerable efforts in algorithm selection or configuration. This paper aims to address the limitation by leveraging the complementary strengths of a group of algorithms and dynamically scheduling them throughout the optimization progress for specific problems. We propose a deep reinforcement learning-based dynamic algorithm selection framework to accomplish this task. Our approach models the dynamic algorithm selection a Markov Decision Process, training an agent in a policy gradient manner to select the most suitable algorithm according to the features observed during the optimization process. To empower the agent with the necessary information, our framework incorporates a thoughtful design of landscape and algorithmic features. Meanwhile, we employ a sophisticated deep neural network model to infer the optimal action, ensuring informed algorithm selections. Additionally, an algorithm context restoration mechanism is embedded to facilitate smooth switching among different algorithms. These mechanisms together enable our framework to seamlessly select and switch algorithms in a dynamic online fashion. Notably, the proposed framework is simple and generic, offering potential improvements across a broad spectrum of evolutionary algorithms. As a proof-of-principle study, we apply this framework to a group of Differential Evolution algorithms. The experimental results showcase the remarkable effectiveness of the proposed framework, not only enhancing the overall optimization performance but also demonstrating favorable generalization ability across different problem classes.","[{'name': 'Hongshu Guo, Yining Ma, Zeyuan Ma, Jiacheng Chen, Xinglin Zhang, Zhiguang Cao, Jun Zhang, Yue-Jiao Gong'}]",
1753,Speech emotion recognition from voice messages recorded in the wild,https://arxiv.org/abs/2403.02167,"arXiv:2403.02167v1 Announce Type: cross 
Abstract: Emotion datasets used for Speech Emotion Recognition (SER) often contain acted or elicited speech, limiting their applicability in real-world scenarios. In this work, we used the Emotional Voice Messages (EMOVOME) database, including spontaneous voice messages from conversations of 100 Spanish speakers on a messaging app, labeled in continuous and discrete emotions by expert and non-expert annotators. We created speaker-independent SER models using the eGeMAPS features, transformer-based models and their combination. We compared the results with reference databases and analyzed the influence of annotators and gender fairness. The pre-trained Unispeech-L model and its combination with eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10% improvement over baseline models. For the emotion categories, 42.58% UA was obtained. EMOVOME performed lower than the acted RAVDESS database. The elicited IEMOCAP database also outperformed EMOVOME in the prediction of emotion categories, while similar results were obtained in valence and arousal. Additionally, EMOVOME outcomes varied with annotator labels, showing superior results and better fairness when combining expert and non-expert annotations. This study significantly contributes to the evaluation of SER models in real-life situations, advancing in the development of applications for analyzing spontaneous voice messages.","[{'name': \"Luc\\\\'ia G\\\\'omez-Zaragoz\\\\'a, \\\\'Oscar Valls, Roc\\\\'io del Amor, Mar\\\\'ia Jos\\\\'e Castro-Bleda, Valery Naranjo, Mariano Alca\\\\~niz Raya, Javier Mar\\\\'in-Morales\"}]",
1754,Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models,https://arxiv.org/abs/2403.02178,"arXiv:2403.02178v1 Announce Type: cross 
Abstract: In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% improvement in GSM8K accuracy and 1% improvement in MATH accuracy across five datasets of various quality and size, as well as two base models. We further investigate the mechanisms behind this improvement through case studies and quantitative analysis, suggesting that our approach may provide superior support for the model in capturing long-distance dependencies, especially those related to questions. This enhancement could deepen understanding of premises in questions and prior steps. Our code is available at Github.","[{'name': 'Changyu Chen, Xiting Wang, Ting-En Lin, Ang Lv, Yuchuan Wu, Xin Gao, Ji-Rong Wen, Rui Yan, Yongbin Li'}]",
1755,Not all Layers of LLMs are Necessary during Inference,https://arxiv.org/abs/2403.02181,"arXiv:2403.02181v1 Announce Type: cross 
Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, \"During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?\" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment tasks, while maintaining comparable performance. Additionally, this method is orthogonal to other model acceleration techniques, potentially boosting inference efficiency further.","[{'name': 'Siqi Fan, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Shuo Shang, Aixin Sun, Yequan Wang, Zhongyuan Wang'}]",
1756,Policy Space Response Oracles: A Survey,https://arxiv.org/abs/2403.02227,"arXiv:2403.02227v1 Announce Type: cross 
Abstract: In game theory, a game refers to a model of interaction among rational decision-makers or players, making choices with the goal of achieving their individual objectives. Understanding their behavior in games is often referred to as game reasoning. This survey provides a comprehensive overview of a fast-developing game-reasoning framework for large games, known as Policy Space Response Oracles (PSRO). We first motivate PSRO, provide historical context, and position PSRO within game-reasoning approaches. We then focus on the strategy exploration issue for PSRO, the challenge of assembling an effective strategy portfolio for modeling the underlying game with minimum computational cost. We also survey current research directions for enhancing the efficiency of PSRO, and explore the applications of PSRO across various domains. We conclude by discussing open questions and future research.","[{'name': 'Ariyan Bighashdel, Yongzhao Wang, Stephen McAleer, Rahul Savani, Frans A. Oliehoek'}]",
1757,Comprehensive evaluation of Mal-API-2019 dataset by machine learning in malware detection,https://arxiv.org/abs/2403.02232,"arXiv:2403.02232v1 Announce Type: cross 
Abstract: This study conducts a thorough examination of malware detection using machine learning techniques, focusing on the evaluation of various classification models using the Mal-API-2019 dataset. The aim is to advance cybersecurity capabilities by identifying and mitigating threats more effectively. Both ensemble and non-ensemble machine learning methods, such as Random Forest, XGBoost, K Nearest Neighbor (KNN), and Neural Networks, are explored. Special emphasis is placed on the importance of data pre-processing techniques, particularly TF-IDF representation and Principal Component Analysis, in improving model performance. Results indicate that ensemble methods, particularly Random Forest and XGBoost, exhibit superior accuracy, precision, and recall compared to others, highlighting their effectiveness in malware detection. The paper also discusses limitations and potential future directions, emphasizing the need for continuous adaptation to address the evolving nature of malware. This research contributes to ongoing discussions in cybersecurity and provides practical insights for developing more robust malware detection systems in the digital era.","[{'name': 'Zhenglin Li, Haibei Zhu, Houze Liu, Jintong Song, Qishuo Cheng'}]",
1758,Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks,https://arxiv.org/abs/2403.02238,"arXiv:2403.02238v1 Announce Type: cross 
Abstract: The integration of Machine Learning and Artificial Intelligence (ML/AI) into fifth-generation (5G) networks has made evident the limitations of network intelligence with ever-increasing, strenuous requirements for current and next-generation devices. This transition to ubiquitous intelligence demands high connectivity, synchronicity, and end-to-end communication between users and network operators, and will pave the way towards full network automation without human intervention. Intent-based networking is a key factor in the reduction of human actions, roles, and responsibilities while shifting towards novel extraction and interpretation of automated network management. This paper presents the development of a custom Large Language Model (LLM) for 5G and next-generation intent-based networking and provides insights into future LLM developments and integrations to realize end-to-end intent-based networking for fully automated network intelligence.","[{'name': 'Dimitrios Michael Manias, Ali Chouman, Abdallah Shami'}]",
1759,Neural Redshift: Random Networks are not Random Functions,https://arxiv.org/abs/2403.02241,"arXiv:2403.02241v1 Announce Type: cross 
Abstract: Our understanding of the generalization capabilities of neural networks (NNs) is still incomplete. Prevailing explanations are based on implicit biases of gradient descent (GD) but they cannot account for the capabilities of models from gradient-free methods nor the simplicity bias recently observed in untrained networks. This paper seeks other sources of generalization in NNs.
  Findings. To understand the inductive biases provided by architectures independently from GD, we examine untrained, random-weight networks. Even simple MLPs show strong inductive biases: uniform sampling in weight space yields a very biased distribution of functions in terms of complexity. But unlike common wisdom, NNs do not have an inherent \"simplicity bias\". This property depends on components such as ReLUs, residual connections, and layer normalizations. Alternative architectures can be built with a bias for any level of complexity. Transformers also inherit all these properties from their building blocks.
  Implications. We provide a fresh explanation for the success of deep learning independent from gradient-based training. It points at promising avenues for controlling the solutions implemented by trained models.","[{'name': 'Damien Teney, Armand Nicolicioiu, Valentin Hartmann, Ehsan Abbasnejad'}]",
1760,Better Schedules for Low Precision Training of Deep Neural Networks,https://arxiv.org/abs/2403.02243,"arXiv:2403.02243v1 Announce Type: cross 
Abstract: Low precision training can significantly reduce the computational overhead of training deep neural networks (DNNs). Though many such techniques exist, cyclic precision training (CPT), which dynamically adjusts precision throughout train- ing according to a cyclic schedule, achieves particularly impressive improvements in training efficiency, while actually improving DNN performance. Existing CPT implementations take common learning rate schedules (e.g., cyclical cosine sched- ules) and use them for low precision training without adequate comparisons to alternative scheduling options. We define a diverse suite of CPT schedules and analyze their performance across a variety of DNN training regimes, some of which are unexplored in the low precision training literature (e.g., node classification with graph neural networks). From these experiments, we discover alternative CPT schedules that offer further improvements in training efficiency and model performance, as well as derive a set of best practices for choosing CPT schedules. Going further, we find that a correlation exists between model performance and training cost, and that changing the underlying CPT schedule can control the tradeoff between these two variables. To explain the direct correlation between model performance and training cost, we draw a connection between quantized training and critical learning periods, suggesting that aggressive quantization is a form of learning impairment that can permanently damage model performance.","[{'name': 'Cameron R. Wolfe, Anastasios Kyrillidis'}]",
1761,Non-autoregressive Sequence-to-Sequence Vision-Language Models,https://arxiv.org/abs/2403.02249,"arXiv:2403.02249v1 Announce Type: cross 
Abstract: Sequence-to-sequence vision-language models are showing promise, but their applicability is limited by their inference latency due to their autoregressive way of generating predictions. We propose a parallel decoding sequence-to-sequence vision-language model, trained with a Query-CTC loss, that marginalizes over multiple inference paths in the decoder. This allows us to model the joint distribution of tokens, rather than restricting to conditional distribution as in an autoregressive model. The resulting model, NARVL, achieves performance on-par with its state-of-the-art autoregressive counterpart, but is faster at inference time, reducing from the linear complexity associated with the sequential generation of tokens to a paradigm of constant time joint inference.","[{'name': 'Kunyu Shi, Qi Dong, Luis Goncalves, Zhuowen Tu, Stefano Soatto'}]",
1762,KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection,https://arxiv.org/abs/2403.02253,"arXiv:2403.02253v1 Announce Type: cross 
Abstract: Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect and release a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML. To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text. Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos. We evaluate KnowPhish and KPD on a manually validated dataset, and on a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines.","[{'name': 'Yuexin Li, Chengyu Huang, Shumin Deng, Mei Lin Lock, Tri Cao, Nay Oo, Bryan Hooi, Hoon Wei Lim'}]",
1763,Subjective $\\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection,https://arxiv.org/abs/2403.02268,"arXiv:2403.02268v1 Announce Type: cross 
Abstract: Natural language processing research has begun to embrace the notion of annotator subjectivity, motivated by variations in labelling. This approach understands each annotator's view as valid, which can be highly suitable for tasks that embed subjectivity, e.g., sentiment analysis. However, this construction may be inappropriate for tasks such as hate speech detection, as it affords equal validity to all positions on e.g., sexism or racism. We argue that the conflation of hate and offence can invalidate findings on hate speech, and call for future work to be situated in theory, disentangling hate from its orthogonal concept, offence.","[{'name': 'Amanda Cercas Curry, Gavin Abercrombie, Zeerak Talat'}]",
1764,Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation,https://arxiv.org/abs/2403.02302,"arXiv:2403.02302v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune the ShareGPT4V model for this specific task, aiming to achieve state-of-the-art results in this particular challenge. Although such a model would not be practical in production, as it is incredibly expensive compared to a specialized model like MiVOLO, it could be very useful in some tasks, like data annotation.","[{'name': 'Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh'}]",
1765,Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training,https://arxiv.org/abs/2403.02325,"arXiv:2403.02325v1 Announce Type: cross 
Abstract: Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a \"visual prompt\", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When region annotations are provided, CRG increases absolute accuracy by up to 11.1% on ViP-Bench, a collection of six diverse region-based tasks such as recognition, math, and object relationship reasoning. We also show CRG's applicability to spatial reasoning, with 10% improvement on What'sUp, as well as to compositional generalization -- improving accuracy by 11.5% and 7.5% on two challenging splits from SugarCrepe -- and to image-text alignment for generated images, where we improve by up to 8.4 AUROC and 6.8 F1 points on SeeTRUE. When reference regions are absent, CRG allows us to re-rank proposed regions in referring expression comprehension and phrase grounding benchmarks like RefCOCO/+/g and Flickr30K Entities, with an average gain of 3.2% in accuracy. Our analysis explores alternative masking strategies for CRG, quantifies CRG's probability shift, and evaluates the role of region guidance strength, empirically validating CRG's design choices.","[{'name': 'David Wan, Jaemin Cho, Elias Stengel-Eskin, Mohit Bansal'}]",
1766,Model Lakes,https://arxiv.org/abs/2403.02327,"arXiv:2403.02327v1 Announce Type: cross 
Abstract: Given a set of deep learning models, it can be hard to find models appropriate to a task, understand the models, and characterize how models are different one from another. Currently, practitioners rely on manually-written documentation to understand and choose models. However, not all models have complete and reliable documentation. As the number of machine learning models increases, this issue of finding, differentiating, and understanding models is becoming more crucial. Inspired from research on data lakes, we introduce and define the concept of model lakes. We discuss fundamental research challenges in the management of large models. And we discuss what principled data management techniques can be brought to bear on the study of large model management.","[{'name': \"Koyena Pal, David Bau, Ren\\\\'ee J. Miller\"}]",
1767,Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning,https://arxiv.org/abs/2403.02333,"arXiv:2403.02333v1 Announce Type: cross 
Abstract: Large language models (LLMs) have shown great potential in complex reasoning tasks, yet their performance is often hampered by the scarcity of high-quality, reasoning-focused training datasets. Addressing this challenge, we propose Key-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that synthesizes question-answer pairs by leveraging key points and exemplar pairs from authentic data sources. KPDDS ensures the generation of novel questions with rigorous quality control and substantial scalability. As a result, we present KPMath, the most extensive synthetic dataset tailored for mathematical reasoning to date, comprising over one million question-answer pairs. Utilizing KPMath and augmenting it with additional reasoning-intensive corpora, we create the comprehensive KPMath-Plus dataset. Fine-tuning the Mistral-7B model on KPMath-Plus yields a zero-shot PASS@1 accuracy of 39.3% on the MATH test set, a performance that not only outpaces other finetuned 7B models but also exceeds that of certain 34B models. Our ablation studies further confirm the substantial enhancement in mathematical reasoning across various subtopics, marking a significant stride in LLMs' reasoning capabilities.","[{'name': 'Yiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, Weizhu Chen'}]",
1768,Gradient Correlation Subspace Learning against Catastrophic Forgetting,https://arxiv.org/abs/2403.02334,"arXiv:2403.02334v1 Announce Type: cross 
Abstract: Efficient continual learning techniques have been a topic of significant research over the last few years. A fundamental problem with such learning is severe degradation of performance on previously learned tasks, known also as catastrophic forgetting. This paper introduces a novel method to reduce catastrophic forgetting in the context of incremental class learning called Gradient Correlation Subspace Learning (GCSL). The method detects a subspace of the weights that is least affected by previous tasks and projects the weights to train for the new task into said subspace. The method can be applied to one or more layers of a given network architectures and the size of the subspace used can be altered from layer to layer and task to task. Code will be available at \\href{https://github.com/vgthengane/GCSL}{https://github.com/vgthengane/GCSL}","[{'name': 'Tammuz Dubnov, Vishal Thengane'}]",
1769,"Brand Visibility in Packaging: A Deep Learning Approach for Logo Detection, Saliency-Map Prediction, and Logo Placement Analysis",https://arxiv.org/abs/2403.02336,"arXiv:2403.02336v1 Announce Type: cross 
Abstract: In the highly competitive area of product marketing, the visibility of brand logos on packaging plays a crucial role in shaping consumer perception, directly influencing the success of the product. This paper introduces a comprehensive framework to measure the brand logo's attention on a packaging design. The proposed method consists of three steps. The first step leverages YOLOv8 for precise logo detection across prominent datasets, FoodLogoDet-1500 and LogoDet-3K. The second step involves modeling the user's visual attention with a novel saliency prediction model tailored for the packaging context. The proposed saliency model combines the visual elements with text maps employing a transformers-based architecture to predict user attention maps. In the third step, by integrating logo detection with a saliency map generation, the framework provides a comprehensive brand attention score. The effectiveness of the proposed method is assessed module by module, ensuring a thorough evaluation of each component. Comparing logo detection and saliency map prediction with state-of-the-art models shows the superiority of the proposed methods. To investigate the robustness of the proposed brand attention score, we collected a unique dataset to examine previous psychophysical hypotheses related to brand visibility. the results show that the brand attention score is in line with all previous studies. Also, we introduced seven new hypotheses to check the impact of position, orientation, presence of person, and other visual elements on brand attention. This research marks a significant stride in the intersection of cognitive psychology, computer vision, and marketing, paving the way for advanced, consumer-centric packaging designs.","[{'name': 'Alireza Hosseini, Kiana Hooshanfar, Pouria Omrani, Reza Toosi, Ramin Toosi, Zahra Ebrahimian, Mohammad Ali Akhaee'}]",
1770,Twisting Lids Off with Two Hands,https://arxiv.org/abs/2403.02338,"arXiv:2403.02338v1 Announce Type: cross 
Abstract: Manipulating objects with two multi-fingered hands has been a long-standing challenge in robotics, attributed to the contact-rich nature of many manipulation tasks and the complexity inherent in coordinating a high-dimensional bimanual system. In this work, we consider the problem of twisting lids of various bottle-like objects with two hands, and demonstrate that policies trained in simulation using deep reinforcement learning can be effectively transferred to the real world. With novel engineering insights into physical modeling, real-time perception, and reward design, the policy demonstrates generalization capabilities across a diverse set of unseen objects, showcasing dynamic and dexterous behaviors. Our findings serve as compelling evidence that deep reinforcement learning combined with sim-to-real transfer remains a promising approach for addressing manipulation problems of unprecedented complexity.","[{'name': 'Toru Lin, Zhao-Heng Yin, Haozhi Qi, Pieter Abbeel, Jitendra Malik'}]",
1771,Similar Cases Recommendation using Legal Knowledge Graphs,https://arxiv.org/abs/2107.04771,"arXiv:2107.04771v2 Announce Type: replace 
Abstract: A legal knowledge graph constructed from court cases, judgments, laws and other legal documents can enable a number of applications like question answering, document similarity, and search. While the use of knowledge graphs for distant supervision in NLP tasks is well researched, using knowledge graphs for applications like case similarity presents challenges. In this work, we describe our solution for predicting similar cases in Indian court judgements. We present our results and also discuss the impact of large language models on this task.","[{'name': 'Jaspreet Singh Dhani, Ruchika Bhatt, Balaji Ganesan, Parikshet Sirohi, Vasudha Bhatnagar'}]",
1772,Retrosynthetic Planning with Dual Value Networks,https://arxiv.org/abs/2301.13755,"arXiv:2301.13755v3 Announce Type: replace 
Abstract: Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro*, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for RetroGraph). Our code is available at \\url{https://github.com/DiXue98/PDVN}.","[{'name': 'Guoqing Liu, Di Xue, Shufang Xie, Yingce Xia, Austin Tripp, Krzysztof Maziarz, Marwin Segler, Tao Qin, Zongzhang Zhang, Tie-Yan Liu'}]",
1773,Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach,https://arxiv.org/abs/2306.03604,"arXiv:2306.03604v5 Announce Type: replace 
Abstract: Large language models (LLMs) encode a vast amount of world knowledge acquired from massive text datasets. Recent studies have demonstrated that LLMs can assist an embodied agent in solving complex sequential decision making tasks by providing high-level instructions. However, interactions with LLMs can be time-consuming. In many practical scenarios, they require a significant amount of storage space that can only be deployed on remote cloud server nodes. Additionally, using commercial LLMs can be costly since they may charge based on usage frequency. In this paper, we explore how to enable intelligent cost-effective interactions between the agent and an LLM. We find that this problem can be naturally formulated by a Markov decision process (MDP), and propose When2Ask, a reinforcement learning based approach that learns when it is necessary to query LLMs for high-level instructions to accomplish a target task. Experiments on MiniGrid and Habitat environments that entail planning sub-goals demonstrate that When2Ask learns to solve target tasks with only a few necessary interactions with an LLM, and significantly reduces interaction costs in testing environments compared with baseline methods. Experiment results also suggest that by learning a mediator model to interact with the LLM, the agent's performance becomes more robust against partial observability of the environment. Our code is available at https://github.com/ZJLAB-AMMI/LLM4RL.","[{'name': 'Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin Xu, Bin Liu'}]",
1774,MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models,https://arxiv.org/abs/2308.09729,"arXiv:2308.09729v5 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named \\method, that leverages knowledge graphs (KGs) to enhance LLMs' inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question \\& answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference. To reproduce our results and extend the framework further, we make our codebase available at https://github.com/wyl-willing/MindMap.","[{'name': 'Yilin Wen, Zifeng Wang, Jimeng Sun'}]",
1775,Safe POMDP Online Planning via Shielding,https://arxiv.org/abs/2309.10216,"arXiv:2309.10216v2 Announce Type: replace 
Abstract: Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees which are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions which would violate the almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored variants designed to improve scalability. Experimental results on a set of benchmark domains demonstrate that the proposed shielding methods successfully guarantee safety (unlike the baseline POMCP without shielding) on large POMDPs, with negligible impact on the runtime for online planning.","[{'name': 'Shili Sheng, David Parker, Lu Feng'}]",
1776,Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding and Fixing Bugs,https://arxiv.org/abs/2312.05588,"arXiv:2312.05588v2 Announce Type: replace 
Abstract: Vision models with high overall accuracy often exhibit systematic errors in specific scenarios, posing potential serious safety concerns. Diagnosing bugs of vision models is gaining increased attention, however traditional diagnostic approaches require annotation efforts (eg rich metadata accompanying each samples of CelebA). To address this issue,We propose a language-assisted diagnostic method that uses texts instead of images to diagnose bugs in vision models based on multi-modal models (eg CLIP). Our approach connects the embedding space of CLIP with the buggy vision model to be diagnosed; meanwhile, utilizing a shared classifier and the cross-modal transferability of embedding space from CLIP, the text-branch of CLIP become a proxy model to find bugs in the buggy model. The proxy model can classify texts paired with images. During the diagnosis, a Large Language Model (LLM) is employed to obtain task-relevant corpora, and this corpora is used to extract keywords. Descriptions constructed with templates containing these keywords serve as input text to probe errors in the proxy model. Finally, we validate the ability to diagnose existing visual models using language on the Waterbirds and CelebA datasets, we can identify bugs comprehensible to human experts, uncovering not only known bugs but also previously unknown ones.","[{'name': 'Chaoquan Jiang, Jinqiang Wang, Rui Hu, Jitao Sang'}]",
1777,Reconciling Shared versus Context-Specific Information in a Neural Network Model of Latent Causes,https://arxiv.org/abs/2312.08519,"arXiv:2312.08519v2 Announce Type: replace 
Abstract: It has been proposed that, when processing a stream of events, humans divide their experiences in terms of inferred latent causes (LCs) to support context-dependent learning. However, when shared structure is present across contexts, it is still unclear how the \"splitting\" of LCs and learning of shared structure can be simultaneously achieved. Here, we present the Latent Cause Network (LCNet), a neural network model of LC inference. Through learning, it naturally stores structure that is shared across tasks in the network weights. Additionally, it represents context-specific structure using a context module, controlled by a Bayesian nonparametric inference algorithm, which assigns a unique context vector for each inferred LC. Across three simulations, we found that LCNet could 1) extract shared structure across LCs in a function learning task while avoiding catastrophic interference, 2) capture human data on curriculum effects in schema learning, and 3) infer the underlying event structure when processing naturalistic videos of daily events. Overall, these results demonstrate a computationally feasible approach to reconciling shared structure and context-specific structure in a model of LCs that is scalable from laboratory experiment settings to naturalistic settings.","[{'name': 'Qihong Lu, Tan T. Nguyen, Qiong Zhang, Uri Hasson, Thomas L. Griffiths, Jeffrey M. Zacks, Samuel J. Gershman, Kenneth A. Norman'}]",
1778,Layerwise complexity-matched learning yields an improved model of cortical area V2,https://arxiv.org/abs/2312.11436,"arXiv:2312.11436v2 Announce Type: replace 
Abstract: Human ability to recognize complex visual patterns arises through transformations performed by successive areas in the ventral visual cortex. Deep neural networks trained end-to-end for object recognition approach human capabilities, and offer the best descriptions to date of neural responses in the late stages of the hierarchy. But these networks provide a poor account of the early stages, compared to traditional hand-engineered models, or models optimized for coding efficiency or prediction. Moreover, the gradient backpropagation used in end-to-end learning is generally considered to be biologically implausible. Here, we overcome both of these limitations by developing a bottom-up self-supervised training methodology that operates independently on successive layers. Specifically, we maximize feature similarity between pairs of locally-deformed natural image patches, while decorrelating features across patches sampled from other images. Crucially, the deformation amplitudes are adjusted proportionally to receptive field sizes in each layer, thus matching the task complexity to the capacity at each stage of processing. In comparison with architecture-matched versions of previous models, we demonstrate that our layerwise complexity-matched learning (LCL) formulation produces a two-stage model (LCL-V2) that is better aligned with selectivity properties and neural activity in primate area V2. We demonstrate that the complexity-matched learning paradigm is critical for the emergence of the improved biological alignment. Finally, when the two-stage model is used as a fixed front-end for a deep network trained to perform object recognition, the resultant model (LCL-V2Net) is significantly better than standard end-to-end self-supervised, supervised, and adversarially-trained models in terms of generalization to out-of-distribution tasks and alignment with human behavior.","[{'name': \"Nikhil Parthasarathy, Olivier J. H\\\\'enaff, Eero P. Simoncelli\"}]",
1779,Sophisticated Behavioral Simulation: A Possible Solution to Problems of Organized Complexity,https://arxiv.org/abs/2401.09851,"arXiv:2401.09851v2 Announce Type: replace 
Abstract: Simulation technologies have been widely utilized in many scientific research fields such as weather forecasting, fluid mechanics, and biological populations. As a matter of facts, they act as the best tool to handle problems in complex systems where closed-form expressions are unavailable and the target distribution in the representation space is too complex to be fully represented by data-driven learning models, such as deep learning (DL) models. This paper investigates the effectiveness and preference of simulation technologies based on the analyses of scientific paradigms and problems. We revisit the evolution of scientific paradigms from the perspective of data, algorithms, and computational power, and rethink a classic classification of scientific problems which consists of the problems of organized simplicity, problems of disorganized complexity, and problems of organized complexity. These different problems reflect the strengths of different paradigms, indicating that a new simulation technology integrating different paradigms is required to deal with unresolved problems of organized complexity in more complex systems. Therefore, we summarize existent simulation technologies aligning with the scientific paradigms, and propose the concept of behavioral simulation (BS), and further sophisticated behavioral simulation (SBS). They represent a higher degree of paradigms integration based on foundation models to simulate complex social systems involving sophisticated human strategies and behaviors. Beyond the capacity of traditional agent-based modeling simulation (ABMS), BS and further SBS are designed to tackle challenges concerning the complex human system, which can be regarded as a possible next paradigm for science. Through this work, we look forward to more powerful BS and SBS applications in scientific research branches within social science.","[{'name': 'Cheng Wang, Chuwen Wang, Yu Zhao, Wang Zhang, Shirong Zeng, Ronghui Ning, Changjun Jiang'}]",
1780,Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control,https://arxiv.org/abs/2401.12624,"arXiv:2401.12624v2 Announce Type: replace 
Abstract: In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.","[{'name': 'Yongjun Kim, Sejin Seo, Jihong Park, Mehdi Bennis, Seong-Lyun Kim, Junil Choi'}]",
1781,Developing and Evaluating a Design Method for Positive Artificial Intelligence,https://arxiv.org/abs/2402.01499,"arXiv:2402.01499v2 Announce Type: replace 
Abstract: As artificial intelligence (AI) continues advancing, ensuring positive societal impacts becomes critical, especially as AI systems become increasingly ubiquitous in various aspects of life. However, developing \"AI for good\" poses substantial challenges around aligning systems with complex human values. Presently, we lack mature methods for addressing these challenges. This article presents and evaluates the Positive AI design method aimed at addressing this gap. The method provides a human-centered process to translate wellbeing aspirations into concrete practices. First, we explain the method's four key steps: contextualizing, operationalizing, optimizing, and implementing wellbeing supported by continuous measurement for feedback cycles. We then present a multiple case study where novice designers applied the method, revealing strengths and weaknesses related to efficacy and usability. Next, an expert evaluation study assessed the quality of the resulting concepts, rating them moderately high for feasibility, desirability, and plausibility of achieving intended wellbeing benefits. Together, these studies provide preliminary validation of the method's ability to improve AI design, while surfacing areas needing refinement like developing support for complex steps. Proposed adaptations such as examples and evaluation heuristics could address weaknesses. Further research should examine sustained application over multiple projects. This human-centered approach shows promise for realizing the vision of 'AI for Wellbeing' that does not just avoid harm, but actively benefits humanity.","[{'name': 'Willem van der Maden, Derek Lomas, Paul Hekkert'}]",
1782,C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models,https://arxiv.org/abs/2402.03181,"arXiv:2402.03181v3 Announce Type: replace 
Abstract: Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk functions under test distribution shifts. We prove that RAG achieves a lower conformal generation risk than that of a single LLM when the quality of the retrieval model and transformer is non-trivial. Our intensive empirical results demonstrate the soundness and tightness of our conformal generation risk guarantees across four widely-used NLP datasets on four state-of-the-art retrieval models.","[{'name': 'Mintong Kang, Nezihe Merve G\\\\\"urel, Ning Yu, Dawn Song, Bo Li'}]",
1783,CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain,https://arxiv.org/abs/2402.07234,"arXiv:2402.07234v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated significant potential and effectiveness across multiple application domains. To assess the performance of mainstream LLMs in public security tasks, this study aims to construct a specialized evaluation benchmark tailored to the Chinese public security domain--CPSDbench. CPSDbench integrates datasets related to public security collected from real-world scenarios, supporting a comprehensive assessment of LLMs across four key dimensions: text classification, information extraction, question answering, and text generation. Furthermore, this study introduces a set of innovative evaluation metrics designed to more precisely quantify the efficacy of LLMs in executing tasks related to public security. Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the future development of more accurate and customized LLM models targeted at applications in this field.","[{'name': 'Xin Tong, Bo Jin, Zhi Lin, Binjun Wang, Ting Yu, Qiang Cheng'}]",
1784,Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis,https://arxiv.org/abs/2402.07787,"arXiv:2402.07787v3 Announce Type: replace 
Abstract: Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses. Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods.","[{'name': 'Xiaowei Zhao, Yong Zhou, Xiujuan Xu, Yu Liu'}]",
1785,Recursive Joint Simulation in Games,https://arxiv.org/abs/2402.08128,"arXiv:2402.08128v2 Announce Type: replace 
Abstract: Game-theoretic dynamics between AI agents could differ from traditional human-human interactions in various ways. One such difference is that it may be possible to accurately simulate an AI agent, for example because its source code is known. Our aim is to explore ways of leveraging this possibility to achieve more cooperative outcomes in strategic settings. In this paper, we study an interaction between AI agents where the agents run a recursive joint simulation. That is, the agents first jointly observe a simulation of the situation they face. This simulation in turn recursively includes additional simulations (with a small chance of failure, to avoid infinite recursion), and the results of all these nested simulations are observed before an action is chosen. We show that the resulting interaction is strategically equivalent to an infinitely repeated version of the original game, allowing a direct transfer of existing results such as the various folk theorems.","[{'name': 'Vojtech Kovarik, Caspar Oesterheld, Vincent Conitzer'}]",
1786,Premise Order Matters in Reasoning with Large Language Models,https://arxiv.org/abs/2402.08939,"arXiv:2402.08939v2 Announce Type: replace 
Abstract: Large language models (LLMs) have accomplished remarkable reasoning performance in various domains. However, in the domain of reasoning tasks, we discover a frailty: LLMs are surprisingly brittle to the ordering of the premises, despite the fact that such ordering does not alter the underlying task. In particular, we observe that LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps. For example, in deductive reasoning tasks, presenting the premises in the same order as the ground truth proof in the prompt (as opposed to random ordering) drastically increases the model's accuracy. We first examine the effect of premise ordering on deductive reasoning on a variety of LLMs, and our evaluation shows that permuting the premise order can cause a performance drop of over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to examine the ordering effect for mathematical problem-solving, and we again observe a significant drop in accuracy, relative to the original GSM8K benchmark.","[{'name': 'Xinyun Chen, Ryan A. Chi, Xuezhi Wang, Denny Zhou'}]",
1787,Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective,https://arxiv.org/abs/2402.09099,"arXiv:2402.09099v2 Announce Type: replace 
Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of \"self-organization\" and \"multifractal analysis,\" we explore how neuron interactions dynamically evolve during training, leading to \"emergence,\" mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a comprehensive examination of the emergent behavior in LLMs through the lens of both model size and training process, paving new avenues for research into the emergence in large models.","[{'name': 'Xiongye Xiao, Chenyu Zhou, Heng Ping, Defu Cao, Yaxing Li, Yizhuo Zhou, Shixuan Li, Paul Bogdan'}]",
1788,An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection,https://arxiv.org/abs/2402.11403,"arXiv:2402.11403v2 Announce Type: replace 
Abstract: Robots and autonomous systems require an understanding of complex events (CEs) from sensor data to interact with their environments and humans effectively. Traditional end-to-end neural architectures, despite processing sensor data efficiently, struggle with long-duration events due to limited context sizes and reasoning capabilities. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning. We investigate neural and neuro-symbolic architectures' performance in a multimodal CED task, analyzing IMU and acoustic data streams to recognize CE patterns. Our methodology includes (i) end-to-end neural architectures for direct CE detection from sensor embeddings, (ii) two-stage concept-based neural models mapping sensor embeddings to atomic events (AEs) before CE detection, and (iii) a neuro-symbolic approach using a symbolic finite-state machine for CE detection from AEs. Empirically, the neuro-symbolic architecture significantly surpasses purely neural models, demonstrating superior performance in CE recognition, even with extensive training data and ample temporal context for neural approaches.","[{'name': 'Liying Han, Mani B. Srivastava'}]",
1789,A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs,https://arxiv.org/abs/2402.15140,"arXiv:2402.15140v2 Announce Type: replace 
Abstract: Hyper-relational knowledge graphs (KGs) contain additional key-value pairs, providing more information about the relations. In many scenarios, the same relation can have distinct key-value pairs, making the original triple fact more recognizable and specific. Prior studies on hyper-relational KGs have established a solid standard method for hyper-relational graph encoding. In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE. Compared to the prior state-of-the-art approach, ReSaE emphasizes the interaction of relations during message passing process and optimizes the readout structure for link prediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational KGs and ensures stronger performance on downstream link prediction tasks. Our experiments demonstrate that ReSaE achieves state-of-the-art performance on multiple link prediction benchmarks. Furthermore, we also analyze the influence of different model structures on model performance.",[{'name': 'Yonglin Jing'}],
1790,Data Interpreter: An LLM Agent For Data Science,https://arxiv.org/abs/2402.18679,"arXiv:2402.18679v2 Announce Type: replace 
Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated superior performance, exhibiting significant improvements in machine learning tasks, increasing from 0.86 to 0.95. Additionally, it showed a 26% increase in the MATH dataset and a remarkable 112% improvement in open-ended tasks. The solution will be released at https://github.com/geekan/MetaGPT.","[{'name': 'Sirui Hong, Yizhang Lin, Bangbang Liu, Binhao Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Lingyao Zhang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Wenyi Wang, Xiangru Tang, Xiangtao Lu, Xinbing Liang, Yaying Fei, Yuheng Cheng, Zongze Xu, Chenglin Wu, Li Zhang, Min Yang, Xiawu Zheng'}]",
1791,Identification of Craving Maps among Marijuana Users via Analysis of Functional Brain Networks with High-Order Attention Graph Neural Networks,https://arxiv.org/abs/2403.00033,"arXiv:2403.00033v2 Announce Type: replace 
Abstract: The consumption of high doses of marijuana can have significant psychological and social impacts. In this study, we propose an interpretable novel framework called the HOGAB (High-Order Graph Attention Neural Networks) model for addictive Marijuana classification and analysis of the localized network clusters that demonstrated abnormal brain activities among chronic marijuana users. The HOGAB integrates dynamic intrinsic functional networks with LSTM technology to capture temporal patterns in fMRI time series of marijuana users. We employed the high-order attention module in neighborhood nodes for information fusion and message passing, enhancing community clustering analysis for long-term marijuana users. Furthermore, we improve the overall classification ability of the model by incorporating attention mechanisms, achieving an AUC of 85.1% and an accuracy of 80.7% in classification, higher than the comparison algoirthms. Specifically, we identified the most relevant subnetworks and cognitive regions that are influenced by persistent marijuana usage, revealing that chronic marijuana consumption adversely affects cognitive control, particularly within the Dorsal Attention and Frontoparietal networks, which are essential for attentional, cognitive and higher cognitive functions. The results show that our proposed model is capable of accurately predicting craving bahavior and identifying brain maps associated with long-term cravings, and thus pinpointing brain regions that are important for analysis.","[{'name': 'Jun-En Ding, Shihao Yang, Anna Zilverstand, Feng Liu'}]",
1792,Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound,https://arxiv.org/abs/1907.01743,"arXiv:1907.01743v2 Announce Type: replace-cross 
Abstract: Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of essential importance for image-guided prostate interventions and treatment planning. However, developing such automatic solutions remains very challenging due to the missing/ambiguous boundary and inhomogeneous intensity distribution of the prostate in TRUS, as well as the large variability in prostate shapes. This paper develops a novel 3D deep neural network equipped with attention modules for better prostate segmentation in TRUS by fully exploiting the complementary information encoded in different layers of the convolutional neural network (CNN). Our attention module utilizes the attention mechanism to selectively leverage the multilevel features integrated from different layers to refine the features at each individual layer, suppressing the non-prostate noise at shallow layers of the CNN and increasing more prostate details into features at deep layers. Experimental results on challenging 3D TRUS volumes show that our method attains satisfactory segmentation performance. The proposed attention mechanism is a general strategy to aggregate multi-level deep features and has the potential to be used for other medical image segmentation tasks. The code is publicly available at https://github.com/wulalago/DAF3D.","[{'name': 'Yi Wang, Haoran Dou, Xiaowei Hu, Lei Zhu, Xin Yang, Ming Xu, Jing Qin, Pheng-Ann Heng, Tianfu Wang, Dong Ni'}]",
1793,Private Prediction Sets,https://arxiv.org/abs/2102.06202,"arXiv:2102.06202v3 Announce Type: replace-cross 
Abstract: In real-world settings involving consequential decision-making, the deployment of machine learning systems generally requires both reliable uncertainty quantification and protection of individuals' privacy. We present a framework that treats these two desiderata jointly. Our framework is based on conformal prediction, a methodology that augments predictive models to return prediction sets that provide uncertainty quantification -- they provably cover the true response with a user-specified probability, such as 90%. One might hope that when used with privately-trained models, conformal prediction would yield privacy guarantees for the resulting prediction sets; unfortunately, this is not the case. To remedy this key problem, we develop a method that takes any pre-trained predictive model and outputs differentially private prediction sets. Our method follows the general approach of split conformal prediction; we use holdout data to calibrate the size of the prediction sets but preserve privacy by using a privatized quantile subroutine. This subroutine compensates for the noise introduced to preserve privacy in order to guarantee correct coverage. We evaluate the method on large-scale computer vision datasets.","[{'name': 'Anastasios N. Angelopoulos, Stephen Bates, Tijana Zrnic, Michael I. Jordan'}]",
1794,CMGAN: Conformer-based Metric GAN for Speech Enhancement,https://arxiv.org/abs/2203.15149,"arXiv:2203.15149v4 Announce Type: replace-cross 
Abstract: Recently, convolution-augmented transformer (Conformer) has achieved promising performance in automatic speech recognition (ASR) and time-domain speech enhancement (SE), as it can capture both local and global dependencies in the speech signal. In this paper, we propose a conformer-based metric generative adversarial network (CMGAN) for SE in the time-frequency (TF) domain. In the generator, we utilize two-stage conformer blocks to aggregate all magnitude and complex spectrogram information by modeling both time and frequency dependencies. The estimation of magnitude and complex spectrogram is decoupled in the decoder stage and then jointly incorporated to reconstruct the enhanced speech. In addition, a metric discriminator is employed to further improve the quality of the enhanced estimated speech by optimizing the generator with respect to a corresponding evaluation score. Quantitative analysis on Voice Bank+DEMAND dataset indicates the capability of CMGAN in outperforming various previous models with a margin, i.e., PESQ of 3.41 and SSNR of 11.10 dB.","[{'name': 'Ruizhe Cao, Sherif Abdulatif, Bin Yang'}]",
1795,Multi-View Hypercomplex Learning for Breast Cancer Screening,https://arxiv.org/abs/2204.05798,"arXiv:2204.05798v3 Announce Type: replace-cross 
Abstract: Traditionally, deep learning methods for breast cancer classification perform a single-view analysis. However, radiologists simultaneously analyze all four views that compose a mammography exam, owing to the correlations contained in mammography views, which present crucial information for identifying tumors. In light of this, some studies have started to propose multi-view methods. Nevertheless, in such existing architectures, mammogram views are processed as independent images by separate convolutional branches, thus losing correlations among them. To overcome such limitations, in this paper, we propose a methodological approach for multi-view breast cancer classification based on parameterized hypercomplex neural networks. Thanks to hypercomplex algebra properties, our networks are able to model, and thus leverage, existing correlations between the different views that comprise a mammogram, thus mimicking the reading process performed by clinicians. This happens because hypercomplex networks capture both global properties, as standard neural models, as well as local relations, i.e., inter-view correlations, which real-valued networks fail at modeling. We define architectures designed to process two-view exams, namely PHResNets, and four-view exams, i.e., PHYSEnet and PHYBOnet. Through an extensive experimental evaluation conducted with publicly available datasets, we demonstrate that our proposed models clearly outperform real-valued counterparts and state-of-the-art methods, proving that breast cancer classification benefits from the proposed multi-view architectures. We also assess the method generalizability beyond mammogram analysis by considering different benchmarks, as well as a finer-scaled task such as segmentation. Full code and pretrained models for complete reproducibility of our experiments are freely available at https://github.com/ispamm/PHBreast.","[{'name': 'Eleonora Lopez, Eleonora Grassucci, Martina Valleriani, Danilo Comminiello'}]",
1796,Approximate Nash Equilibrium Learning for n-Player Markov Games in Dynamic Pricing,https://arxiv.org/abs/2207.06492,"arXiv:2207.06492v3 Announce Type: replace-cross 
Abstract: We investigate Nash equilibrium learning in a competitive Markov Game (MG) environment, where multiple agents compete, and multiple Nash equilibria can exist. In particular, for an oligopolistic dynamic pricing environment, exact Nash equilibria are difficult to obtain due to the curse-of-dimensionality. We develop a new model-free method to find approximate Nash equilibria. Gradient-free black box optimization is then applied to estimate $\\epsilon$, the maximum reward advantage of an agent unilaterally deviating from any joint policy, and to also estimate the $\\epsilon$-minimizing policy for any given state. The policy-$\\epsilon$ correspondence and the state to $\\epsilon$-minimizing policy are represented by neural networks, the latter being the Nash Policy Net. During batch update, we perform Nash Q learning on the system, by adjusting the action probabilities using the Nash Policy Net. We demonstrate that an approximate Nash equilibrium can be learned, particularly in the dynamic pricing domain where exact solutions are often intractable.",[{'name': 'Larkin Liu'}],
1797,Using Forwards-Backwards Models to Approximate MDP Homomorphisms,https://arxiv.org/abs/2209.06356,"arXiv:2209.06356v3 Announce Type: replace-cross 
Abstract: Reinforcement learning agents must painstakingly learn through trial and error what sets of state-action pairs are value equivalent -- requiring an often prohibitively large amount of environment experience. MDP homomorphisms have been proposed that reduce the MDP of an environment to an abstract MDP, enabling better sample efficiency. Consequently, impressive improvements have been achieved when a suitable homomorphism can be constructed a priori -- usually by exploiting a practitioner's knowledge of environment symmetries. We propose a novel approach to constructing homomorphisms in discrete action spaces, which uses a learnt model of environment dynamics to infer which state-action pairs lead to the same state -- which can reduce the size of the state-action space by a factor as large as the cardinality of the original action space. In MinAtar, we report an almost 4x improvement over a value-based off-policy baseline in the low sample limit, when averaging over all games and optimizers.","[{'name': 'Augustine N. Mavor-Parker, Matthew J. Sargent, Christian Pehle, Andrea Banino, Lewis D. Griffin, Caswell Barry'}]",
1798,SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction,https://arxiv.org/abs/2210.04870,"arXiv:2210.04870v3 Announce Type: replace-cross 
Abstract: Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. The implementation of SMiLE is available at https://github.com/GKNL/SMiLE.","[{'name': 'Miao Peng, Ben Liu, Qianqian Xie, Wenjie Xu, Hua Wang, Min Peng'}]",
1799,FedTracker: Furnishing Ownership Verification and Traceability for Federated Learning Model,https://arxiv.org/abs/2211.07160,"arXiv:2211.07160v3 Announce Type: replace-cross 
Abstract: Federated learning (FL) is a distributed machine learning paradigm allowing multiple clients to collaboratively train a global model without sharing their local data. However, FL entails exposing the model to various participants. This poses a risk of unauthorized model distribution or resale by the malicious client, compromising the intellectual property rights of the FL group. To deter such misbehavior, it is essential to establish a mechanism for verifying the ownership of the model and as well tracing its origin to the leaker among the FL participants. In this paper, we present FedTracker, the first FL model protection framework that provides both ownership verification and traceability. FedTracker adopts a bi-level protection scheme consisting of global watermark mechanism and local fingerprint mechanism. The former authenticates the ownership of the global model, while the latter identifies which client the model is derived from. FedTracker leverages Continual Learning (CL) principles to embed the watermark in a way that preserves the utility of the FL model on both primitive task and watermark task. FedTracker also devises a novel metric to better discriminate different fingerprints. Experimental results show FedTracker is effective in ownership verification, traceability, and maintains good fidelity and robustness against various watermark removal attacks.","[{'name': 'Shuo Shao, Wenyuan Yang, Hanlin Gu, Zhan Qin, Lixin Fan, Qiang Yang, Kui Ren'}]",
1800,PIP: Positional-encoding Image Prior,https://arxiv.org/abs/2211.14298,"arXiv:2211.14298v3 Announce Type: replace-cross 
Abstract: In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior\" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page https://nimrodshabtay.github.io/PIP/","[{'name': 'Nimrod Shabtay, Eli Schwartz, Raja Giryes'}]",
1801,Discovering Latent Knowledge in Language Models Without Supervision,https://arxiv.org/abs/2212.03827,"arXiv:2212.03827v2 Announce Type: replace-cross 
Abstract: Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels.","[{'name': 'Collin Burns, Haotian Ye, Dan Klein, Jacob Steinhardt'}]",
1802,Complementary Random Masking for RGB-Thermal Semantic Segmentation,https://arxiv.org/abs/2303.17386,"arXiv:2303.17386v2 Announce Type: replace-cross 
Abstract: RGB-thermal semantic segmentation is one potential solution to achieve reliable semantic scene understanding in adverse weather and lighting conditions. However, the previous studies mostly focus on designing a multi-modal fusion module without consideration of the nature of multi-modality inputs. Therefore, the networks easily become over-reliant on a single modality, making it difficult to learn complementary and meaningful representations for each modality. This paper proposes 1) a complementary random masking strategy of RGB-T images and 2) self-distillation loss between clean and masked input modalities. The proposed masking strategy prevents over-reliance on a single modality. It also improves the accuracy and robustness of the neural network by forcing the network to segment and classify objects even when one modality is partially available. Also, the proposed self-distillation loss encourages the network to extract complementary and meaningful representations from a single modality or complementary masked modalities. Based on the proposed method, we achieve state-of-the-art performance over three RGB-T semantic segmentation benchmarks. Our source code is available at https://github.com/UkcheolShin/CRM_RGBTSeg.","[{'name': 'Ukcheol Shin, Kyunghyun Lee, In So Kweon, Jean Oh'}]",
1803,False Claims against Model Ownership Resolution,https://arxiv.org/abs/2304.06607,"arXiv:2304.06607v5 Announce Type: replace-cross 
Abstract: Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.
  In this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our core idea is that a malicious accuser can deviate (without detection) from the specified MOR process by finding (transferable) adversarial examples that successfully serve as evidence against independent suspect models. To this end, we first generalize the procedures of common MOR schemes and show that, under this generalization, defending against false claims is as challenging as preventing (transferable) adversarial examples. Via systematic empirical evaluation, we demonstrate that our false claim attacks always succeed in the MOR schemes that follow our generalization, including against a real-world model: Amazon's Rekognition API.","[{'name': 'Jian Liu, Rui Zhang, Sebastian Szyller, Kui Ren, N. Asokan'}]",
1804,Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion,https://arxiv.org/abs/2305.07912,"arXiv:2305.07912v2 Announce Type: replace-cross 
Abstract: Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that our model has great competitiveness compared to other models with four metrics. Our model can effectively incorporate information from temporal knowledge graphs into the language models.","[{'name': 'Wenjie Xu, Ben Liu, Miao Peng, Xu Jia, Min Peng'}]",
1805,Deep Temporal Graph Clustering,https://arxiv.org/abs/2305.10738,"arXiv:2305.10738v2 Announce Type: replace-cross 
Abstract: Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which introduces deep clustering techniques to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and static graph clustering from several levels. To verify the superiority of the proposed framework TGC, we conduct extensive experiments. The experimental results show that temporal graph clustering enables more flexibility in finding a balance between time and space requirements, and our framework can effectively improve the performance of existing temporal graph learning methods. The code is released: https://github.com/MGitHubL/Deep-Temporal-Graph-Clustering.","[{'name': 'Meng Liu, Yue Liu, Ke Liang, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu'}]",
1806,Unpaired Image-to-Image Translation via Neural Schr\\\"odinger Bridge,https://arxiv.org/abs/2305.15086,"arXiv:2305.15086v3 Announce Type: replace-cross 
Abstract: Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. While diffusion models have achieved remarkable progress, they have limitations in unpaired image-to-image (I2I) translation tasks due to the Gaussian prior assumption. Schr\\\"{o}dinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. Yet, to our best knowledge, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose Unpaired Neural Schr\\\"{o}dinger Bridge (UNSB), which expresses the SB problem as a sequence of adversarial learning problems. This allows us to incorporate advanced discriminators and regularization to learn a SB between unpaired data. We show that UNSB is scalable and successfully solves various unpaired I2I translation tasks. Code: \\url{https://github.com/cyclomon/UNSB}","[{'name': 'Beomsu Kim, Gihyun Kwon, Kwanyoung Kim, Jong Chul Ye'}]",
1807,Learning Safety Constraints from Demonstrations with Unknown Rewards,https://arxiv.org/abs/2305.16147,"arXiv:2305.16147v2 Announce Type: replace-cross 
Abstract: We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in gridworld environments and a driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior. Importantly, we can safely transfer the learned constraints to different tasks and environments. In contrast, alternative methods based on Inverse Reinforcement Learning (IRL) often exhibit poor performance and learn unsafe policies.","[{'name': 'David Lindner, Xin Chen, Sebastian Tschiatschek, Katja Hofmann, Andreas Krause'}]",
1808,Multi-Objective Genetic Algorithm for Multi-View Feature Selection,https://arxiv.org/abs/2305.18352,"arXiv:2305.18352v2 Announce Type: replace-cross 
Abstract: Multi-view datasets offer diverse forms of data that can enhance prediction models by providing complementary information. However, the use of multi-view data leads to an increase in high-dimensional data, which poses significant challenges for the prediction models that can lead to poor generalization. Therefore, relevant feature selection from multi-view datasets is important as it not only addresses the poor generalization but also enhances the interpretability of the models. Despite the success of traditional feature selection methods, they have limitations in leveraging intrinsic information across modalities, lacking generalizability, and being tailored to specific classification tasks. We propose a novel genetic algorithm strategy to overcome these limitations of traditional feature selection methods for multi-view data. Our proposed approach, called the multi-view multi-objective feature selection genetic algorithm (MMFS-GA), simultaneously selects the optimal subset of features within a view and between views under a unified framework. The MMFS-GA framework demonstrates superior performance and interpretability for feature selection on multi-view datasets in both binary and multiclass classification tasks. The results of our evaluations on three benchmark datasets, including synthetic and real data, show improvement over the best baseline methods. This work provides a promising solution for multi-view feature selection and opens up new possibilities for further research in multi-view datasets.","[{'name': 'Vandad Imani, Carlos Sevilla-Salcedo, Elaheh Moradi, Vittorio Fortino, Jussi Tohka'}]",
1809,Safe Offline Reinforcement Learning with Real-Time Budget Constraints,https://arxiv.org/abs/2306.00603,"arXiv:2306.00603v2 Announce Type: replace-cross 
Abstract: Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many real-world applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that models this problem from the perspective of trajectory distribution and solves it through diffusion model planning. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance guarantee for TREBI. Empirical results on a wide range of simulation tasks and a real-world large-scale advertising application demonstrate the capability of TREBI in solving real-time budget constraint problems under offline settings.","[{'name': 'Qian Lin, Bo Tang, Zifan Wu, Chao Yu, Shangqin Mao, Qianlong Xie, Xingxing Wang, Dong Wang'}]",
1810,Prompt Injection attack against LLM-integrated Applications,https://arxiv.org/abs/2306.05499,"arXiv:2306.05499v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and severe attack outcomes, such as unrestricted arbitrary LLM usage and uncomplicated application prompt theft. We deploy HouYi on 36 actual LLM-integrated applications and discern 31 applications susceptible to prompt injection. 10 vendors have validated our discoveries, including Notion, which has the potential to impact millions of users. Our investigation illuminates both the possible risks of prompt injection attacks and the possible tactics for mitigation.","[{'name': 'Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Zihao Wang, Xiaofeng Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, Yang Liu'}]",
1811,Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing,https://arxiv.org/abs/2306.06022,"arXiv:2306.06022v2 Announce Type: replace-cross 
Abstract: The computing in the network (COIN) paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation-demanding applications, such as the metaverse. In this vein, we consider the partial computation offloading problem in the metaverse for multiple subtasks in a COIN environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. The problem is NP-hard, and we transform it into two subproblems: the task-splitting problem (TSP) on the user side and the task-offloading problem (TOP) on the COIN side. We model the TSP as an ordinal potential game and propose a decentralized algorithm to obtain its Nash equilibrium (NE). Then, we model the TOP as a Markov decision process and propose the double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decisions randomly within a certain probability, the COIN agent explores the NE of the TSP and the deep neural network. Finally, the simulation results reveal that the proposed model approach allows the COIN agent to update its policies and make more informed decisions, leading to improved performance over time compared to the traditional baseline","[{'name': 'Ibrahim Aliyu, Seungmin Oh, Namseok Ko, Tai-Won Um, Jinsul Kim'}]",
1812,Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models,https://arxiv.org/abs/2306.08018,"arXiv:2306.08018v5 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.","[{'name': 'Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen'}]",
1813,DCTX-Conformer: Dynamic context carry-over for low latency unified streaming and non-streaming Conformer ASR,https://arxiv.org/abs/2306.08175,"arXiv:2306.08175v2 Announce Type: replace-cross 
Abstract: Conformer-based end-to-end models have become ubiquitous these days and are commonly used in both streaming and non-streaming automatic speech recognition (ASR). Techniques like dual-mode and dynamic chunk training helped unify streaming and non-streaming systems. However, there remains a performance gap between streaming with a full and limited past context. To address this issue, we propose the integration of a novel dynamic contextual carry-over mechanism in a state-of-the-art (SOTA) unified ASR system. Our proposed dynamic context Conformer (DCTX-Conformer) utilizes a non-overlapping contextual carry-over mechanism that takes into account both the left context of a chunk and one or more preceding context embeddings. We outperform the SOTA by a relative 25.0% word error rate, with a negligible latency impact due to the additional context embeddings.","[{'name': 'Goeric Huybrechts, Srikanth Ronanki, Xilai Li, Hadis Nosrati, Sravan Bodapati, Katrin Kirchhoff'}]",
1814,LabelBench: A Comprehensive Framework for Benchmarking Adaptive Label-Efficient Learning,https://arxiv.org/abs/2306.09910,"arXiv:2306.09910v4 Announce Type: replace-cross 
Abstract: Labeled data are critical to modern machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and active learning, aim to be label-efficient: achieving high predictive performance from relatively few labeled examples. While obtaining the best label-efficiency in practice often requires combinations of these techniques, existing benchmark and evaluation frameworks do not capture a concerted combination of all such techniques. This paper addresses this deficiency by introducing LabelBench, a new computationally-efficient framework for joint evaluation of multiple label-efficient learning techniques. As an application of LabelBench, we introduce a novel benchmark of state-of-the-art active learning methods in combination with semi-supervised learning for fine-tuning pretrained vision transformers. Our benchmark demonstrates better label-efficiencies than previously reported in active learning. LabelBench's modular codebase is open-sourced for the broader community to contribute label-efficient learning methods and benchmarks. The repository can be found at: https://github.com/EfficientTraining/LabelBench.","[{'name': 'Jifan Zhang, Yifang Chen, Gregory Canal, Stephen Mussmann, Arnav M. Das, Gantavya Bhatt, Yinglun Zhu, Jeffrey Bilmes, Simon Shaolei Du, Kevin Jamieson, Robert D Nowak'}]",
1815,MATNet: Multi-Level Fusion Transformer-Based Model for Day-Ahead PV Generation Forecasting,https://arxiv.org/abs/2306.10356,"arXiv:2306.10356v2 Announce Type: replace-cross 
Abstract: Accurate forecasting of renewable generation is crucial to facilitate the integration of RES into the power system. Focusing on PV units, forecasting methods can be divided into two main categories: physics-based and data-based strategies, with AI-based models providing state-of-the-art performance. However, while these AI-based models can capture complex patterns and relationships in the data, they ignore the underlying physical prior knowledge of the phenomenon. Therefore, in this paper we propose MATNet, a novel self-attention transformer-based architecture for multivariate multi-step day-ahead PV power generation forecasting. It consists of a hybrid approach that combines the AI paradigm with the prior physical knowledge of PV power generation of physics-based methods. The model is fed with historical PV data and historical and forecast weather data through a multi-level joint fusion approach. The effectiveness of the proposed model is evaluated using the Ausgrid benchmark dataset with different regression performance metrics. The results show that our proposed architecture significantly outperforms the current state-of-the-art methods. These findings demonstrate the potential of MATNet in improving forecasting accuracy and suggest that it could be a promising solution to facilitate the integration of PV energy into the power grid.","[{'name': 'Matteo Tortora, Francesco Conte, Gianluca Natrella, Paolo Soda'}]",
1816,Tackling the Curse of Dimensionality with Physics-Informed Neural Networks,https://arxiv.org/abs/2307.12306,"arXiv:2307.12306v5 Announce Type: replace-cross 
Abstract: The curse-of-dimensionality taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs, as Richard E. Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. We develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and randomly samples a subset of these dimensional pieces in each iteration of training PINNs. We prove theoretically the convergence and other desired properties of the proposed method. We demonstrate in various diverse tests that the proposed method can solve many notoriously hard high-dimensional PDEs, including the Hamilton-Jacobi-Bellman (HJB) and the Schr\\\"{o}dinger equations in tens of thousands of dimensions very fast on a single GPU using the PINNs mesh-free approach. Notably, we solve nonlinear PDEs with nontrivial, anisotropic, and inseparable solutions in 100,000 effective dimensions in 12 hours on a single GPU using SDGD with PINNs. Since SDGD is a general training methodology of PINNs, it can be applied to any current and future variants of PINNs to scale them up for arbitrary high-dimensional PDEs.","[{'name': 'Zheyuan Hu, Khemraj Shukla, George Em Karniadakis, Kenji Kawaguchi'}]",
1817,Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation,https://arxiv.org/abs/2307.15337,"arXiv:2307.15337v3 Announce Type: replace-cross 
Abstract: This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose Skeleton-of-Thought (SoT), which first guides LLMs to generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-ups across 12 LLMs, but it can also potentially improve the answer quality on several question categories. SoT is an initial attempt at data-centric optimization for inference efficiency, and showcases the potential of eliciting high-quality answers by explicitly planning the answer structure in language.","[{'name': 'Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, Yu Wang'}]",
1818,Physically Grounded Vision-Language Models for Robotic Manipulation,https://arxiv.org/abs/2309.02561,"arXiv:2309.02561v4 Announce Type: replace-cross 
Abstract: Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 39.6K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, including generalization to held-out concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically grounded VLM in an interactive framework with a large language model-based robotic planner, and show improved planning performance on tasks that require reasoning about physical object concepts, compared to baselines that do not leverage physically grounded VLMs. We additionally illustrate the benefits of our physically grounded VLM on a real robot, where it improves task success rates. We release our dataset and provide further details and visualizations of our results at https://iliad.stanford.edu/pg-vlm/.","[{'name': 'Jensen Gao, Bidipta Sarkar, Fei Xia, Ted Xiao, Jiajun Wu, Brian Ichter, Anirudha Majumdar, Dorsa Sadigh'}]",
1819,A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism,https://arxiv.org/abs/2309.03720,"arXiv:2309.03720v3 Announce Type: replace-cross 
Abstract: Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.","[{'name': \"Radek Svoboda, Sebastian Basterrech, J\\\\k{e}drzej Kozal, Jan Plato\\\\v{s}, Micha{\\\\l} Wo\\\\'zniak\"}]",
1820,Contrastive Continual Multi-view Clustering with Filtered Structural Fusion,https://arxiv.org/abs/2309.15135,"arXiv:2309.15135v2 Announce Type: replace-cross 
Abstract: Multi-view clustering thrives in applications where views are collected in advance by extracting consistent and complementary information among views. However, it overlooks scenarios where data views are collected sequentially, i.e., real-time data. Due to privacy issues or memory burden, previous views are not available with time in these situations. Some methods are proposed to handle it but are trapped in a stability-plasticity dilemma. In specific, these methods undergo a catastrophic forgetting of prior knowledge when a new view is attained. Such a catastrophic forgetting problem (CFP) would cause the consistent and complementary information hard to get and affect the clustering performance. To tackle this, we propose a novel method termed Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF). Precisely, considering that data correlations play a vital role in clustering and prior knowledge ought to guide the clustering process of a new view, we develop a data buffer with fixed size to store filtered structural information and utilize it to guide the generation of a robust partition matrix via contrastive learning. Furthermore, we theoretically connect CCMVC-FSF with semi-supervised learning and knowledge distillation. Extensive experiments exhibit the excellence of the proposed method.","[{'name': 'Xinhang Wan, Jiyuan Liu, Hao Yu, Ao Li, Xinwang Liu, Ke Liang, Zhibin Dong, En Zhu'}]",
1821,"Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities",https://arxiv.org/abs/2309.16739,"arXiv:2309.16739v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, quantization, and parameter-sharing inference, to facilitate the efficient deployment of LLMs. This article serves as a position paper for thoroughly identifying the motivation, challenges, and pathway for empowering LLMs at the 6G edge.","[{'name': 'Zheng Lin, Guanqiao Qu, Qiyuan Chen, Xianhao Chen, Zhe Chen, Kaibin Huang'}]",
1822,Active-Perceptive Motion Generation for Mobile Manipulation,https://arxiv.org/abs/2310.00433,"arXiv:2310.00433v2 Announce Type: replace-cross 
Abstract: Mobile Manipulation (MoMa) systems incorporate the benefits of mobility and dexterity, due to the enlarged space in which they can move and interact with their environment. However, even when equipped with onboard sensors, e.g., an embodied camera, extracting task-relevant visual information in unstructured and cluttered environments, such as households, remains challenging. In this work, we introduce an active perception pipeline for mobile manipulators to generate motions that are informative toward manipulation tasks, such as grasping in unknown, cluttered scenes. Our proposed approach, ActPerMoMa, generates robot paths in a receding horizon fashion by sampling paths and computing path-wise utilities. These utilities trade-off maximizing the visual Information Gain (IG) for scene reconstruction and the task-oriented objective, e.g., grasp success, by maximizing grasp reachability. We show the efficacy of our method in simulated experiments with a dual-arm TIAGo++ MoMa robot performing mobile grasping in cluttered scenes with obstacles. We empirically analyze the contribution of various utilities and parameters, and compare against representative baselines both with and without active perception objectives. Finally, we demonstrate the transfer of our mobile grasping strategy to the real world, indicating a promising direction for active-perceptive MoMa.","[{'name': 'Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki'}]",
1823,Language Models Represent Space and Time,https://arxiv.org/abs/2310.02207,"arXiv:2310.02207v3 Announce Type: replace-cross 
Abstract: The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual \"space neurons\" and \"time neurons\" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.","[{'name': 'Wes Gurnee, Max Tegmark'}]",
1824,From asynchronous states to Griffiths phases and back: structural heterogeneity and homeostasis in excitatory-inhibitory networks,https://arxiv.org/abs/2310.02369,"arXiv:2310.02369v2 Announce Type: replace-cross 
Abstract: Balanced neural networks -- in which excitatory and inhibitory inputs compensate each other on average -- give rise to a dynamical phase dominated by fluctuations called asynchronous state, crucial for brain functioning. However, structural disorder -- which is inherent to random networks -- can hinder such an excitation-inhibition balance. Indeed, structural and synaptic heterogeneities can generate extended regions in phase space akin to critical points, called Griffiths phases, with dynamical features very different from those of asynchronous states. Here, we study a simple neural-network model with tunable levels of heterogeneity able to display these two types of dynamical regimes -- i.e., asynchronous states and Griffiths phases -- putting them together within a single phase diagram. Using this simple model, we are able to emphasize the crucial role played by synaptic plasticity and homeostasis to re-establish balance in intrinsically heterogeneous networks. Overall, we shed light onto how diverse dynamical regimes, each with different functional advantages, can emerge from a given network as a result of self-organizing homeostatic mechanisms.","[{'name': \"Jorge Pretel, Victor Buend\\\\'ia, Joaqu\\\\'in J. Torres, Miguel A. Mu\\\\~noz\"}]",
1825,Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization,https://arxiv.org/abs/2310.03234,"arXiv:2310.03234v4 Announce Type: replace-cross 
Abstract: This paper investigates new families of compositional optimization problems, called $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf w}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf c}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\\epsilon$-stationary point of the Moreau envelop of the objective function. Additionally, we also extend the algorithm to solving novel non-smooth weakly-convex tri-level finite-sum coupled compositional optimization problems, which feature a nested arrangement of three functions. Lastly, we explore the applications of our algorithms in deep learning for two-way partial AUC maximization and multi-instance two-way partial AUC maximization, using empirical studies to showcase the effectiveness of the proposed algorithms.","[{'name': 'Quanqi Hu, Dixian Zhu, Tianbao Yang'}]",
1826,Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction,https://arxiv.org/abs/2310.05207,"arXiv:2310.05207v5 Announce Type: replace-cross 
Abstract: Recently how to introduce large amounts of unlabeled facial images in the wild into supervised Facial Action Unit (AU) detection frameworks has become a challenging problem. In this paper, we propose a new AU detection framework where multi-task learning is introduced to jointly learn AU domain separation and reconstruction and facial landmark detection by sharing the parameters of homostructural facial extraction modules. In addition, we propose a new feature alignment scheme based on contrastive learning by simple projectors and an improved contrastive loss, which adds four additional intermediate supervisors to promote the feature reconstruction process. Experimental results on two benchmarks demonstrate our superiority against the state-of-the-art methods for AU detection in the wild.","[{'name': 'Ziqiao Shang, Li Yu'}]",
1827,Reinforcement learning for freeform robot design,https://arxiv.org/abs/2310.05670,"arXiv:2310.05670v2 Announce Type: replace-cross 
Abstract: Inspired by the necessity of morphological adaptation in animals, a growing body of work has attempted to expand robot training to encompass physical aspects of a robot's design. However, reinforcement learning methods capable of optimizing the 3D morphology of a robot have been restricted to reorienting or resizing the limbs of a predetermined and static topological genus. Here we show policy gradients for designing freeform robots with arbitrary external and internal structure. This is achieved through actions that deposit or remove bundles of atomic building blocks to form higher-level nonparametric macrostructures such as appendages, organs and cavities. Although results are provided for open loop control only, we discuss how this method could be adapted for closed loop control and sim2real transfer to physical machines in future.","[{'name': 'Muhan Li, David Matthews, Sam Kriegman'}]",
1828,HIO-SDF: Hierarchical Incremental Online Signed Distance Fields,https://arxiv.org/abs/2310.09463,"arXiv:2310.09463v2 Announce Type: replace-cross 
Abstract: A good representation of a large, complex mobile robot workspace must be space-efficient yet capable of encoding relevant geometric details. When exploring unknown environments, it needs to be updatable incrementally in an online fashion. We introduce HIO-SDF, a new method that represents the environment as a Signed Distance Field (SDF). State of the art representations of SDFs are based on either neural networks or voxel grids. Neural networks are capable of representing the SDF continuously. However, they are hard to update incrementally as neural networks tend to forget previously observed parts of the environment unless an extensive sensor history is stored for training. Voxel-based representations do not have this problem but they are not space-efficient especially in large environments with fine details. HIO-SDF combines the advantages of these representations using a hierarchical approach which employs a coarse voxel grid that captures the observed parts of the environment together with high-resolution local information to train a neural network. HIO-SDF achieves a 46% lower mean global SDF error across all test scenes than a state of the art continuous representation, and a 30% lower error than a discrete representation at the same resolution as our coarse global SDF grid. Videos and code are available at: https://samsunglabs.github.io/HIO-SDF-project-page/","[{'name': 'Vasileios Vasilopoulos, Suveer Garg, Jinwook Huh, Bhoram Lee, Volkan Isler'}]",
1829,Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring,https://arxiv.org/abs/2310.09680,"arXiv:2310.09680v4 Announce Type: replace-cross 
Abstract: Automatic Speech Recognition (ASR) has witnessed a profound research interest. Recent breakthroughs have given ASR systems different prospects such as faithfully transcribing spoken language, which is a pivotal advancement in building conversational agents. However, there is still an imminent challenge of accurately discerning context-dependent words and phrases. In this work, we propose a novel approach for enhancing contextual recognition within ASR systems via semantic lattice processing leveraging the power of deep learning models in accurately delivering spot-on transcriptions across a wide variety of vocabularies and speaking styles. Our solution consists of using Hidden Markov Models and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks (DNN) models integrating both language and acoustic modeling for better accuracy. We infused our network with the use of a transformer-based model to properly rescore the word lattice achieving remarkable capabilities with a palpable reduction in Word Error Rate (WER). We demonstrate the effectiveness of our proposed framework on the LibriSpeech dataset with empirical analyses.","[{'name': 'Ankitha Sudarshan, Vinay Samuel, Parth Patwa, Ibtihel Amara, Aman Chadha'}]",
1830,Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning,https://arxiv.org/abs/2310.11053,"arXiv:2310.11053v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have made unprecedented breakthroughs, yet their increasing integration into everyday life might raise societal risks due to generated unethical content. Despite extensive study on specific issues like bias, the intrinsic values of LLMs remain largely unexplored from a moral philosophy perspective. This work delves into ethical values utilizing Moral Foundation Theory. Moving beyond conventional discriminative evaluations with poor reliability, we propose DeNEVIL, a novel prompt generation algorithm tailored to dynamically exploit LLMs' value vulnerabilities and elicit the violation of ethics in a generative manner, revealing their underlying value inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset comprising 2,397 prompts covering 500+ value principles, and then benchmark the intrinsic values across a spectrum of LLMs. We discovered that most models are essentially misaligned, necessitating further ethical value alignment. In response, we develop VILMO, an in-context alignment method that substantially enhances the value compliance of LLM outputs by learning to generate appropriate value instructions, outperforming existing competitors. Our methods are suitable for black-box and open-source models, offering a promising initial step in studying the ethical values of LLMs.","[{'name': 'Shitong Duan, Xiaoyuan Yi, Peng Zhang, Tun Lu, Xing Xie, Ning Gu'}]",
1831,Quantum Speedups in Regret Analysis of Infinite Horizon Average-Reward Markov Decision Processes,https://arxiv.org/abs/2310.11684,"arXiv:2310.11684v2 Announce Type: replace-cross 
Abstract: This paper investigates the potential of quantum acceleration in addressing infinite horizon Markov Decision Processes (MDPs) to enhance average reward outcomes. We introduce an innovative quantum framework for the agent's engagement with an unknown MDP, extending the conventional interaction paradigm. Our approach involves the design of an optimism-driven tabular Reinforcement Learning algorithm that harnesses quantum signals acquired by the agent through efficient quantum mean estimation techniques. Through thorough theoretical analysis, we demonstrate that the quantum advantage in mean estimation leads to exponential advancements in regret guarantees for infinite horizon Reinforcement Learning. Specifically, the proposed Quantum algorithm achieves a regret bound of $\\tilde{\\mathcal{O}}(1)$, a significant improvement over the $\\tilde{\\mathcal{O}}(\\sqrt{T})$ bound exhibited by classical counterparts.","[{'name': 'Bhargav Ganguly, Yang Xu, Vaneet Aggarwal'}]",
1832,Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments,https://arxiv.org/abs/2311.00123,"arXiv:2311.00123v2 Announce Type: replace-cross 
Abstract: As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of POMDPs under a uniform controlled filter stability (which does not require the knowledge of the model), and (iv) for multi-agent models where convergence of learning dynamics to a new class of equilibria, subjective Q-learning equilibria, will be studied. In addition to the convergence theorem, some implications of the theorem above are new to the literature and others are interpreted as applications of the convergence theorem. Some open problems are noted.","[{'name': 'Ali Devran Kara, Serdar Yuksel'}]",
1833,Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model,https://arxiv.org/abs/2311.00968,"arXiv:2311.00968v2 Announce Type: replace-cross 
Abstract: Numerous studies in the field of music generation have demonstrated impressive performance, yet virtually no models are able to directly generate music to match accompanying videos. In this work, we develop a generative music AI framework, Video2Music, that can match a provided video. We first curated a unique collection of music videos. Then, we analysed the music videos to obtain semantic, scene offset, motion, and emotion features. These distinct features are then employed as guiding input to our music generation model. We transcribe the audio files into MIDI and chords, and extract features such as note density and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on which we train a novel Affective Multimodal Transformer (AMT) model to generate music given a video. This model includes a novel mechanism to enforce affective similarity between video and music. Finally, post-processing is performed based on a biGRU-based regression model to estimate note density and loudness based on the video features. This ensures a dynamic rendering of the generated chords with varying rhythm and volume. In a thorough experiment, we show that our proposed framework can generate music that matches the video content in terms of emotion. The musical quality, along with the quality of music-video matching is confirmed in a user study. The proposed AMT model, along with the new MuVi-Sync dataset, presents a promising step for the new task of music generation for videos.","[{'name': 'Jaeyong Kang, Soujanya Poria, Dorien Herremans'}]",
1834,"A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",https://arxiv.org/abs/2311.05112,"arXiv:2311.05112v4 Announce Type: replace-cross 
Abstract: Large language models (LLMs), such as ChatGPT, have received substantial attention due to their capabilities for understanding and generating human language. While there has been a burgeoning trend in research focusing on the employment of LLMs in supporting different medical tasks (e.g., enhancing clinical diagnostics and providing medical education), a review of these efforts, particularly their development, practical applications, and outcomes in medicine, remains scarce. Therefore, this review aims to provide a detailed overview of the development and deployment of LLMs in medicine, including the challenges and opportunities they face. In terms of development, we provide a detailed introduction to the principles of existing medical LLMs, including their basic model structures, number of parameters, and sources and scales of data used for model development. It serves as a guide for practitioners in developing medical LLMs tailored to their specific needs. In terms of deployment, we offer a comparison of the performance of different LLMs across various medical tasks, and further compare them with state-of-the-art lightweight models, aiming to provide an understanding of the advantages and limitations of LLMs in medicine. Overall, in this review, we address the following questions: 1) What are the practices for developing medical LLMs 2) How to measure the medical task performance of LLMs in a medical setting? 3) How have medical LLMs been employed in real-world practice? 4) What challenges arise from the use of medical LLMs? and 5) How to more effectively develop and deploy medical LLMs? By answering these questions, this review aims to provide insights into the opportunities for LLMs in medicine and serve as a practical resource. We also maintain a regularly updated list of practical guides on medical LLMs at: https://github.com/AI-in-Health/MedLLMsPracticalGuide.","[{'name': 'Hongjian Zhou, Fenglin Liu, Boyang Gu, Xinyu Zou, Jinfa Huang, Jinge Wu, Yiru Li, Sam S. Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Chenyu You, Xian Wu, Yefeng Zheng, Lei Clifton, Zheng Li, Jiebo Luo, David A. Clifton'}]",
1835,MELA: Multilingual Evaluation of Linguistic Acceptability,https://arxiv.org/abs/2311.09033,"arXiv:2311.09033v2 Announce Type: replace-cross 
Abstract: Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families. We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages. Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting. Cross-lingual and multi-task learning experiments show that unlike semantic tasks, in-language training data is crucial in acceptability judgements. Results in layerwise probing indicate that the upper layers of XLM-R become a task-specific but language-agnostic region for multilingual acceptability judgment. We also introduce the concept of conflicting weight, which could be a potential indicator for the difficulty of cross-lingual transfer between languages. Our data will be available at https://github.com/sjtu-compling/MELA.","[{'name': 'Ziyin Zhang, Yikang Liu, Weifang Huang, Junyu Mao, Rui Wang, Hai Hu'}]",
1836,High-fidelity Person-centric Subject-to-Image Synthesis,https://arxiv.org/abs/2311.10329,"arXiv:2311.10329v3 Announce Type: replace-cross 
Abstract: Current subject-driven image generation methods encounter significant challenges in person-centric image generation. The reason is that they learn the semantic scene and person generation by fine-tuning a common pre-trained diffusion, which involves an irreconcilable training imbalance. Precisely, to generate realistic persons, they need to sufficiently tune the pre-trained model, which inevitably causes the model to forget the rich semantic scene prior and makes scene generation over-fit to the training data. Moreover, even with sufficient fine-tuning, these methods can still not generate high-fidelity persons since joint learning of the scene and person generation also lead to quality compromise. In this paper, we propose Face-diffuser, an effective collaborative generation pipeline to eliminate the above training imbalance and quality compromise. Specifically, we first develop two specialized pre-trained diffusion models, i.e., Text-driven Diffusion Model (TDM) and Subject-augmented Diffusion Model (SDM), for scene and person generation, respectively. The sampling process is divided into three sequential stages, i.e., semantic scene construction, subject-scene fusion, and subject enhancement. The first and last stages are performed by TDM and SDM respectively. The subject-scene fusion stage, that is the collaboration achieved through a novel and highly effective mechanism, Saliency-adaptive Noise Fusion (SNF). Specifically, it is based on our key observation that there exists a robust link between classifier-free guidance responses and the saliency of generated images. In each time step, SNF leverages the unique strengths of each model and allows for the spatial blending of predicted noises from both models automatically in a saliency-aware manner. Extensive experiments confirm the impressive effectiveness and robustness of the Face-diffuser.","[{'name': 'Yibin Wang, Weizhong Zhang, Jianwei Zheng, Cheng Jin'}]",
1837,Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition,https://arxiv.org/abs/2311.16119,"arXiv:2311.16119v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts.","[{'name': 'Sander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-Fran\\\\c{c}ois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Liu Kost, Christopher Carnahan, Jordan Boyd-Graber'}]",
1838,MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following,https://arxiv.org/abs/2312.02436,"arXiv:2312.02436v2 Announce Type: replace-cross 
Abstract: In the realm of large language models (LLMs), enhancing instruction-following capability often involves curating expansive training data. This is achieved through two primary schemes: i) Scaling-Inputs: Amplifying (input, output) pairs per task instruction, aiming for better instruction adherence. ii) Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction, output) pair (without requiring a separate input anymore). However, LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs. This work introduces MUFFIN, a new scheme of instruction-following dataset curation. Specifically, we automatically Scale Tasks per Input by diversifying these tasks with various input facets. Experimental results across four zero-shot benchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes, reveal that LLMs, at various scales, trained on MUFFIN generally demonstrate superior instruction-following capabilities compared to those trained on the two aforementioned schemes.","[{'name': 'Renze Lou, Kai Zhang, Jian Xie, Yuxuan Sun, Janice Ahn, Hanzi Xu, Yu Su, Wenpeng Yin'}]",
1839,Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks,https://arxiv.org/abs/2312.14499,"arXiv:2312.14499v2 Announce Type: replace-cross 
Abstract: Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by seamlessly blending data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the original PINN loss and its unbiased behavior under specific conditions. Comparisons with Stochastic Dimension Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly in scenarios with significant variance among dimensions. We further extend HTE to higher-order and higher-dimensional PDEs, specifically addressing the biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently computes the colossal tensor associated with the fourth-order high-dimensional biharmonic equation, saving memory and enabling rapid computation. The effectiveness of HTE is illustrated through experimental setups, demonstrating comparable convergence rates with SDGD under memory and speed constraints. Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN (gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new capability in scientific machine learning for tackling high-order and high-dimensional PDEs.","[{'name': 'Zheyuan Hu, Zekun Shi, George Em Karniadakis, Kenji Kawaguchi'}]",
1840,BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation,https://arxiv.org/abs/2401.04330,"arXiv:2401.04330v2 Announce Type: replace-cross 
Abstract: The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment metrics and evaluation effects of the model described in this paper on the publicly available datasets DSIFN-CD, S2Looking and WHU-CD are the best when compared to other models.","[{'name': 'Yonghui Tan, Xiaolong Li, Yishu Chen, Jinquan Ai'}]",
1841,Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study,https://arxiv.org/abs/2401.04331,"arXiv:2401.04331v2 Announce Type: replace-cross 
Abstract: In this work, we rigorously investigate the robustness of graph neural fractional-order differential equation (FDE) models. This framework extends beyond traditional graph neural (integer-order) ordinary differential equation (ODE) models by implementing the time-fractional Caputo derivative. Utilizing fractional calculus allows our model to consider long-term memory during the feature updating process, diverging from the memoryless Markovian updates seen in traditional graph neural ODE models. The superiority of graph neural FDE models over graph neural ODE models has been established in environments free from attacks or perturbations. While traditional graph neural ODE models have been verified to possess a degree of stability and resilience in the presence of adversarial attacks in existing literature, the robustness of graph neural FDE models, especially under adversarial conditions, remains largely unexplored. This paper undertakes a detailed assessment of the robustness of graph neural FDE models. We establish a theoretical foundation outlining the robustness characteristics of graph neural FDE models, highlighting that they maintain more stringent output perturbation bounds in the face of input and graph topology disturbances, compared to their integer-order counterparts. Our empirical evaluations further confirm the enhanced robustness of graph neural FDE models, highlighting their potential in adversarially robust applications.","[{'name': 'Qiyu Kang, Kai Zhao, Yang Song, Yihang Xie, Yanan Zhao, Sijie Wang, Rui She, Wee Peng Tay'}]",
1842,DocFinQA: A Long-Context Financial Reasoning Dataset,https://arxiv.org/abs/2401.06915,"arXiv:2401.06915v2 Announce Type: replace-cross 
Abstract: For large language models (LLMs) to be effective in the financial domain -- where each decision can have a significant impact -- it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents that are hundreds of pages long, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with the full-document context, extending the average context length from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments over retrieval-based QA pipelines and long-context language models. DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case-study on the longest documents in DocFinQA and find that models particularly struggle on these documents. Addressing these challenges may have a wide reaching impact across applications where specificity and long-range contexts are critical, like gene sequences and legal document contract analysis.","[{'name': 'Varshini Reddy, Rik Koncel-Kedziorski, Viet Dac Lai, Michael Krumdick, Charles Lovering, Chris Tanner'}]",
1843,Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility,https://arxiv.org/abs/2401.13782,"arXiv:2401.13782v2 Announce Type: replace-cross 
Abstract: As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.","[{'name': 'Iain Xie Weissburg, Mehir Arora, Xinyi Wang, Liangming Pan, William Yang Wang'}]",
1844,FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design,https://arxiv.org/abs/2401.14112,"arXiv:2401.14112v2 Announce Type: replace-cross 
Abstract: Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality consistently across varied applications. However, existing systems do not provide Tensor Core support for FP6 quantization and struggle to achieve practical performance improvements during LLM inference. It is challenging to support FP6 quantization on GPUs due to (1) unfriendly memory access of model weights with irregular bit-width and (2) high runtime overhead of weight de-quantization. To address these problems, we propose TC-FPx, the first full-stack GPU kernel design scheme with unified Tensor Core support of float-point weights for various quantization bit-width. We integrate TC-FPx kernel into an existing inference system, providing new end-to-end support (called FP6-LLM) for quantized LLM inference, where better trade-offs between inference cost and model quality are achieved. Experiments show that FP6-LLM enables the inference of LLaMA-70b using only a single GPU, achieving 1.69x-2.65x higher normalized inference throughput than the FP16 baseline. The source code is publicly available at https://github.com/usyd-fsalab/fp6_llm.","[{'name': 'Haojun Xia, Zhen Zheng, Xiaoxia Wu, Shiyang Chen, Zhewei Yao, Stephen Youn, Arash Bakhtiari, Michael Wyatt, Donglin Zhuang, Zhongzhu Zhou, Olatunji Ruwase, Yuxiong He, Shuaiwen Leon Song'}]",
1845,On Prompt-Driven Safeguarding for Large Language Models,https://arxiv.org/abs/2401.18018,"arXiv:2401.18018v2 Announce Type: replace-cross 
Abstract: Prepending model inputs with safety prompts is a common practice for safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not been revealed yet, which hinders the potential for automatically optimizing them to improve LLM safety. To this end, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by safety prompts in similar directions where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. It treats safety prompts as continuous, trainable embeddings and learns to move the representations of harmful/harmless queries along/opposite the direction in which the model's refusal probability increases. Experiments with eight LLMs on out-of-domain benchmarks demonstrate that DRO remarkably improves the safeguarding performance of human-crafted safety prompts and outperforms strong baselines, without compromising the general model capability.","[{'name': 'Chujie Zheng, Fan Yin, Hao Zhou, Fandong Meng, Jie Zhou, Kai-Wei Chang, Minlie Huang, Nanyun Peng'}]",
1846,Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting,https://arxiv.org/abs/2402.01440,"arXiv:2402.01440v3 Announce Type: replace-cross 
Abstract: Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to catalyze continued innovation in this field.","[{'name': 'Xingtong Yu, Yuan Fang, Zemin Liu, Yuxia Wu, Zhihao Wen, Jianyuan Bo, Xinming Zhang, Steven C. H. Hoi'}]",
1847,Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm,https://arxiv.org/abs/2402.02042,"arXiv:2402.02042v2 Announce Type: replace-cross 
Abstract: This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDP). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, we demonstrate that our proposed algorithm achieves $\\tilde{\\mathcal{O}}({T}^{4/5})$ objective regret and $\\tilde{\\mathcal{O}}({T}^{4/5})$ constraint violation bounds.","[{'name': 'Qinbo Bai, Washim Uddin Mondal, Vaneet Aggarwal'}]",
1848,A Truly Joint Neural Architecture for Segmentation and Parsing,https://arxiv.org/abs/2402.02564,"arXiv:2402.02564v2 Announce Type: replace-cross 
Abstract: Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.","[{'name': 'Danit Yshaayahu Levi, Reut Tsarfaty'}]",
1849,ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer,https://arxiv.org/abs/2402.02733,"arXiv:2402.02733v2 Announce Type: replace-cross 
Abstract: Face re-aging is a prominent field in computer vision and graphics, with significant applications in photorealistic domains such as movies, advertising, and live streaming. Recently, the need to apply face re-aging to non-photorealistic images, like comics, illustrations, and animations, has emerged as an extension in various entertainment sectors. However, the absence of a network capable of seamlessly editing the apparent age on NPR images means that these tasks have been confined to a naive approach, applying each task sequentially. This often results in unpleasant artifacts and a loss of facial attributes due to domain discrepancies. In this paper, we introduce a novel one-stage method for face re-aging combined with portrait style transfer, executed in a single generative step. We leverage existing face re-aging and style transfer networks, both trained within the same PR domain. Our method uniquely fuses distinct latent vectors, each responsible for managing aging-related attributes and NPR appearance. Adopting an exemplar-based approach, our method offers greater flexibility than domain-level fine-tuning approaches, which typically require separate training or fine-tuning for each domain. This effectively addresses the limitation of requiring paired datasets for re-aging and domain-level, data-driven approaches for stylization. Our experiments show that our model can effortlessly generate re-aged images while simultaneously transferring the style of examples, maintaining both natural appearance and controllability.","[{'name': 'Bumsoo Kim, Abdul Muqeet, Kyuchul Lee, Sanghyun Seo'}]",
1850,SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM,https://arxiv.org/abs/2402.03246,"arXiv:2402.03246v3 Announce Type: replace-cross 
Abstract: Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM). Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings. Building on this progress, we propose SGS-SLAM which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation. It outperforms existing methods by a large margin meanwhile preserving real-time rendering ability.","[{'name': 'Mingrui Li, Shuhong Liu, Heng Zhou, Guohao Zhu, Na Cheng, Hongyu Wang'}]",
1851,RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback,https://arxiv.org/abs/2402.03681,"arXiv:2402.03681v3 Announce Type: replace-cross 
Abstract: Reward engineering has long been a challenge in Reinforcement Learning (RL) research, as it often requires extensive human effort and iterative processes of trial-and-error to design effective reward functions. In this paper, we propose RL-VLM-F, a method that automatically generates reward functions for agents to learn new tasks, using only a text description of the task goal and the agent's visual observations, by leveraging feedbacks from vision language foundation models (VLMs). The key to our approach is to query these models to give preferences over pairs of the agent's image observations based on the text description of the task goal, and then learn a reward function from the preference labels, rather than directly prompting these models to output a raw reward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F successfully produces effective rewards and policies across various domains - including classic control, as well as manipulation of rigid, articulated, and deformable objects - without the need for human supervision, outperforming prior methods that use large pretrained models for reward generation under the same assumptions. Videos can be found on our project website: https://rlvlmf2024.github.io/","[{'name': 'Yufei Wang, Zhanyi Sun, Jesse Zhang, Zhou Xian, Erdem Biyik, David Held, Zackory Erickson'}]",
1852,SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models,https://arxiv.org/abs/2402.05044,"arXiv:2402.05044v3 Announce Type: replace-cross 
Abstract: In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our extensive experiments shed light on the resilience of LLMs against emerging threats and the efficacy of contemporary defense tactics. Data and evaluator are released under https://github.com/OpenSafetyLab/SALAD-BENCH.","[{'name': 'Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu Qiao, Jing Shao'}]",
1853,Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application,https://arxiv.org/abs/2402.05448,"arXiv:2402.05448v2 Announce Type: replace-cross 
Abstract: In this paper, we first present the character texture generation system \\textit{Minecraft-ify}, specified to Minecraft video game toward in-game application. Ours can generate face-focused image for texture mapping tailored to 3D virtual character having cube manifold. While existing projects or works only generate texture, proposed system can inverse the user-provided real image, or generate average/random appearance from learned distribution. Moreover, it can be manipulated with text-guidance using StyleGAN and StyleCLIP. These features provide a more extended user experience with enlarged freedom as a user-friendly AI-tool. Project page can be found at https://gh-bumsookim.github.io/Minecraft-ify/","[{'name': 'Bumsoo Kim, Sanghyun Byun, Yonghoon Jung, Wonseop Shin, Sareer UI Amin, Sanghyun Seo'}]",
1854,Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction,https://arxiv.org/abs/2402.05663,"arXiv:2402.05663v2 Announce Type: replace-cross 
Abstract: Accurate real-time traffic state forecasting plays a pivotal role in traffic control research. In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays. After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment. In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting. We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time.","[{'name': 'Raphael Chekroun, Han Wang, Jonathan Lee, Marin Toromanoff, Sascha Hornauer, Fabien Moutarde, Maria Laura Delle Monache'}]",
1855,The last Dance : Robust backdoor attack via diffusion models and bayesian approach,https://arxiv.org/abs/2402.05967,"arXiv:2402.05967v2 Announce Type: replace-cross 
Abstract: Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we aim to fool audio-based DNN models, such as those from the Hugging Face framework, primarily those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and achieve results faster and more efficiently. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence research. The backdoor attack developed in this paper is based on poisoning model training data uniquely by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data.",[{'name': 'Orson Mengara'}],
1856,Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data,https://arxiv.org/abs/2402.06104,"arXiv:2402.06104v2 Announce Type: replace-cross 
Abstract: Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 benchmark datasets with other 8 competitive baselines. The code is open-sourced at \\url{https://github.com/DixianZhu/FAR}.","[{'name': 'Dixian Zhu, Livnat Jerby'}]",
1857,Forecasting high-impact research topics via machine learning on evolving knowledge graphs,https://arxiv.org/abs/2402.08640,"arXiv:2402.08640v2 Announce Type: replace-cross 
Abstract: The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas.","[{'name': 'Xuemei Gu, Mario Krenn'}]",
1858,MC-DBN: A Deep Belief Network-Based Model for Modality Completion,https://arxiv.org/abs/2402.09782,"arXiv:2402.09782v2 Announce Type: replace-cross 
Abstract: Recent advancements in multi-modal artificial intelligence (AI) have revolutionized the fields of stock market forecasting and heart rate monitoring. Utilizing diverse data sources can substantially improve prediction accuracy. Nonetheless, additional data may not always align with the original dataset. Interpolation methods are commonly utilized for handling missing values in modal data, though they may exhibit limitations in the context of sparse information. Addressing this challenge, we propose a Modality Completion Deep Belief Network-Based Model (MC-DBN). This approach utilizes implicit features of complete data to compensate for gaps between itself and additional incomplete data. It ensures that the enhanced multi-modal data closely aligns with the dynamic nature of the real world to enhance the effectiveness of the model. We conduct evaluations of the MC-DBN model in two datasets from the stock market forecasting and heart rate monitoring domains. Comprehensive experiments showcase the model's capacity to bridge the semantic divide present in multi-modal data, subsequently enhancing its performance. The source code is available at: https://github.com/logan-0623/DBN-generate","[{'name': 'Zihong Luo, Kexin He, Chengzhi Liu, Zheng Tao'}]",
1859,Enhancing Convergence in Federated Learning: A Contribution-Aware Asynchronous Approach,https://arxiv.org/abs/2402.10991,"arXiv:2402.10991v4 Announce Type: replace-cross 
Abstract: Federated Learning (FL) is a distributed machine learning paradigm that allows clients to train models on their data while preserving their privacy. FL algorithms, such as Federated Averaging (FedAvg) and its variants, have been shown to converge well in many scenarios. However, these methods require clients to upload their local updates to the server in a synchronous manner, which can be slow and unreliable in realistic FL settings. To address this issue, researchers have developed asynchronous FL methods that allow clients to continue training on their local data using a stale global model. However, most of these methods simply aggregate all of the received updates without considering their relative contributions, which can slow down convergence. In this paper, we propose a contribution-aware asynchronous FL method that takes into account the staleness and statistical heterogeneity of the received updates. Our method dynamically adjusts the contribution of each update based on these factors, which can speed up convergence compared to existing methods.","[{'name': 'Changxin Xu, Yuxin Qiao, Zhanxin Zhou, Fanghao Ni, Jize Xiong'}]",
1860,Aligning Large Language Models by On-Policy Self-Judgment,https://arxiv.org/abs/2402.11253,"arXiv:2402.11253v2 Announce Type: replace-cross 
Abstract: Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning. In this paper, we present a novel alignment framework, \\method{} that (1) does on-policy learning and 2) is parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning. To this end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a single model to act as both a policy and a judge. Specifically, we view the pairwise judgment task, choosing the better response from a response pair, as a special case of the instruction-following task. The resulting model can judge preferences of on-the-fly responses from current policy initialized from itself. Experimental results show the efficacy of \\method{}, outperforming baselines in preference benchmarks. We also show that the rejecting sampling by itself can improve performance further without an additional evaluator.","[{'name': 'Sangkyu Lee, Sungdong Kim, Ashkan Yousefpour, Minjoon Seo, Kang Min Yoo, Youngjae Yu'}]",
1861,"From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions, and Models for Planning from Raw Data",https://arxiv.org/abs/2402.11871,"arXiv:2402.11871v4 Announce Type: replace-cross 
Abstract: Hand-crafted, logic-based state and action representations have been widely used to overcome the intractable computational complexity of long-horizon robot planning problems, including task and motion planning problems. However, creating such representations requires experts with strong intuitions and detailed knowledge about the robot and the tasks it may need to accomplish in a given setting. Removing this dependency on human intuition is a highly active research area.
  This paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories. The learned representations constitute auto-invented PDDL-like domain models. Empirical results in deterministic settings show that powerful abstract representations can be learned from just a handful of robot trajectories; the learned relational representations include but go beyond classical, intuitive notions of high-level actions; and that the learned models allow planning algorithms to scale to tasks that were previously beyond the scope of planning without hand-crafted abstractions.","[{'name': 'Naman Shah, Jayesh Nagpal, Pulkit Verma, Siddharth Srivastava'}]",
1862,Transformer-based Causal Language Models Perform Clustering,https://arxiv.org/abs/2402.12151,"arXiv:2402.12151v2 Announce Type: replace-cross 
Abstract: Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements in the instruction-following capability via additional training for instruction-following tasks. However, the mechanisms responsible for effective instruction-following capabilities remain inadequately understood. Here, we introduce a simplified instruction-following task and use synthetic datasets to analyze a Transformer-based causal language model. Our findings suggest that the model learns task-specific information by clustering data within its hidden space, with this clustering process evolving dynamically during learning. We also demonstrate how this phenomenon assists the model in handling unseen instances, and validate our results in a more realistic setting. Furthermore, we present inspired applications regarding pre-training and alignment.","[{'name': 'Xinbo Wu, Lav R. Varshney'}]",
1863,PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images,https://arxiv.org/abs/2402.12721,"arXiv:2402.12721v2 Announce Type: replace-cross 
Abstract: A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the original, downstream model. Moreover, the proposed PAC-FNO is ready to work with existing image recognition models. Extensively evaluating methods with seven image recognition benchmarks, we show that the proposed PAC-FNO improves the performance of existing baseline models on images with various resolutions by up to 77.1% and various types of natural variations in the images at inference.","[{'name': 'Jinsung Jeon, Hyundong Jin, Jonghyun Choi, Sanghyun Hong, Dongeun Lee, Kookjin Lee, Noseong Park'}]",
1864,Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering,https://arxiv.org/abs/2402.12728,"arXiv:2402.12728v2 Announce Type: replace-cross 
Abstract: Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designed for sufficient multimodal fusion. We utilize the shared mentioned entities in two graphs as mediums to bridge a tight inter-modal exchange, while maximally preserving insightful intra-modal learning by constraining the fusion within mediums. Extensive experiments on two benchmark datasets show the superiority of MAIL with 24x less resources.","[{'name': 'Junnan Dong, Qinggang Zhang, Huachi Zhou, Daochen Zha, Pai Zheng, Xiao Huang'}]",
1865,NeRF Solves Undersampled MRI Reconstruction,https://arxiv.org/abs/2402.13226,"arXiv:2402.13226v2 Announce Type: replace-cross 
Abstract: This article presents a novel undersampled magnetic resonance imaging (MRI) technique that leverages the concept of Neural Radiance Field (NeRF). With radial undersampling, the corresponding imaging problem can be reformulated into an image modeling task from sparse-view rendered data; therefore, a high dimensional MR image is obtainable from undersampled k-space data by taking advantage of implicit neural representation. A multi-layer perceptron, which is designed to output an image intensity from a spatial coordinate, learns the MR physics-driven rendering relation between given measurement data and desired image. Effective undersampling strategies for high-quality neural representation are investigated. The proposed method serves two benefits: (i) The learning is based fully on single undersampled k-space data, not a bunch of measured data and target image sets. It can be used potentially for diagnostic MR imaging, such as fetal MRI, where data acquisition is relatively rare or limited against diversity of clinical images while undersampled reconstruction is highly demanded. (ii) A reconstructed MR image is a scan-specific representation highly adaptive to the given k-space measurement. Numerous experiments validate the feasibility and capability of the proposed approach.","[{'name': 'Tae Jun Jang, Chang Min Hyun'}]",
1866,DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning,https://arxiv.org/abs/2402.13711,"arXiv:2402.13711v4 Announce Type: replace-cross 
Abstract: We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD) approach to consider both the class representativeness and the diversity within each class of the replayed nodes. Moreover, we adopt graph structure learning (GSL) to ensure that the replayed nodes are connected to truly informative neighbors. Extensive experimental results demonstrate the effectiveness and efficiency of DSLR. Our source code is available at https://github.com/seungyoon-Choi/DSLR_official.","[{'name': 'Seungyoon Choi, Wonjoong Kim, Sungwon Kim, Yeonjun In, Sein Kim, Chanyoung Park'}]",
1867,NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion,https://arxiv.org/abs/2402.13809,"arXiv:2402.13809v2 Announce Type: replace-cross 
Abstract: Reconstructing visual stimuli from functional Magnetic Resonance Imaging (fMRI) based on Latent Diffusion Models (LDM) provides a fine-grained retrieval of the brain. A challenge persists in reconstructing a cohesive alignment of details (such as structure, background, texture, color, etc.). Moreover, LDMs would generate different image results even under the same conditions. For these, we first uncover the neuroscientific perspective of LDM-based methods that is top-down creation based on pre-trained knowledge from massive images but lack of detail-driven bottom-up perception resulting in unfaithful details. We propose NeuralDiffuser which introduces primary visual feature guidance to provide detail cues in the form of gradients, extending the bottom-up process for LDM-based methods to achieve faithful semantics and details. We also developed a novel guidance strategy to ensure the consistency of repeated reconstructions rather than a variety of results. We obtain the state-of-the-art performance of NeuralDiffuser on the Natural Senses Dataset (NSD), which offers more faithful details and consistent results.","[{'name': 'Haoyu Li, Hao Wu, Badong Chen'}]",
1868,SDXL-Lightning: Progressive Adversarial Diffusion Distillation,https://arxiv.org/abs/2402.13929,"arXiv:2402.13929v3 Announce Type: replace-cross 
Abstract: We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights.","[{'name': 'Shanchuan Lin, Anran Wang, Xiao Yang'}]",
1869,E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series,https://arxiv.org/abs/2402.14041,"arXiv:2402.14041v4 Announce Type: replace-cross 
Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead.","[{'name': 'Zhichen Lai, Huan Li, Dalin Zhang, Yan Zhao, Weizhu Qian, Christian S. Jensen'}]",
1870,A Collision-Aware Cable Grasping Method in Cluttered Environment,https://arxiv.org/abs/2402.14498,"arXiv:2402.14498v2 Announce Type: replace-cross 
Abstract: We introduce a Cable Grasping-Convolutional Neural Network designed to facilitate robust cable grasping in cluttered environments. Utilizing physics simulations, we generate an extensive dataset that mimics the intricacies of cable grasping, factoring in potential collisions between cables and robotic grippers. We employ the Approximate Convex Decomposition technique to dissect the non-convex cable model, with grasp quality autonomously labeled based on simulated grasping attempts. The CG-CNN is refined using this simulated dataset and enhanced through domain randomization techniques. Subsequently, the trained model predicts grasp quality, guiding the optimal grasp pose to the robot controller for execution. Grasping efficacy is assessed across both synthetic and real-world settings. Given our model implicit collision sensitivity, we achieved commendable success rates of 92.3% for known cables and 88.4% for unknown cables, surpassing contemporary state-of-the-art approaches. Supplementary materials can be found at https://leizhang-public.github.io/cg-cnn/ .","[{'name': 'Lei Zhang, Kaixin Bai, Qiang Li, Zhaopeng Chen, Jianwei Zhang'}]",
1871,OmniPred: Language Models as Universal Regressors,https://arxiv.org/abs/2402.14547,"arXiv:2402.14547v3 Announce Type: replace-cross 
Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.","[{'name': 'Xingyou Song, Oscar Li, Chansoo Lee, Bangding Yang, Daiyi Peng, Sagi Perel, Yutian Chen'}]",
1872,Query Augmentation by Decoding Semantics from Brain Signals,https://arxiv.org/abs/2402.15708,"arXiv:2402.15708v2 Announce Type: replace-cross 
Abstract: Query augmentation is a crucial technique for refining semantically imprecise queries. Traditionally, query augmentation relies on extracting information from initially retrieved, potentially relevant documents. If the quality of the initially retrieved documents is low, then the effectiveness of query augmentation would be limited as well. We propose Brain-Aug, which enhances a query by incorporating semantic information decoded from brain signals. BrainAug generates the continuation of the original query with a prompt constructed with brain signal information and a ranking-oriented inference approach. Experimental results on fMRI (functional magnetic resonance imaging) datasets show that Brain-Aug produces semantically more accurate queries, leading to improved document ranking performance. Such improvement brought by brain signals is particularly notable for ambiguous queries.","[{'name': 'Ziyi Ye, Jingtao Zhan, Qingyao Ai, Yiqun Liu, Maarten de Rijke, Christina Lioma, Tuukka Ruotsalo'}]",
1873,LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper,https://arxiv.org/abs/2402.15727,"arXiv:2402.15727v2 Announce Type: replace-cross 
Abstract: Jailbreaking is an emerging adversarial attack that bypasses the safety alignment deployed in off-the-shelf large language models (LLMs). A considerable amount of research exists proposing more effective jailbreak attacks, including the recent Greedy Coordinate Gradient (GCG) attack, jailbreak template-based attacks such as using \"Do-Anything-Now\" (DAN), and multilingual jailbreak. In contrast, the defensive side has been relatively less explored. This paper proposes a lightweight yet practical defense called SELFDEFEND, which can defend against all existing jailbreak attacks with minimal delay for jailbreak prompts and negligible delay for normal user prompts. Our key insight is that regardless of the kind of jailbreak strategies employed, they eventually need to include a harmful prompt (e.g., \"how to make a bomb\") in the prompt sent to LLMs, and we found that existing LLMs can effectively recognize such harmful prompts that violate their safety policies. Based on this insight, we design a shadow stack that concurrently checks whether a harmful prompt exists in the user prompt and triggers a checkpoint in the normal stack once a token of \"No\" or a harmful prompt is output. The latter could also generate an explainable LLM response to adversarial prompts. We demonstrate our idea of SELFDEFEND works in various jailbreak scenarios through manual analysis in GPT-3.5/4. We also list three future directions to further enhance SELFDEFEND.","[{'name': 'Daoyuan Wu, Shuai Wang, Yang Liu, Ning Liu'}]",
1874,Rethinking Software Engineering in the Foundation Model Era: A Curated Catalogue of Challenges in the Development of Trustworthy FMware,https://arxiv.org/abs/2402.15943,"arXiv:2402.15943v2 Announce Type: replace-cross 
Abstract: Foundation models (FMs), such as Large Language Models (LLMs), have revolutionized software development by enabling new use cases and business models. We refer to software built using FMs as FMware. The unique properties of FMware (e.g., prompts, agents, and the need for orchestration), coupled with the intrinsic limitations of FMs (e.g., hallucination) lead to a completely new set of software engineering challenges. Based on our industrial experience, we identified 10 key SE4FMware challenges that have caused enterprise FMware development to be unproductive, costly, and risky. In this paper, we discuss these challenges in detail and state the path for innovation that we envision. Next, we present FMArts, which is our long-term effort towards creating a cradle-to-grave platform for the engineering of trustworthy FMware. Finally, we (i) show how the unique properties of FMArts enabled us to design and develop a complex FMware for a large customer in a timely manner and (ii) discuss the lessons that we learned in doing so. We hope that the disclosure of the aforementioned challenges and our associated efforts to tackle them will not only raise awareness but also promote deeper and further discussions, knowledge sharing, and innovative solutions across the software engineering discipline.","[{'name': 'Ahmed E. Hassan, Dayi Lin, Gopi Krishnan Rajbahadur, Keheliya Gallaba, Filipe R. Cogo, Boyuan Chen, Haoxiang Zhang, Kishanthan Thangarajah, Gustavo Ansaldi Oliva, Jiahuei Lin, Wali Mohammad Abdullah, Zhen Ming Jiang'}]",
1875,Citation-Enhanced Generation for LLM-based Chatbots,https://arxiv.org/abs/2402.16063,"arXiv:2402.16063v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc Citation-Enhanced Generation (CEG) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-based citation generation module. Once the statements in the generated content lack of reference, our model can regenerate responses until all statements are supported by citations. Note that our method is a training-free plug-and-play plugin that is capable of various LLMs. Experiments on various hallucination-related datasets show our framework outperforms state-of-the-art methods in both hallucination detection and response regeneration on three benchmarks. Our codes and dataset will be publicly available.","[{'name': 'Weitao Li, Junkai Li, Weizhi Ma, Yang Liu'}]",
1876,Improving LLM-based Machine Translation with Systematic Self-Correction,https://arxiv.org/abs/2402.16379,"arXiv:2402.16379v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3) different estimation strategies yield varied impacts on AI feedback, directly affecting the effectiveness of the final corrections. We further compare different LLMs and conduct various experiments involving self-correction and cross-model correction to investigate the potential relationship between the translation and evaluation capabilities of LLMs. Our code and data are available at https://github.com/fzp0424/self_correct_mt","[{'name': 'Zhaopeng Feng, Yan Zhang, Hao Li, Wenqiang Liu, Jun Lang, Yang Feng, Jian Wu, Zuozhu Liu'}]",
1877,LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step,https://arxiv.org/abs/2402.16906,"arXiv:2402.16906v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifically, LDB segments the programs into basic blocks and tracks the values of intermediate variables after each block throughout the runtime execution. This allows LLMs to concentrate on simpler code units within the overall execution flow, verify their correctness against the task description block by block, and efficiently pinpoint any potential errors. Experiments demonstrate that LDB consistently enhances the baseline performance by up to 9.8% across the HumanEval, MBPP, and TransCoder benchmarks, archiving new state-of-the-art performance in code debugging for various LLM selections.","[{'name': 'Li Zhong, Zilong Wang, Jingbo Shang'}]",
1878,When Your AIs Deceive You: Challenges with Partial Observability of Human Evaluators in Reward Learning,https://arxiv.org/abs/2402.17747,"arXiv:2402.17747v2 Announce Type: replace-cross 
Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observable settings and propose research directions to help tackle these challenges.","[{'name': 'Leon Lang, Davis Foote, Stuart Russell, Anca Dragan, Erik Jenner, Scott Emmons'}]",
1879,REPrune: Channel Pruning via Kernel Representative Selection,https://arxiv.org/abs/2402.17862,"arXiv:2402.17862v2 Announce Type: replace-cross 
Abstract: Channel pruning is widely accepted to accelerate modern convolutional neural networks (CNNs). The resulting pruned model benefits from its immediate deployment on general-purpose software and hardware resources. However, its large pruning granularity, specifically at the unit of a convolution filter, often leads to undesirable accuracy drops due to the inflexibility of deciding how and where to introduce sparsity to the CNNs. In this paper, we propose REPrune, a novel channel pruning technique that emulates kernel pruning, fully exploiting the finer but structured granularity. REPrune identifies similar kernels within each channel using agglomerative clustering. Then, it selects filters that maximize the incorporation of kernel representatives while optimizing the maximum cluster coverage problem. By integrating with a simultaneous training-pruning paradigm, REPrune promotes efficient, progressive pruning throughout training CNNs, avoiding the conventional train-prune-finetune sequence. Experimental results highlight that REPrune performs better in computer vision tasks than existing methods, effectively achieving a balance between acceleration ratio and performance retention.","[{'name': 'Mincheol Park, Dongjin Kim, Cheonjun Park, Yuna Park, Gyeong Eun Gong, Won Woo Ro, Suhyun Kim'}]",
1880,Mixer is more than just a model,https://arxiv.org/abs/2402.18007,"arXiv:2402.18007v2 Announce Type: replace-cross 
Abstract: Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example. In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information. Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information. The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of \"mixing\" in the realm of neural network architectures. Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements. This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and frequency domains. Experimental results demonstrate that ASM-RH is particularly well-suited for audio data and yields promising outcomes across multiple classification tasks. The models and optimal weights files will be published.","[{'name': 'Qingfeng Ji, Yuxin Wang, Letong Sun'}]",
1881,Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging,https://arxiv.org/abs/2402.18205,"arXiv:2402.18205v2 Announce Type: replace-cross 
Abstract: Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \\textbf{L}og parsing framework with \\textbf{E}ntropy sampling and Chain-of-Thought \\textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method for large language models (LLMs). LLMs exhibit exceptional semantic comprehension, deftly distinguishing between parameters and invariant tokens. We have conducted experiments on large-scale public datasets. Extensive evaluation demonstrates that Lemur achieves the state-of-the-art performance and impressive efficiency.","[{'name': 'Wei Zhang, Hongcheng Guo, Anjie Le, Jian Yang, Jiaheng Liu, Zhoujun Li, Tieqiao Zheng, Shi Xu, Runqiang Zang, Liangfan Zheng, Bo Zhang'}]",
1882,Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization,https://arxiv.org/abs/2402.18284,"arXiv:2402.18284v2 Announce Type: replace-cross 
Abstract: Wide usage of ChatGPT has highlighted the potential of reinforcement learning from human feedback. However, its training pipeline relies on manual ranking, a resource-intensive process. To reduce labor costs, we propose a self-supervised text ranking approach for applying Proximal-Policy-Optimization to fine-tune language models while eliminating the need for human annotators. Our method begins with probabilistic sampling to encourage a language model to generate diverse responses for each input. We then employ TextRank and ISODATA algorithms to rank and cluster these responses based on their semantics. Subsequently, we construct a reward model to learn the rank and optimize our generative policy. Our experimental results, conducted using two language models on three tasks, demonstrate that the models trained by our method considerably outperform baselines regarding BLEU, GLEU, and METEOR scores. Furthermore, our manual evaluation shows that our ranking results exhibit a remarkably high consistency with that of humans. This research significantly reduces training costs of proximal policy-guided models and demonstrates the potential for self-correction of language models.","[{'name': 'Shuo Yang, Gjergji Kasneci'}]",
1883,Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review,https://arxiv.org/abs/2402.18590,"arXiv:2402.18590v2 Announce Type: replace-cross 
Abstract: The paper underscores the significance of Large Language Models (LLMs) in reshaping recommender systems, attributing their value to unique reasoning abilities absent in traditional recommenders. Unlike conventional systems lacking direct user interaction data, LLMs exhibit exceptional proficiency in recommending items, showcasing their adeptness in comprehending intricacies of language. This marks a fundamental paradigm shift in the realm of recommendations. Amidst the dynamic research landscape, researchers actively harness the language comprehension and generation capabilities of LLMs to redefine the foundations of recommendation tasks. The investigation thoroughly explores the inherent strengths of LLMs within recommendation frameworks, encompassing nuanced contextual comprehension, seamless transitions across diverse domains, adoption of unified approaches, holistic learning strategies leveraging shared data reservoirs, transparent decision-making, and iterative improvements. Despite their transformative potential, challenges persist, including sensitivity to input prompts, occasional misinterpretations, and unforeseen recommendations, necessitating continuous refinement and evolution in LLM-driven recommender systems.","[{'name': 'Arpita Vats, Vinija Jain, Rahul Raja, Aman Chadha'}]",
1884,Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective,https://arxiv.org/abs/2402.18607,"arXiv:2402.18607v2 Announce Type: replace-cross 
Abstract: Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.
  In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execute fairness poisoning attacks to undermine the receiver's downstream models by manipulating the training data distribution of the diffusion model. Meanwhile, the receiver can perform property inference attacks to reveal the distribution of sensitive features in the sharer's dataset. Our experiments conducted on real-world datasets demonstrate remarkable attack performance on different types of diffusion models, which highlights the critical importance of robust data auditing and privacy protection protocols in pertinent applications.","[{'name': 'Xinjian Luo, Yangfan Jiang, Fei Wei, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi'}]",
1885,Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation,https://arxiv.org/abs/2402.18920,"arXiv:2402.18920v2 Announce Type: replace-cross 
Abstract: Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both pose-dominant and shape-dominant deformations. Using different challenging datasets, we demonstrate that our method outperforms previous state-of-the-art methods for both shape matching and interpolation, even compared to supervised approaches.","[{'name': 'Dongliang Cao, Marvin Eisenberger, Nafie El Amrani, Daniel Cremers, Florian Bernard'}]",
1886,How to Understand \"Support\"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding,https://arxiv.org/abs/2402.19116,"arXiv:2402.19116v2 Announce Type: replace-cross 
Abstract: Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep multimodal semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and counterfactual techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting finding that IECI outperforms the advanced multimodal LLMs by a large margin on this implicit-enhanced dataset, which may facilitate more research to evaluate the multimodal LLMs in this direction.","[{'name': 'Jiamin Luo, Jianing Zhao, Jingjing Wang, Guodong Zhou'}]",
1887,Broken detailed balance and entropy production in directed networks,https://arxiv.org/abs/2402.19157,"arXiv:2402.19157v2 Announce Type: replace-cross 
Abstract: The structure of a complex network plays a crucial role in determining its dynamical properties. In this work, we show that the directed, hierarchical organisation of a network causes the system to break detailed balance and dictates the production of entropy through non-equilibrium dynamics. We consider a wide range of dynamical processes and show how different directed network features govern their thermodynamics. Next, we analyse a collection of 97 empirical networks and show that strong directedness and non-equilibrium dynamics are both ubiquitous in real-world systems. Finally, we present a simple method for inferring broken detailed balance and directed network structure from multivariate time-series and apply our method to identify non-equilibrium and hierarchical organisation in both human neuroimaging and financial time-series. Overall, our results shed light on the thermodynamic consequences of directed network structure and indicate the importance and ubiquity of hierarchical organisation and non-equilibrium dynamics in real-world systems.","[{'name': \"Ram\\\\'on Nartallo-Kaluarachchi, Malbor Asllani, Gustavo Deco, Morten L. Kringelbach, Alain Goriely, Renaud Lambiotte\"}]",
1888,On the Scaling Laws of Geographical Representation in Language Models,https://arxiv.org/abs/2402.19406,"arXiv:2402.19406v2 Announce Type: replace-cross 
Abstract: Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.","[{'name': \"Nathan Godey, \\\\'Eric de la Clergerie, Beno\\\\^it Sagot\"}]",
1889,"ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models",https://arxiv.org/abs/2403.00510,"arXiv:2403.00510v2 Announce Type: replace-cross 
Abstract: Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and variance, just to name a few.","[{'name': 'Bo Li, Qinghua Zhao, Lijie Wen'}]",
1890,Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks,https://arxiv.org/abs/2403.00692,"arXiv:2403.00692v2 Announce Type: replace-cross 
Abstract: The upcoming landscape of Earth Observation missions will defined by networked heterogeneous nanosatellite constellations required to meet strict mission requirements, such as revisit times and spatial resolution. However, scheduling satellite communications in these satellite networks through efficiently creating a global satellite Contact Plan (CP) is a complex task, with current solutions requiring ground-based coordination or being limited by onboard computational resources. The paper proposes a novel approach to overcome these challenges by modeling the constellations and CP as dynamic networks and employing graph-based techniques. The proposed method utilizes a state-of-the-art dynamic graph neural network to evaluate the performance of a given CP and update it using a heuristic algorithm based on simulated annealing. The trained neural network can predict the network delay with a mean absolute error of 3.6 minutes. Simulation results show that the proposed method can successfully design a contact plan for large satellite networks, improving the delay by 29.1%, similar to a traditional approach, while performing the objective evaluations 20x faster.","[{'name': 'Guillem Casadesus-Vila, Joan-Adria Ruiz-de-Azua, Eduard Alarcon'}]",
1891,Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?,https://huggingface.co/blog/leaderboard-contextual,,[],"Tue, 05 Mar 2024 00:00:00 GMT"
1892,Data is better together,https://huggingface.co/blog/community-datasets,,[],"Mon, 04 Mar 2024 00:00:00 GMT"
1893,Text-Generation Pipeline on Intel® Gaudi® 2 AI Accelerator,https://huggingface.co/blog/textgen-pipe-gaudi,,[],"Thu, 29 Feb 2024 00:00:00 GMT"
1894,StarCoder2 and The Stack v2,https://huggingface.co/blog/starcoder2,,[],"Wed, 28 Feb 2024 00:00:00 GMT"
1895,TTS Arena: Benchmarking Text-to-Speech Models in the Wild,https://huggingface.co/blog/arena-tts,,[],"Tue, 27 Feb 2024 00:00:00 GMT"
1896,AI Watermarking 101: Tools and Techniques,https://huggingface.co/blog/watermarking,,[],"Mon, 26 Feb 2024 00:00:00 GMT"
1897,Fine-Tuning Gemma Models in Hugging Face,https://huggingface.co/blog/gemma-peft,,[],"Fri, 23 Feb 2024 00:00:00 GMT"
1898,Introducing the Red-Teaming Resistance Leaderboard,https://huggingface.co/blog/leaderboard-haizelab,,[],"Fri, 23 Feb 2024 00:00:00 GMT"
1899,🪆 Introduction to Matryoshka Embedding Models,https://huggingface.co/blog/matryoshka,,[],"Fri, 23 Feb 2024 00:00:00 GMT"
1900,Welcome Gemma - Google's new open LLM,https://huggingface.co/blog/gemma,,[],"Wed, 21 Feb 2024 00:00:00 GMT"
1901,Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem,https://huggingface.co/blog/leaderboard-upstage,,[],"Tue, 20 Feb 2024 00:00:00 GMT"
1902,🤗 PEFT welcomes new merging methods,https://huggingface.co/blog/peft_merging,,[],"Mon, 19 Feb 2024 00:00:00 GMT"
1903,"Synthetic data: save money, time and carbon with open source",https://huggingface.co/blog/synthetic-data-save-costs,,[],"Fri, 16 Feb 2024 00:00:00 GMT"
1904,AMD Pervasive AI Developer Contest!,https://huggingface.co/blog/amd_pervasive_developer_ai_contest,,[],"Wed, 14 Feb 2024 00:00:00 GMT"
1905,From OpenAI to Open LLMs with Messages API,https://huggingface.co/blog/tgi-messages-api,,[],"Thu, 08 Feb 2024 00:00:00 GMT"
1906,SegMoE: Segmind Mixture of Diffusion Experts,https://huggingface.co/blog/segmoe,,[],"Sat, 03 Feb 2024 00:00:00 GMT"
1907,NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates,https://huggingface.co/blog/leaderboard-nphardeval,,[],"Fri, 02 Feb 2024 00:00:00 GMT"
1908,Constitutional AI with Open LLMs,https://huggingface.co/blog/constitutional_ai,,[],"Thu, 01 Feb 2024 00:00:00 GMT"
1909,Hugging Face Text Generation Inference available for AWS Inferentia2,https://huggingface.co/blog/text-generation-inference-on-inferentia2,,[],"Thu, 01 Feb 2024 00:00:00 GMT"
1910,Patch Time Series Transformer in Hugging Face,https://huggingface.co/blog/patchtst,,[],"Thu, 01 Feb 2024 00:00:00 GMT"
1911,Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases,https://huggingface.co/blog/leaderboard-patronus,,[],"Wed, 31 Jan 2024 00:00:00 GMT"
1912,Accelerate StarCoder with 🤗 Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding,https://huggingface.co/blog/intel-starcoder-quantization,,[],"Tue, 30 Jan 2024 00:00:00 GMT"
1913,"The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",https://huggingface.co/blog/leaderboard-hallucinations,,[],"Mon, 29 Jan 2024 00:00:00 GMT"
1914,An Introduction to AI Secure LLM Safety Leaderboard,https://huggingface.co/blog/leaderboard-decodingtrust,,[],"Fri, 26 Jan 2024 00:00:00 GMT"
1915,Hugging Face and Google partner for open AI collaboration,https://huggingface.co/blog/gcp-partnership,,[],"Thu, 25 Jan 2024 00:00:00 GMT"
1916,Open-source LLMs as LangChain Agents,https://huggingface.co/blog/open-source-llms-as-agents,,[],"Wed, 24 Jan 2024 00:00:00 GMT"
1917,Fine-Tune W2V2-Bert for low-resource ASR with 🤗 Transformers,https://huggingface.co/blog/fine-tune-w2v2-bert,,[],"Fri, 19 Jan 2024 00:00:00 GMT"
1918,PatchTSMixer in HuggingFace,https://huggingface.co/blog/patchtsmixer,,[],"Fri, 19 Jan 2024 00:00:00 GMT"
1919,Preference Tuning LLMs with Direct Preference Optimization Methods,https://huggingface.co/blog/pref-tuning,,[],"Thu, 18 Jan 2024 00:00:00 GMT"
1920,Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive,https://huggingface.co/blog/sdxl_ort_inference,,[],"Mon, 15 Jan 2024 00:00:00 GMT"
1921,A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard,https://huggingface.co/blog/leaderboard-vectara,,[],"Fri, 12 Jan 2024 00:00:00 GMT"
1922,Faster fine-tuning using TRL & Unsloth,https://huggingface.co/blog/unsloth-trl,,[],"Wed, 10 Jan 2024 00:00:00 GMT"
1923,Welcome aMUSEd: Efficient Text-to-Image Generation,https://huggingface.co/blog/amused,,[],"Thu, 04 Jan 2024 00:00:00 GMT"
1924,"LoRA training scripts of the world, unite!",https://huggingface.co/blog/sdxl_lora_advanced_script,,[],"Tue, 02 Jan 2024 00:00:00 GMT"
1925,Speculative Decoding for 2x Faster Whisper Inference,https://huggingface.co/blog/whisper-speculative-decoding,,[],"Wed, 20 Dec 2023 00:00:00 GMT"
1926,"2023, year of open LLMs",https://huggingface.co/blog/2023-in-llms,,[],"Mon, 18 Dec 2023 00:00:00 GMT"
1927,Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face,https://huggingface.co/blog/mixtral,,[],"Mon, 11 Dec 2023 00:00:00 GMT"
1928,Mixture of Experts Explained,https://huggingface.co/blog/moe,,[],"Mon, 11 Dec 2023 00:00:00 GMT"
1929,AMD + 🤗: Large Language Models Out-of-the-Box Acceleration with AMD GPU,https://huggingface.co/blog/huggingface-and-optimum-amd,,[],"Tue, 05 Dec 2023 00:00:00 GMT"
1930,SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit,https://huggingface.co/blog/setfit-absa,,[],"Wed, 06 Dec 2023 00:00:00 GMT"
1931,Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code,https://huggingface.co/blog/optimum-nvidia,,[],"Tue, 05 Dec 2023 00:00:00 GMT"
1932,Goodbye cold boot - how we made LoRA inference 300% faster,https://huggingface.co/blog/lora-adapters-dynamic-loading,,[],"Tue, 05 Dec 2023 00:00:00 GMT"
1933,Open LLM Leaderboard: DROP deep dive,https://huggingface.co/blog/open-llm-leaderboard-drop,,[],"Fri, 01 Dec 2023 00:00:00 GMT"
1934,SDXL in 4 steps with Latent Consistency LoRAs,https://huggingface.co/blog/lcm_lora,,[],"Thu, 09 Nov 2023 00:00:00 GMT"
1935,Make your llama generation time fly with AWS Inferentia2,https://huggingface.co/blog/inferentia-llama2,,[],"Tue, 07 Nov 2023 00:00:00 GMT"
1936,Introducing Prodigy-HF: a direct integration with Hugging Face,https://huggingface.co/blog/prodigy-hf,,[],"Tue, 07 Nov 2023 00:00:00 GMT"
1937,"Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral,,[],"Tue, 07 Nov 2023 00:00:00 GMT"
1938,Introducing Storage Regions on the HF Hub,https://huggingface.co/blog/regions,,[],"Fri, 03 Nov 2023 00:00:00 GMT"
1939,Creating open machine learning datasets? Share them on the Hugging Face Hub!,https://huggingface.co/blog/researcher-dataset-sharing,,[],"Mon, 30 Oct 2023 00:00:00 GMT"
1940,Personal Copilot: Train Your Own Coding Assistant,https://huggingface.co/blog/personal-copilot,,[],"Fri, 27 Oct 2023 00:00:00 GMT"
1941,Interactively explore your Huggingface dataset with one line of code,https://huggingface.co/blog/scalable-data-inspection,,[],"Wed, 25 Oct 2023 00:00:00 GMT"
1942,Deploy Embedding Models with Hugging Face Inference Endpoints,https://huggingface.co/blog/inference-endpoints-embeddings,,[],"Tue, 24 Oct 2023 00:00:00 GMT"
1943,The N Implementation Details of RLHF with PPO,https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo,,[],"Tue, 24 Oct 2023 00:00:00 GMT"
1944,Exploring simple optimizations for SDXL,https://huggingface.co/blog/simple_sdxl_optimizations,,[],"Tue, 24 Oct 2023 00:00:00 GMT"
1945,Gradio-Lite: Serverless Gradio Running Entirely in Your Browser,https://huggingface.co/blog/gradio-lite,,[],"Thu, 19 Oct 2023 00:00:00 GMT"
1946,"Accelerating over 130,000 Hugging Face models with ONNX Runtime",https://huggingface.co/blog/ort-accelerating-hf-models,,[],"Wed, 04 Oct 2023 00:00:00 GMT"
1947,Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e,https://huggingface.co/blog/sdxl_jax,,[],"Tue, 03 Oct 2023 00:00:00 GMT"
1948,Chat Templates: An End to the Silent Performance Killer,https://huggingface.co/blog/chat-templates,,[],"Tue, 03 Oct 2023 00:00:00 GMT"
1949,Deploying the AI Comic Factory using the Inference API,https://huggingface.co/blog/ai-comic-factory,,[],"Mon, 02 Oct 2023 00:00:00 GMT"
1950,Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings,https://huggingface.co/blog/ethics-soc-5,,[],"Fri, 29 Sep 2023 00:00:00 GMT"
1951,Finetune Stable Diffusion Models with DDPO via TRL,https://huggingface.co/blog/trl-ddpo,,[],"Fri, 29 Sep 2023 00:00:00 GMT"
1952,Non-engineers guide: Train a LLaMA 2 chatbot,https://huggingface.co/blog/Llama2-for-non-engineers,,[],"Thu, 28 Sep 2023 00:00:00 GMT"
1953,Llama 2 on Amazon SageMaker a Benchmark,https://huggingface.co/blog/llama-sagemaker-benchmark,,[],"Tue, 26 Sep 2023 00:00:00 GMT"
1954,Inference for PROs,https://huggingface.co/blog/inference-pro,,[],"Fri, 22 Sep 2023 00:00:00 GMT"
1955,Rocket Money x Hugging Face: Scaling Volatile ML Models in Production,https://huggingface.co/blog/rocketmoney-case-study,,[],"Tue, 19 Sep 2023 00:00:00 GMT"
1956,Introduction to 3D Gaussian Splatting,https://huggingface.co/blog/gaussian-splatting,,[],"Mon, 18 Sep 2023 00:00:00 GMT"
1957,Object Detection Leaderboard,https://huggingface.co/blog/object-detection-leaderboard,,[],"Mon, 18 Sep 2023 00:00:00 GMT"
1958,Optimizing your LLM in production,https://huggingface.co/blog/optimize-llm,,[],"Fri, 15 Sep 2023 00:00:00 GMT"
1959,Introducing Würstchen: Fast Diffusion for Image Generation,https://huggingface.co/blog/wuerstchen,,[],"Wed, 13 Sep 2023 00:00:00 GMT"
1960,Fine-tuning Llama 2 70B using PyTorch FSDP,https://huggingface.co/blog/ram-efficient-pytorch-fsdp,,[],"Wed, 13 Sep 2023 00:00:00 GMT"
1961,Overview of natively supported quantization schemes in 🤗 Transformers,https://huggingface.co/blog/overview-quantization-transformers,,[],"Tue, 12 Sep 2023 00:00:00 GMT"
1962,SafeCoder vs. Closed-source Code Assistants,https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants,,[],"Mon, 11 Sep 2023 00:00:00 GMT"
1963,Efficient Controllable Generation for SDXL with T2I-Adapters,https://huggingface.co/blog/t2i-sdxl-adapters,,[],"Fri, 08 Sep 2023 00:00:00 GMT"
1964,Spread Your Wings: Falcon 180B is here,https://huggingface.co/blog/falcon-180b,,[],"Wed, 06 Sep 2023 00:00:00 GMT"
1965,Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face,https://huggingface.co/blog/fetch-case-study,,[],"Fri, 01 Sep 2023 00:00:00 GMT"
1966,"AudioLDM 2, but faster ⚡️",https://huggingface.co/blog/audioldm2,,[],"Wed, 30 Aug 2023 00:00:00 GMT"
1967,Code Llama: Llama 2 learns to code,https://huggingface.co/blog/codellama,,[],"Fri, 25 Aug 2023 00:00:00 GMT"
1968,Deprecation of Git Authentication using password,https://huggingface.co/blog/password-git-deprecation,,[],"Fri, 25 Aug 2023 00:00:00 GMT"
1969,Making LLMs lighter with AutoGPTQ and transformers,https://huggingface.co/blog/gptq-integration,,[],"Wed, 23 Aug 2023 00:00:00 GMT"
1970,Introducing SafeCoder,https://huggingface.co/blog/safecoder,,[],"Tue, 22 Aug 2023 00:00:00 GMT"
1971,Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model,https://huggingface.co/blog/idefics,,[],"Tue, 22 Aug 2023 00:00:00 GMT"
1972,Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account,https://huggingface.co/blog/aws-marketplace,,[],"Thu, 10 Aug 2023 00:00:00 GMT"
1973,Optimizing Bark using 🤗 Transformers,https://huggingface.co/blog/optimizing-bark,,[],"Wed, 09 Aug 2023 00:00:00 GMT"
1974,Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action,https://huggingface.co/blog/deploy-deepfloydif-using-bentoml,,[],"Wed, 09 Aug 2023 00:00:00 GMT"
1975,Fine-tune Llama 2 with DPO,https://huggingface.co/blog/dpo-trl,,[],"Tue, 08 Aug 2023 00:00:00 GMT"
1976,Releasing Swift Transformers: Run On-Device LLMs in Apple Devices,https://huggingface.co/blog/swift-coreml-llm,,[],"Tue, 08 Aug 2023 00:00:00 GMT"
1977,Deploy MusicGen in no time with Inference Endpoints,https://huggingface.co/blog/run-musicgen-as-an-api,,[],"Fri, 04 Aug 2023 00:00:00 GMT"
1978,Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub,https://huggingface.co/blog/huggy-lingo,,[],"Wed, 02 Aug 2023 00:00:00 GMT"
1979,Towards Encrypted Large Language Models with FHE,https://huggingface.co/blog/encrypted-llm,,[],"Wed, 02 Aug 2023 00:00:00 GMT"
1980,Practical 3D Asset Generation: A Step-by-Step Guide,https://huggingface.co/blog/3d-assets,,[],"Tue, 01 Aug 2023 00:00:00 GMT"
1981,Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny,https://huggingface.co/blog/sd_distillation,,[],"Tue, 01 Aug 2023 00:00:00 GMT"
1982,Stable Diffusion XL on Mac with Advanced Core ML Quantization,https://huggingface.co/blog/stable-diffusion-xl-coreml,,[],"Thu, 27 Jul 2023 00:00:00 GMT"
1983,AI Policy @🤗: Open ML Considerations in the EU AI Act,https://huggingface.co/blog/eu-ai-act-oss,,[],"Mon, 24 Jul 2023 00:00:00 GMT"
1984,Introducing Agents.js: Give tools to your LLMs using JavaScript,https://huggingface.co/blog/agents-js,,[],"Mon, 24 Jul 2023 00:00:00 GMT"
1985,Results of the Open Source AI Game Jam,https://huggingface.co/blog/game-jam-first-edition-results,,[],"Fri, 21 Jul 2023 00:00:00 GMT"
1986,Happy 1st anniversary 🤗 Diffusers!,https://huggingface.co/blog/diffusers-turns-1,,[],"Thu, 20 Jul 2023 00:00:00 GMT"
1987,Llama 2 is here - get it on Hugging Face,https://huggingface.co/blog/llama2,,[],"Tue, 18 Jul 2023 00:00:00 GMT"
1988,Building an AI WebTV,https://huggingface.co/blog/ai-webtv,,[],"Mon, 17 Jul 2023 00:00:00 GMT"
1989,Open-Source Text Generation & LLM Ecosystem at Hugging Face,https://huggingface.co/blog/os-llms,,[],"Mon, 17 Jul 2023 00:00:00 GMT"
1990,Fine-tuning Stable Diffusion models on Intel CPUs,https://huggingface.co/blog/stable-diffusion-finetuning-intel,,[],"Fri, 14 Jul 2023 00:00:00 GMT"
1991,Making ML-powered web games with Transformers.js,https://huggingface.co/blog/ml-web-games,,[],"Wed, 05 Jul 2023 00:00:00 GMT"
1992,Deploy LLMs with Hugging Face Inference Endpoints,https://huggingface.co/blog/inference-endpoints-llm,,[],"Tue, 04 Jul 2023 00:00:00 GMT"
1993,Making a web app generator with open ML models,https://huggingface.co/blog/text-to-webapp,,[],"Mon, 03 Jul 2023 00:00:00 GMT"
1994,Leveraging Hugging Face for complex generative AI use cases,https://huggingface.co/blog/writer-case-study,,[],"Sat, 01 Jul 2023 00:00:00 GMT"
1995,Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2,https://huggingface.co/blog/bridgetower,,[],"Thu, 29 Jun 2023 00:00:00 GMT"
1996,Ethics and Society Newsletter #4: Bias in Text-to-Image Models,https://huggingface.co/blog/ethics-soc-4,,[],"Mon, 26 Jun 2023 00:00:00 GMT"
1997,What's going on with the Open LLM Leaderboard?,https://huggingface.co/blog/open-llm-leaderboard-mmlu,,[],"Fri, 23 Jun 2023 00:00:00 GMT"
1998,Panel on Hugging Face,https://huggingface.co/blog/panel-on-hugging-face,,[],"Thu, 22 Jun 2023 00:00:00 GMT"
1999,Fine-tuning MMS Adapter Models for Multi-Lingual ASR,https://huggingface.co/blog/mms_adapters,,[],"Mon, 19 Jun 2023 00:00:00 GMT"
2000,AI Policy @🤗: Response to the U.S. NTIA's Request for Comment on AI Accountability,https://huggingface.co/blog/policy-ntia-rfc,,[],"Tue, 20 Jun 2023 00:00:00 GMT"
2001,"Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",https://huggingface.co/blog/autoformer,,[],"Fri, 16 Jun 2023 00:00:00 GMT"
2002,"Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",https://huggingface.co/blog/fast-diffusers-coreml,,[],"Thu, 15 Jun 2023 00:00:00 GMT"
2003,Deploy Livebook notebooks as apps to Hugging Face Spaces,https://huggingface.co/blog/livebook-app-deployment,,[],"Thu, 15 Jun 2023 00:00:00 GMT"
2004,Announcing our new Content Guidelines and Policy,https://huggingface.co/blog/content-guidelines-update,,[],"Thu, 15 Jun 2023 00:00:00 GMT"
2005,Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms,https://huggingface.co/blog/huggingface-and-amd,,[],"Tue, 13 Jun 2023 00:00:00 GMT"
2006,Can foundation models label data like humans?,https://huggingface.co/blog/open-llm-leaderboard-rlhf,,[],"Mon, 12 Jun 2023 00:00:00 GMT"
2007,"The Hugging Face Hub for Galleries, Libraries, Archives and Museums",https://huggingface.co/blog/hf-hub-glam-guide,,[],"Mon, 12 Jun 2023 00:00:00 GMT"
2008,"DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",https://huggingface.co/blog/hub-duckdb,,[],"Wed, 07 Jun 2023 00:00:00 GMT"
2009,Welcome fastText to the 🤗 Hub,https://huggingface.co/blog/fasttext,,[],"Tue, 06 Jun 2023 00:00:00 GMT"
2010,The Falcon has landed in the Hugging Face ecosystem,https://huggingface.co/blog/falcon,,[],"Mon, 05 Jun 2023 00:00:00 GMT"
2011,AI Speech Recognition in Unity,https://huggingface.co/blog/unity-asr,,[],"Fri, 02 Jun 2023 00:00:00 GMT"
2012,Announcing the Open Source AI Game Jam 🎮,https://huggingface.co/blog/game-jam,,[],"Thu, 01 Jun 2023 00:00:00 GMT"
2013,Hugging Face Selected for the French Data Protection Agency Enhanced Support Program,https://huggingface.co/blog/cnil,,[],"Mon, 15 May 2023 00:00:00 GMT"
2014,Introducing the Hugging Face LLM Inference Container for Amazon SageMaker,https://huggingface.co/blog/sagemaker-huggingface-llm,,[],"Wed, 31 May 2023 00:00:00 GMT"
2015,Introducing BERTopic Integration with Hugging Face Hub,https://huggingface.co/blog/bertopic,,[],"Wed, 31 May 2023 00:00:00 GMT"
2016,Optimizing Stable Diffusion for Intel CPUs with NNCF and 🤗 Optimum,https://huggingface.co/blog/train-optimize-sd-intel,,[],"Thu, 25 May 2023 00:00:00 GMT"
2017,"Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",https://huggingface.co/blog/4bit-transformers-bitsandbytes,,[],"Wed, 24 May 2023 00:00:00 GMT"
2018,Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure,https://huggingface.co/blog/hugging-face-endpoints-on-azure,,[],"Wed, 24 May 2023 00:00:00 GMT"
2019,"Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",https://huggingface.co/blog/huggingface-and-ibm,,[],"Tue, 23 May 2023 00:00:00 GMT"
2020,Safetensors audited as really safe and becoming the default,https://huggingface.co/blog/safetensors-security-audit,,[],"Tue, 23 May 2023 00:00:00 GMT"
2021,Instruction-tuning Stable Diffusion with InstructPix2Pix,https://huggingface.co/blog/instruction-tuning-sd,,[],"Tue, 23 May 2023 00:00:00 GMT"
2022,Large-scale Near-deduplication Behind BigCode,https://huggingface.co/blog/dedup,,[],"Tue, 16 May 2023 00:00:00 GMT"
2023,"Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",https://huggingface.co/blog/generative-ai-models-on-intel-cpu,,[],"Tue, 16 May 2023 00:00:00 GMT"
2024,Run a Chatgpt-like Chatbot on a Single GPU with ROCm,https://huggingface.co/blog/chatbot-amd-gpu,,[],"Mon, 15 May 2023 00:00:00 GMT"
2025,Introducing RWKV — An RNN with the advantages of a transformer,https://huggingface.co/blog/rwkv,,[],"Mon, 15 May 2023 00:00:00 GMT"
2026,Assisted Generation: a new direction toward low-latency text generation,https://huggingface.co/blog/assisted-generation,,[],"Thu, 11 May 2023 00:00:00 GMT"
2027,Creating a Coding Assistant with StarCoder,https://huggingface.co/blog/starchat-alpha,,[],"Tue, 09 May 2023 00:00:00 GMT"
2028,A Dive into Text-to-Video Models,https://huggingface.co/blog/text-to-video,,[],"Mon, 08 May 2023 00:00:00 GMT"
2029,StarCoder: A State-of-the-Art LLM for Code,https://huggingface.co/blog/starcoder,,[],"Thu, 04 May 2023 00:00:00 GMT"
2030,How to Install and Use the Hugging Face Unity API,https://huggingface.co/blog/unity-api,,[],"Mon, 01 May 2023 00:00:00 GMT"
2031,Running IF with 🧨 diffusers on a Free Tier Google Colab,https://huggingface.co/blog/if,,[],"Wed, 26 Apr 2023 00:00:00 GMT"
2032,Training a language model with 🤗 Transformers using TensorFlow and TPUs,https://huggingface.co/blog/tf_tpu,,[],"Thu, 27 Apr 2023 00:00:00 GMT"
2033,Databricks ❤️ Hugging Face: up to 40% faster training and tuning of Large Language Models,https://huggingface.co/blog/databricks-case-study,,[],"Wed, 26 Apr 2023 00:00:00 GMT"
2034,Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community,https://huggingface.co/blog/chinese-language-blog,,[],"Mon, 24 Apr 2023 00:00:00 GMT"
2035,How to host a Unity game in a Space,https://huggingface.co/blog/unity-in-spaces,,[],"Fri, 21 Apr 2023 00:00:00 GMT"
2036,Accelerating Hugging Face Transformers with AWS Inferentia2,https://huggingface.co/blog/accelerate-transformers-with-inferentia2,,[],"Mon, 17 Apr 2023 00:00:00 GMT"
2037,Graph Classification with Transformers,https://huggingface.co/blog/graphml-classification,,[],"Fri, 14 Apr 2023 00:00:00 GMT"
2038,Creating Privacy Preserving AI with Substra,https://huggingface.co/blog/owkin-substra,,[],"Wed, 12 Apr 2023 00:00:00 GMT"
2039,Snorkel AI x Hugging Face: unlock foundation models for enterprises,https://huggingface.co/blog/snorkel-case-study,,[],"Thu, 06 Apr 2023 00:00:00 GMT"
2040,StackLLaMA: A hands-on guide to train LLaMA with RLHF,https://huggingface.co/blog/stackllama,,[],"Wed, 05 Apr 2023 00:00:00 GMT"
2041,Ethics and Society Newsletter #3: Ethical Openness at Hugging Face,https://huggingface.co/blog/ethics-soc-3,,[],"Thu, 30 Mar 2023 00:00:00 GMT"
2042,Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator,https://huggingface.co/blog/habana-gaudi-2-bloom,,[],"Tue, 28 Mar 2023 00:00:00 GMT"
2043,Accelerating Stable Diffusion Inference on Intel CPUs,https://huggingface.co/blog/stable-diffusion-inference-intel,,[],"Tue, 28 Mar 2023 00:00:00 GMT"
2044,Federated Learning using Hugging Face and Flower,https://huggingface.co/blog/fl-with-flower,,[],"Mon, 27 Mar 2023 00:00:00 GMT"
2045,Train your ControlNet with diffusers,https://huggingface.co/blog/train-your-controlnet,,[],"Fri, 24 Mar 2023 00:00:00 GMT"
2046,Jupyter X Hugging Face,https://huggingface.co/blog/notebooks-hub,,[],"Thu, 23 Mar 2023 00:00:00 GMT"
2047,Multivariate Probabilistic Time Series Forecasting with Informer,https://huggingface.co/blog/informer,,[],"Fri, 10 Mar 2023 00:00:00 GMT"
2048,Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU,https://huggingface.co/blog/trl-peft,,[],"Thu, 09 Mar 2023 00:00:00 GMT"
2049,New ViT and ALIGN Models From Kakao Brain,https://huggingface.co/blog/vit-align,,[],"Mon, 06 Mar 2023 00:00:00 GMT"
2050,Using Machine Learning to Aid Survivors and Race through Time,https://huggingface.co/blog/using-ml-for-disasters,,[],"Fri, 03 Mar 2023 00:00:00 GMT"
2051,ControlNet in Diffusers 🧨,https://huggingface.co/blog/controlnet,,[],"Fri, 03 Mar 2023 00:00:00 GMT"
2052,Ethical guidelines for developing the Diffusers library,https://huggingface.co/blog/ethics-diffusers,,[],"Thu, 02 Mar 2023 00:00:00 GMT"
2053,How Hugging Face Accelerated Development of Witty Works Writing Assistant,https://huggingface.co/blog/classification-use-cases,,[],"Wed, 01 Mar 2023 00:00:00 GMT"
2054,Red-Teaming Large Language Models,https://huggingface.co/blog/red-teaming,,[],"Fri, 24 Feb 2023 00:00:00 GMT"
2055,Swift Diffusers: Fast Stable Diffusion for Mac,https://huggingface.co/blog/fast-mac-diffusers,,[],"Fri, 24 Feb 2023 00:00:00 GMT"
2056,Hugging Face and AWS partner to make AI more accessible,https://huggingface.co/blog/aws-partnership,,[],"Tue, 21 Feb 2023 00:00:00 GMT"
2057,Zero-shot image-to-text generation with BLIP-2,https://huggingface.co/blog/blip-2,,[],"Wed, 15 Feb 2023 00:00:00 GMT"
2058,"Why we’re switching to Hugging Face Inference Endpoints, and maybe you should too",https://huggingface.co/blog/mantis-case-study,,[],"Wed, 15 Feb 2023 00:00:00 GMT"
2059,🤗 PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware,https://huggingface.co/blog/peft,,[],"Fri, 10 Feb 2023 00:00:00 GMT"
2060,"Speech Synthesis, Recognition, and More With SpeechT5",https://huggingface.co/blog/speecht5,,[],"Wed, 08 Feb 2023 00:00:00 GMT"
2061,Generating Stories: AI for Game Development #5,https://huggingface.co/blog/ml-for-games-5,,[],"Tue, 07 Feb 2023 00:00:00 GMT"
2062,Introducing ⚔️ AI vs. AI ⚔️ a deep reinforcement learning multi-agents competition system,https://huggingface.co/blog/aivsai,,[],"Tue, 07 Feb 2023 00:00:00 GMT"
2063,"Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",https://huggingface.co/blog/intel-sapphire-rapids-inference,,[],"Mon, 06 Feb 2023 00:00:00 GMT"
2064,A Dive into Pretraining Strategies for Vision-Language Models,https://huggingface.co/blog/vision_language_pretraining,,[],"Fri, 03 Feb 2023 00:00:00 GMT"
2065,The State of Computer Vision at Hugging Face 🤗,https://huggingface.co/blog/cv_state,,[],"Mon, 30 Jan 2023 00:00:00 GMT"
2066,2D Asset Generation: AI for Game Development #4,https://huggingface.co/blog/ml-for-games-4,,[],"Thu, 26 Jan 2023 00:00:00 GMT"
2067,Using LoRA for Efficient Stable Diffusion Fine-Tuning,https://huggingface.co/blog/lora,,[],"Thu, 26 Jan 2023 00:00:00 GMT"
2068,What Makes a Dialog Agent Useful?,https://huggingface.co/blog/dialog-agents,,[],"Tue, 24 Jan 2023 00:00:00 GMT"
2069,"Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",https://huggingface.co/blog/optimum-onnxruntime-training,,[],"Tue, 24 Jan 2023 00:00:00 GMT"
2070,3D Asset Generation: AI for Game Development #3,https://huggingface.co/blog/ml-for-games-3,,[],"Fri, 20 Jan 2023 00:00:00 GMT"
2071,Universal Image Segmentation with Mask2Former and OneFormer,https://huggingface.co/blog/mask2former,,[],"Thu, 19 Jan 2023 00:00:00 GMT"
2072,Welcome PaddlePaddle to the Hugging Face Hub,https://huggingface.co/blog/paddlepaddle,,[],"Tue, 17 Jan 2023 00:00:00 GMT"
2073,Image Similarity with Hugging Face Datasets and Transformers,https://huggingface.co/blog/image-similarity,,[],"Mon, 16 Jan 2023 00:00:00 GMT"
2074,AI for Game Development: Creating a Farming Game in 5 Days. Part 2,https://huggingface.co/blog/ml-for-games-2,,[],"Mon, 09 Jan 2023 00:00:00 GMT"
2075,Introduction to Graph Machine Learning,https://huggingface.co/blog/intro-graphml,,[],"Tue, 03 Jan 2023 00:00:00 GMT"
2076,AI for Game Development: Creating a Farming Game in 5 Days. Part 1,https://huggingface.co/blog/ml-for-games-1,,[],"Mon, 02 Jan 2023 00:00:00 GMT"
2077,"Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",https://huggingface.co/blog/intel-sapphire-rapids,,[],"Mon, 02 Jan 2023 00:00:00 GMT"
2078,Zero-shot image segmentation with CLIPSeg,https://huggingface.co/blog/clipseg-zero-shot,,[],"Wed, 21 Dec 2022 00:00:00 GMT"
2079,Model Cards: Introducing HF Model documentation tools,https://huggingface.co/blog/model-cards,,[],"Tue, 20 Dec 2022 00:00:00 GMT"
2080,Ethics and Society Newsletter #2: Let's talk about bias!,https://huggingface.co/blog/ethics-soc-2,,[],"Thu, 15 Dec 2022 00:00:00 GMT"
2081,A Complete Guide to Audio Datasets,https://huggingface.co/blog/audio-datasets,,[],"Thu, 15 Dec 2022 00:00:00 GMT"
2082,Faster Training and Inference: Habana Gaudi®2 vs Nvidia A100 80GB,https://huggingface.co/blog/habana-gaudi-2-benchmark,,[],"Wed, 14 Dec 2022 00:00:00 GMT"
2083,Illustrating Reinforcement Learning from Human Feedback (RLHF),https://huggingface.co/blog/rlhf,,[],"Fri, 09 Dec 2022 00:00:00 GMT"
2084,From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community,https://huggingface.co/blog/elixir-bumblebee,,[],"Fri, 09 Dec 2022 00:00:00 GMT"
2085,Deep Learning with Proteins,https://huggingface.co/blog/deep-learning-with-proteins,,[],"Fri, 02 Dec 2022 00:00:00 GMT"
2086,Using Stable Diffusion with Core ML on Apple Silicon,https://huggingface.co/blog/diffusers-coreml,,[],"Thu, 01 Dec 2022 00:00:00 GMT"
2087,Probabilistic Time Series Forecasting with 🤗 Transformers,https://huggingface.co/blog/time-series-transformers,,[],"Thu, 01 Dec 2022 00:00:00 GMT"
2088,VQ Diffusion with 🧨 Diffusers,https://huggingface.co/blog/vq-diffusion,,[],"Wed, 30 Nov 2022 00:00:00 GMT"
2089,We are hiring interns!,https://huggingface.co/blog/interns-2023,,[],"Tue, 29 Nov 2022 00:00:00 GMT"
2090,Diffusion Models Live Event,https://huggingface.co/blog/diffusion-models-event,,[],"Fri, 25 Nov 2022 00:00:00 GMT"
2091,Accelerating Document AI,https://huggingface.co/blog/document-ai,,[],"Mon, 21 Nov 2022 00:00:00 GMT"
2092,An Overview of Inference Solutions on Hugging Face,https://huggingface.co/blog/inference-update,,[],"Mon, 21 Nov 2022 00:00:00 GMT"
2093,Director of Machine Learning Insights [Part 4],https://huggingface.co/blog/ml-director-insights-4,,[],"Wed, 23 Nov 2022 00:00:00 GMT"
2094,Hugging Face Machine Learning Demos on arXiv,https://huggingface.co/blog/arxiv,,[],"Thu, 17 Nov 2022 00:00:00 GMT"
2095,Sentiment Classification with Fully Homomorphic Encryption using Concrete ML,https://huggingface.co/blog/sentiment-analysis-fhe,,[],"Thu, 17 Nov 2022 00:00:00 GMT"
2096,Generating Human-level Text with Contrastive Search in Transformers 🤗,https://huggingface.co/blog/introducing-csearch,,[],"Tue, 08 Nov 2022 00:00:00 GMT"
2097,Introducing our new pricing,https://huggingface.co/blog/pricing-update,,[],"Tue, 08 Nov 2022 00:00:00 GMT"
2098,Training Stable Diffusion with Dreambooth using 🧨 Diffusers,https://huggingface.co/blog/dreambooth,,[],"Mon, 07 Nov 2022 00:00:00 GMT"
2099,Fine-Tune Whisper with 🤗 Transformers,https://huggingface.co/blog/fine-tune-whisper,,[],"Thu, 03 Nov 2022 00:00:00 GMT"
2100,Accelerate your models with 🤗 Optimum Intel and OpenVINO,https://huggingface.co/blog/openvino,,[],"Wed, 02 Nov 2022 00:00:00 GMT"
2101,Evaluating Language Model Bias with 🤗 Evaluate,https://huggingface.co/blog/evaluating-llm-bias,,[],"Mon, 24 Oct 2022 00:00:00 GMT"
2102,"From PyTorch DDP to 🤗 Accelerate to 🤗 Trainer, mastery of distributed training with ease",https://huggingface.co/blog/pytorch-ddp-accelerate-transformers,,[],"Fri, 21 Oct 2022 00:00:00 GMT"
2103,MTEB: Massive Text Embedding Benchmark,https://huggingface.co/blog/mteb,,[],"Wed, 19 Oct 2022 00:00:00 GMT"
2104,Getting started with Hugging Face Inference Endpoints,https://huggingface.co/blog/inference-endpoints,,[],"Fri, 14 Oct 2022 00:00:00 GMT"
2105,Stable Diffusion in JAX/Flax 🚀,https://huggingface.co/blog/stable_diffusion_jax,,[],"Thu, 13 Oct 2022 00:00:00 GMT"
2106,Optimization story: Bloom inference,https://huggingface.co/blog/bloom-inference-optimization,,[],"Wed, 12 Oct 2022 00:00:00 GMT"
2107,Introducing DOI: the Digital Object Identifier to Datasets and Models,https://huggingface.co/blog/introducing-doi,,[],"Fri, 07 Oct 2022 00:00:00 GMT"
2108,Japanese Stable Diffusion,https://huggingface.co/blog/japanese-stable-diffusion,,[],"Wed, 05 Oct 2022 00:00:00 GMT"
2109,Very Large Language Models and How to Evaluate Them,https://huggingface.co/blog/zero-shot-eval-on-the-hub,,[],"Mon, 03 Oct 2022 00:00:00 GMT"
2110,Image Classification with AutoTrain,https://huggingface.co/blog/autotrain-image-classification,,[],"Wed, 28 Sep 2022 00:00:00 GMT"
2111,How 🤗 Accelerate runs very large models thanks to PyTorch,https://huggingface.co/blog/accelerate-large-models,,[],"Tue, 27 Sep 2022 00:00:00 GMT"
2112,SetFit: Efficient Few-Shot Learning Without Prompts,https://huggingface.co/blog/setfit,,[],"Mon, 26 Sep 2022 00:00:00 GMT"
2113,Ethics and Society Newsletter #1,https://huggingface.co/blog/ethics-soc-1,,[],"Thu, 22 Sep 2022 00:00:00 GMT"
2114,Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate,https://huggingface.co/blog/bloom-inference-pytorch-scripts,,[],"Fri, 16 Sep 2022 00:00:00 GMT"
2115,How to train a Language Model with Megatron-LM,https://huggingface.co/blog/megatron-training,,[],"Wed, 07 Sep 2022 00:00:00 GMT"
2116,What's new in Diffusers? 🎨,https://huggingface.co/blog/diffusers-2nd-month,,[],"Mon, 12 Sep 2022 00:00:00 GMT"
2117,Train your first Decision Transformer,https://huggingface.co/blog/train-decision-transformers,,[],"Thu, 08 Sep 2022 00:00:00 GMT"
2118,OpenRAIL: Towards open and responsible AI licensing frameworks,https://huggingface.co/blog/open_rail,,[],"Wed, 31 Aug 2022 00:00:00 GMT"
2119,Visualize proteins on Hugging Face Spaces,https://huggingface.co/blog/spaces_3dmoljs,,[],"Wed, 24 Aug 2022 00:00:00 GMT"
2120,Stable Diffusion with 🧨 Diffusers,https://huggingface.co/blog/stable_diffusion,,[],"Mon, 22 Aug 2022 00:00:00 GMT"
2121,Pre-Train BERT with Hugging Face Transformers and Habana Gaudi,https://huggingface.co/blog/pretraining-bert,,[],"Mon, 22 Aug 2022 00:00:00 GMT"
2122,Deploying 🤗 ViT on Vertex AI,https://huggingface.co/blog/deploy-vertex-ai,,[],"Fri, 19 Aug 2022 00:00:00 GMT"
2123,Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore,https://huggingface.co/blog/vision-transformers,,[],"Thu, 18 Aug 2022 00:00:00 GMT"
2124,"A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",https://huggingface.co/blog/hf-bitsandbytes-integration,,[],"Wed, 17 Aug 2022 00:00:00 GMT"
2125,Introducing Skops,https://huggingface.co/blog/skops,,[],"Fri, 12 Aug 2022 00:00:00 GMT"
2126,Hugging Face's TensorFlow Philosophy,https://huggingface.co/blog/tensorflow-philosophy,,[],"Fri, 12 Aug 2022 00:00:00 GMT"
2127,Deploying 🤗 ViT on Kubernetes with TF Serving,https://huggingface.co/blog/deploy-tfserving-kubernetes,,[],"Thu, 11 Aug 2022 00:00:00 GMT"
2128,Train and Fine-Tune Sentence Transformers Models,https://huggingface.co/blog/how-to-train-sentence-transformers,,[],"Wed, 10 Aug 2022 00:00:00 GMT"
2129,Proximal Policy Optimization (PPO),https://huggingface.co/blog/deep-rl-ppo,,[],"Fri, 05 Aug 2022 00:00:00 GMT"
2130,Introducing the Private Hub: A New Way to Build With Machine Learning,https://huggingface.co/blog/introducing-private-hub,,[],"Wed, 03 Aug 2022 00:00:00 GMT"
2131,"Nyströmformer, Approximating self-attention in linear time and memory via the Nyström method",https://huggingface.co/blog/nystromformer,,[],"Tue, 02 Aug 2022 00:00:00 GMT"
2132,AI Policy @🤗: Comments on U.S. National AI Research Resource Interim Report,https://huggingface.co/blog/us-national-ai-research-resource,,[],"Mon, 01 Aug 2022 00:00:00 GMT"
2133,Introducing new audio and vision documentation in 🤗 Datasets,https://huggingface.co/blog/datasets-docs-update,,[],"Thu, 28 Jul 2022 00:00:00 GMT"
2134,Faster Text Generation with TensorFlow and XLA,https://huggingface.co/blog/tf-xla-generate,,[],"Wed, 27 Jul 2022 00:00:00 GMT"
2135,Deploying TensorFlow Vision Models in Hugging Face with TF Serving,https://huggingface.co/blog/tf-serving-vision,,[],"Mon, 25 Jul 2022 00:00:00 GMT"
2136,Advantage Actor Critic (A2C),https://huggingface.co/blog/deep-rl-a2c,,[],"Fri, 22 Jul 2022 00:00:00 GMT"
2137,How to train your model dynamically using adversarial data,https://huggingface.co/blog/mnist-adversarial,,[],"Sat, 16 Jul 2022 00:00:00 GMT"
2138,The Technology Behind BLOOM Training,https://huggingface.co/blog/bloom-megatron-deepspeed,,[],"Thu, 14 Jul 2022 00:00:00 GMT"
2139,Building a Playlist Generator with Sentence Transformers,https://huggingface.co/blog/playlist-generator,,[],"Wed, 13 Jul 2022 00:00:00 GMT"
2140,Introducing The World's Largest Open Multilingual Language Model: BLOOM,https://huggingface.co/blog/bloom,,[],"Tue, 12 Jul 2022 00:00:00 GMT"
2141,Getting Started with Sentiment Analysis on Twitter,https://huggingface.co/blog/sentiment-analysis-twitter,,[],"Thu, 07 Jul 2022 00:00:00 GMT"
2142,Policy Gradient with PyTorch,https://huggingface.co/blog/deep-rl-pg,,[],"Thu, 30 Jun 2022 00:00:00 GMT"
2143,Liftoff! How to get started with your first ML project 🚀,https://huggingface.co/blog/your-first-ml-project,,[],"Wed, 29 Jun 2022 00:00:00 GMT"
2144,Accelerate Large Model Training using DeepSpeed,https://huggingface.co/blog/accelerate-deepspeed,,[],"Tue, 28 Jun 2022 00:00:00 GMT"
2145,Announcing Evaluation on the Hub,https://huggingface.co/blog/eval-on-the-hub,,[],"Tue, 28 Jun 2022 00:00:00 GMT"
2146,Getting Started With Embeddings,https://huggingface.co/blog/getting-started-with-embeddings,,[],"Thu, 23 Jun 2022 00:00:00 GMT"
2147,Convert Transformers to ONNX with Hugging Face Optimum,https://huggingface.co/blog/convert-transformers-to-onnx,,[],"Wed, 22 Jun 2022 00:00:00 GMT"
2148,Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration,https://huggingface.co/blog/intel,,[],"Wed, 15 Jun 2022 00:00:00 GMT"
2149,Director of Machine Learning Insights [Part 3: Finance Edition],https://huggingface.co/blog/ml-director-insights-3,,[],"Tue, 14 Jun 2022 00:00:00 GMT"
2150,Using Sentence Transformers for semantic search,https://huggingface.co/spaces/sentence-transformers/Sentence_Transformers_for_semantic_search,,[],"Fri, 10 Jun 2022 00:00:00 GMT"
2151,Code generation with Hugging Face,https://huggingface.co/spaces/loubnabnl/code-generation-models,,[],"Wed, 08 Jun 2022 00:00:00 GMT"
2152,The Annotated Diffusion Model,https://huggingface.co/blog/annotated-diffusion,,[],"Tue, 07 Jun 2022 00:00:00 GMT"
2153,Deep Q-Learning with Atari,https://huggingface.co/blog/deep-rl-dqn,,[],"Tue, 07 Jun 2022 00:00:00 GMT"
2154,Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers,https://huggingface.co/blog/graphcore-update,,[],"Thu, 26 May 2022 00:00:00 GMT"
2155,Introducing Pull Requests and Discussions 🥳,https://huggingface.co/blog/community-update,,[],"Wed, 25 May 2022 00:00:00 GMT"
2156,Efficient Table Pre-training without Real Data: An Introduction to TAPEX,https://huggingface.co/blog/tapex,,[],"Mon, 23 May 2022 00:00:00 GMT"
2157,An Introduction to Q-Learning Part 2,https://huggingface.co/blog/deep-rl-q-part2,,[],"Fri, 20 May 2022 00:00:00 GMT"
2158,How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap,https://huggingface.co/blog/sempre-health-eap-case-study,,[],"Thu, 19 May 2022 00:00:00 GMT"
2159,Putting ethical principles at the core of research lifecycle,https://huggingface.co/blog/ethical-charter-multimodal,,[],"Thu, 19 May 2022 00:00:00 GMT"
2160,An Introduction to Q-Learning Part 1,https://huggingface.co/blog/deep-rl-q-part1,,[],"Wed, 18 May 2022 00:00:00 GMT"
2161,Machine Learning Experts - Sasha Luccioni Interview,https://huggingface.co/blog/sasha-luccioni-interview,,[],"Tue, 17 May 2022 00:00:00 GMT"
2162,Announcing the Hugging Face Fellowship Program,https://huggingface.co/blog/fellowship,,[],"Tue, 17 May 2022 00:00:00 GMT"
2163,Gradio 3.0 is Out!,https://huggingface.co/blog/gradio-blocks,,[],"Mon, 16 May 2022 00:00:00 GMT"
2164,Director of Machine Learning Insights [Part 2: SaaS Edition],https://huggingface.co/blog/ml-director-insights-2,,[],"Fri, 13 May 2022 00:00:00 GMT"
2165,Student Ambassador Program's call for applications is open!,https://huggingface.co/blog/ambassadors,,[],"Fri, 13 May 2022 00:00:00 GMT"
2166,Accelerated Inference with Optimum and Transformers Pipelines,https://huggingface.co/blog/optimum-inference,,[],"Tue, 10 May 2022 00:00:00 GMT"
2167,We Raised $100 Million for Open & Collaborative Machine Learning 🚀,https://huggingface.co/blog/series-c,,[],"Mon, 09 May 2022 00:00:00 GMT"
2168,Welcome fastai to the Hugging Face Hub,https://huggingface.co/blog/fastai,,[],"Fri, 06 May 2022 00:00:00 GMT"
2169,An Introduction to Deep Reinforcement Learning,https://huggingface.co/blog/deep-rl-intro,,[],"Wed, 04 May 2022 00:00:00 GMT"
2170,Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel,https://huggingface.co/blog/pytorch-fsdp,,[],"Mon, 02 May 2022 00:00:00 GMT"
2171,Opinion Classification with Kili and HuggingFace AutoTrain,https://huggingface.co/blog/opinion-classification-with-kili,,[],"Thu, 28 Apr 2022 00:00:00 GMT"
2172,Director of Machine Learning Insights [Series],https://huggingface.co/blog/ml-director-insights,,[],"Wed, 27 Apr 2022 00:00:00 GMT"
2173,Getting Started with Transformers on Habana Gaudi,https://huggingface.co/blog/getting-started-habana,,[],"Tue, 26 Apr 2022 00:00:00 GMT"
2174,Introducing Hugging Face for Education,https://huggingface.co/blog/education,,[],"Mon, 25 Apr 2022 00:00:00 GMT"
2175,Supercharged Customer Service with Machine Learning,https://huggingface.co/blog/supercharge-customer-service-with-machine-learning,,[],"Mon, 25 Apr 2022 00:00:00 GMT"
2176,CO2 Emissions and the 🤗 Hub: Leading the Charge,https://huggingface.co/blog/carbon-emissions-on-the-hub,,[],"Fri, 22 Apr 2022 00:00:00 GMT"
2177,Machine Learning Experts - Lewis Tunstall Interview,https://huggingface.co/blog/lewis-tunstall-interview,,[],"Wed, 13 Apr 2022 00:00:00 GMT"
2178,Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training,https://huggingface.co/blog/habana,,[],"Tue, 12 Apr 2022 00:00:00 GMT"
2179,Don't repeat yourself - 🤗 Transformers Design Philosophy,https://huggingface.co/blog/transformers-design-philosophy,,[],"Tue, 05 Apr 2022 00:00:00 GMT"
2180,Introducing Decision Transformers on Hugging Face 🤗,https://huggingface.co/blog/decision-transformers,,[],"Mon, 28 Mar 2022 00:00:00 GMT"
2181,Machine Learning Experts - Meg Mitchell Interview,https://huggingface.co/blog/meg-mitchell-interview,,[],"Wed, 23 Mar 2022 00:00:00 GMT"
2182,Announcing the 🤗 AI Research Residency Program,https://huggingface.co/blog/ai-residency,,[],"Tue, 22 Mar 2022 00:00:00 GMT"
2183,Fine-Tune a Semantic Segmentation Model with a Custom Dataset,https://huggingface.co/blog/fine-tune-segformer,,[],"Thu, 17 Mar 2022 00:00:00 GMT"
2184,Accelerate BERT inference with Hugging Face Transformers and AWS inferentia,https://huggingface.co/blog/bert-inferentia-sagemaker,,[],"Wed, 16 Mar 2022 00:00:00 GMT"
2185,Image search with 🤗 datasets,https://huggingface.co/blog/image-search-datasets,,[],"Wed, 16 Mar 2022 00:00:00 GMT"
2186,Guiding Text Generation with Constrained Beam Search in 🤗 Transformers,https://huggingface.co/blog/constrained-beam-search,,[],"Fri, 11 Mar 2022 00:00:00 GMT"
2187,BERT 101 🤗 State Of The Art NLP Model Explained,https://huggingface.co/blog/bert-101,,[],"Wed, 02 Mar 2022 00:00:00 GMT"
2188,Fine-Tune ViT for Image Classification with 🤗 Transformers,https://huggingface.co/blog/fine-tune-vit,,[],"Fri, 11 Feb 2022 00:00:00 GMT"
2189,Getting Started with Sentiment Analysis using Python,https://huggingface.co/blog/sentiment-analysis-python,,[],"Wed, 02 Feb 2022 00:00:00 GMT"
2190,Making automatic speech recognition work on large files with Wav2Vec2 in 🤗 Transformers,https://huggingface.co/blog/asr-chunking,,[],"Tue, 01 Feb 2022 00:00:00 GMT"
2191,Supercharged Searching on the Hugging Face Hub,https://huggingface.co/blog/searching-the-hub,,[],"Tue, 25 Jan 2022 00:00:00 GMT"
2192,Welcome Stable-baselines3 to the Hugging Face Hub 🤗,https://huggingface.co/blog/sb3,,[],"Fri, 21 Jan 2022 00:00:00 GMT"
2193,Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs,https://huggingface.co/blog/infinity-cpu-performance,,[],"Thu, 13 Jan 2022 00:00:00 GMT"
2194,Boost Wav2Vec2 with n-gram LM in 🤗 Transformers,https://huggingface.co/blog/wav2vec2-with-ngram,,[],"Wed, 12 Jan 2022 00:00:00 GMT"
2195,Deploy GPT-J 6B for inference using  Hugging Face Transformers and Amazon SageMaker,https://huggingface.co/blog/gptj-sagemaker,,[],"Tue, 11 Jan 2022 00:00:00 GMT"
2196,Active Learning with AutoNLP and Prodigy,https://huggingface.co/blog/autonlp-prodigy,,[],"Thu, 23 Dec 2021 00:00:00 GMT"
2197,Gradio joins Hugging Face!,https://huggingface.co/blog/gradio-joins-hf,,[],"Tue, 21 Dec 2021 00:00:00 GMT"
2198,"Perceiver IO: a scalable, fully-attentional model that works on any modality",https://huggingface.co/blog/perceiver,,[],"Wed, 15 Dec 2021 00:00:00 GMT"
2199,Training CodeParrot 🦜 from Scratch,https://huggingface.co/blog/codeparrot,,[],"Wed, 08 Dec 2021 00:00:00 GMT"
2200,"Introducing Snowball Fight ☃️, our First ML-Agents Environment",https://huggingface.co/blog/snowball-fight,,[],"Thu, 02 Dec 2021 00:00:00 GMT"
2201,Getting Started with Hugging Face Transformers for IPUs with Optimum,https://huggingface.co/blog/graphcore-getting-started,,[],"Tue, 30 Nov 2021 00:00:00 GMT"
2202,Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets,https://huggingface.co/blog/data-measurements-tool,,[],"Mon, 29 Nov 2021 00:00:00 GMT"
2203,Accelerating PyTorch distributed fine-tuning with Intel technologies,https://huggingface.co/blog/accelerating-pytorch,,[],"Fri, 19 Nov 2021 00:00:00 GMT"
2204,Fine-tuning XLS-R for Multi-Lingual ASR with 🤗 Transformers,https://huggingface.co/blog/fine-tune-xlsr-wav2vec2,,[],"Mon, 15 Nov 2021 00:00:00 GMT"
2205,Scaling up BERT-like model Inference on modern CPU - Part 2,https://huggingface.co/blog/bert-cpu-scaling-part-2,,[],"Thu, 04 Nov 2021 00:00:00 GMT"
2206,Course Launch Community Event,https://huggingface.co/blog/course-launch-event,,[],"Tue, 26 Oct 2021 00:00:00 GMT"
2207,Large Language Models: A New Moore's Law?,https://huggingface.co/blog/large-language-models,,[],"Tue, 26 Oct 2021 00:00:00 GMT"
2208,Train a Sentence Embedding Model with 1B Training Pairs,https://huggingface.co/blog/1b-sentence-embeddings,,[],"Mon, 25 Oct 2021 00:00:00 GMT"
2209,The Age of Machine Learning As Code Has Arrived,https://huggingface.co/blog/the-age-of-ml-as-code,,[],"Wed, 20 Oct 2021 00:00:00 GMT"
2210,Fine tuning CLIP with Remote Sensing (Satellite) images and captions,https://huggingface.co/blog/fine-tune-clip-rsicd,,[],"Wed, 13 Oct 2021 00:00:00 GMT"
2211,Hosting your Models and Datasets on Hugging Face Spaces using Streamlit,https://huggingface.co/blog/streamlit-spaces,,[],"Tue, 05 Oct 2021 00:00:00 GMT"
2212,Showcase Your Projects in Spaces using Gradio,https://huggingface.co/blog/gradio-spaces,,[],"Tue, 05 Oct 2021 00:00:00 GMT"
2213,Summer at Hugging Face ☀️,https://huggingface.co/blog/summer-at-huggingface,,[],"Fri, 24 Sep 2021 00:00:00 GMT"
2214,Hugging Face and Graphcore partner for IPU-optimized Transformers,https://huggingface.co/blog/graphcore,,[],"Tue, 14 Sep 2021 00:00:00 GMT"
2215,Introducing Optimum: The Optimization Toolkit for Transformers at Scale,https://huggingface.co/blog/hardware-partners-program,,[],"Tue, 14 Sep 2021 00:00:00 GMT"
2216,Deep Learning over the Internet: Training Language Models Collaboratively,https://huggingface.co/blog/collaborative-training,,[],"Thu, 15 Jul 2021 00:00:00 GMT"
2217,Welcome spaCy to the 🤗 Hub,https://huggingface.co/blog/spacy,,[],"Tue, 13 Jul 2021 00:00:00 GMT"
2218,Deploy Hugging Face models easily with Amazon SageMaker,https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker,,[],"Thu, 08 Jul 2021 00:00:00 GMT"
2219,Sentence Transformers in the 🤗 Hub,https://huggingface.co/blog/sentence-transformers-in-the-hub,,[],"Mon, 28 Jun 2021 00:00:00 GMT"
2220,Few-shot learning in practice: GPT-NEO and the 🤗 Accelerated Inference API,https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api,,[],"Thu, 03 Jun 2021 00:00:00 GMT"
2221,Using & Mixing Hugging Face Models with Gradio 2.0,https://huggingface.co/blog/gradio,,[],"Tue, 25 May 2021 00:00:00 GMT"
2222,Scaling-up BERT Inference on CPU (Part 1),https://huggingface.co/blog/bert-cpu-scaling-part-1,,[],"Tue, 20 Apr 2021 00:00:00 GMT"
2223,Introducing 🤗 Accelerate,https://huggingface.co/blog/accelerate-library,,[],"Fri, 16 Apr 2021 00:00:00 GMT"
2224,Distributed Training: Train BART/T5 for Summarization using 🤗 Transformers and Amazon SageMaker,https://huggingface.co/blog/sagemaker-distributed-training-seq2seq,,[],"Thu, 08 Apr 2021 00:00:00 GMT"
2225,How many data points is a prompt worth?,https://huggingface.co/blog/how_many_data_points,,[],"Mon, 05 Apr 2021 00:00:00 GMT"
2226,Understanding BigBird's Block Sparse Attention,https://huggingface.co/blog/big-bird,,[],"Wed, 31 Mar 2021 00:00:00 GMT"
2227,The Partnership: Amazon SageMaker and Hugging Face,https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face,,[],"Tue, 23 Mar 2021 00:00:00 GMT"
2228,My Journey to a serverless transformers pipeline on Google Cloud,https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds,,[],"Thu, 18 Mar 2021 00:00:00 GMT"
2229,Fine-Tune Wav2Vec2 for English ASR with 🤗 Transformers,https://huggingface.co/blog/fine-tune-wav2vec2-english,,[],"Fri, 12 Mar 2021 00:00:00 GMT"
2230,"Hugging Face Reads, Feb. 2021 - Long-range Transformers",https://huggingface.co/blog/long-range-transformers,,[],"Tue, 09 Mar 2021 00:00:00 GMT"
2231,Simple considerations for simple people building fancy neural networks,https://huggingface.co/blog/simple-considerations,,[],"Thu, 25 Feb 2021 00:00:00 GMT"
2232,Retrieval Augmented Generation with Huggingface Transformers and Ray,https://huggingface.co/blog/ray-rag,,[],"Wed, 10 Feb 2021 00:00:00 GMT"
2233,Hugging Face on PyTorch / XLA TPUs,https://huggingface.co/blog/pytorch-xla,,[],"Tue, 09 Feb 2021 00:00:00 GMT"
2234,Faster TensorFlow models in Hugging Face Transformers,https://huggingface.co/blog/tf-serving,,[],"Tue, 26 Jan 2021 00:00:00 GMT"
2235,Fit More and Train Faster With ZeRO via DeepSpeed and FairScale,https://huggingface.co/blog/zero-deepspeed-fairscale,,[],"Tue, 19 Jan 2021 00:00:00 GMT"
2236,How we sped up transformer inference 100x for 🤗 API customers,https://huggingface.co/blog/accelerated-inference,,[],"Mon, 18 Jan 2021 00:00:00 GMT"
2237,Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models,https://huggingface.co/blog/warm-starting-encoder-decoder,,[],"Mon, 09 Nov 2020 00:00:00 GMT"
2238,Porting fairseq wmt19 translation system to transformers,https://huggingface.co/blog/porting-fsmt,,[],"Tue, 03 Nov 2020 00:00:00 GMT"
2239,Hyperparameter Search with Transformers and Ray Tune,https://huggingface.co/blog/ray-tune,,[],"Mon, 02 Nov 2020 00:00:00 GMT"
2240,Transformer-based Encoder-Decoder Models,https://huggingface.co/blog/encoder-decoder,,[],"Sat, 10 Oct 2020 00:00:00 GMT"
2241,Retrieval Augmented Generation (RAG),https://huggingface.co/rag,,[],"Mon, 28 Sep 2020 00:00:00 GMT"
2242,Block Sparse Matrices for Smaller and Faster Language Models,https://huggingface.co/blog/pytorch_block_sparse,,[],"Thu, 10 Sep 2020 00:00:00 GMT"
2243,The Reformer - Pushing the limits of language modeling,https://huggingface.co/blog/reformer,,[],"Fri, 03 Jul 2020 00:00:00 GMT"
2244,Long Form Question Answering with ELI5,https://yjernite.github.io/lfqa.html,,[],"Wed, 17 Jun 2020 00:00:00 GMT"
2245,How Big Should My Language Model Be?,https://huggingface.co/calculator,,[],"Mon, 08 Jun 2020 00:00:00 GMT"
2246,Zero Shot Topic Classification,https://huggingface.co/zero-shot,,[],"Fri, 29 May 2020 00:00:00 GMT"
2247,How to generate text: using different decoding methods for language generation with Transformers,https://huggingface.co/blog/how-to-generate,,[],"Sun, 01 Mar 2020 00:00:00 GMT"
2248,How to train a new language model from scratch using Transformers and Tokenizers,https://huggingface.co/blog/how-to-train,,[],"Fri, 14 Feb 2020 00:00:00 GMT"
2249,"Meta's AI Watermarking Plan is Flimsy, At Best",https://spectrum.ieee.org/meta-ai-watermarks,"<img src=\"https://spectrum.ieee.org/media-library/letters-and-numbers-bunched-together-with-the-colors-blue-in-a-box-and-red-and-white-in-stripes.jpg?id=51634902&amp;width=1200&amp;height=800&amp;coordinates=0%2C125%2C0%2C125\" /><br /><br /><p>In the past few months, we’ve seen a <a href=\"https://www.axios.com/2024/02/07/new-hampshire-fake-robocall-ai-biden-voice-texas\" target=\"_blank\">deepfake robocall</a> of Joe Biden encouraging New Hampshire voters to “save your vote for the November election” and a <a href=\"https://www.nbcnews.com/tech/internet/taylor-swift-deepfake-x-falsely-depict-supporting-trump-grammys-flag-rcna137620\" target=\"_blank\">fake endorsement</a> of Donald Trump from Taylor Swift. It’s clear that 2024 will mark the first “AI election” in United States history.<br /></p><p>With many advocates <a href=\"https://www.brennancenter.org/our-work/research-reports/regulating-ai-deepfakes-and-synthetic-media-political-arena\" target=\"_blank\">calling for safeguards</a> against AI’s potential harms to our democracy, <a href=\"https://about.meta.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Meta</a> (the parent company of Facebook and Instagram) proudly <a href=\"https://about.fb.com/news/2024/02/labeling-ai-generated-images-on-facebook-instagram-and-threads/\" rel=\"noopener noreferrer\" target=\"_blank\">announced</a> last month that it will label AI-generated content that was created using the most popular generative AI tools. The company said it’s “building industry-leading tools that can identify invisible markers at scale—specifically, the ‘AI generated’ information in the <a href=\"https://c2pa.org/\" rel=\"noopener noreferrer\" target=\"_blank\">C2PA</a> and IPTC technical standards.” </p><p>Unfortunately, social media companies will not solve the problem of deepfakes on social media this year with this approach. Indeed, this new effort will do very little to tackle the problem of AI-generated material polluting the election environment.</p><p>The most obvious weakness is that Meta’s system will only work if the bad actors creating deepfakes use tools that already put watermarks—that is, hidden or visible information about the origin of digital content—into their images. Unsecured “open-source” generative AI tools mostly don’t produce watermarks at all. (We use the term unsecured and put “open-source” in quotes to denote that many such tools don’t meet traditional definitions of open-source software, but <a href=\"https://spectrum.ieee.org/open-source-ai-2666932122\" target=\"_self\">still pose a threat</a> because their underlying code or model weights have been made publicly available.) If new versions of these unsecured tools are released that do contain watermarks, the old tools will still be available and able to produce watermark-free content, including personalized and highly persuasive disinformation and nonconsensual deepfake pornography.</p><p>We are also concerned that bad actors can easily circumvent Meta’s labeling regimen even if they are using the AI tools that Meta says will be covered, which include products from Google, OpenAI, Microsoft, Adobe, Midjourney, and Shutterstock. Given that it takes about two seconds to remove a watermark from an image produced using <a href=\"https://spectrum.ieee.org/deepfakes-election\" target=\"_self\">the current C2PA watermarking standard</a> that these companies have implemented, Meta’s promise to label AI-generated images falls flat.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"website screengrab of an image with text\" class=\"rm-shortcode\" id=\"910ce\" src=\"https://spectrum.ieee.org/media-library/website-screengrab-of-an-image-with-text.jpg?id=51635174&amp;width=980\" />
<small class=\"image-media media-caption\">When the authors uploaded an image they’d generated to a website that checks for watermarks, the site correctly stated that it was a synthetic image generated by an OpenAI tool. </small><small class=\"image-media media-photo-credit\">IEEE Spectrum</small></p><p>We know this because we were able to easily remove the watermarks Meta claims it will detect—and neither of us is an engineer. Nor did we have to write a single line of code or install any software. </p><p>First, we generated an image with OpenAI’s DALL-E 3. Then, to see if the watermark worked, we uploaded the image to the <a href=\"https://contentcredentials.org/verify\" rel=\"noopener noreferrer\" target=\"_blank\">C2PA content credentials verification</a> website. A simple and elegant interface showed us that this image was indeed made with OpenAI’s DALL-E 3. How did we then remove the watermark? By taking a screenshot. When we uploaded the screenshot to the same verification website, the verification site found no evidence that the image had been generated by AI. The same process worked when we made an image with <a href=\"https://imagine.meta.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Meta’s AI image generator</a> and took a screenshot of it—and uploaded it to a <a href=\"https://compress-or-die.com/analyze\" rel=\"noopener noreferrer\" target=\"_blank\">website</a> that detects the IPTC metadata that contains Meta’s AI “watermark.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"website screengrab of an image with text\" class=\"rm-shortcode\" id=\"190c3\" src=\"https://spectrum.ieee.org/media-library/website-screengrab-of-an-image-with-text.png?id=51635179&amp;width=980\" />
<small class=\"image-media media-caption\">However, when the authors took a screenshot of the image and uploaded that screenshot to the same verification site, the site found no watermark and therefore no evidence that the image was AI-generated. </small><small class=\"image-media media-photo-credit\">IEEE Spectrum</small></p><h2>Is there a better way to identify AI-generated content?</h2><p>Meta’s announcement states that it’s “working hard to develop classifiers that can help ... to automatically detect AI-generated content, even if the content lacks invisible markers.” It’s nice that the company is working on it, but until it succeeds and shares this technology with the entire industry, we will be stuck wondering whether anything we see or hear online is real. </p><p>For a more immediate solution, the industry could adopt <em>maximally indelible</em> watermarks—meaning watermarks that are as difficult to remove as possible.</p><p>Today’s imperfect watermarks typically attach information to a file in the form of metadata. For maximally indelible watermarks to offer an improvement, they need to hide information imperceptibly in the actual pixels of images, the waveforms of audio (Google Deepmind claims to have done this with their proprietary <a href=\"https://deepmind.google/technologies/synthid/\" rel=\"noopener noreferrer\" target=\"_blank\">SynthID watermark</a>) or through slightly modified <a href=\"https://www.nytimes.com/interactive/2023/02/17/business/ai-text-detection.html\" rel=\"noopener noreferrer\" target=\"_blank\">word frequency</a> patterns in AI-generated text. We use the term “maximally” to acknowledge that there may never be a perfectly indelible watermark. This is not a problem just with watermarks though. The celebrated security expert <a href=\"https://www.schneier.com/blog/about/\" rel=\"noopener noreferrer\" target=\"_blank\">Bruce Schneier</a> notes that “<a href=\"https://www.schneier.com/news/archives/2007/05/is_security_a_solvab.html\" target=\"_blank\">computer security is not a solvable problem</a>…. Security has always been an arms race, and always will be.”<strong></strong></p><p>In metaphorical terms, it’s instructive to consider automobile safety. No car manufacturer has ever produced a car that cannot crash. Yet that hasn’t stopped regulators from implementing comprehensive safety standards that require seatbelts, airbags, and backup cameras on cars. If we waited for safety technologies to be perfected before requiring implementation of the best available options, we would be much worse off in many domains.</p><p>There’s increasing political momentum to tackle deepfakes. Fifteen of the biggest AI companies—including almost every one mentioned in this article—signed on to the <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/09/12/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-eight-additional-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/\" rel=\"noopener noreferrer\" target=\"_blank\">White House Voluntary AI Commitments</a> last year, which included pledges to “develop robust mechanisms, including provenance and/or watermarking systems for audio or visual content” and to “develop tools or APIs to determine if a particular piece of content was created with their system.” Unfortunately, the White House did not set any timeline for the voluntary commitments.</p><p>Then, in October, the White House, in its <a href=\"https://spectrum.ieee.org/biden-ai-executive-order\" target=\"_self\">AI Executive Order</a>, defined AI watermarking as “the act of embedding information, which is typically difficult to remove, into outputs created by AI—including into outputs such as photos, videos, audio clips, or text—for the purposes of verifying the authenticity of the output or the identity or characteristics of its provenance, modifications, or conveyance.”</p><p>Next, at the <a href=\"https://securityconference.org/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Munich Security Conference</a> on 16 February, a group of 20 tech companies (half of which had previously signed the voluntary commitments) signed onto a new “<a href=\"https://www.aielectionsaccord.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Tech Accord to Combat Deceptive Use of AI in 2024 Elections</a>.” Without making any concrete commitments or providing any timelines, the accord offers a vague intention to implement some form of watermarking or content provenance efforts. Although a standard is not specified, the accord lists both C2PA and SynthID as examples of technologies that could be adopted.<strong></strong></p><h2>Could regulations help?</h2><p>We’ve seen examples of robust pushback against deepfakes. Following the <a rel=\"noopener noreferrer\" target=\"_blank\">AI-generated Biden robocalls, the New Hampshire Department of Justice launched an </a><a href=\"https://www.doj.nh.gov/news/2024/20240206-voter-robocall-update.html\" rel=\"noopener noreferrer\" target=\"_blank\">investigation</a> in coordination with state and federal partners, including a bipartisan task force made up of all 50 state attorneys general and the Federal Communications Commission. Meanwhile, in early February the FCC clarified that calls using voice-generation AI will be considered artificial and <a href=\"https://spectrum.ieee.org/ai-robocalls-2667266649\" target=\"_blank\">subject to restrictions</a> under existing laws regulating robocalls.</p><p>Unfortunately, we don’t have laws to force action by either AI developers or social media companies. Congress and the states should mandate that all generative AI products embed maximally indelible watermarks in their image, audio, video, and text content using state-of-the-art technology. They should also address risks from unsecured “open-source” systems that can either have their watermarking functionality disabled or be used to remove watermarks from other content. Furthermore, any company that makes a generative AI tool should be encouraged to release a detector that can identify, with the highest accuracy possible, any content it produces. This proposal shouldn’t be controversial, as its rough outlines have already been agreed to by the signers of the voluntary commitments and the recent elections accord.</p><p>Standards organizations like C2PA, the National Institute of Standards and Technology, and the International Organization for Standardization should also move faster to build consensus and release standards for maximally indelible watermarks and content labeling in preparation for laws requiring these technologies. Google, as C2PA’s newest steering committee member, should also quickly move to open up its <a href=\"https://www.theverge.com/2023/8/29/23849107/synthid-google-deepmind-ai-image-detector\" rel=\"noopener noreferrer\" target=\"_blank\">seemingly best-in-class</a> SynthID watermarking technology to all members for testing.</p><p>Misinformation and voter deception are nothing new in elections. But AI is accelerating existing threats to our already fragile democracy. Congress must also consider what steps it can take to protect our elections more generally from those who are seeking to undermine them. That should include some basic steps, such as passing the <a href=\"https://www.rules.senate.gov/news/majority-news/on-senate-floor-ranking-member-klobuchar-calls-for-immediate-consideration-of-new-legislation-to-stop-foreign-interference-in-our-elections\" rel=\"noopener noreferrer\" target=\"_blank\">Deceptive Practices and Voter Intimidation Act</a>, which would make it illegal to knowingly lie to voters about the time, place, and manner of elections with the intent of preventing them from voting in the period before a federal election.</p><p>Congress has been woefully slow to take up <a href=\"https://www.brennancenter.org/our-work/research-reports/pass-freedom-vote-act\" rel=\"noopener noreferrer\" target=\"_blank\">comprehensive democracy reform</a> in the face of recent shocks. The potential amplification of these shocks through abuse of AI ought to be enough to finally get lawmakers to act.</p>",[{'name': 'Lawrence Norden'}],"Mon, 04 Mar 2024 17:35:31 +0000"
2250,"Faster, More Secure Photonic Chip Boosts AI Training",https://spectrum.ieee.org/photonic-ai-chip,"<img src=\"https://spectrum.ieee.org/media-library/a-series-of-colored-micrographs-showing-a-blow-out-and-then-a-second-blow-out-of-a-chip-on-a-circuit-board.jpg?id=51579120&amp;width=1200&amp;height=800&amp;coordinates=601%2C0%2C602%2C0\" /><br /><br /><p>A microchip that uses light instead of electricity can potentially be faster and more energy-efficient at the complex computations essential to training AI  than conventional electronics. In addition, researchers say the new chips may be significantly more secure against hacking.</p><p>AI typically relies on <a href=\"https://spectrum.ieee.org/dendrocentric-learning\" target=\"_blank\">neural networks</a> in applications such as analyzing medical scans and supporting autonomous vehicles. In these systems, components known as neurons are fed data and cooperate to solve a problem, such as recognizing faces.</p><p>As neural networks grow in size and power, they are becoming more energy hungry when run on conventional electronics. This has led some researchers to investigate <a href=\"https://spectrum.ieee.org/optical-neural-networks\" target=\"_blank\">optical computing</a> as a promising, next-generation foundation for AI. This photonic approach uses light instead of electricity to perform computations more quickly and with less power than an electronic counterpart. “It might be around 1,000 to 10,000 times faster,” says <a href=\"https://live-sas-physics.pantheon.sas.upenn.edu/people/standing-faculty/nader-engheta\" target=\"_blank\">Nader Engheta</a>, a professor of electrical and systems engineering at the University of Pennsylvania.</p><p>In the new study, researchers created a silicon wafer that varied in height from 150 to 220 nanometers. The height variations were organized such that the chip could make scatter light in specific patterns. When input in the form of light flows into the chip, the output light encodes data from complex tasks.</p><p>The scientists designed the microchip to perform <u><a href=\"https://spectrum.ieee.org/matrix-multiplication-deepmind\" target=\"_self\">vector matrix multiplication operations</a></u>. These calculations, which involve multiplying grids of numbers known as matrices, are key to many computational tasks, including operating neural networks.</p><p class=\"pull-quote\">“It might be around 1,000 to 10,000 times faster.” <strong>—Nader Engheta, University of Pennsylvania</strong></p><p>Whereas conventional electronics perform these calculations line by line, the new optical device performs the entirety of these computations at once. This means “one does not need to store the intermediate-stage information in a memory,” Engheta says. “Therefore, the results and processes are less vulnerable to hacking.”</p><p>Previously, when it came to designing photonics to perform these kinds of calculations, one challenge that scientists faced arose from how they had to use complex 3D simulations to model the three-dimensional behavior of the light waves inside these chips. This in turn made it computationally difficult to scale the devices to larger matrix sizes.</p><p>In the new study, by limiting how much the silicon’s thickness could vary across the chip, the researchers developed a way to use much simpler 2D simulations to model the devices. This in turn let them operate with larger matrix sizes.</p><p>In experiments, the scientists tested microchips capable of calculations with matrices as large as three by three on a side. They also designed a device capable of supporting matrices up to ten by ten on a side.</p><p>“To me, one of the exciting features of our work is conducting mathematical operations with near the speed of light using light,” Engheta says.</p><p>In the future, the scientists want to explore “how to add reconfigurability and programmability to such structures,” Engheta says. “Another possible direction to consider will be to have structures with more inputs and more outputs.”</p><p>The scientists detailed <u><a href=\"https://www.nature.com/articles/s41566-024-01394-2\" rel=\"noopener noreferrer\" target=\"_blank\">their findings</a></u> online 16 February in the journal <em>Nature Photonics</em>.</p>",[{'name': 'Charles Q. Choi'}],"Mon, 04 Mar 2024 16:09:20 +0000"
2251,A Few Social Media Influencers Are Shaping AI,https://spectrum.ieee.org/social-media-ai,"<img src=\"https://spectrum.ieee.org/media-library/illustration-of-a-group-of-people-standing-on-gray-lines-that-branch-out-in-different-directions-on-a-navy-background.jpg?id=51614082&amp;width=1200&amp;height=800&amp;coordinates=0%2C15%2C0%2C0\" /><br /><br /><p>The term “social media influencer” may call to mind Instagram accounts shilling hair growth gummies and cute outfits—but in reality, influencers influence all types of things. Including artificial intelligence research trends.</p><p>Mainstream interest in AI and machine learning is at an all-time high, and the industry is responding—churning out thousands of AI and ML works for conferences and journals. The AI/ML community is also particularly active in posting non-peer-reviewed preprints via online platforms like <a href=\"https://arxiv.org/\" target=\"_blank\">ArXiv</a>. Given this glut of work, what rises to the top and receives attention?</p><p>The answer, at least in part, is: the research that a pair of highly influential users of <a href=\"https://twitter.com/home\" target=\"_blank\">X</a> (formerly Twitter) choose to highlight, according to <a href=\"https://arxiv.org/html/2401.13782v1\" rel=\"noopener noreferrer\" target=\"_blank\">a new preprint</a> from researchers at <a href=\"https://www.ucsb.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California at Santa Barbara</a>.</p><p>The UCSB paper analyzed more than 8,000 AI and ML papers, considering both social media mentions and the number of citations. Reviewing tweets from December 2018 to October 2023, the researchers concluded AI/ML papers shared by two specific influencers had median citation counts two to three times higher than those of the control group.</p><p>This is crucial because academic citations aren’t just about recognition in one’s field; they also affect decisions like research funding and tenure at academic institutions. And it’s a change from the status quo. As recently as 2018, a <a href=\"https://www.semanticscholar.org/paper/Predictive-power-of-conference-related-factors-on-Lee/0aa6c99d04808c4bc53336694205960eb1f53b99\" target=\"_blank\">study of conference papers</a> showed that a paper’s review score—meaning acceptance to top conferences—was a primary indicator of future citation count.</p><p>Now, “the correlation between influencer tweets and citation count—and not review scores—points to a shift in how the community finds and reads papers,” this new work concludes.</p><h2>Two influencers with an outsized effect on AI</h2><p>The researchers selected two influencers as case studies. Both share AI/ML papers consistently and have a significant following on X (formerly Twitter): <a href=\"https://twitter.com/_akhaliq\" rel=\"noopener noreferrer\" target=\"_blank\">@_akhaliq</a> and <a href=\"https://twitter.com/arankomatsuzaki\" rel=\"noopener noreferrer\" target=\"_blank\">@arankomatsuzaki</a>. “These influencers have emerged as pivotal figures in navigating the flood of information, akin to journalists in civic society, highlighting and contextualizing significant works for the community,” the authors write.</p><p>That curation is a helpful—and, of course, unpaid—service from these influencers given the deluge of research. But “an over-reliance on a select group of curators may inadvertently skew the research landscape, emphasizing certain topics or perspectives over others,” the researchers write. Inadvertent bias in sharing certain labs’ or researchers’ work may entrench a lack of geographic, gender, and/or institutional diversity, the paper adds.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_1\" rel=\"noopener noreferrer\" target=\"_blank\"></a></p><p>Awareness is the first step to busting this social media echo chamber, says lead author <a href=\"https://haewonjeong.com/people/iain-weissburg\" rel=\"noopener noreferrer\" target=\"_blank\">Iain Xie Weissburg,</a> a first-year master’s student in UCSB’s Electrical and Computer Engineering program.</p><p>“We wanted to help the community recognize this and be vigilant in ensuring that research remains an evenly leveled domain,” he tells <em>Spectrum</em>. “As it stands now we all tend to get our information from a select few, we conclude that these are the hot topics, and then we often select our research based on that hype.”</p><p>The point is not to shame or place undue responsibility on these influencers or others, Weissburg is careful to note. “It’s that the publication and conference systems need to adapt to the vast increase in the volume of AI/ML research, which we can see continuing for the foreseeable future—especially with the influx of generative AI in the public sphere,” Weissburg says.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_2\" target=\"_blank\"></a></p><p>The analysis highlights not only social media’s expanding influence in AI/ML research, but also the importance of an evolving ecosystem to bring diversity of thought to today’s digital academic landscape.</p><h2>The volume of AI papers is overwhelming</h2><p>The researchers’ selection of just two influencers is “far from perfect” methodology, says <a href=\"https://deliprao.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Delip Rao</a>, an independent researcher affiliated with the <a href=\"https://www.upenn.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Pennsylvania</a> and <a href=\"https://www.ucsc.edu/\" target=\"_blank\">University of California at Santa Cruz</a>. He adds “these two folks tend to tweet out papers from big labs and famous names. So, it is not clear who is influencing whom.”</p><p>Still, he agrees with the overall conclusion that a small group of influencers have an outsize effect, “which is problematic for science.” Citation counts are meant to be driven by experts who deeply understand the work they’re citing and the context, he notes, adding that it’s “unrealistic” to expect even expert influencers to bring this type of rigorous review to the social media activity that’s outside of their day jobs.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_3\" rel=\"noopener noreferrer\" target=\"_blank\"></a></p><p>That’s especially true given the proliferation of AI/ML research as of late, as one of the two featured influencers acknowledged recently. “I hate when arXiv casually releases like 500 papers almost every day,” <a href=\"https://arankomatsuzaki.wordpress.com/about-me/\" rel=\"noopener noreferrer\" target=\"_blank\">Aran Komatsuzaki</a> <a href=\"https://twitter.com/arankomatsuzaki/status/1757242871680287222\" rel=\"noopener noreferrer\" target=\"_blank\">wrote on X</a>.</p><p>The “sheer volume of papers published daily is overwhelming, making it impractical for individuals to sift through arXiv feeds,” Komatsuzaki, the chief technology officer of <a href=\"https://www.teraflop.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Teraflop.ai</a>, tells <em>Spectrum</em> in an interview. “The community relies on curators like @_akhaliq and myself to highlight a selection of noteworthy papers each day…. [I’m] cautious about not promoting research with unconvincing, weak, or dubious results.”</p><p>The other influencer cited, Ahsen Khaliq or “AK,” is a machine learning engineer at <a href=\"https://huggingface.co/\" target=\"_blank\">Hugging Face</a>. “I think there is some shift in the community toward finding/discovering new research and citing it through Twitter or other social media rather than conferences/reviewer scores—although each has their own place in the community,” Khaliq says in an interview.</p><h2>Can the AI social media bubble be popped?</h2><p>The paper’s core conclusion, Weissburg says, is that researchers, conference organizers, and academic institutions must be aware of the shifting norms as preprint platforms and social media accounts change the landscape of sharing research—especially in the AI/ML space. The authors also argue that conferences and peer-review processes may have to evolve to ensure that quality research is effectively distributed. </p><p>Weissburg says that engineers working in the field should at times resist the urge to hop on the hype train, lest they ignore other important areas of research. Influencers, too, can take note that “paper-sharing isn’t a zero-sum game. You have an effect, and you don’t necessarily always have to share the biggest companies and most famous researchers. It’s important we have a diverse community in terms of different ideas and different backgrounds.” </p><p>In future work, Weissburg hopes to explore possible outsize social-media effects in other areas of science. There’s also an opportunity to explore the underlying mechanisms of social media—like how algorithms surface content to users—as they relate to academic recognition.</p><p>Rao would like to see new ideas for new ideas for surfacing and disseminating quality papers. “When there is excessive production, it is natural to rely on curators, and the community’s reliance on such folks is a cry for help,” he says. “We need better ways to combat this information deluge, and the answer is, hopefully, not influencers.”</p>",[{'name': 'Julianne Pepitone'}],"Sat, 02 Mar 2024 14:00:02 +0000"
2252,"AI Is Being Built on Dated, Flawed Motion-Capture Data",https://spectrum.ieee.org/motion-capture-standards,"<img src=\"https://spectrum.ieee.org/media-library/colorful-illustration-of-different-people-walking.jpg?id=51546172&amp;width=1200&amp;height=800&amp;coordinates=261%2C0%2C0%2C0\" /><br /><br /><p>Diversity of thought in industrial design is crucial: If no one thinks to design a technology for multiple body types, people can get hurt. The invention of seat belts is an oft-cited example of this phenomenon, as they were designed based on crash dummies that had traditionally male proportions, reflecting the bodies of the team members working on them.</p><p>The same phenomenon is now at work in the field of motion-capture technology. Throughout history, scientists have endeavored to understand how the human body moves. But how do we define the human body? Decades ago many studies assessed “healthy male” subjects; others used surprising models like dismembered cadavers. Even now, some <a href=\"https://www.frontiersin.org/articles/10.3389/frobt.2020.00071/full\" target=\"_blank\">modern studies</a> used in the design of fall-detection technology rely on methods like hiring stunt actors who pretend to fall.</p><p>Over time, a variety of flawed assumptions have become codified into standards for motion-capture data that’s being used to design some AI-based technologies. These flaws mean that AI-based applications may not be as safe for people who don’t fit a preconceived “typical” body type, according to new work recently <a href=\"https://arxiv.org/html/2401.10877v1\" target=\"_blank\">published as a preprint</a> and set to be presented at the <a href=\"https://chi2024.acm.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Conference on Human Factors in Computing Systems</a> in May.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_1\" rel=\"noopener noreferrer\" target=\"_blank\"></a></p><p>“We dug into these so-called gold standards being used for all kinds of studies and designs, and many of them had errors or were focused on a very particular type of body,” says <a href=\"https://www.si.umich.edu/people/abigail-jacobs\" rel=\"noopener noreferrer\" target=\"_blank\">Abigail Jacobs,</a> coauthor of the study and an assistant professor at the University of Michigan’s <a href=\"https://www.si.umich.edu/\" target=\"_blank\">School of Information</a> and the <a href=\"https://lsa.umich.edu/cscs\" rel=\"noopener noreferrer\" target=\"_blank\">Center for the Study of Complex Systems</a>. “We want engineers to be aware of how these social aspects become coded into the technical—hidden in mathematical models that seem objective or infrastructural.”</p><p>It’s an important moment for AI-based systems, Jacobs says, as we may still have time to catch and avoid potentially dangerous assumptions from being codified into applications informed by AI. </p><p>Motion-capture systems create representations of bodies by collecting data from sensors placed on the subjects, logging how these bodies move through space. These schematics become part of the tools that researchers use, such as open-source libraries of movement data and measurement systems that are meant to provide baseline standards for how human bodies move. Developers are increasingly using these baselines to build all manner of AI-based applications: fall-detection algorithms for smartwatches and other wearables, self-driving vehicles that need to detect pedestrians, computer-generated imagery for movies and video games, manufacturing equipment that interacts safely with human workers, and more.</p><p>“Many researchers don’t have access to advanced motion-capture labs to collect data, so we’re increasingly relying on benchmarks and standards to build new tech,” Jacobs says. “But when these benchmarks don’t include representations of all bodies, especially those people who are likely to be involved in real-world use cases—like elderly people who may fall—these standards can be quite flawed.”</p><p>She hopes we can learn from past mistakes, such as cameras that didn’t accurately capture all skin tones and seat belts and airbags that didn’t protect people of all shapes and sizes in car crashes.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_3\" target=\"_blank\"></a></p><h2>The Cadaver in the Machine</h2><p>Jacobs and her collaborators from Cornell University, Intel, and the University of Virginia performed a systematic literature review of 278 motion-capture-related studies. In most cases, they concluded, motion-capture systems captured the motion of “those who are male, white, ‘able-bodied,’ and of unremarkable weight.”</p><p>And sometimes these white male bodies were dead. In reviewing works dating back to the 1930s and running through three historical eras of motion-capture science, the researchers studied projects that were influential in how scientists of the time understood the movement of body segments. A <a href=\"https://deepblue.lib.umich.edu/bitstream/handle/2027.42/73105/j.1749-6632.1955.tb32112.x.pdf?sequence=1\" target=\"_blank\">seminal 1955 study</a> funded by the Air Force, for example, used overwhelmingly white, male, and slender or athletic bodies to create the optimal cockpit based on pilots’ range of motion. That study also gathered data from eight dismembered cadavers. </p><p>A full 20 years later, <a href=\"https://www.researchgate.net/publication/235057658_Investigation_of_Inertial_Properties_of_the_Human_Body\" target=\"_blank\">a study</a> prepared for the National Highway Traffic Safety Administration used similar methods: Six dismembered male cadavers were used to inform the design of impact-protection systems in vehicles.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_5\" target=\"_blank\"></a></p><p class=\"pull-quote\">In most of the 278 studies reviewed, motion-capture systems captured the motion of “those who are male, white, ‘able-bodied,’ and of unremarkable weight.”</p><p>Although those studies are many decades old, these assumptions became baked in over time. Jacobs and her colleagues found many examples of these outdated inferences being passed down to later studies and ultimately still influencing modern motion-capture studies.</p><p>“If you look at technical documents of a modern system in production, they’ll explain the ‘traditional baseline standards’ they’re using,” Jacobs says. “By digging through that, you quickly start hopping through time: OK, that’s based on this prior study, which is based on this one, which is based on this one, and eventually we’re back to the Air Force study designing cockpits with frozen cadavers.”</p><p>The components that underpin technological best practices are “man-made—intentional emphasis on man, rather than human—often preserving biases and inaccuracies from the past,” says <a href=\"https://www.linkedin.com/in/kchmielinski/\" rel=\"noopener noreferrer\" target=\"_blank\">Kasia Chmielinski</a>, project lead of the <a href=\"https://datanutrition.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Data Nutrition Project</a> and a fellow at Stanford University’s <a href=\"https://pacscenter.stanford.edu/research/digital-civil-society-lab/\" rel=\"noopener noreferrer\" target=\"_blank\">Digital Civil Society Lab</a>. “Thus historical errors often inform the ‘neutral’ basis of our present-day technological systems. This can lead to software and hardware that does not work equally for all populations, experiences, or purposes.”</p><p>These problems may hinder engineers who want to make things right, Chmielinski says. “Since many of these issues are baked into the foundational elements of the system, teams innovating today may not have quick recourse to address bias or error, even if they want to,” they say. “If you’re building an application that uses third-party sensors, and the sensors themselves have a bias in what they detect or do not detect, what is the appropriate recourse?”</p><p>Jacobs says that engineers must interrogate their sources of “ground truth” and confirm that the gold standards they measure against are, in fact, gold. Technicians must consider these social evaluations to be part of their jobs in order to design technologies for all.<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_7\" target=\"_blank\"></a></p><p>“If you go in saying, ‘I know that human assumptions get built in and are often hidden or obscured,’ that will inform how you choose what’s in your dataset and how you report it in your work,” Jacobs says. “It’s sociotechnical, and technologists need that lens to be able to say: My system does what I say it does, and it doesn’t create undue harm.”</p>",[{'name': 'Julianne Pepitone'}],"Fri, 01 Mar 2024 15:00:04 +0000"
2253,Figure Raises $675M for Its Humanoid Robot Development,https://spectrum.ieee.org/figure-robot-video,"<img src=\"https://spectrum.ieee.org/media-library/a-close-up-shot-of-a-metal-humanoid-torso-in-a-white-room.png?id=51595601&amp;width=1200&amp;height=800&amp;coordinates=0%2C51%2C0%2C51\" /><br /><br /><p>Today, <a href=\"https://www.figure.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Figure</a> is announcing an astonishing US $675 million Series B raise, which values the company at an even more astonishing $2.6 billion. <a href=\"https://spectrum.ieee.org/figure-humanoid-robot-2665982283\" target=\"_blank\">Figure</a> is <a href=\"https://spectrum.ieee.org/humanoid-robots\" target=\"_self\">one of the companies</a> working toward a multipurpose or general-purpose (depending on whom you ask) bipedal or humanoid (depending on whom you ask) robot. The astonishing thing about this valuation is that Figure’s robot is still very much in the development phase—although they’re making rapid progress, which they demonstrate in a new video posted this week.</p><hr /><p>This round of funding comes from Microsoft, OpenAI Startup Fund, Nvidia, Jeff Bezos (through Bezos Expeditions), Parkway Venture Capital, Intel Capital, Align Ventures, and ARK Invest. Figure says that they’re going to use this new capital “for scaling up AI training, robot manufacturing, expanding engineering head count, and advancing commercial deployment efforts.” In addition, Figure and OpenAI will be collaborating on the development of “next-generation AI models for humanoid robots” which will “help accelerate Figure’s commercial timeline by enhancing the capabilities of humanoid robots to process and reason from language.”</p><p>As far as that commercial timeline goes, here’s the most recent update:</p><p class=\"shortcode-media shortcode-media-youtube\">
<span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span>
<small class=\"image-media media-photo-credit\">Figure</small></p><p>And to understand everything that’s going on here, we sent a whole bunch of questions to <a href=\"https://www.linkedin.com/in/jennareher/\" rel=\"noopener noreferrer\" target=\"_blank\">Jenna Reher</a>, senior robotics/AI engineer at Figure.</p><p><strong>What does “fully autonomous” mean, exactly?</strong></p><p><strong>Jenna Reher: </strong>In this case, we simply put the robot on the ground and hit go on the task with no other user input. What you see is using a learned vision model for bin detection that allows us to localize the robot relative to the target bin and get the bin pose. The robot can then navigate itself to within reach of the bin, determine grasp points based on the bin pose, and detect grasp success through the measured forces on the hands. Once the robot turns and sees the conveyor, the rest of the task rolls out in a similar manner. By doing things in this way we can move the bins and conveyor around in the test space or start the robot from a different position and still complete the task successfully.</p><p><strong>How many takes did it take to get this take?</strong></p><p><strong>Reher: </strong>We’ve been running this use case consistently for some time now as part of our work in the lab, so we didn’t really have to change much for the filming here. We did two or three practice runs in the morning and then three filming takes. All of the takes were successful, so the extras were to make sure we got the cleanest one to show.</p><p><strong>What’s back in the Advanced Actuator Lab?</strong></p><p><strong>Reher:</strong> We have an awesome team of folks working on some exciting custom actuator designs for our future robots, as well as supporting and characterizing the actuators that went into our current robots.</p><p><strong>That’s a very specific number for “speed vs. human.” Which human did you measure the robot’s speed against?</strong></p><p><strong>Reher: </strong>We timed <a href=\"https://www.linkedin.com/in/brettadcock/\" target=\"_blank\">Brett</a> [Adcock, founder of Figure] and a few poor engineers doing the task and took the average to get a rough baseline. If you are observant, that seemingly overspecific number is just saying we’re at 1/6 human speed. The main point that we’re trying to make here is that we are aware we are currently below human speed, and it’s an important metric to track as we improve.</p><p><strong>What’s the tether for?</strong></p><p><strong>Reher:</strong> For this task we currently process the camera data off-robot while all of the behavior planning and control happens on board in the computer that’s in the torso. Our robots should be fully tetherless in the near future as we finish packaging all of that on board. We’ve been developing behaviors quickly in the lab here at Figure in parallel to all of the other systems engineering and integration efforts happening, so hopefully folks notice all of these subtle parallel threads converging as we try to release regular updates.</p><p><strong>How the heck do you keep your robotics lab so clean?</strong></p><p><strong>Reher:</strong> Everything we’ve filmed so far is in our large robot test lab, so it’s a lot easier to keep the area clean when people’s desks aren’t intruding in the space. Definitely no guarantees on that level of cleanliness if the camera were pointed in the other direction!</p><p><strong>Is the robot in the background doing okay?</strong></p><p><strong>Reher: </strong>Yes! The other robot was patiently standing there in the background, waiting for the filming to finish up so that our manipulation team could get back to training it to do more manipulation tasks. We hope we can share some more developments with that robot as the main star in the near future.</p><p><strong>What would happen if I put a single bowling ball into that tote?</strong></p><p><strong>Reher: </strong>A bowling ball is particularly menacing to this task primarily due to the moving mass, in addition to the impact if you are throwing it in. The robot would in all likelihood end up dropping the tote, stay standing, and abort the task. With what you see here, we assume that the mass of the tote is known a priori so that our whole-body controller can compensate for the external forces while tracking the manipulation task. Reacting to and estimating larger unknown disturbances such as this is a challenging problem, but we’re definitely working on it.</p><p><strong>Tell me more about that very Zen arm and hand pose that the robot adopts after putting the tote on the conveyor.</strong></p><p><strong>Reher:</strong> It does look kind of Zen! If you rewatch our coffee video, you’ll notice the same pose after the robot gets things brewing. This is a reset pose that our controller will go into between manipulation tasks while the robot is awaiting commands to execute either an engineered behavior or a learned policy.</p><p><strong>Are the fingers less fragile than they look?</strong></p><p><strong>Reher: </strong>They are more robust than they look, but not impervious to damage by any means. The design is pretty modular, which is great, meaning that if we damage one or two fingers, there is a small number of parts to swap to get everything back up and running. The current fingers won’t necessarily survive a direct impact from a bad fall, but can pick up totes and do manipulation tasks all day without issues.</p><p><strong>Is the Figure logo footsteps?</strong></p><strong>Reher:</strong> One of the reasons I really like the Figure logo is that it has a bunch of different interpretations depending on how you look at it. In some cases it’s just an F that looks like a footstep plan rollout, while some of the logo animations we have look like active stepping. One other possible interpretation could be an occupancy grid.",[{'name': 'Evan Ackerman'}],"Thu, 29 Feb 2024 13:00:03 +0000"
2254,What If the Biggest AI Fear Is AI Fear Itself?,https://spectrum.ieee.org/ai-fears-jobs-technology,"<img src=\"https://spectrum.ieee.org/media-library/illustration-of-a-man-holding-a-large-jigsaw-puzzle-piece-in-front-of-a-robot-on-a-computer-screen-holding-a-jigsaw-puzzle-piece.jpg?id=51567004&amp;width=1200&amp;height=800&amp;coordinates=0%2C125%2C0%2C126\" /><br /><br /><p>It’s been just about a year now—a nonprofit called the <a href=\"https://spectrum.ieee.org/ai-pause-letter-stokes-fear\" target=\"_self\">Future of Life Institute</a> posted an <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\" rel=\"noopener noreferrer\" target=\"_blank\">open letter</a> reflecting people’s darkest fears about <a href=\"https://spectrum.ieee.org/topic/artificial-intelligence/\" target=\"_self\">artificial intelligence</a>. </p><p>“Contemporary AI systems are now becoming human-competitive at general tasks,” it said. It called for a pause in training of the most advanced AI, so that technology companies could develop safety protocols. It expressed worry about disinformation and out-of-control machines. And it struck a nerve with its concerns that some AI could make human work irrelevant. </p><p class=\"pull-quote\">“AI is a tool.... And tools generally aren’t substitutes for expertise but rather levers for its application.” <strong>—David Autor, MIT </strong></p><p>“Should we automate away all the jobs, including the fulfilling ones?” the letter asked. “Should we develop nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us? Should we risk loss of control of our civilization?” At last count, the institute said more than 33,000 people involved in computer science (including about <a href=\"https://spectrum.ieee.org/ai-pause-letter-stokes-fear\" target=\"_blank\">100 IEEE members</a>) had signed it.<br /></p><p>But there are many others who say we are far—perhaps very far—from a world in which smart machines make human talent redundant. On the contrary, they can extend human reach. That argument is laid out most recently by <a href=\"https://economics.mit.edu/people/faculty/david-h-autor\" target=\"_blank\">David Autor</a>, an economist at the Massachusetts Institute of Technology who has written and spoken extensively on the future of work. </p><p>“It’s important to understand that many of our tools are not our competitors,” he says. “They are more like enablers of the use of human expertise.”</p><h3>AI as Calculator—and Chainsaw</h3><p>In an essay, posted on the website of the <a href=\"https://www.nber.org/papers/w32140\" target=\"_blank\">National Bureau of Economic Research</a> and published in the magazine <a href=\"https://www.noemamag.com/how-ai-could-help-rebuild-the-middle-class/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Noema</em></a>, Autor says that if we do it right, AI can create many more opportunities than it disrupts. Certainly, there are jobs that will go away, and many things that once demanded a human touch will be done more cheaply and quickly by machines. But, he argues, many new lines of work will be created, or made more effective, by AI’s help. Autor says they may outnumber the jobs made obsolete, potentially by a substantial degree. He writes that “AI—used well—can assist with restoring the middle-skill, middle-class heart of the U.S. labor market that has been hollowed out by automation and globalization.”</p><p class=\"pull-quote\">“People are worried about the wrong things. They’re worried primarily about whether we’ll run out of work, when they ought to be worrying about how we will use human expertise, whether we use it well or badly.” <strong>—David Autor, MIT</strong></p><p>“AI is a tool, like a calculator or a chainsaw,” he says. “And tools generally aren’t substitutes for expertise but rather levers for its application.”</p><p>He cites, among other evidence, an <a href=\"https://arxiv.org/abs/2302.06590\" rel=\"noopener noreferrer\" target=\"_blank\">experiment</a> led by economist <a href=\"https://www.sidapeng.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Sida Peng</a> of <a href=\"https://www.microsoft.com/en-us/research/\" target=\"_blank\">Microsoft Research</a>, in which software developers were given access to <a href=\"https://github.com/features/copilot\" rel=\"noopener noreferrer\" target=\"_blank\">Github Copilot</a>, a <a href=\"https://spectrum.ieee.org/what-is-generative-ai\" target=\"_self\">generative AI</a> programming aid. They were asked to implement an HTTP server in JavaScript. If they used Copilot, they did the job 56 percent faster than a control group. </p><p>In another experiment, published in the journal <em><a href=\"https://www.science.org/doi/10.1126/science.adh2586\" rel=\"noopener noreferrer\" target=\"_blank\">Science</a></em>, grant writers, consultants, and managers were invited to use <a href=\"https://chat.openai.com/\" rel=\"noopener noreferrer\" target=\"_blank\">ChatGPT</a> to help them write short documents, such as press releases and analysis plans. The AI didn’t take over the writing—but it sped the writers’ progress by 40 percent, and an outside peer group rated the quality of their work as 18 percent better.</p><p>Autor emphasizes that he is not saying there’s nothing to worry about. There’s plenty—much of it still unknowable. But, he says, “People are worried about the wrong things. They’re worried primarily about whether we’ll run out of work, when they ought to be worrying about how we will use human expertise, whether we use it well or badly.”</p><h3>The “Pause” That Never Happened</h3><p><a href=\"https://homes.cs.washington.edu/~etzioni/site/\" rel=\"noopener noreferrer\" target=\"_blank\">Oren Etzioni</a> is now focused on that question. An entrepreneur and computer scientist, he has started a nonprofit called <a href=\"https://www.truemedia.org/\" rel=\"noopener noreferrer\" target=\"_blank\">TrueMedia.org</a>, dedicated to fighting the rise of political deepfakes. He says that in many ways he agrees with Autor’s theme: “I think it can help to train people and it can help to level their expertise, and obviously those are positive things, but it’s a nuanced topic.”</p><p class=\"pull-quote\">People would never have guessed a few decades ago at the rise of programmers, statisticians, or social-media managers. Or cybersecurity analysts. Or AI ethicists.</p><p>Etzioni says AI technologies can create work opportunities in countless different fields, but they can also make it easier and cheaper for small groups to do what he calls “disinformation terrorism,” planting falsehoods on social channels to take down opponents.</p><p>AI technologies in their current stage have considerable limits, says Autor. What’s not happening, he says, is AI bots going off on their own and doing creative work or exercising judgment the way a person can. An AI system can improve computer code, for instance, but not suggest new applications out of the blue. </p><p>Among other things, Autor points out that generative AI is transforming a lot of cognitive work—in computing, medicine, finance, and the like—but not physical work, where too many things are beyond a machine’s control. </p><p>“The progress in robotics that deals in an uncertain world, as opposed to robotics on assembly lines where everything is bolted down and under control, that progress has been incredibly slow,” he says. “I mean, how many robots do you encounter in the course of a day? Just about none, right? Maybe your Roomba?”</p><p>The “pause” proposed in that open letter didn’t happen. AI in its many forms continues to transform people’s work at dizzying speed, much as software did a generation ago, or, long before it, electricity. Many jobs have disappeared, like those of farriers or typesetters. But, as Autor says, people would never have guessed a few decades ago at the rise of programmers, statisticians, or social-media managers. </p><p>Or, on the other hand, cybersecurity analysts. Or AI ethicists. </p><p>“A favorite line which I repeat over and over to people,” says Etzioni, “is that AI is the tool, but the choice is ours.” </p>",[{'name': 'Ned Potter'}],"Tue, 27 Feb 2024 14:37:51 +0000"
2255,AI Spam Threatens the Internet—AI Can Also Protect It,https://spectrum.ieee.org/ai-detection,"<img src=\"https://spectrum.ieee.org/media-library/boxes-of-greens-blues-and-red-with-large-error-letters-in-middle-with-bright-pink-yellow-purple-and-red.jpg?id=51566558&amp;width=1200&amp;height=800&amp;coordinates=0%2C125%2C0%2C125\" /><br /><br /><p>2023 wasn’t a great year for AI detectors. Leaders like GPTZero surged in popularity but <a href=\"https://futurism.com/gptzero-accuracy\" rel=\"noopener noreferrer\" target=\"_blank\">faced a backlash</a> as false positives led to incorrect accusations. Then OpenAI quietly tossed ice-cold water on the idea <a href=\"https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own\" rel=\"noopener noreferrer\" target=\"_blank\">with an FAQ to answer whether AI detectors work</a>. The verdict? “No, not in our experience.”</p><p>OpenAI’s conclusion was correct—at the time. Yet the demise of AI detectors is greatly exaggerated. Researchers are inventing new detectors that perform better than their predecessors and can operate at scale. And these come alongside “data poisoning” attacks that individuals can use to safeguard their work from being scooped up against their wishes to train AI models.</p><p>“Language model detection can be done with a high enough level of accuracy to be useful, and it can also be done in the ‘zero shot’ sense, meaning you can detect all sorts of different language models at the same time,” says <a href=\"https://www.cs.umd.edu/~tomg/\" target=\"_blank\">Tom Goldstein</a>, a professor of computer science at the University of Maryland. “It’s a real counterpoint to the narrative that language model detection is basically impossible.”</p><h2>Using AI to detect AI</h2><p>Goldstein coauthored a <a href=\"https://arxiv.org/abs/2401.12070\" target=\"_blank\">paper recently uploaded to the arXiv preprint server</a> that describes “Binoculars”: A detector that pairs an AI detective with a helpful sidekick.</p><p>Early AI detectors played at detective by asking a simple question: How surprising is this text? The assumption was that statistically less surprising text is more likely to be AI-generated. It’s an LLM’s mission to predict the “correct” word at each point in a string of text, which should lead to patterns a detector can pick up. Most detectors answered by giving users a numerical probability that the text submitted to it was AI-generated.<strong></strong></p><p>But that approach is flawed. AI-generated text can still be surprising if it’s generated in response to a surprising prompt, which the detector has no way to deduce. And the opposite is true, as well. Humans may write unsurprising text if covering a well-worn topic. </p><p class=\"pull-quote\">Detectors will only prove useful to companies, governments, and educational institutions if they create fewer headaches than they solve, and false positives cause many headaches.</p><p>Binoculars asks its AI detective (in this case <a href=\"https://huggingface.co/tiiuae/falcon-7b\" target=\"_blank\">Falcon-7B</a>, an open-source large language model) the same question as previous detectors, but also asks an AI sidekick to do the same work. The results are compared to calculate how much the sidekick surprised the detective, creating a benchmark for comparison. Text written by a human should prove more surprising to the detective than the AI sidekick. </p><p>There are gaps in what Binoculars can see. <a href=\"https://www.cs.umd.edu/people/vinu\" target=\"_blank\">Vinu Sankar Sadasivan</a>, a graduate student in the University of Maryland’s computer science department and a coauthor on another preprint paper <a href=\"https://arxiv.org/abs/2303.11156\" target=\"_blank\">evaluating a variety of LLM detection techniques</a>, says that Binoculars “significantly improves the performance of zero-shot detection, but it’s still not better than watermarking or retrieval-based methods in terms of accuracy.” Binoculars is also still being peer reviewed; <a href=\"https://www.avischwarzschild.com/\" target=\"_blank\">Avi Schwarzschild</a>, a coauthor on the Binoculars paper, says the goal is to present at a leading AI conference.<strong></strong></p><p>However, Goldstein contends that accuracy isn’t Binoculars’ secret sauce. He believes its real advantage lies in the ability to reveal AI text with fewer false positives. </p><p>“People tend to dwell a lot on accuracy, but this is a mistake,” says Goldstein. “If a detector mistakenly says human-written text was written by a language model…that can lead to false accusations. But if you make a mistake and say AI text is human, it’s not so bad.”</p><p>That might feel counterintuitive. AI can generate text at incredible scale, so even a near-perfect detector could let a lot of AI-generated text slip through. </p><p>But detectors will only prove useful to companies, governments, and educational institutions if they create fewer headaches than they solve, and false positives cause many headaches. Goldstein points out that even a false-positive rate in the single digits will, at the scale of a modern social network, make tens of thousands of false accusations each day, eroding faith in the detector itself. </p><h2>Deepfakes fool people, but not detectors</h2><p>Of course, AI-generated text is just one front in this fight. AI-generated images are of equal concern and, in recent studies, have proven they can fool humans. </p><p>A preprint paper from researchers at Ruhr University Bochum and the Helmholtz Center for Information Security, both in Germany, found people <a href=\"https://arxiv.org/pdf/2312.05976.pdf\" target=\"_blank\">can’t reliably separate AI-generated images of human faces from real photos</a>. Another from researchers at Indiana University and Northeastern University in Boston estimated that between 8,500 and 17,500 daily active accounts on social-media platform X (formerly Twitter) <a href=\"https://arxiv.org/pdf/2401.02627.pdf\" target=\"_blank\">use an AI-generated profile picture</a>.</p><p>It gets worse. These findings focus on generative adversarial networks (GANs), an older class of AI image model that is better understood and known to cause identifiable image artifacts. But the state-of-the-art image generators currently sweeping the Internet, such as AI’s Stable Diffusion, instead use diffusion probabilistic models, which learn to convert random noise into an image likely to mimic what a user wanted. Diffusion models <a href=\"https://openreview.net/pdf?id=AAWuCvzaVt\" target=\"_blank\">significantly outperform</a> their GAN predecessors. </p><p>But even so, it turns out that diffusion isn’t as sly as feared. <a href=\"https://arxiv.org/abs/2210.14571\" rel=\"noopener noreferrer\" target=\"_blank\">A preprint paper to be presented</a> at the International Conference on Computer Vision Theory and Applications (<a href=\"https://visapp.scitevents.org/\" target=\"_blank\">VISAPP 2024</a>), being held in Rome from 27 to 29 February, found that detectors trained on GANs can, with some tweaks, also detect diffusion models. </p><p>“We found that the detectors that we already had, that were trained on GANs, failed to detect diffusion,” says paper coauthor <a href=\"https://jonasricker.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Jonas Ricker</a>, a graduate student at Ruhr University Bochum. “But it’s not undetectable. If we update those detectors, we are still able to detect [images generated by diffusion models].” This suggests that earlier AI image detectors don’t need to be reinvented from scratch to detect the latest models.</p><p>Accuracy is reduced when compared to the detection of GANs, which in some cases can reach 100 percent, but accuracy when detecting diffusion models still often remains higher than 90 percent (the results depend on the diffusion model and detector used). The detectors tweaked to detect diffusion models also remain capable of detecting images generated by a GAN, which makes them useful in many situations.</p><p>But what, exactly, do the updated detectors detect? The answer, as is so often true of modern AI models, is a bit mysterious. “It’s not super clear which artifacts are detectable,” says <a href=\"https://scholar.google.com/citations?user=rswJ0gUAAAAJ&amp;hl=en\" rel=\"noopener noreferrer\" target=\"_blank\">Simon Damm</a>, another graduate student at Ruhr University Bochum and one of the VISAPP 2024 paper’s coauthors. “The performance shows they are for sure detectable…but the interpretability isn’t there.” </p><h2>Data poison degrades spam</h2><p>The latest AI detectors are promising, but detection is an inherently defensive approach. Some researchers are investigating proactive tactics like data poisoning, which disrupts an AI model at training. </p><p>Perhaps the strongest example is <a href=\"https://arxiv.org/pdf/2310.13828.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Nightshade</a>, a technique invented by researchers at the University of Chicago. Nightshade is a prompt-specific data-poisoning attack built to degrade diffusion models. It laces an image with subtle changes to pixels, most of which aren’t visible to the human eye. However, an AI model trained on these images will learn incorrect associations. It might learn that a car looks like a cow or that a hat looks like a toaster.</p><p>“The simplest way to describe it is a small poison pill you can put in your own art,” says <a href=\"https://people.cs.uchicago.edu/~ravenben/\" target=\"_blank\">Ben Y. Zhao</a>, a professor of computer science at the University of Chicago and one of the researchers who developed Nightshade. “If it’s downloaded against your wishes [and used for training an AI model], it can have a negative effect on the model.”</p><p>Critically, Nightshade can degrade a model even when a slim slice of the training data is poisoned. As little as 100 poisoned samples can successfully attack specific concepts (like “dog” or “cat”) in the latest models, including <a href=\"https://clipdrop.co/stable-diffusion?utm_campaign=stable_diffusion_promo&amp;utm_medium=cta_button&amp;utm_source=stability_ai\" target=\"_blank\">Stable Diffusion XL</a>. The effects compound over multiple attacks, bleed into related concepts, and degrade a wide variety of models.</p><p class=\"pull-quote\">“The simplest way to describe it is a small poison pill you can put in your own art.” <strong>—Ben Y. Zhao, University of Chicago</strong></p><p>How that will translate to the real world remains murky. The researchers had just one Nvidia A100 GPU for training—far less than the dozens or hundreds used to train the latest models—so they were limited to training on smaller datasets than those used by OpenAI or Stability AI. Nightshade is still under peer review, though the team behind it intends to present it at a conference in May. “There’s still unknown factors that are hard to control,” says Zhao. “But at a high level, we should see the effect.”</p><p>Zhao hopes that Nightshade, <a href=\"https://nightshade.cs.uchicago.edu/faq.html\" rel=\"noopener noreferrer\" target=\"_blank\">which is available for anyone to download and use for free</a>, will prove a more effective tool than opt-out schemes and no-crawl requests. Compliance with such requests is voluntary, and while many large AI companies and organizations have pledged to respect them, it’s not legally required and difficult to verify. Data poisoning doesn’t require cooperation, instead offering protection that degrades any image model which includes the poisoned data.</p><p>“We’re not trying to break models out of spite,” says Zhao. “We’re trying to provide a tool for content owners to discourage unauthorized scraping for AI training. This is the way to push back, to provide a real disincentive to model trainers.” </p>",[{'name': 'Matthew S. Smith'}],"Mon, 26 Feb 2024 17:33:35 +0000"
2256,What Is Generative AI?,https://spectrum.ieee.org/what-is-generative-ai,"<img src=\"https://spectrum.ieee.org/media-library/an-animation-showing-a-conceptual-representation-of-a-generative-ai-network.gif?id=51461227&amp;width=1200&amp;height=800&amp;coordinates=0%2C19%2C0%2C19\" /><br /><br /><p>Generative AI is today’s buzziest form of artificial intelligence, and it’s what powers chatbots like <a href=\"https://spectrum.ieee.org/chatbot-chatgpt-interview\" target=\"_self\">ChatGPT</a>, <a href=\"https://www.youtube.com/watch?v=ZLTpvQpY95w\" target=\"_blank\">Ernie</a>, <a href=\"https://spectrum.ieee.org/llama-2-llm\" target=\"_self\">LLaMA</a>, <a href=\"https://www.anthropic.com/news/introducing-claude\" target=\"_blank\">Claude</a>, and <a href=\"https://cohere.com/models/command\" target=\"_blank\">Command</a>—as well as <a href=\"https://spectrum.ieee.org/ai-design\" target=\"_self\">image generators</a> like <a href=\"https://spectrum.ieee.org/openai-dall-e-2\" target=\"_self\">DALL-E 2</a>, <a href=\"https://stability.ai/stable-image\" target=\"_blank\">Stable Diffusion</a>, <a href=\"https://www.adobe.com/products/firefly.html\" target=\"_blank\">Adobe Firefly</a>, and <a href=\"https://spectrum.ieee.org/tag/midjourney\" target=\"_self\">Midjourney</a>. Generative AI is the branch of AI that enables machines to learn patterns from vast datasets and then to autonomously produce new content based on those patterns. Although generative AI is fairly new, there are already many examples of models that can produce text, images, videos, and audio.</p><p>
	Many “<a href=\"https://crfm.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">foundation models</a>” have been trained on enough data to be competent in a wide variety of tasks. For example, a large language model can generate essays, <a href=\"https://spectrum.ieee.org/ai-programming\" target=\"_blank\">computer code</a>, recipes, <a href=\"https://spectrum.ieee.org/ai-protein-design\" target=\"_blank\">protein structures</a>, jokes, <a href=\"https://spectrum.ieee.org/chatgpt-medical-exam\" target=\"_blank\">medical diagnostic advice</a>, and <a href=\"https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/\" target=\"_blank\">much more</a>. It can also theoretically generate instructions for building a bomb or creating a bioweapon, though safeguards are supposed to prevent such types of misuse.
</p><h2>What’s the difference between AI, machine learning, and generative AI?</h2><p>
	Artificial intelligence (AI) refers to a wide variety of computational approaches to mimicking human intelligence. 
	<a href=\"https://spectrum.ieee.org/can-machine-learning-teach-us-anything\" target=\"_self\">Machine learning</a> (ML) is a subset of AI; it focuses on algorithms that enable systems to learn from data and improve their performance. Before generative AI came along, most ML models learned from datasets to perform tasks such as classification or prediction. Generative AI is a specialized type of ML involving models that perform the task of generating new content, venturing into the realm of creativity.
</p><h2>What architectures do generative AI models use?</h2><p>
	Generative models are built using a variety of neural network architectures—essentially the design and structure that defines how the model is organized and how information flows through it. Some of the most well-known architectures are 
	<a href=\"https://en.wikipedia.org/wiki/Variational_autoencoder\" rel=\"noopener noreferrer\" target=\"_blank\">variational autoencoders</a> (VAEs), <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"noopener noreferrer\" target=\"_blank\">generative adversarial networks</a> (GANs), and <a href=\"https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)\" rel=\"noopener noreferrer\" target=\"_blank\">transformers</a>. It’s the transformer architecture, first shown in this seminal <a href=\"https://arxiv.org/abs/1706.03762\" rel=\"noopener noreferrer\" target=\"_blank\">2017 paper from Google</a>, that powers today’s large language models. However, the transformer architecture is less suited for other types of generative AI, such as image and audio generation.</p><p>
	Autoencoders learn efficient representations of data through an 
	<a href=\"https://www.cloudskillsboost.google/course_templates/543\" rel=\"noopener noreferrer\" target=\"_blank\">encoder-decoder framework</a>. The encoder compresses input data into a lower-dimensional space, known as the <a href=\"https://en.wikipedia.org/wiki/Latent_space\" rel=\"noopener noreferrer\" target=\"_blank\">latent (or embedding) space</a>, that preserves the most essential aspects of the data. A decoder can then use this compressed representation to reconstruct the original data. Once an autoencoder has been trained in this way, it can use novel inputs to generate what it considers the appropriate outputs. These models are often deployed in <a href=\"https://medium.com/@judyyes10/generate-images-using-variational-autoencoder-vae-4d429d9bdb5\" rel=\"noopener noreferrer\" target=\"_blank\">image-generation tools</a> and have also found use in <a href=\"https://keras.io/examples/generative/molecule_generation/\" rel=\"noopener noreferrer\" target=\"_blank\">drug discovery</a>, where they can be used to generate new molecules with desired properties.
</p><p>
	With generative adversarial networks (GANs), the training involves a 
	<a href=\"https://developers.google.com/machine-learning/gan/generator\" rel=\"noopener noreferrer\" target=\"_blank\">generator and a discriminator</a> that can be considered adversaries. The generator strives to create realistic data, while the discriminator aims to distinguish between those generated outputs and real “ground truth” outputs. Every time the discriminator catches a generated output, the generator uses that feedback to try to improve the quality of its outputs. But the discriminator also receives feedback on its performance. This adversarial interplay results in the refinement of both components, leading to the generation of increasingly authentic-seeming content. GANs are best known for <a href=\"https://www.sciencedirect.com/science/article/pii/S1877050923001916\" rel=\"noopener noreferrer\" target=\"_blank\">creating deepfakes</a> but can also be used for more benign forms of image generation and many other applications.
</p><p>
	The transformer is arguably the reigning champion of generative AI architectures for its ubiquity in today’s powerful large language models (LLMs). Its strength lies in its attention mechanism, which enables the model to focus on different parts of an input sequence while making predictions. In the case of language models, the input consists of strings of words that make up sentences, and the transformer predicts what words will come next (we’ll get into the details below). In addition, transformers can process all the elements of a sequence in parallel rather than marching through it from beginning to end, as earlier types of models did; this 
	<a href=\"https://huggingface.co/docs/transformers/v4.15.0/parallelism\" rel=\"noopener noreferrer\" target=\"_blank\">parallelization</a> makes training faster and more efficient. When developers added vast datasets of text for transformer models to learn from, today’s remarkable chatbots emerged.
</p><h2>How do large language models work?</h2><p>
	A transformer-based LLM is trained by giving it a vast dataset of text to learn from. The attention mechanism comes into play as it processes sentences and looks for patterns. By looking at all the words in a sentence at once, it gradually begins to understand which words are most commonly found together and which words are most important to the meaning of the sentence. It learns these things by trying to predict the next word in a sentence and comparing its guess to the ground truth. Its errors act as feedback signals that cause the model to adjust the weights it assigns to various words before it tries again.
</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\">
<img alt=\"A chart shows the size of five LLMs in parameters and their performance on a benchmark.\" class=\"rm-shortcode rm-resized-image\" id=\"91ba0\" src=\"https://spectrum.ieee.org/media-library/a-chart-shows-the-size-of-five-llms-in-parameters-and-their-performance-on-a-benchmark.png?id=51455578&amp;width=980\" />
<small class=\"image-media media-caption\">These five LLMs vary greatly in size (given in parameters), and the larger models have better performance on a standard LLM benchmark test. </small><small class=\"image-media media-photo-credit\">IEEE Spectrum</small>
</p><p>
	To explain the training process in slightly more technical terms, the text in the training data is broken down into elements called 
	<a href=\"https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/\" rel=\"noopener noreferrer\" target=\"_blank\">tokens</a>, which are words or pieces of words—but for simplicity’s sake, let’s say all tokens are words. As the model goes through the sentences in its training data and learns the relationships between tokens, it creates a list of numbers, called a vector, for each one. All the numbers in the vector represent various aspects of the word: its semantic meanings, its relationship to other words, its frequency of use, and so on. Similar words, like <em>elegant </em>and <em>fancy</em>, will have similar vectors and will also be near each other in the vector space. These vectors are called word embeddings. The parameters of an LLM include the weights associated with all the word embeddings and the attention mechanism. <a href=\"https://spectrum.ieee.org/tag/gpt-4\" target=\"_blank\">GPT-4</a>, the OpenAI model that’s considered the current champion, is rumored to have more than 1 trillion parameters. </p><p>
	Given enough data and training time, the LLM begins to understand the subtleties of language. While much of the training involves looking at text sentence by sentence, the attention mechanism also captures relationships between words throughout a longer text sequence of many paragraphs. Once an LLM is trained and is ready for use, the attention mechanism is still in play. When the model is generating text in response to a prompt, it’s using its predictive powers to decide what the next word should be. When generating longer pieces of text, it predicts the next word in the context of all the words it has written so far; this function increases the coherence and continuity of its writing.
</p><h2>Why do large language models hallucinate?</h2><p>
	You may have heard that LLMs sometimes “<a href=\"https://spectrum.ieee.org/ai-hallucination\" target=\"_self\">hallucinate</a>.” That’s a polite way to say they make stuff up very convincingly. A model sometimes generates text that fits the context and is grammatically correct, yet the material is erroneous or nonsensical. This bad habit stems from LLMs training on vast troves of data drawn from the Internet, plenty of which is not factually accurate. Since the model is simply trying to predict the next word in a sequence based on what it has seen, it may generate plausible-sounding text that has no grounding in reality.
</p><h2>Why is generative AI controversial?</h2><p>
	One source of controversy for generative AI is the provenance of its training data. Most AI companies that train large models to generate text, images, video, and audio have 
	<a href=\"https://spectrum.ieee.org/ai-ethics\" target=\"_self\">not been transparent</a> about the content of their training datasets. Various leaks and experiments have revealed that those datasets <a href=\"https://spectrum.ieee.org/midjourney-copyright\" target=\"_self\">include copyrighted material</a> such as books, newspaper articles, and movies. A <a href=\"https://www.reuters.com/legal/litigation/artists-take-new-shot-stability-midjourney-updated-copyright-lawsuit-2023-11-30\" rel=\"noopener noreferrer\" target=\"_blank\">number</a> of <a href=\"https://www.reuters.com/legal/john-grisham-other-top-us-authors-sue-openai-over-copyrights-2023-09-20/\" rel=\"noopener noreferrer\" target=\"_blank\">lawsuits</a> are underway to determine whether <a href=\"https://spectrum.ieee.org/generative-ai-ip-problem\" target=\"_self\">use of copyrighted material</a> for training AI systems constitutes fair use, or whether the AI companies need to pay the copyright holders for use of their material.
</p><p>
	On a related note, many people are concerned that the widespread use of generative AI <a href=\"https://spectrum.ieee.org/ai-taking-over-jobs\" target=\"_blank\">will take jobs away</a> from creative humans who make art, music, written works, and so forth. People are also concerned that it could take jobs from humans who do a wide range of white-collar jobs, including translators, paralegals, customer-service representatives, and journalists. There have already been a few 
	<a href=\"https://www.washingtonpost.com/technology/2024/01/10/duolingo-ai-layoffs/\" rel=\"noopener noreferrer\" target=\"_blank\">troubling layoffs</a>, but it’s hard to say yet whether generative AI will be reliable enough for large-scale enterprise applications. (See above about hallucinations.)</p><p>
	Finally, there’s the danger that generative AI will be used to make bad stuff. And there are of course many categories of bad stuff it could theoretically be used for. Generative AI can be used for personalized scams and phishing attacks: For example, using “voice cloning,” scammers can 
	<a href=\"https://www.cbsnews.com/news/scammers-ai-mimic-voices-loved-ones-in-distress/\" rel=\"noopener noreferrer\" target=\"_blank\">copy the voice of a specific person</a> and call the person’s family with a plea for help (and money). All formats of generative AI—text, audio, image, and video—can be used to generate misinformation by creating plausible-seeming representations of things that never happened, which is a particularly worrying possibility when it comes to <a href=\"https://spectrum.ieee.org/deepfakes-election\" target=\"_self\">elections</a>. (Meanwhile, as <em>IEEE </em><em>Spectrum</em> reported this week, the U.S. Federal Communications Commission has responded by <a href=\"https://spectrum.ieee.org/ai-robocalls-2667266649\" target=\"_blank\">outlawing AI-generated robocalls</a>.) Image- and video-generating tools can be used to produce nonconsensual pornography, although the tools made by mainstream companies disallow such use. And chatbots can theoretically walk a would-be terrorist through the steps of making a bomb, nerve gas, and a host of other horrors. Although the big LLMs have safeguards to prevent such misuse, some hackers delight in circumventing those safeguards. What’s more, “uncensored” versions of <a href=\"https://spectrum.ieee.org/open-source-ai-2666932122\" target=\"_self\">open-source LLMs</a> are out there.
</p><p>
	Despite such potential problems, many people think that generative AI can also make people more productive and could be used as a tool to enable entirely new forms of creativity. We’ll likely see both disasters and creative flowerings and plenty else that we don’t expect. But knowing the basics of how these models work is increasingly crucial for tech-savvy people today. Because no matter how sophisticated these systems grow, it’s the humans’ job to keep them running, make the next ones better, and with any luck, help people out too.
</p>",[{'name': 'Eliza Strickland'}],"Wed, 14 Feb 2024 16:34:55 +0000"
2257,The FCC’s Ban on AI in Robocalls Won’t Be Enough,https://spectrum.ieee.org/ai-robocalls-2667266649,"<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-a-red-robot-hand-holding-a-blue-phone-with-a-line-emanating-from-it-in-the-shape-of-a-face.jpg?id=51451321&amp;width=1200&amp;height=800&amp;coordinates=0%2C125%2C0%2C125\" /><br /><br /><p>
	In the days before the U.S. Democratic Party’s New Hampshire primary election on 23 January, potential voters began receiving a call with <a href=\"https://apnews.com/article/new-hampshire-primary-biden-ai-deepfake-robocall-f3469ceb6dd613079092287994663db5\" rel=\"noopener noreferrer\" target=\"_blank\">AI-generated audio of a fake President Biden</a> urging them not to vote until the general election in November. In Slovakia a <a href=\"https://www.wired.co.uk/article/slovakia-election-deepfakes\" target=\"_blank\">Facebook post</a> contained fake, AI-generated audio of a presidential candidate planning to steal the election—which <a href=\"https://www.cnn.com/2024/02/01/politics/election-deepfake-threats-invs/index.html\" target=\"_blank\">may have tipped</a> the election in another candidate’s favor. Recent elections in <a href=\"https://www.cnn.com/2024/02/12/asia/suharto-deepfake-ai-scam-indonesia-election-hnk-intl/index.html\" target=\"_blank\">Indonesia</a> and <a href=\"https://www.npr.org/2024/01/11/1216340756/taiwan-election-disinformation-social-media-ptt\" target=\"_blank\">Taiwan</a> have been marred by AI-generated misinformation, too.</p><p>
	In response to the faux-Biden robocall in New Hampshire, the <a href=\"https://www.fcc.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">U.S. Federal Communications Commission</a> moved to make <a href=\"https://www.fcc.gov/document/fcc-makes-ai-generated-voices-robocalls-illegal\" rel=\"noopener noreferrer\" target=\"_blank\">AI-generated voices in robocalls illegal</a> on 8 February. But experts <em>IEEE Spectrum</em> spoke to aren’t convinced that the move will be enough, even as generative AI brings new twists to old robocall scams and offers opportunities to turbocharge efforts to defraud individuals.
</p><p>
	The total lost to scams and spam in the United States in 2022 is thought to be US <a href=\"https://www.truecaller.com/blog/insights/truecaller-insights-2022-us-spam-scam-report\" rel=\"noopener noreferrer\" target=\"_blank\">$39.5 billion</a>, according to TrueCaller, which makes a caller ID and spam-blocking app. That same year, the average amount of money lost by people scammed in the United States <a href=\"https://www.hiya.com/state-of-the-call\" rel=\"noopener noreferrer\" target=\"_blank\">was $431.26</a>, according to a survey by Hiya, a company that provides call-protection and identity services. Hiya says that amount stands to go up as the usage of generative AI gains traction.</p><p>“In aggregate, it’s mind-boggling how much is lost to fraud perpetuated through robocalls,” says <a href=\"https://spia.vt.edu/people/Faculty/bios/burger.html\" rel=\"noopener noreferrer\" target=\"_blank\">Eric Burger</a>, the research director of the <a href=\"https://cyberinitiative.org/\" target=\"_blank\">Commonwealth Cyber Initiative</a> at Virginia Tech.
</p><p class=\"pull-quote\">
	“I don’t think we can appreciate just how fast the telephone experience is going to change because of this.” <strong>—Jonathan Nelson, Hiya</strong>
</p><h2>AI Will Make It Easier for Scammers to Target Individuals</h2><p>
	“The big fear with generative AI is it’s going to take custom-tailored scams and take them mainstream,” says Jonathan Nelson, director of product management at Hiya. In particular, he says, generative AI will make it easier to carry out <a href=\"https://usa.kaspersky.com/resource-center/definitions/spear-phishing\" rel=\"noopener noreferrer\" target=\"_blank\">spear-phishing attacks</a>.
</p><h3>The Cost of Phone Fraud</h3><br /><div>The average amount of money lost by a phone-scam victim in 2022, in U.S. dollars:</div><ul>
<li>United States: $431.26</li>
<li>UK: $324.04</li>
<li>Canada: $472.87</li>
<li>France: $360.62</li>
<li>Germany: $325.87</li>
<li>Spain: $282.35</li>
</ul><p class=\"photo-credit\">
	Source: Hiya
</p><p>
	Generally, <a href=\"https://en.wikipedia.org/wiki/Phishing\" rel=\"noopener noreferrer\" target=\"_blank\">phishing attacks</a> aim to trick people into parting with personal information, such as passwords and financial information. <a href=\"https://us.norton.com/blog/online-scams/spear-phishing\" target=\"_blank\">Spear-phishing</a>, however, is more targeted: The scammer knows exactly whom they’re targeting, and they’re hoping for a bigger payout through a more tailored approach. Now, with generative AI, Nelson says, a scammer can scrape social-media sites, draft text, and even <a href=\"https://blog.hiya.com/voice-fraud-and-the-threat-of-generative-ai\" target=\"_blank\">clone a trusted voice</a> to part unsuspecting individuals from their money en masse.
</p><p>
	With the FCC’s unanimous vote to make generative AI in robocalls illegal, the question naturally turns to enforcement. That’s where the experts whom <em>IEEE Spectrum </em>spoke to are generally doubtful, although many also see it as a necessary first step. “It’s a helpful step,” says <a href=\"https://www.brennancenter.org/experts/daniel-i-weiner\" rel=\"noopener noreferrer\" target=\"_blank\">Daniel Weiner</a>, the director of the Brennan Center’s Elections and Government Program, “but it’s not a full solution.” Weiner says that it’s difficult for the FCC to take a broader regulatory approach in the same vein as the <a href=\"https://www.politico.eu/article/eu-big-tech-help-deepfake-proof-election-2024/\" rel=\"noopener noreferrer\" target=\"_blank\">general prohibition on deepfakes</a> being mulled by the European Union, given the FCC’s scope of authority.
</p><p>
	Burger, who was the FCC’s chief technology officer from 2017 to 2019, says that the agency’s vote will ultimately have an impact only if it starts enforcing the ban on robocalls more generally. Most types of robocalls <a href=\"https://www.fcc.gov/general/telemarketing-and-robocalls\" rel=\"noopener noreferrer\" target=\"_blank\">have been prohibited</a> since the agency instituted the Telephone Consumer Protection Act in 1991. (There are some exceptions, such as prerecorded messages from your dentist’s office, for example, reminding you of an upcoming appointment.)</p><p>
	“Enforcement doesn’t seem to be happening,” says Burger. “The politicians like to say, ‘We’re going after the bad guys,’ and they don’t—not with the vigor we’d like to see.”
</p><h2>Robocall Enforcement Tools May Not Be Enough Against AI</h2><p>
	The key method to identify the source of a robocall—and therefore prevent bad actors from continuing to make them—is to trace the call back through the complex network of telecom infrastructure and identify the call’s originating point. Tracebacks used to be complicated affairs, as a call typically traverses infrastructure maintained by multiple network operators like AT&amp;T and T-Mobile. However, in 2020, <a href=\"https://www.fcc.gov/document/mandating-stirshaken-combat-spoofed-robocalls-0\" rel=\"noopener noreferrer\" target=\"_blank\">the FCC approved a mandate</a> for network operators to begin implementing <a href=\"https://spectrum.ieee.org/how-your-phone-company-aims-to-stop-robocalls\" target=\"_self\">a protocol called STIR/SHAKEN</a> that would, among other antirobocall measures, make one-step tracebacks possible.
</p><p>
	“One-step traceback has been borne out,” says Burger. Traceback, for example, <a href=\"https://apnews.com/article/biden-robocalls-artificial-intelligence-new-hampshire-texas-a8665277d43d05380d2c7594edf27617\" rel=\"noopener noreferrer\" target=\"_blank\">identified the source of the fake Biden calls</a> targeting New Hampshire voters as a Texas-based company called Life Corporation. The problem, Burger says, is that the FCC, the U.S. Federal Bureau of Investigation, and state agencies aren’t providing the resources to make it possible to go after the sheer number of illegal robocall operations. Historically, the FCC has gone after only <a href=\"https://www.jacksonville.com/story/news/state/2018/05/10/florida-man-behind-100-million-robocalls-hit-with-huge-fcc-fine/12273922007/\" rel=\"noopener noreferrer\" target=\"_blank\">the very largest perpetrators</a>.
</p><p>
	“There is no stopping these calls,” says Hiya’s Nelson—at least not entirely. “Our job isn’t to stop them, it’s to make them unprofitable.” Hiya, like similar companies, aims to accomplish that goal by lowering the amount of successful fraud through protective services, including exposing where a call was created and by whom, to make it less likely that an individual will answer the call in the first place.
</p><p>
	However, Nelson worries that generative AI will make the barrier to entry so low that those preventative actions will be less effective. For example, today’s scams still almost always require transferring the victim to a live agent in a call center to close out the scam successfully. With AI-generated voices, scam operators can eventually cut out the call center entirely.
</p><p class=\"pull-quote\">
	“In aggregate, it’s mind-boggling how much is lost to fraud perpetuated through robocalls.” <strong>—Eric Burger, Virginia Tech</strong>
</p><p>
	Nelson is also concerned that as generative AI improves, it will be harder for people to even recognize that they weren’t speaking to an actual person in the first place. “That’s where we’re going to start to lose our footing,” says Nelson. “We may have an increase in call recipients not realizing it’s a scam at all.” Scammers positioning themselves as fake charities, for example, could successfully solicit “donations” without donors ever realizing what actually happened.
</p><p>
	“I don’t think we can appreciate just how fast the telephone experience is going to change because of this,” says Nelson.
</p><p>
	One other complicating issue for enforcement is that the majority of illegal robocalls in the United States originate from beyond the country’s borders. The <a href=\"https://tracebacks.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Industry Traceback Group</a> found that in 2021, for example, <a href=\"https://docs.fcc.gov/public/attachments/DOC-383499A1.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">65 percent of all such calls</a> were international in origin.
</p><p>
	Burger points out that the FCC has taken steps to combat international robocalls. The agency made it possible for other carriers to refuse to pass along traffic from gateway providers—a term for network operators connecting domestic infrastructure to international infrastructure—that are originating scam calls. In December 2023, for example, the FCC ordered two companies, <a href=\"https://docs.fcc.gov/public/attachments/DOC-399297A1.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Solid Double and CallWin</a>, to stop transmitting illegal robocalls or risk other carriers being required to refuse their traffic.
</p><p class=\"pull-quote\">
	“Enforcement doesn’t seem to be happening. . . . not with the vigor we’d like to see.” <strong>—Eric Burger, Virginia Tech</strong>
</p><p>
	The FCC’s recent action against generative AI in robocalls is the first of its kind, and it remains to be seen if regulatory bodies in other countries will follow. “I certainly think the FCC is setting a good example in swift and bold action in the scope of its regulatory authority,” says Weiner. However, he also notes that the FCC’s counterparts in other democracies will likely end up with more comprehensive results.</p><p>It’s hard to say how the FCC’s actions will stack up versus other regulators, according to Burger. As often as the FCC is way ahead of the curve—such as in <a href=\"https://spectrum.ieee.org/tag/spectrum-sharing\" target=\"_self\">spectrum sharing</a>—it’s just as often way behind, such as the use of <a href=\"https://spectrum.ieee.org/5g-tv\" target=\"_self\">mid-band 5G</a>.
</p><p>Nelson says he expects to see revisions to the FCC’s decision within a couple of years, because it currently prevents companies from using generative AI for legitimate business practices.</p><p>It also remains to be seen whether the FCC’s vote will have any real effect. Burger points out that, in the case of calls like the fake Biden one, it was already illegal to place those robocalls and impersonate the president, so making another aspect of the call illegal likely won’t be a game-changer.<br /></p><p>
	“By making it triply illegal, is that really going to deter people?” Burger says.
</p>",[{'name': 'Michael Koziol'}],"Tue, 13 Feb 2024 17:00:03 +0000"
2258,Open-Source AI Is Good for Us,https://spectrum.ieee.org/open-source-ai-good,"<img src=\"https://spectrum.ieee.org/media-library/a-computer-generated-landscape-with-framework-over-the-land-and-mountains-and-a-beautiful-sun-on-the-horizon-in-the-foreground.jpg?id=51405458&amp;width=1200&amp;height=800&amp;coordinates=600%2C0%2C600%2C0\" /><br /><br /><p><em>This is a guest post. For the other side of the argument about open-source AI, see the recent guest post “<a href=\"https://spectrum.ieee.org/open-source-ai-2666932122\" target=\"_blank\">Open-Source AI Is Uniquely Dangerous.</a>“</em></p><p>A culture war in AI is emerging between those who believe that the development of models should be restricted or unrestricted by default. In 2024, that clash is spilling over into the law, and it has major implications for the future of open innovation in AI.<br /></p><p>Today, the AI technologies under most scrutiny are generative AI models that have learned how to read, write, draw, animate, and speak, and that can be used to power tools like ChatGPT. Intertwined with the wider debate over AI regulation is a heated and ongoing disagreement over the risk of open models—models that can be used, modified, and shared by other developers—and the wisdom of releasing their distinctive settings, or “weights,” to the public.</p><p>Since the launch of powerful open models like the <a href=\"https://ai.meta.com/blog/large-language-model-llama-meta-ai/\" target=\"_blank\">Llama</a>, <a href=\"https://falconllm.tii.ae/falcon-180b.html\" rel=\"noopener noreferrer\" target=\"_blank\">Falcon</a>, <a href=\"https://mistral.ai/news/announcing-mistral-7b/\" rel=\"noopener noreferrer\" target=\"_blank\">Mistral</a>, and <a href=\"https://stability.ai/stable-image\" rel=\"noopener noreferrer\" target=\"_blank\">Stable Diffusion</a> families, critics have pressed to keep other such genies in the bottle. “Open source software and open data can be an extraordinary resource for furthering science,” <a href=\"https://www.hawley.senate.gov/hawley-and-blumenthal-demand-answers-meta-warn-misuse-after-leak-metas-ai-model\" rel=\"noopener noreferrer\" target=\"_blank\">wrote</a> two U.S. senators to Meta (creator of Llama), but “centralized AI models can be more effectively updated and controlled to prevent and respond to abuse.” Think tanks and closed-source firms have <a href=\"https://openai.com/blog/governance-of-superintelligence\" rel=\"noopener noreferrer\" target=\"_blank\">called</a> for AI development to be regulated like nuclear research, with restrictions on who can develop the most powerful AI models. Last month, one commentator <a href=\"https://spectrum.ieee.org/open-source-ai-2666932122\" target=\"_self\">argued</a> in <em>IEEE </em><em>Spectrum</em> that “open-source AI is uniquely dangerous,” echoing calls for the registration and licensing of AI models.</p><p>The debate is surfacing in recent efforts to regulate AI. First, the European Union has just finalized its <a href=\"https://artificialintelligenceact.eu/the-act/\" rel=\"noopener noreferrer\" target=\"_blank\">AI Act</a> to govern the development and deployment of AI systems. Among its most hotly contested provisions was whether to apply these rules to “free and open-source” models. Second, following President Biden’s <a href=\"https://spectrum.ieee.org/biden-ai-executive-order\" target=\"_self\">executive order</a> on AI, the U.S. government has begun to <a href=\"https://www.axios.com/2024/01/30/commerce-ai-model-info-sharing\" rel=\"noopener noreferrer\" target=\"_blank\">compel reports</a> from the developers of certain AI models, and will soon launch a <a href=\"https://www.ntia.gov/press-release/2023/ntia-kicks-public-engagement-executive-order-ai-work\" rel=\"noopener noreferrer\" target=\"_blank\">public inquiry</a> into the regulation of “widely-available” AI models.</p><p>However our governments choose to regulate AI, we need to promote a diverse AI ecosystem: from large companies building proprietary superintelligence to everyday tinkerers experimenting with open technology. Open models are the bedrock for grassroots innovation in AI. </p><p>I serve as <a href=\"https://www.linkedin.com/in/ben-brooks-7527318a/\" target=\"_blank\">head of public policy</a> for <a href=\"https://stability.ai/\" target=\"_blank\">Stability AI</a> (makers of Stable Diffusion), where I work with a small team of passionate researchers who share media and language models that are freely used by millions of everyday developers and creators around the world. My concern is that this grassroots ecosystem is uniquely vulnerable to mounting restrictions on who can develop and share models. Eventually, these regulations may lead to limits on fundamental research and collaboration in ways that erode this culture of open development, which made AI possible in the first place and helps make it safer.</p><h2>Open models promote transparency and competition</h2><p>Open models play a vital role in helping to drive transparency and competition in AI. Over the coming years, generative AI will support creative, analytic, and scientific applications that go far beyond today’s text and image generators; we’ll see such applications as personalized tutors, desktop healthcare assistants, and backyard film studios. These models will revolutionize essential services, reshape how we access information online, and transform our public and private institutions. In short, AI will become critical infrastructure.</p><p>As I have <a href=\"https://www.schumer.senate.gov/imo/media/doc/Ben%20Brooks%20%20-%20Statement.pdf\" target=\"_blank\">argued</a> before the U.S. Congress and U.K. Parliament, the next wave of digital services should not rely solely on a few “black box” systems operated by a cluster of big tech firms. Today, our digital economy runs on opaque systems that feed us content, control our access to information, determine our exposure to advertising, and mediate our online interactions. We’re unable to inspect these systems or build competitive alternatives. If models—our AI building blocks—are owned by a handful of firms, we risk repeating what played out with the Internet. </p><p class=\"pull-quote\">We’ve seen what happens when critical digital infrastructure is controlled by just a few companies.</p><p>In this environment, open models play a vital role. If a model’s weights are released, researchers, developers, and authorities can “look under the hood” of these AI engines to understand their suitability and to mitigate their vulnerabilities before deploying them in real-world tools. Everyday developers and small businesses can adapt these open models to create new AI applications, tune <a href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\" rel=\"noopener noreferrer\" target=\"_blank\">safer AI models</a> for specific tasks, train <a href=\"https://spectrum.ieee.org/inclusive-ai\" target=\"_self\">more representative AI models</a> for diverse communities, or launch new AI ventures without spending tens of millions of dollars to build a model from scratch.</p><p>We know from experience that transparency and competition are the foundation for a thriving digital ecosystem. That’s why open-source software like <a href=\"https://spectrum.ieee.org/tag/android\" target=\"_self\">Android</a> powers most of the world’s smartphones, and why <a href=\"https://spectrum.ieee.org/tag/linux\" target=\"_self\">Linux</a> can be found in data centers, nuclear submarines, and SpaceX rockets. Open-source software has <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4693148&amp;ref=thestack.technology\" rel=\"noopener noreferrer\" target=\"_blank\">contributed</a> as much as US $8.8 trillion in value globally. Indeed, recent breakthroughs in AI were only possible because of open research like the transformer architecture, open code libraries like <a href=\"https://pytorch.org/\" rel=\"noopener noreferrer\" target=\"_blank\">PyTorch</a>, and open collaboration from researchers and developers around the world.</p><h2>Regulations may stifle grassroots innovation </h2><p>Fortunately, no government has ventured to abolish open models altogether. If anything, governments have resisted the most extreme calls to intervene. The White House declined to require premarket licenses for AI models in its executive order. And after a confrontation with its member state governments in December, the E.U. agreed to partially exempt open models from its AI Act. Meanwhile, Singapore is funding a US $52 million open-source development effort for Southeast Asia, and the UAE continues to bankroll some of the largest available open generative AI models. French President Macron has <a href=\"https://www.politico.eu/article/open-source-artificial-intelligence-france-bets-big/\" rel=\"noopener noreferrer\" target=\"_blank\">declared</a> “on croit dans l’open-source”—we believe in open-source.</p><p>However, the E.U. and U.S. regulations could put the brakes on this culture of open development in AI. For the first time, these instruments establish a legal threshold beyond which models will be deemed “dual use” or “systemic risk” technologies. Those thresholds are based on a range of factors, including the computing power used to train the model. Models over the threshold will attract new regulatory controls, such as notifying authorities of test results and maintaining exhaustive research and development records, and they will lose E.U. exemptions for open-source development.</p><p>In one sense, these thresholds are a good faith effort to avoid overregulating AI. They focus regulatory attention on future models with unknown capabilities instead of restricting existing models. Few existing models will meet the current thresholds, and those that do first will be models from well-resourced firms that are equipped to meet the new obligations.</p><p>In another sense, however, this approach to regulation is troubling, and augurs a seismic shift in how we govern novel technology. Grassroots innovation may become collateral damage.</p><h2>Regulations could hurt everyday developers</h2><p>First, regulating “upstream” components like models could have a disproportionate chilling effect on research in “downstream” systems. Many of the restrictions for above-the-threshold models assume that developers are sophisticated firms with formal relationships to those who use their models. For example, the U.S. executive order requires developers to report on individuals who can access the model’s weights, and detail the steps taken to secure those weights. The E.U. legislation requires developers to conduct “state of the art” evaluations and systematically monitor for incidents involving their models.</p><p class=\"pull-quote\">For the first time, these instruments establish a legal threshold beyond which models will be deemed “dual use” or “systemic risk” technologies.</p><p>Yet the AI ecosystem is more than a handful of corporate labs. It also includes countless developers, researchers, and creators who can freely access, refine, and share open models. They can iterate on powerful “base” models to create safer, less biased, or more reliable “fine-tuned” models that they release back to the community.</p><p>If governments treat these everyday developers the same as the companies that first released the model, there will be problems. Developers operating from dorm rooms and dining tables won’t be able to comply with the premarket <a href=\"https://www.blumenthal.senate.gov/newsroom/press/release/blumenthal-and-hawley-announce-bipartisan-framework-on-artificial-intelligence-legislation\" target=\"_blank\">licensing and approval</a> requirements that have been proposed in Congress, or the “one size fits all” <a href=\"https://artificialintelligenceact.eu/wp-content/uploads/2024/01/AIA-Final-Draft-21-January-2024.pdf\" target=\"_blank\">evaluation, mitigation, and documentation requirements</a> initially drafted by the European Parliament. And they would never contribute to model development—or any other kind of software development—if they thought a senator might <a href=\"https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-rules-for-artificial-intelligence\" rel=\"noopener noreferrer\" target=\"_blank\">hold them liable</a> for how downstream actors use or abuse their research. Individuals releasing new and improved models on <a href=\"https://github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a> shouldn’t face the same compliance burden as OpenAI or Meta.</p><h2>The thresholds for restrictions seem arbitrary</h2><p>Second, the criteria underpinning these thresholds are unclear. Before we put up barriers around the development and distribution of a useful technology, governments should assess the initial risk of the technology, the residual risk after considering all available legal and technical mitigations, and the opportunity cost of getting it wrong.</p><p>Yet there is still no framework for determining whether these models actually pose a serious and unmitigated risk of catastrophic misuse, or for measuring the impact of these rules on AI innovation. The preliminary U.S. threshold—10<sup>26</sup> floating point operations (FLOPs) in training computation—first appeared as a <a href=\"https://arxiv.org/pdf/2307.03718.pdf\" target=\"_blank\">passing footnote</a> in a research paper. The EU threshold of 10<sup>25</sup> FLOPs is an order of magnitude more conservative, and didn’t appear at all until the final month of negotiation. We may <a href=\"https://epochai.org/trends\" rel=\"noopener noreferrer\" target=\"_blank\">cross</a> that threshold in the foreseeable future. What’s more, both governments reserve the right to move these goalposts for any reason, potentially bringing into scope a massive number of smaller but increasingly powerful models, many of which can be run locally on laptops or smartphones.</p><h2>Restrictions are based on speculative risks</h2><p>Third, there is no consensus about precisely which risks justify these exceptional controls. Online safety, election disinformation, smart malware, and fraud are some of the most immediate and tangible risks posed by generative AI. Economic disruption is possible too. However, these risks are rarely invoked to justify premarket controls for other helpful software technologies with dual-use applications. Photoshop, Word, Facebook, Google Search, and WhatsApp have contributed to the proliferation of deepfakes, fake news, and phishing scams, but our first instinct isn’t to regulate their underlying C++ or Java libraries. </p><p>Instead, critics have focused on “existential risk” to make the case for regulating model development and distribution, citing the prospect of runaway agents or homebuilt weapons of mass destruction. However, as a <a href=\"https://hai.stanford.edu/sites/default/files/2023-12/Governing-Open-Foundation-Models.pdf\" target=\"_blank\">recent paper</a> from Stanford’s Institute for Human-Centered Artificial Intelligence (<a href=\"https://hai.stanford.edu/\" target=\"_blank\">HAI</a>) notes of these claims, “the weakness of evidence is striking.” If these arguments are to justify a radical departure from our conventional approach to regulating technology, the standard of proof should be higher than speculation.</p><h2>We should regulate AI while preserving openness</h2><p>There is no debate that AI should be regulated, and all actors—from model developers to application deployers—have a role to play in mitigating emerging risks. However, new rules must account for grassroots innovation in open models. Right now, well-intended efforts to regulate models run the risk of stifling open development. Taken to their extreme, these frameworks may limit access to foundational technology, saddle hobbyists with corporate obligations, or formally restrict the exchange of ideas and resources between everyday developers.</p><p><span></span> In many ways, models are regulated already, thanks to a complex patchwork of legal frameworks that governs the development and deployment of any technology. Where there are gaps in existing law—such as U.S. federal law governing abusive, fraudulent, or political deepfakes—they can and should be closed. </p><p>However, presumptive restrictions on model development should be the option of last resort. We should regulate for emerging risks while preserving the culture of open development that made these breakthroughs possible in the first place, and that drives transparency and competition in AI.</p>",[{'name': 'Ben Brooks'}],"Thu, 08 Feb 2024 20:19:06 +0000"
2259,Tiny Quadrotor Learns to Fly in 18 Seconds,https://spectrum.ieee.org/drone-quadrotor,"<img src=\"https://spectrum.ieee.org/media-library/a-short-gif-of-simulated-x-shaped-devices-scrambling-around-until-they-gradually-settle-down-and-stay-in-place.gif?id=51413016&amp;width=1200&amp;height=800&amp;coordinates=60%2C0%2C61%2C0\" /><br /><br /><p>
	It’s kind of astonishing how quadrotors have scaled over the past decade. Like, we’re now at the point where they’re verging on disposable, at least from a commercial or research perspective—for a bit over US $200, you can buy a little <a href=\"https://www.bitcraze.io/products/crazyflie-2-1/\" rel=\"noopener noreferrer\" target=\"_blank\">27-gram, completely open-source drone</a>, and all you have to do is teach it to fly. That’s where things do get a bit more challenging, though, because teaching drones to fly is not a straightforward process. Thanks to good simulation and techniques like reinforcement learning, it’s much easier to imbue drones with autonomy than it used to be. But it’s not typically a fast process, and it can be finicky to make a smooth transition from simulation to reality.
</p><p>
	New York University’s <a href=\"https://wp.nyu.edu/arpl/\" target=\"_blank\">Agile Robotics and Perception Lab</a> in collaboration with the <a href=\"https://www.tii.ae/\" target=\"_blank\">Technology Innovation Institute</a> (TII) have managed to streamline the process of getting basic autonomy to work on drones, and streamline it by a lot: The lab’s system is able to train a drone in simulation from nothing up to stable and controllable flying in 18 seconds flat on a MacBook Pro. And it actually takes longer to compile and flash the firmware onto the drone itself than it does for the entire training process.
</p><hr /><p class=\"shortcode-media shortcode-media-youtube\">
<span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span>
<small class=\"image-media media-photo-credit\">ARPL NYU</small></p><p>
	So not only is the drone able to keep a stable hover while rejecting pokes and nudges and wind, but it’s also able to fly specific trajectories. Not bad for 18 seconds, right?
</p><p>
	One of the things that typically slows down training times is the need to keep refining exactly what you’re training for, without refining it so much that you’re only training your system to fly in your specific simulation rather than the real world. The strategy used here is what the researchers call a curriculum (you can also think of it as a sort of lesson plan) to adjust the reward function used to train the system through reinforcement learning. The curriculum starts things off being more forgiving and gradually increasing the penalties to emphasize robustness and reliability. This is all about efficiency: Doing that training that you need to do in the way that it needs to be done to get the results you want, and no more.
</p><p>
	There are other, more straightforward, tricks that optimize this technique for speed as well. The deep-reinforcement learning algorithms are particularly efficient, and leverage the hardware acceleration that comes along with Apple’s M-series processors. The simulator efficiency multiplies the benefits of the curriculum-driven sample efficiency of the reinforcement-learning pipeline, leading to that wicked-fast training time.
</p><p>
	This approach isn’t limited to simple tiny drones—it’ll work on pretty much any drone, including bigger and more expensive ones, or even a drone that you yourself build from scratch.
</p><p class=\"shortcode-media shortcode-media-youtube\">
<span class=\"rm-shortcode\" style=\"display: block; padding-top: 56.25%;\"></span>
<small class=\"image-media media-photo-credit\">Jonas Eschmann</small></p><p>
We’re told that it took minutes rather than seconds to train a policy for the drone in the video above, although the researchers expect that 18 seconds is achievable even for a more complex drone like this in the near future. And it’s all <a href=\"https://github.com/arplaboratory/learning-to-fly\" rel=\"noopener noreferrer\" target=\"_blank\">open source</a>, so you can, in fact, build a drone and teach it to fly with this system. But if you wait a little bit, it’s only going to get better: The researchers tell us that they’re working on integrating with the PX4 open source drone autopilot. Longer term, the idea is to have a single policy that can adapt to different environmental conditions, as well as different vehicle configurations, meaning that this could work on all kinds of flying robots rather than just quadrotors.
</p><p>
	Everything you need to run this yourself <a href=\"https://github.com/arplaboratory/learning-to-fly\" target=\"_blank\">is available on GitHub</a>, and the paper is on ArXiv <a href=\"https://arxiv.org/abs/2311.13081\" target=\"_blank\">here</a>.</p>",[{'name': 'Evan Ackerman'}],"Thu, 08 Feb 2024 17:00:02 +0000"
2260,"Standards Matter for Cars, Plugs, Wi-Fi—and AI?",https://spectrum.ieee.org/tech-standards-responsible-ai,"<img src=\"https://spectrum.ieee.org/media-library/a-layer-of-cream-and-blue-silhouetted-heads-forming-a-swirl-resulting-in-an-upside-down-head-within-the-head.jpg?id=51406236&amp;width=1200&amp;height=800&amp;coordinates=62%2C0%2C63%2C0\" /><br /><br /><p><a href=\"https://spectrum.ieee.org/topic/artificial-intelligence/\" target=\"_self\">Artificial intelligence</a> holds much promise for innovation and progress, but it also has the potential to cause harm. To enable the responsible development and use of AI, the <a href=\"https://www.iso.org/home.html\" rel=\"noopener noreferrer\" target=\"_blank\">International Organization for Standardization</a> (ISO) recently released <a href=\"https://www.iso.org/standard/81230.html\" rel=\"noopener noreferrer\" target=\"_blank\">ISO/IEC 42001</a>, a new standard for AI management systems. According to ISO, this standard “offers organizations the comprehensive guidance they need to use AI responsibly and effectively, even as the technology is rapidly evolving.”</p><p>As AI has rapidly matured and broadly been rolled out across the world, there’s been a tangle of conflicting standards from big AI companies like <a href=\"https://ai.meta.com/responsible-ai/\" target=\"_blank\">Meta</a>, <a href=\"https://www.microsoft.com/en-us/ai/responsible-ai\" target=\"_blank\">Microsoft</a>, and <a href=\"https://ai.google/responsibility/responsible-ai-practices/\" target=\"_blank\">Google</a>. (Although in November, Meta <a href=\"https://www.reuters.com/technology/meta-breaks-up-its-responsible-ai-team-information-2023-11-18/\" target=\"_blank\">reportedly</a> disbanded its Responsible AI group.) And the Austin, Tex.-based <a href=\"https://www.linkedin.com/company/responsible-ai-institute\" target=\"_blank\">Responsible AI Institute</a> has its own <a href=\"https://www.responsible.ai/how-we-help\" target=\"_blank\">assessments and certification program</a> for ethical uses and applications for AI. Yet, maintaining consistent standards and practices are also an age-old challenge over the entire history of technology. And standards-keeping organizations like the ISO—and the IEEE—could be natural places to turn for a widely agreed-upon set of parameters for responsible AI development and use. </p><p class=\"pull-quote\">“If there is this kind of buy-in from organizations that are promoting the responsible development and use of AI, others will follow.” <strong>—Virginia Dignum, Umeå University, Umeå, Sweden</strong></p><p>In ISO’s case, their standard concerns AI <em>management</em> systems. These are catalogs or inventories of the different AI systems that a company is using, along with information on how, where, and why these systems are being used, says <a href=\"https://umangsbhatt.github.io/\" target=\"_blank\">Umang Bhatt</a>, an assistant professor and faculty fellow at <a href=\"https://www.nyu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">New York University</a> and an advisor to the <a href=\"https://www.responsible.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Responsible AI Institute</a>. And as the standard specifies, an AI management system is “intended to establish policies and objectives, as well as processes to achieve those objectives, in relation to the responsible development, provision, or use of AI systems.”</p><p>So ISO’s new standard provides a set of concrete guidelines—as opposed to just high-level principles—that support responsible AI, says <a href=\"https://www.cs.cmu.edu/~hheidari/\" rel=\"noopener noreferrer\" target=\"_blank\">Hoda Heidari</a>, who coleads the <a href=\"https://www.cmu.edu/block-center/responsible-ai/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">Responsible AI Initiative</a> at <a href=\"https://www.cmu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Carnegie Mellon University</a>. Heidari adds that the standard also gives AI developers confidence that “the appropriate processes were followed in the creation and evaluation of the system before it was released, and there are appropriate processes around to monitor it and address any adverse outcomes.”</p><h3>IEEE, ISO, and governments consider</h3><p>Meanwhile, <em>IEEE Spectrum</em>’s parent organization, the <a href=\"http://ieee.org\" target=\"_blank\">IEEE</a>, also maintains and develops a <a href=\"https://standards.ieee.org/\" target=\"_blank\">wide range of standards</a> across many fields of technology. As of press time, <em>Spectrum</em> has learned of at least one effort now afoot within the broad global reach of IEEE standards-making organizations to develop responsible AI standards. It would reportedly be an outgrowth of the <a href=\"https://standards.ieee.org/ieee/2863/10142/\" target=\"_blank\">2020 Recommended Practice standard</a> for AI development and use. In addition, the <a href=\"https://standards.ieee.org/industry-connections/ec/autonomous-systems/\" target=\"_blank\">IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems</a> has made available <a href=\"https://standards.ieee.org/wp-content/uploads/import/documents/other/ead1e-overview.pdf\" target=\"_blank\">this document</a> promoting ethically aligned development of autonomous systems. </p><p>As with some standards in tech, the ISO’s standard is not a mandatory standard. “What would compel companies to adopt this? The standard itself is not enough—you have to have reason and motivation for these developers to adopt it,” says <a href=\"https://chiragshah.org/index.php\" target=\"_blank\">Chirag Shah</a>, a founding codirector of <a href=\"https://www.raise.uw.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">RAISE</a>, a center for responsible AI at the <a href=\"https://www.washington.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Washington</a>. He adds that organizations might also view the standard as an overhead task, especially for small ones without enough resources or even large corporations that already have their own standards.</p><p class=\"pull-quote\">“It’s just like a tracking record that I hope will become part of the culture in the software development community.” <strong>—Umang Bhatt, New York University</strong></p><p><a href=\"https://www.umu.se/en/staff/virginia-dignum/\" rel=\"noopener noreferrer\" target=\"_blank\">Virginia Dignum</a>, a professor in responsible AI and director of the AI Policy Lab at Sweden’s <a href=\"https://www.umu.se/\" rel=\"noopener noreferrer\" target=\"_blank\">Umeå University</a>, echoes the sentiment, noting that the standard “only really works when there is a sufficient number of organizations taking it up, and by doing that, we also identify what will and will not work in the standard.” To address this issue, Dignum suggests turning to <a href=\"https://spectrum.ieee.org/ai-ethics-industry-guidelines\" target=\"_blank\">big tech firms</a> and convincing them to adopt the standard, because “if there is this kind of buy-in from organizations that are promoting the responsible development and use of AI, others will follow.” For instance, <a href=\"https://aws.amazon.com/blogs/machine-learning/iso-42001-a-new-foundational-global-standard-to-advance-responsible-ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Amazon’s AWS participated in creating the standard and is now pursuing its adoption</a>.</p><p>Another motivation to apply the standard is to be prepared and create a framework for looming <a href=\"https://spectrum.ieee.org/ai-regulation-worldwide\" target=\"_self\">regulations</a> from other standards-making bodies, which may align with ISO’s new standard. For example, the U.S. government recently released an <a href=\"https://spectrum.ieee.org/biden-ai-executive-order\" target=\"_self\">executive order on AI</a>, while the <a href=\"https://apnews.com/article/ai-act-europe-regulation-59466a4d8fd3597b04542ef25831322c\" rel=\"noopener noreferrer\" target=\"_blank\">European Union’s AI Act is expected to take full effect by 2025</a>.</p><h3>Trust matters, too</h3><p>An additional incentive for AI companies to take up the standard is to cultivate trust with end users. In the United States, for instance, people express <a href=\"https://www.pewresearch.org/science/2023/02/15/public-awareness-of-artificial-intelligence-in-everyday-activities/\" rel=\"noopener noreferrer\" target=\"_blank\">more concern over excitement about AI’s impact on their daily lives</a>, with these <a href=\"https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2023/10/consumers-are-voicing-concerns-about-ai\" rel=\"noopener noreferrer\" target=\"_blank\">concerns</a> spanning the data used to train AI, its biases and inaccuracies, and its potential for misuse. “When there are standards and best practices around, and we can assure consumers that those are followed, they will trust the system more, and they are more willing to interact with it,” Heidari says.</p><p>Akin to a car’s braking system, which has been built and tested following particular standards and specifications, “even if users don’t understand what the standard is, it will provide them the confidence that things were developed in a certain way, and that there are also some auditing or checks and oversight on what has been developed,” Dignum says.</p><p>For AI firms looking to adopt the standard, Bhatt advises viewing it much like you would the practices you’ve established to keep track of any issues with your AI system. “These standards are going to come in place in a way that is quite similar to the continuous monitoring tools you might build and use,” he says. “It’s just like a tracking record that I hope will become part of the culture in the software development community.”</p><p>Beyond implementation, Heidari hopes ISO’s new standard will spur a mindset shift in AI companies and the people creating them. She points to design choices when training machine-learning models as an example: It may seem like making just another engineering or technical decision that doesn’t have any meaning outside the machinery they’re dealing with, but “all those choices have huge implications when the resulting model will be utilized for decision-making processes or for automating practices on the ground,” she says. “The most important thing for developers of these systems is to keep in mind that whether they know it or not and whether they accept it or not, a lot of the choices they make have real-world consequences.”</p><p><br /></p><p><strong>UPDATE 9 Feb. 2024: </strong>The story was updated to provide a link to the most recent IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems document, from 2019. The original story had linked to the 2017 version. <br /></p>",[{'name': 'Rina Diane Caballar'}],"Wed, 07 Feb 2024 20:32:26 +0000"
2261,Could AI Disrupt Peer Review?,https://spectrum.ieee.org/ai-peer-review,"<img src=\"https://spectrum.ieee.org/media-library/a-3d-illustration-of-a-horizontal-stack-of-papers-all-of-which-are-glowing-green-except-for-one-red-one-that-is-being-pulled-o.jpg?id=51385865&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C0\" /><br /><br /><p>Spending time poring over manuscripts to offer thoughtful and incisive critique as a peer reviewer is one of academia’s most thankless jobs. Peer review is often the final line of defense between new research and the general public and is aimed at ensuring the accuracy, novelty, and significance of new findings.</p><p>This crucial role is voluntary, unpaid, and often underappreciated by academic publishers and institutions. As with other tedious jobs in today’s world, this raises the question: Can, and more importantly, should,  publishers trust AI to handle peer review instead? A number of researchers say no and are growing concerned about how AI may threaten the integrity of the review process by reinforcing bias and introducing misinformation.</p><p><a href=\"https://www.ihu.gr/ucips/cv/vasiliki-mollaki\" target=\"_blank\">Vasiliki Mollaki</a> is a bioethicist and geneticist at the International Hellenic University in Greece addressed this issue in the journal <em>Research Ethics</em> on 9 January in <a href=\"https://journals.sagepub.com/doi/full/10.1177/17470161231224552\" rel=\"noopener noreferrer\" target=\"_blank\">an article</a> pointedly titled “Death of a Reviewer or Death of Peer Review Integrity?”</p><p>In her paper, Mollaki reviewed the AI policies of top academic publishers—including Elsevier and Wiley—to determine whether they were preparing to address the potential use of AI in peer review. While several journals have developed policies around AI used by authors to write manuscripts, such policies for peer review were almost nonexistent. </p><p>“If [AI] is mentioned, it’s on the basis that there might be confidential data or even personal data that should not be shared with tools [because] they don’t know how this data can be used,” Mollaki says. “The basis is not on ethical grounds.” </p><p>Without concrete policies that lay out guidance on transparency or penalties for using AI in peer review, Mollaki worries that the integrity and good faith trust in the peer review process could collapse. Never mind that the question of whether AI is actually capable yet of providing effective peer review is also up for debate. </p><p class=\"pull-quote\">“Current AI tools are very bad at suggesting specific authors, journals, or papers, and often start hallucinating because their training data is not aimed at forming these connections.”<strong>—Tjibbe Donker, Freiburg University Hospital</strong></p><p><a href=\"https://profiles.stanford.edu/james-zou?tab=bio\" rel=\"noopener noreferrer\" target=\"_blank\">James Zou</a> is an assistant professor of biomedical data science at Stanford University and is the senior author on <a href=\"https://arxiv.org/abs/2310.01783?ref=PDF\" rel=\"noopener noreferrer\" target=\"_blank\">a preprint paper</a> published on arXiv in late 2023 that evaluated how AI’s feedback on research papers compared to that of human reviewers. This work found that AI reviewers’ points overlapped with human reviewers’ points at a rate comparable to two human reviewers and that more than 80 percent of researchers found AI’s feedback more helpful than that of human reviewers.</p><p>“This is especially helpful for authors working on early drafts of manuscripts,” Zou says. “Instead of waiting for weeks to get feedback from mentors or experts, they can get immediate feedback from the LLM.”</p><p>Yet, <a href=\"https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(23)00290-6/fulltext#seccestitle20\" rel=\"noopener noreferrer\" target=\"_blank\">work published</a> that same year in <em>Lancet Infectious</em> <em>Diseases</em> by <a href=\"https://www.linkedin.com/in/tjibbe-donker-294a3a15/\" rel=\"noopener noreferrer\" target=\"_blank\">Tjibbe Donker</a>, an infectious disease epidemiologist at Freiburg University Hospital, in Germany, found that AI struggled to generate personalized feedback responses and even created false citations to support its reviews. </p><p>“Current AI tools are very bad at suggesting specific authors, journals, or papers, and often start hallucinating because their training data is not aimed at forming these connections,” Donker says.</p><p>Despite his reservations, Donker is not necessarily in favor of barring all AI tools from peer review. Instead, he says that using these tools selectively to assist human reviewers in their process could be beneficial, such as helping reviewers assess novelty independent of an author’s writing style by summarizing the paper’s main points. AI could also play a role in consolidating human reviewer’s letters into a single decision letter for authors.</p><p>To ensure that reviewers use AI tools in a minimally invasive way, Mollaki says it will be important for journals to write AI review policies that go beyond issues of privacy and focus on disclosure and transparency.</p><p>“[Journals] should be as clear as possible about what is not permitted,” Mollaki says. “[How] the tools have been used should be disclosed and even the prompts that were used.”<br /></p><p>For authors who break these policies, Mollaki is in favor of a penalty that excludes future participation in peer review. Donker, however, says those repercussions may need to be a little more nuanced. Reacting too strongly to the use of AI in peer review could ironically have the same impact as letting AI run wild.</p><p>“Peer reviewing is done voluntarily, unpaid, without much of a reward for the reviewer,” Donker says. “Most scientists would be quite happy to be excluded from this process, while journals end up with even fewer reviewers to choose from.”</p>",[{'name': 'Sarah Wells'}],"Tue, 06 Feb 2024 14:40:00 +0000"
2262,MIT and IBM Find Clever AI Ways Around Brute-Force Math,https://spectrum.ieee.org/mathematical-model-ai,"<img src=\"https://spectrum.ieee.org/media-library/dots-of-light-starting-from-the-outside-in.jpg?id=51285289&amp;width=1200&amp;height=800&amp;coordinates=0%2C1%2C0%2C2\" /><br /><br /><p>Since the days of Isaac Newton, the fundamental laws of nature all ultimately reduce to a vital, broad set of equations. Now researchers have found a new way to use brain-inspired neural networks to solve these equations significantly more efficiently than before for numerous potential applications in science and engineering.</p><p>In modern science and engineering, <u><a href=\"https://people.math.harvard.edu/~knill/pedagogy/pde/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">partial differential equations</a></u> help model <u><a href=\"https://uwaterloo.ca/applied-mathematics/future-undergraduates/what-you-can-learn-applied-mathematics/differential-equations/partial-differential-equations-pdes\" rel=\"noopener noreferrer\" target=\"_blank\">complex physical systems involving multiple rates of change, such as ones changing across both space and time</a></u>. They can help <u><a href=\"https://www.ias.edu/ideas/curiosities-partial-differential-equations\" rel=\"noopener noreferrer\" target=\"_blank\">model</a></u> all sorts of things, such as the flow of air past the wings of an airplane, the spreading of a pollutant in the air, or the collapse of a star into a black hole.</p><p>To solve these difficult equations, scientists traditionally used high-precision numerical methods. However, these can be very time-consuming and computationally resource-intensive to run.</p><p>Currently, simpler alternatives exist, known as <a href=\"https://en.wikipedia.org/wiki/Surrogate_model\" target=\"_blank\">data-driven surrogate models</a>. These models, which include <u><a href=\"https://spectrum.ieee.org/deep-neural-network\" target=\"_self\">neural networks</a></u>, are trained on data from numerical solvers to predict what answers they might produce. However, these still require a large amount of data from numerical solvers for training. The amount of data needed increases exponentially as these models grow in size, making this strategy difficult to scale, says study lead author <a href=\"https://cse.gatech.edu/people/raphael-pestourie\" target=\"_blank\">Raphaël Pestourie</a>, a computational scientist at the Georgia Institute of Technology in Atlanta.</p><p>In a new study, researchers developed an approach to developing surrogate models. This strategy uses physics simulators to help train neural networks to match the output of the high-precision numerical systems. The aim is to generate accurate results with the help of expert knowledge in a field—in this case, physics—instead of merely throwing a lot of computational resources at these problems to find solutions using brute force.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"black and white figures with arrows against a white background\" class=\"rm-shortcode\" id=\"40582\" src=\"https://spectrum.ieee.org/media-library/black-and-white-figures-with-arrows-against-a-white-background.jpg?id=51285294&amp;width=980\" />
<small class=\"image-media media-caption\">Researchers have found that numerical surrogates (symbolized here as a cartoon of James Clerk Maxwell) can arrive at solutions to hard mathematical problems that had previously required high-precision, brute-force math—symbolized by the Maxwell daguerreotype. </small><small class=\"image-media media-photo-credit\">MIT</small></p><p>The scientists tested what they called physics-enhanced deep surrogate (PEDS) models on three kinds of physical systems. These included diffusion, such as a dye spreading in a liquid over time; reaction-diffusion, such as diffusion that might take place following a chemical reaction; and electromagnetic scattering.</p><p>The researchers found these new models can be up to three times as accurate as other neural networks at tackling partial differential equations. At the same time, these models needed only about 1,000 training points. This reduces the training data required by at least a factor of 100 to achieve a target error of 5 percent.</p><p>“The idea is quite intuitive—let the neural networks do the learning and the scientific model do the science,” Pestourie says. “PEDS shows that combining both is far greater than the sum of its parts.”</p><p>Potential applications for PEDS models include accelerating simulations “of complex systems that show up everywhere in engineering—weather forecasts, carbon capture, and nuclear reactors, to name a few,” Pestourie says.</p><p>The scientists detailed <u><a href=\"https://www.nature.com/articles/s42256-023-00761-y\" rel=\"noopener noreferrer\" target=\"_blank\">their findings</a></u> in the journal <em>Nature Machine Intelligence</em>.</p><p><em>Updated 5 Feb 2024 to remove incorrectly stated laws of nature. Spectrum regrets the error.</em></p>",[{'name': 'Charles Q. Choi'}],"Fri, 02 Feb 2024 20:30:43 +0000"
2263,Brain-Connection Maps Help Neuromorphic Chips,https://spectrum.ieee.org/connectome-neuromorphic-chips,"<img src=\"https://spectrum.ieee.org/media-library/black-dots-representing-neurons-and-blue-lines-representing-connections-form-a-web-network.jpg?id=51234408&amp;width=1200&amp;height=800&amp;coordinates=37%2C0%2C38%2C0\" /><br /><br /><p>In neuroscience—as in geography, genomics, and plenty else—it’s hard to navigate without a good map. Recent advances in <a href=\"https://spectrum.ieee.org/brain-scanning-just-got-very-good-and-very-unsettling\" target=\"_self\"><u>brain mapping technologies</u></a> have enabled scientists to create larger and more detailed models. And as those models for different animals are compared, some surprising similarities have cropped up. So much so that these neurological connection maps (a.k.a. “connectomes”) may inform the designs of advanced <a href=\"https://spectrum.ieee.org/manan-suri-profile\" target=\"_self\"><u>neuromorphic electronics</u></a>: chip and algorithmic models that seek to mimic the computational power and efficiency of brains and neurons.</p><p>Scientists at Yale, Princeton, and the University of Chicago seized the 2021 publication of the <a href=\"https://www.nature.com/articles/s41592-021-01330-0.pdf?proof=t\" rel=\"noopener noreferrer\" target=\"_blank\"><u>fruit-fly connectome</u></a>—a landmark in the emerging field of <a href=\"https://hms.harvard.edu/news/new-field-neuroscience-aims-map-connections-brain#:~:text=Lee%3A%20We%20define%20connectomics%20as,every%20neuron%20and%20every%20connection.\" rel=\"noopener noreferrer\" target=\"_blank\">connectomics</a>—as their opportunity to compare aspects of brain structure across widely different size and complexity scales. </p><p>Mapping out a connectome is no small feat, says Christopher Lynn, <a href=\"https://physics.yale.edu/people/christopher-lynn\" rel=\"noopener noreferrer\" target=\"_blank\">assistant professor of physics</a> at Yale. Even a species as minuscule as the fruit fly represents a substantial neurological challenge. Fruit-fly brains comprise a network of over 120,000 neurons with more than 30 million connections among them. Which, for the purpose of a connectome, means each connection must somehow be isolated, recognized, and graphed. </p><h3>How <em>C. elegans</em> mapped the way</h3><p>“For a sense of scale, <em>C. elegans</em> [the nematode worm] has only 302 neurons,” Lynn says. “They <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4360118/#:~:text=By%201984%2C%20the%20complete%20wiring,the%20synapses%20in%20nervous%20systems.\" target=\"_blank\">mapped out the entire connectome</a> for the first worm in the ’80s, and that was a big breakthrough,” says Lynn. “Each neuron might have between 100 to 10,000 synapses in the case of the fruit fly. When you get to larger systems, you’re tracking hundreds of thousands or millions of synapses.”<br /></p><p class=\"pull-quote\">“There is a simple phrase they say when teaching this: ‘If two neurons fire together, they are likely to wire together.’ ” <strong>—Christopher Lynn, Yale University</strong></p><p>The researchers found persistent connectivity statistics across five different connectomes scaling from the simple <em>C. elegans</em> nematode to the retina of a mouse. They used what’s called <a href=\"https://en.wikipedia.org/wiki/Heavy-tailed_distribution\" target=\"_blank\">heavy-tailed statistics</a>—recognizing that while most connections between neurons are weak, a small number of those connections are much stronger. This result complements <a href=\"https://journals.sagepub.com/doi/full/10.1177/1073858416667720\" target=\"_blank\">prior work</a> showing that brain networks tend to show “<a href=\"https://news.cornell.edu/stories/2023/05/mathematical-model-changed-everything-turns-25\" target=\"_blank\"><u>small-world</u></a>“ characteristics: a small number of neurons are connected to many other neurons, but most neurons aren’t connected to very many at all.</p><p>The presence of heavy-tailed connectivity across species indicates that some of the same principles of neural function may also bridge across organisms of entirely different scales. To help provide a possible framework, the team created a model of brain development that weighed random reorganization with what neuroscientists call <a href=\"https://en.wikipedia.org/wiki/Hebbian_theory\" target=\"_blank\">Hebbian plasticity</a>, or the tendency of nearby, concurrently active neurons to connect to each other. “There is a simple phrase they say when teaching this: ‘If two neurons fire together, they are likely to wire together,’ ” says Lynn. The model, though a simple approximation of how neurons in a brain may come together, consistently recreated the heavy-tailed distributions Lynn and his colleagues saw across connectomes.</p><h3>Brain maps inspire neuromorphic hardware</h3><p>The researchers’ discovery of cross-species connectome similarities could pave the way for new neuromorphic hardware. For instance, the heavy-tailed connectivity patterns they studied suggest a productive line of inspiration for chip design. </p><p class=\"pull-quote\">“There are details that are different, but the heavy-tailed shape is consistent across animals and brain regions.” <strong>—Christopher Lynn, Yale University</strong></p><p>Mike Davies, director of <a href=\"https://spectrum.ieee.org/neuromorphic-computing-with-lohi2\" target=\"_self\"><u>Intel’s Neuromorphic computing laboratory</u></a>, says that small-world connectivity patterns are an attractive feature to model one’s design ideas after. “There’s a tendency to want to simplify the connectivity in a neuromorphic chip to what you can conveniently fabricate,” says Davies. “To represent all possible connections is an <em>n</em>-squared explosion.”</p><p>He adds, however, that Intel has taken a slightly different approach to its neuromorphic designs than strictly following nature’s lead. Instead of trying to explicitly build dense networks in the chips themselves, the company is using adaptive networking systems that route the networking traffic. “It’s the most efficient system we have for modeling these sparse connections,” says Davies. “With that, we actually can replicate some of these heavy-tailed networks.”</p><p>Looking forward, Lynn says the connectomics team will now expand the list of species whose connectomes they map. While the cell-level mouse connectome used in the present study was limited to the animal’s retina, Lynn says the researchers also observed similar heavy-tailed connectivity in much larger parts of the mouse brain. </p><p>While the team’s present results are limited to a handful of connectomes, Lynn says he expects their results will be recapitulated for the connectomes of even larger and more complicated brains. “Based on literally every dataset we’ve seen so far, this distribution looks similar across all of them,” he says. “I would expect these heavy-tailed distributions to be pretty ubiquitous across brains generally.”</p><p>The researchers published <a href=\"https://www.nature.com/articles/s41567-023-02332-9\" target=\"_blank\">their results</a> earlier this month in the journal <em>Nature Physics. </em></p>",[{'name': 'Michael Nolan'}],"Wed, 31 Jan 2024 20:37:59 +0000"
2264,"The Battle for Better, Broader, More Inclusive AI",https://spectrum.ieee.org/inclusive-ai,"<img src=\"https://spectrum.ieee.org/media-library/photo-illustration-of-a-black-man-and-woman-looking-at-the-camera-with-dots-data-and-other-imagery-related-to-ai-around-them.jpg?id=51234058&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C250%2C0\" /><br /><br /><p>AI’s inclusivity problem is no secret. <a href=\"https://www.aclu.org/news/privacy-technology/how-artificial-intelligence-can-deepen-racial-and-economic-inequities\" rel=\"noopener noreferrer\" target=\"_blank\">According to the ACLU</a>, AI systems can perpetuate housing discrimination and bias in the justice system, among other harms. <a href=\"https://spectrum.ieee.org/untold-history-of-ai-the-birth-of-machine-bias\" target=\"_self\">Bias in the data an AI model relies on is reproduced in its results</a>. </p><p>Large Language Models (LLMs) share this problem; <a href=\"https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00225-X/fulltext\">they can reproduce bias in medical settings</a> and perpetuate<a href=\"https://arxiv.org/abs/2304.05335\"> harmful stereotypes</a>, among other problems. To combat that, the New York City–based <a href=\"https://www.futuresum.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">FutureSum AI</a> is building Latimer, the first “racially inclusive large language model.” Latimer—named after a <a href=\"https://spectrum.ieee.org/lewis-latimer-history-lightbulb-moments\" target=\"_blank\">pioneering engineer</a> of the 19th and early 20th centuries—hopes to reduce bias, better represent underrepresented voices, and prevent results that erase or minimize black and brown cultural data.</p><p class=\"pull-quote\">Hugging Face, the hub for the open-source AI community, lists over 2,700 “conversational” AI models. </p><p>“Data is king,” says <a href=\"https://www.linkedin.com/in/malur/\" rel=\"noopener noreferrer\" target=\"_blank\">Malur Narayan, technology advisor for FutureSum AI</a>. “The only way to create a moat is to have the relevant data for the topic you’re trying to address.”</p><h2>Curating a Different Dataset</h2><p>Large Language Models have proliferated with incredible speed. <a href=\"https://huggingface.co/\" target=\"_blank\">Hugging Face</a>, the hub for the open-source AI community, lists over 2,700 “conversational” AI models. Yet most are trained on similar data (<a href=\"https://commoncrawl.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Common Crawl is a popular source</a>), and many user-facing apps that use an LLM lean on one of several large providers, such as OpenAI and Anthropic. In other words, the vast majority of the AI apps and tools popular right now are rooted in a handful of models trained on similar data.</p><p>Latimer also leans on a popular LLM provider (it uses OpenAI’s ChatGPT as its foundation model) but augments that model with additional data to better represent minority voices. The company has an exclusive partnership with <a href=\"https://amsterdamnews.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>New York Amsterdam News</em></a>, a black-owned newspaper founded in 1909, and works with <a href=\"https://sites.ed.gov/whhbcu/one-hundred-and-five-historically-black-colleges-and-universities/\" target=\"_blank\">historically black colleges and universities</a> to obtain access to both license-free and licensed data.</p><p>“We’re going for any and all available sources and resources, which we believe are more representative and more accurate sources, based on our own judgement, and a set of criteria we use to determine legitimacy,” says Narayan. Latimer’s data has a particular focus on educational and academic sources, as “they’re more likely to be legitimate sources.” With these sources available, Latimer’s engineers can use weighting techniques to adjust the model’s weights to counteract any known biases. </p><p>Narayan says FutureSum isn’t ready to release benchmark results for Latimer yet. But, he adds, the organization hopes to have some available within weeks. <a href=\"https://www.latimer.ai/#waitlist\" rel=\"noopener noreferrer\" target=\"_blank\">The LLM is currently in beta testing</a> and announced its public wait list on 24 January. Those who sign up for the wait list will join students from Alabama’s <a href=\"https://en.wikipedia.org/wiki/Miles_College\" target=\"_blank\">Miles College</a> in testing the model.</p><h2>A New Kind of Generation </h2><p>At its heart, Latimer relies on a technique known as retrieval-augmented generation (RAG). This technique was first described <a href=\"https://arxiv.org/pdf/2005.11401v4.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">in a 2020 paper from researchers at Meta in collaboration with the University College London and New York University</a>. RAG makes it possible for LLMs to verify and update their knowledge by accessing and cross-referencing a second source of data.</p><p>RAG inspired a major shift in how the world’s best LLMs function, Narayan says. It can improve an LLM’s accuracy, help it find and cite a source for data it provides in its response, or unlock access to new data that wasn’t available when the model was trained. IBM <a href=\"https://research.ibm.com/blog/retrieval-augmented-generation-RAG\" target=\"_blank\">offers it as a feature</a> of its Watsonx.ai platform; Microsoft and OpenAI use <a href=\"https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview\" target=\"_blank\">something like it</a> to present Bing search results in Co-Pilot; OpenAI uses <a href=\"https://cookbook.openai.com/examples/vector_databases/pinecone/gen_qa\" target=\"_blank\">something like it</a> to allow for custom GPTs that reference files provided by users.</p><p class=\"pull-quote\">“We’re developing an API, but the most important thing is the key applications. We want to help pharmaceutical companies have better reach into this community for clinical trials, help recruiters attract a black audience, help banking, and finance, and insurance.” <strong>—Malur Narayan, FutureSumAI</strong></p><p>Latimer specifically uses RAG as a lens to focus its ability to detect bias and promote underrepresented voices. “We’re using that not just for recent information, but also to ensure the data itself is more comprehensive when it comes to the topic we’re addressing, “says Narayan. “When a prompt is sent by a user, it first goes into our RAG model to see if that topic is relevant.” That includes preprompting rules to ensure responses are “more accurate and relevant to black history, black culture, and black heritage, and that there’s minimal bias.”</p><p>The approach is sound in theory, but it’s important to check that it works in practice. Narayan says Latimer’s early testing was mostly conducted through manual human feedback including A/B comparisons between its performance and that of the most popular LLMs, such as ChatGPT and Bard. Manual testing is difficult to scale, however, so the company also relies on automated bias-detection tools and comparisons with fairness metrics. This, in part, is what Latimer’s public beta test should help establish, Narayan says, as more users will provide more responses to examine.</p><p>Once testing is complete, Latimer plans to provide an API that any company or organization can use to tap into the LLM. It’s an obvious move from both a technical and business perspective; many organizations offering a commercial LLM eventually offer an API to let developers access it for a fee. For Latimer, however, it’s ultimately about the fulfillment of Latimer’s purpose.</p><p>“We’re developing an API, but the most important thing is the key applications. We want to help pharmaceutical companies have better reach into this community for clinical trials, help recruiters attract a black audience, help banking, and finance, and insurance,” says Narayan. “That’s our end goal. How do we let businesses better communicate with a black audience, or a brown audience.”</p>",[{'name': 'Matthew S. Smith'}],"Wed, 31 Jan 2024 17:30:45 +0000"
2265,Why the AI Boom is a Windfall for Tiny Anguilla,https://spectrum.ieee.org/ai-domains,"<img src=\"https://spectrum.ieee.org/media-library/a-photo-illustration-of-a-man-a-map-and-some-palm-trees.jpg?id=51098577&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C0%2C127\" /><br /><br /><p>The rising popularity of artificial intelligence has impacted the entire world, including the tiny island of Anguilla. Located in the Caribbean, the country, home to about 15,000 people, has a unique and suddenly in-demand resource.</p><p>In the late 1980s, the Internet Assigned Numbers Authority (IANA) assigned countries and regions of geographic interest<a href=\"https://spectrum.ieee.org/the-most-remote-island-in-the-world-is-home-to-seals-seabirds-and-an-internet-toplevel-domain\" target=\"_self\"> their own two-letter domains</a>. Anguilla received .ai, a luck of the draw that is now paying dividends as the country registers website domains for AI companies. <em>IEEE Spectrum </em>spoke with<a href=\"https://en.wikipedia.org/wiki/Vince_Cate\" rel=\"noopener noreferrer\" target=\"_blank\"> Vince Cate</a>, who manages domain registrations for the Anguillan government, on how AI has had an impact on .ai.</p><h3>Vince Cate</h3><br /><p><a href=\"http://offshore.ai/vince/\" rel=\"noopener noreferrer\" target=\"_blank\">Vince Cate</a> is a software developer and the founder of <a href=\"http://datahaven.net/\" rel=\"noopener noreferrer\" target=\"_blank\">DataHaven.Net</a>, which handles sales of the .ai domain for the Anguillan government.</p><p><strong>How did you end up managing the .ai domain?</strong></p><p><strong>Vince Cate: </strong>I came to Anguilla in 1994. I started out doing an email business, because there wasn’t any email or Internet on this island. And I wanted to have a domain name<a href=\"http://offshore.ai/vince/\" rel=\"noopener noreferrer\" target=\"_blank\"> that was .ai</a>. So I reached out to <a href=\"https://spectrum.ieee.org/computer-networking\" target=\"_self\">Jon Postel</a>—he was the one that was in charge of all these top-level domains. He said, there’s nobody running .ai, do you want to run .ai? And I said, “Okay.” That was really how it went!</p><p>At some point, I said, this shouldn’t be in my name, right? So I changed the [IANA] <a href=\"https://www.iana.org/domains/root/db/ai.html\" rel=\"noopener noreferrer\" target=\"_blank\">admin contact</a> to be the government of Anguilla. Somebody else saw that and convinced the government to give it to them, so it went to this company in Taiwan. After a couple of years, they disappeared. They didn’t answer emails or phone calls or anything. And we got it back. A number of small countries got really messed up by losing their domain names, and I would say we kind of came close.</p><p><strong>How did .ai open up for use outside of Anguilla?</strong></p><p><strong>Cate: </strong>This other company came and convinced the government that they could make a lot of money on it. They had this idea, that in Chinese “ài” means love. They thought they<a href=\"https://en.wikipedia.org/wiki/Vanity_domain\" rel=\"noopener noreferrer\" target=\"_blank\"> could market it</a> to [Chinese websites]. At the time, I thought that artificial intelligence was a much better market.</p><p><strong>Has the surge in AI interest been reflected in the number of .ai domains being registered?</strong></p><p><strong>Cate: </strong>November 30 [2022] is when<a href=\"https://spectrum.ieee.org/chatbot-chatgpt-interview\" target=\"_self\"> ChatGPT came out</a>. In the five months after that, our sales went up by almost a factor of four. Then they sort of leveled off at this new, much higher level. It’s just wild—we’re already like a third of the government’s budget.</p><p><strong>Tuvalu is perhaps the first and most well-known example of a country<a href=\"https://www.washingtonpost.com/video-games/2019/12/23/tuvalu-is-tiny-island-nation-people-its-cashing-thanks-twitch/\" rel=\"noopener noreferrer\" target=\"_blank\"> opening up its top-level domain (</a>.tv). Is Anguilla approaching this opportunity differently than that situation?</strong></p><p><strong>Cate: </strong>Tuvalu gave [domain registrations] to a big foreign company, and locked themselves in for 50 years. And we’re doing it locally. So the government is getting almost all the money. And that’s not what was happening in Tuvalu, right? Most of the money was not going to the country.</p><p><em>[Editor’s note: Tuvalu has</em><a href=\"https://theworld.org/stories/2022-01-24/tuvalu-cashes-its-coveted-internet-domain-name-amid-rise-online-streaming\" rel=\"noopener noreferrer\" target=\"_blank\"> <em>recently renegotiated</em></a><em> and is leasing its domain name for more money, but an outside company still manages domain registrations.]</em></p><p><strong>How much money is being brought in by .ai registrations, and how is that affecting Anguilla?</strong></p><p><strong>Cate:</strong> It’s about US $3 million per month. We do the domains for two years, and so all of our money now is new domains. And if we just stay at this level of $3 million per month for new domains, when the renewals kick in a year from now, we’ll just jump to $6 million per month.</p><p>And it’s just part of the general budget—the government can use it however they want. But I’ve noticed that they’ve paid down some of their debt, which is pretty unusual. They’ve eliminated property taxes on residential buildings. So we’re doing well, I would say.</p><p><em>This article appears in the February 2024 print issue as “5 Questions for Vince Cate.”</em><br /></p>",[{'name': 'Michael Koziol'}],"Tue, 30 Jan 2024 17:00:02 +0000"
2266,"Why Rip Off Creatives, if Generative AI Can Play Fair?",https://spectrum.ieee.org/generative-ai-sony-centering-creators,"<img src=\"https://spectrum.ieee.org/media-library/photo-illustration-of-a-smiling-woman-in-front-of-a-colorful-background-of-connected-lines-and-dots.jpg?id=51177842&amp;width=1200&amp;height=800&amp;coordinates=169%2C0%2C83%2C0\" /><br /><br /><p>
	In recent years, AI ethicists have had a tough job. The engineers developing generative AI tools have been racing ahead, competing with one another to create models of even more breathtaking abilities, leaving both regulators and ethicists to comment on what’s already been done.
</p><p>
	One of the people working to shift this paradigm is <a href=\"https://ai.sony/people/Alice-Xiang/\" rel=\"noopener noreferrer\" target=\"_blank\">Alice Xiang</a>, global head of AI ethics at <a href=\"https://www.sony.com/en/\" target=\"_blank\">Sony</a>. Xiang has worked to create an ethics-first process in AI development within Sony and in the larger AI community. She spoke to <em>IEEE </em><em>Spectrum</em> about starting with the data and whether Sony, with half its business in content creation, could play a role in building a new kind of generative AI.
</p><p class=\"rm-anchors\" id=\"top\">Alice Xiang on...</p><ol>
<li><a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#data\">Responsible data collection</a></li>
<li><a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#sony\">Her work at Sony</a></li>
<li><a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#regulations\">The impact of new AI regulations</a></li>
<li><a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#creator\">Creator-centric generative AI </a></li>
</ol><h2 class=\"rm-anchors\" id=\"data\">Responsible data collection</h2><p><strong>What’s the origin of your work on <a href=\"https://neurips.cc/virtual/2023/oral/73743\" target=\"_blank\">responsible data collection</a>? And in that work, why have you focused specifically on computer vision?<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#_msocom_1\" rel=\"noopener noreferrer\" target=\"_blank\"></a>
</strong></p><p>
<strong>Alice Xiang: </strong>In recent years, there has been a growing awareness of the importance of looking at AI development in terms of entire life cycle, and not just thinking about AI ethics issues at the endpoint. And that’s something we see in practice as well, when we’re doing AI ethics evaluations within our company: How many AI ethics issues are really hard to address if you’re just looking at things at the end. A lot of issues are rooted in the data-collection process—issues like consent, privacy, fairness, intellectual property. And a lot of AI researchers are not well equipped to think about these issues. It’s not something that was necessarily in their curricula when they were in school.
</p><p>
	In terms of <a href=\"https://spectrum.ieee.org/tag/generative-ai\" rel=\"noopener noreferrer\" target=\"_blank\">generative AI</a>, there is growing awareness of the importance of training data being not just something you can take off the shelf without thinking carefully about where the data came from. And we really wanted to explore what practitioners should be doing and what are best practices for data curation. Human-centric computer vision is an area that is arguably one of the most sensitive for this because you have biometric information.
</p><p><strong>The term “human-centric computer vision”: Does that mean <a href=\"https://spectrum.ieee.org/tag/computer-vision\" rel=\"noopener noreferrer\" target=\"_blank\">computer vision</a> systems that recognize human faces or human bodies?
</strong></p><p>
<strong>Xiang: </strong>Since we’re focusing on the data layer, the way we typically define it is any sort of [computer vision] data that involves humans. So this ends up including a much wider range of AI. If you wanted to create a model that recognizes objects, for example—objects exist in a world that has humans, so you might want to have humans in your data even if that’s not the main focus. This kind of technology is very ubiquitous in both high- and low-risk contexts.
</p><p class=\"pull-quote\">
	“A lot of AI researchers are not well equipped to think about these issues. It’s not something that was necessarily in their curricula when they were in school.” <strong>—Alice Xiang, Sony</strong></p><p><strong>What were some of your findings about best practices in terms of privacy and fairness?
</strong></p><p>
<strong>Xiang:</strong> The current baseline in the human-centric computer vision space is not great. This is definitely a field where researchers have been accustomed to using large Web-scraped datasets that do not have any consideration of these ethical dimensions. So when we talk about, for example, privacy, we’re focused on: Do people have any concept of their data being collected for this sort of use case? Are they informed of how the datasets are collected and used? And this work starts by asking: Are the researchers really thinking about the purpose of this data collection? This sounds very trivial, but it’s something that usually doesn’t happen. People often use datasets as available, rather than really trying to go out and source data in a thoughtful manner.
</p><p>
	This also connects with <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4068921\" rel=\"noopener noreferrer\" target=\"_blank\">issues of fairness</a>. How broad is this data collection? When we look at this field, most of the major datasets are extremely U.S.-centric, and a lot of biases we see are a result of that. For example, researchers have found that object-detection models tend to work far worse in lower-income countries versus higher-income countries, because most of the images are sourced from higher-income countries. Then on a human layer, that becomes even more problematic if the datasets are predominantly of Caucasian individuals and predominantly male individuals. A lot of these problems become very hard to fix once you’re already using these [datasets].
</p><p>
	So we start there, and then we go into much more detail as well: If you were to collect a data set from scratch, what are some of the best practices? [Including] these purpose statements, the types of consent and best practices around human-subject research, considerations for vulnerable individuals, and thinking very carefully about the attributes and metadata that are collected.
</p><p><strong>I recently read <a href=\"https://spectrum.ieee.org/joy-buolamwini\" rel=\"noopener noreferrer\" target=\"_blank\">Joy Buolamwini’</a>s book <em>Unmasking AI</em>, in which she documents her painstaking process to put together a dataset that felt ethical. It was really impressive. Did you try to build a dataset that felt ethical in all the dimensions?
</strong></p><p>
<em><strong></strong></em><strong>Xiang</strong>: Ethical data collection is an important area of focus for our research, and we have additional recent work on some of the challenges and opportunities for building more ethical datasets, such as the need for improved <a href=\"https://ai.sony/blog/blog-037/\" rel=\"noopener noreferrer\" target=\"_blank\">skin-tone annotations</a> and <a href=\"https://ai.sony/publications/Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data/\" rel=\"noopener noreferrer\" target=\"_blank\">diversity in computer vision</a>. As our own ethical data collection continues, we will have more to say on this subject in the coming months.<em></em>
</p><p>
<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#top\">back to top</a>
</p><h2 class=\"rm-anchors\" id=\"sony\">Her work at Sony</h2><p><strong>How does this work manifest within Sony? Are you working with internal teams who have been using these kinds of datasets? Are you saying they should stop using them?
</strong></p><p>
<strong>Xiang: </strong>An important part of our ethics assessment process is asking folks about the datasets they use. The governance team that I lead spends a lot of time with the business units to talk through specific use cases. For particular datasets, we ask: What are the risks? How do we mitigate those risks? This is especially important for bespoke data collection. In the research and academic space, there’s a primary corpus of datasets that people tend to draw from, but in industry, people are often creating their own bespoke datasets.
</p><p class=\"pull-quote\">“I think with everything AI ethics related, it’s going to be impossible to be purists.” <strong>—Alice Xiang, Sony</strong></p><p><strong>I know you’ve spoken about AI ethics by design. Is that something that’s in place already inside Sony? Are AI ethics talked about from the beginning stages of a product or a use case?
</strong></p><p>
<strong>Xiang:</strong> Definitely. There are a bunch of different processes, but the one that’s probably the most concrete is our process for all our different electronics products. For that one, we have several checkpoints as part of the standard quality-management system. This starts in the design and planning stage, and then goes to the development stage, and then the actual release of the product. As a result, we are talking about AI ethics issues from the very beginning, even before any sort of code has been written, when it’s just about the idea for the product.
</p><p>
<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#top\">back to top</a>
</p><h2 class=\"rm-anchors\" id=\"regulations\">The impact of new AI regulations</h2><p><strong>There’s been a lot of action recently on <a href=\"https://spectrum.ieee.org/ai-regulation-worldwide\" rel=\"noopener noreferrer\" target=\"_blank\">AI regulations</a> and governance initiatives around the world. <a href=\"https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117\" rel=\"noopener noreferrer\" target=\"_blank\">China</a> already has AI regulations, the EU passed its <a href=\"https://artificialintelligenceact.eu/\" rel=\"noopener noreferrer\" target=\"_blank\">AI Act</a>, and here in the United States we had President <a href=\"https://spectrum.ieee.org/biden-ai-executive-order\" rel=\"noopener noreferrer\" target=\"_blank\">Biden’s executive order</a>. Have those changed either your practices or your thinking about product design cycles?
</strong></p><p>
<strong>Xiang:</strong> Overall, it’s been very helpful in terms of increasing the relevance and visibility of AI ethics across the company. Sony’s a unique company in that we are simultaneously a major technology company, but also a major content company. A lot of our business is entertainment, including films, music, video games, and so forth. We’ve always been working very heavily with folks on the technology-development side. Increasingly we’re spending time talking with folks on the content side, because now there’s a huge interest in AI in terms of the artists they represent, the content they’re disseminating, and how to protect rights.
</p><p class=\"pull-quote\">“When people say ‘go get consent,’ we don’t have that debate or negotiation of what is reasonable.” <strong>—Alice Xiang, Sony</strong></p><p>
	Generative AI has also dramatically impacted that landscape. We’ve seen, for example, one of our executives at <a href=\"https://www.sonymusic.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Sony Music</a> making <a href=\"https://musically.com/2023/11/30/sony-musics-kooker-slams-distorted-view-of-copyright-in-ai-debate/\" rel=\"noopener noreferrer\" target=\"_blank\">statements</a> about the importance of <a href=\"https://www.schumer.senate.gov/imo/media/doc/Dennis%20Kooker%20-%20Statement1.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">consent, compensation, and credit</a> for artists whose data is being used to train AI models. So [our work] has expanded beyond just thinking of AI ethics for specific products, but also the broader landscapes of rights, and how do we protect our artists? How do we move AI in a direction that is more creator-centric? That’s something that is quite unique about Sony, because most of the other companies that are very active in this AI space don’t have much of an incentive in terms of protecting data rights.
</p><p>
<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#top\">back to top</a>
</p><h2 class=\"rm-anchors\" id=\"creator\">Creator-centric generative AI </h2><p><strong>I’d love to see what more creator-centric AI would look like. Can you imagine it being something in which the people who make generative AI models get consent or compensate artists if they train on their material?
</strong></p><p>
<strong>Xiang: </strong>It’s a very challenging question. I think this is one area where our work on ethical data curation can hopefully be a starting point, because we see the same problems in generative AI that we see for more classical AI models. Except they’re even more important, because it’s not only a matter of whether my image is being used to train a model, now [the model] might be able to generate new images of people who look like me, or if I’m the copyright holder, it might be able to generate new images in my style. So a lot of these things that we’re trying to push on—consent, fairness, IP, and such—they become a lot more important when we’re thinking about [generative AI]. I hope that both our past research and future research projects will be able to really help.
</p><p><strong>Are you able to say whether Sony is developing generative AI models?
</strong></p><p class=\"pull-quote\">“I don’t think we can just say, ‘Well, it’s way too hard for us to solve today, so we’re just going to try to filter the output at the end.’ ” <strong>—Alice Xiang, Sony</strong></p><p>
<em><strong></strong></em><strong>Xiang</strong>: I can’t speak for all of Sony, but certainly we believe that AI technology, including generative AI, has the potential to augment human creativity. In the context of my work, we think a lot about the need to respect the rights of stakeholders, including creators, through the building of AI systems that creators can use with peace of mind.<em></em>
</p><p><strong>I’ve been thinking a lot lately about generative AI’s <a href=\"https://spectrum.ieee.org/midjourney-copyright\" target=\"_blank\">problems with copyright and IP</a>. Do you think it’s something that can be patched with the Gen AI systems we have now, or do you think we really need to start over with how we train these things? And this can be totally your opinion, not Sony’s opinion.
</strong></p><p>
<strong>Xiang:</strong> In my personal opinion, I think with everything AI ethics related, it’s going to be impossible to be purists. Even though we are pushing very strongly for these best practices, we also acknowledge in all our research papers just how insanely difficult this is. If you were to, for example, uphold the highest practices for obtaining consent, it’s difficult to imagine that you could have datasets of the magnitude that a lot of the models nowadays require. You’d have to maintain relationships with billions of people around the world in terms of informing them of how their data is being used and letting them revoke consent.
</p><p>
	Part of the problem right now is when people say “go get consent,” we don’t have that debate or negotiation of what is reasonable. The tendency becomes either to throw the baby out with the bathwater and ignore this issue, or go to the other extreme, and not have the technology at all. I think the reality will always have to be somewhere in between.
</p><p>
	So when it comes to these issues of reproduction of IP-infringing content, I think it’s great that there’s a lot of research now being done on this specific topic. There are a lot of patches and filters that people are proposing. That said, I think we also will need to think more carefully about the data layer as well. I don’t think we can just say, “Well, it’s way too hard for us to solve today, so we’re just going to try to filter the output at the end.”
</p><p>
	We’ll ultimately see what shakes out in terms of the courts, in terms of whether this is going to be okay from a <a href=\"https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html\" rel=\"noopener noreferrer\" target=\"_blank\">legal perspective</a>. But from an ethics perspective, I think we’re at a point where there needs to be deep conversations on what is reasonable in terms of the relationships between companies that benefit from AI technologies and the people whose works were used to create it. My hope is that Sony can play a role in those conversations.
</p><p>
<a href=\"https://spectrum.ieee.org/feeds/topic/artificial-intelligence.rss#top\">back to top</a>
</p>",[{'name': 'Eliza Strickland'}],"Sun, 28 Jan 2024 14:00:02 +0000"
2267,Google’s New AI Is Learning to Diagnose Patients,https://spectrum.ieee.org/ai-doctor,"<img src=\"https://spectrum.ieee.org/media-library/photo-illustration-of-a-network-and-a-stethoscope.jpg?id=51177447&amp;width=1200&amp;height=800&amp;coordinates=140%2C0%2C140%2C0\" /><br /><br /><p>Navigating health care systems as a patient can be daunting at the best of times, whether you’re interpreting jargon-filled diagnoses or determining which specialists to see next. Similarly, doctors often have grueling schedules that make it difficult to offer personalized attention to all their patients. These issues are only exacerbated in areas with limited physicians and medical infrastructure.<strong><del></del></strong></p><p>Bringing AI into the doctor’s office to alleviate these problems is a dream that researchers have been working toward since IBM’s Watson made its debut over a decade ago, but <a href=\"https://spectrum.ieee.org/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care\" target=\"_self\">progress toward these goals</a> has been slow-moving. Now, large language models (LLMs),<a href=\"https://spectrum.ieee.org/chatgpt-medical-exam\" target=\"_self\"> including ChatGPT</a>, could have the potential to reinvigorate those ambitions.</p><p>The team behind <a href=\"https://spectrum.ieee.org/googles-deep-mind-boosts-memory-to-navigate-london-underground\" target=\"_blank\">Google DeepMind</a> have proposed a new AI model called AMIE (Articulate Medical Intelligence Explorer), in a recent <a href=\"https://arxiv.org/abs/2401.05654\" target=\"_blank\">preprint paper</a> published 11 January on arXiv. The model could take in information from patients and provide clear explanations of medical conditions in a wellness visit consultation.</p><p><a href=\"https://www.linkedin.com/in/vivek-natarajan-a3670118/\" rel=\"noopener noreferrer\" target=\"_blank\">Vivek Natarajan</a> is an AI researcher at Google and lead author on the recent paper. He says that while AMIE isn’t designed to replace human physicians, he does believe a similar AI could play a role in assisting both physicians and patients.</p><p>“There may be scenarios when people might benefit from interacting with systems like AMIE as part or in addition to their clinical journeys,” Natarajan says. “These include understanding symptoms and conditions better, including simplifying explanations in local vernaculars…and acting as a valuable second opinion.”</p><p class=\"pull-quote\">“This, in turn, potentially provides a pathway for medical AI towards superhuman diagnostic performance.” <strong>—Vivek Natarajan, Google</strong></p><p><a href=\"https://geiselmed.dartmouth.edu/faculty/facultydb/view.php/?uid=8274\" rel=\"noopener noreferrer\" target=\"_blank\">Thomas Thesen</a> is an associate professor of medical education at Dartmouth’s Geisel School of Medicine who created the <a href=\"https://home.dartmouth.edu/news/2024/01/geisel-professor-harnesses-ai-act-patient\" target=\"_blank\">AI Patient Actor</a> app to help train medical students on diverse patient scenarios. While he thinks AI will play an increasingly larger role in health care, he doesn’t believe it will replace the expertise of human physicians. </p><p>“What I see coming in the next decade is AI increasingly supporting doctors by streamlining their work and contributing to certain limited diagnostic processes,” Thesen says. “However, the expert judgment of a trained doctor will remain crucial for final diagnosis and treatment plans.”</p><p>To bring AMIE up to speed without sending it through medical school, Natarajan and colleagues started by feeding the AI on real-world medical texts, including the transcripts of nearly 100,000 real physician-patient dialogues, 65 clinician-written summaries of intensive care unit medical notes, and thousands of medical reasoning questions taken from the <a href=\"https://en.wikipedia.org/wiki/United_States_Medical_Licensing_Examination\" target=\"_blank\">United States Medical Licensing Examination</a>.</p><p>Yet, these data alone were not enough to set AMIE up for success, Natarajan says, particularly because the data tend to be noisy and capture only a small subset of potential medical scenarios. To fill in these gaps, the team also used a simulated diagnostic environment that allowed AMIE to learn from its own mistakes through two different “self-play” loops.</p><p>“The environment included two self-play loops—an ‘inner’ self-play loop, where AMIE leveraged in-context critic feedback to refine its behavior on simulated conversations with an AI patient simulator, and an ‘outer’ self-play loop where the set of refined simulated dialogues were incorporated into subsequent fine-tuning iterations,” Natarajan says. “The resulting new version of AMIE could then participate in the inner loop again, creating a virtuous continuous learning cycle.”</p><p>While Natarajan stresses that there is no substitute for real human experience in medicine, this training model does give AMIE a leg up in some ways over human physicians. For example, a human physician may see only 10,000 patients in their career, but AMIE could “see” that many patients in just a couple of training cycles.</p><p>“This, in turn, potentially provides a pathway for medical AI towards superhuman diagnostic performance,” Natarajan says.</p><p>To see how well AMIE stacked up against human physicians, Natarajan and colleagues pitted it against 20 human primary-care providers in a blind and randomly controlled trial to consult with patient actors located in Canada, India, and the United Kingdom. There were 149 different consults conducted via live texting and evaluated by both the patient actors and human specialists. </p><p class=\"pull-quote\">“The expert judgment of a trained doctor will remain crucial for final diagnosis and treatment plans.” <strong>—Thomas Thesen, Dartmouth</strong></p><p>The consults were measured using several factors, including perceived empathy, openness and honesty, diagnostic accuracy, and management planning. Both the patient actors and specialists determined that AMIE provided “greater diagnostic accuracy and superior performance” compared to their human counterparts. However, these results are not necessarily as black and white as they sound.</p><p>For one thing, these consults were completed using the type of live, text-based chats that are typically used to communicate with LLMs. However, this format is very different from the type of face-to-face interaction that human physicians are used to, potentially offering AMIE an advantage. The team found that AMIE also tended to write significantly longer responses than human physicians, which they believe could be interpreted as more time-intensive—and thus thoughtful and empathetic—by patients.</p><p>Going forward, Natarajan says he and colleagues are interested in expanding AMIE’s capabilities to include multimodal sources, such as video chats. The team will also look at problems of equity, fairness, and adversarial testing to better prepare AMIE for the real world.</p><p>As for the human physicians anticipating AMIE’s arrival, Thesen says it’s important that they proactively prepare for how this technology could change medicine.</p><p>“Medical schools have a responsibility to incorporate AI literacy into their curriculum,” Thesen says. “This includes understanding the ethical implications to ensure that as AI becomes more integrated into clinical practice, future doctors can use it responsibly and protect their patients’ well-being.”</p>",[{'name': 'Sarah Wells'}],"Thu, 25 Jan 2024 20:49:41 +0000"
2268,AI-Powered Proof Generator Helps Debug Software,https://spectrum.ieee.org/ai-debug-software,"<img src=\"https://spectrum.ieee.org/media-library/blue-pixelated-1-s-and-0-s-with-error-text-in-middle.jpg?id=51167174&amp;width=1200&amp;height=800&amp;coordinates=0%2C125%2C0%2C125\" /><br /><br /><p>Not all <a href=\"https://spectrum.ieee.org/tag/Software\" target=\"_self\">software</a> is perfect—many apps, programs, and websites are released despite bugs. But the software behind critical systems like <a href=\"https://spectrum.ieee.org/tag/encryption\" target=\"_self\">cryptographic protocols</a>, <a href=\"https://spectrum.ieee.org/topic/biomedical/\" target=\"_self\">medical devices</a>, and <a href=\"https://spectrum.ieee.org/topic/aerospace/\" target=\"_self\">space shuttles</a> must be error-free, and ensuring the <a href=\"https://spectrum.ieee.org/tla\" target=\"_self\">absence of bugs</a> requires going beyond code reviews and testing. It requires formal verification.</p><p><a href=\"https://www.sciencedirect.com/topics/computer-science/formal-verification\" rel=\"noopener noreferrer\" target=\"_blank\">Formal verification</a> involves writing a mathematical proof of your code and is “one of the hardest but also most powerful ways of making sure your code is correct,” says <a href=\"https://people.cs.umass.edu/~brun/\" rel=\"noopener noreferrer\" target=\"_blank\">Yuriy Brun</a>, a professor<strong> </strong>at the <a href=\"https://www.umass.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Massachusetts Amherst</a>.</p><p>To make formal verification easier, Brun and his colleagues devised a new AI-powered method called Baldur to automatically generate proofs. The accompanying <a href=\"https://dl.acm.org/doi/10.1145/3611643.3616243\" rel=\"noopener noreferrer\" target=\"_blank\">paper</a>, presented in December 2023 at the <a href=\"https://2023.esec-fse.org/\" rel=\"noopener noreferrer\" target=\"_blank\">ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering</a> in San Francisco, won a <a href=\"https://2023.esec-fse.org/info/awards\" rel=\"noopener noreferrer\" target=\"_blank\">Distinguished Paper award</a>. The team includes <a href=\"https://people.cs.umass.edu/~efirst/\" rel=\"noopener noreferrer\" target=\"_blank\">Emily First</a>, who completed the study as part of her doctoral dissertation at UMass Amherst; Markus Rabe, a former researcher at <a href=\"https://spectrum.ieee.org/tag/Google\" target=\"_self\">Google</a>, where the study was conducted; and <a href=\"https://dependenttyp.es/\" rel=\"noopener noreferrer\" target=\"_blank\">Talia Ringer</a>, an assistant professor at the <a href=\"https://illinois.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Illinois Urbana-Champaign</a>.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\">
<img alt=\"text with arrows and boxes\" class=\"rm-shortcode rm-resized-image\" id=\"3bb58\" src=\"https://spectrum.ieee.org/media-library/text-with-arrows-and-boxes.jpg?id=51167083&amp;width=980\" />
<small class=\"image-media media-caption\">   This flowchart shows at a high level how Baldur generates a proof. </small><small class=\"image-media media-photo-credit\">    University of Massachusetts/    University of Illinois Urbana-Champaign </small></p><p>Baldur is powered by Google’s <a href=\"https://blog.research.google/2022/06/minerva-solving-quantitative-reasoning.html\" rel=\"noopener noreferrer\" target=\"_blank\">Minerva</a> large language model (<a href=\"https://spectrum.ieee.org/tag/llms\" target=\"_self\">LLM</a>)—which was trained on scientific papers and Web pages containing mathematical expressions—and fine-tuned on data about proofs and theorems. Baldur works with <a href=\"https://isabelle.in.tum.de/\" rel=\"noopener noreferrer\" target=\"_blank\">Isabelle</a>, a proof assistant or automated theorem prover,<strong> </strong>to check its proofs. When given a theorem statement, Baldur is able to generate an entire proof almost 41 percent of the time.</p><p>To boost Baldur’s success, the team fed the model additional contextual information—such as other definitions or the lines preceding the theorem statement in a theory file—and found that the proof rate increased to 47.5 percent. This means that Baldur is able to take the context and use it to predict a new correct proof, says First. Similar to a programmer who may be better equipped to fix a bug in a method when they know how that method relates to its surrounding code and the other methods in the same class, Baldur can perform better with extra context.</p><p><a href=\"https://arxiv.org/abs/2205.10893\" rel=\"noopener noreferrer\" target=\"_blank\">Thor</a>, the current state-of-the-art tool for automatic proof generation, has a higher proof rate at 57 percent. Baldur’s advantage lies in its ability to generate whole proofs; Thor predicts the next step in a proof using a smaller language model combined with a method that searches the space of possible proofs. But when Thor and Baldur (<a href=\"https://en.wikipedia.org/wiki/Baldr\" target=\"_blank\">Thor’s brother</a> in Norse mythology) work together, the pair can generate correct proofs nearly 66 percent of the time.</p><p>The team also discovered that Baldur can “repair” its own proofs, further improving its proof rate. When provided with its previous failed attempt plus the error message returned by Isabelle, Baldur can turn its wrong proof into a right one.</p><p>“The fact that the error message helped so much was surprising,” Brun says. “[It] suggests that there’s more useful information that could potentially be fed into the large language model to give better answers. We’re just scratching the surface.”</p><p>The team has yet to find the right amount of information that would be deemed valuable for the model. “One limitation is that we’re giving it some information around the proof that it’s trying to generate, but we don’t know what’s the limit and where it stops being useful,” says Brun. And there’s still a considerable degree of error, which he hopes can be improved by fine-tuning the model using more datasets that better explain what a proof looks like and what a theorem and proof pair look like.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\">
<img alt=\"text with different color highlights, arrows and boxes\" class=\"rm-shortcode rm-resized-image\" id=\"86f54\" src=\"https://spectrum.ieee.org/media-library/text-with-different-color-highlights-arrows-and-boxes.jpg?id=51167151&amp;width=980\" />
<small class=\"image-media media-caption\">This flowchart shows how the proof repair model creates new training data for Baldur.</small><small class=\"image-media media-photo-credit\">University of Massachusetts/ University of Illinois Urbana-Champaign</small></p><p>In terms of next steps, First is looking at implementing the approach used for Baldur in other proof assistants, as well as uncovering ways to more smartly gather contextual information that can help enhance the model’s accuracy. The team envisions Baldur helping simplify the jobs of <a href=\"https://proofengineering.org/\" rel=\"noopener noreferrer\" target=\"_blank\">proof engineers</a>, who are tasked with, for example, <a href=\"https://www.darpa.mil/program/proof-engineering-adaptation-repair-and-learning-for-software\" rel=\"noopener noreferrer\" target=\"_blank\">formal verification of national security systems</a> at organizations like the U.S. Department of Defense and its Defense Advanced Research Projects Agency (DARPA).</p><p>On a broader scale, the team is planning on getting feedback from software developers to see how tools like Baldur can help them—be it through debugging an error in their code, refining specifications, or creating a higher-quality system.</p><p>“There’s a lot of power in building interactive tools where a developer is trying to prove some property of their code,” Brun says. “Understanding how developers can interact with these tools and supporting them by building automated approaches can take them even farther.”</p>",[{'name': 'Rina Diane Caballar'}],"Thu, 25 Jan 2024 16:30:03 +0000"
2269,Weighing the Prophecies of AI Doom,https://spectrum.ieee.org/ai-existential-risk-survey,"<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-a-person-running-away-from-a-tornado-shape-full-of-code.jpg?id=51164800&amp;width=1200&amp;height=800&amp;coordinates=0%2C8%2C0%2C9\" /><br /><br /><p>As the steady hum of artificial intelligence activity carries on from 2023 into the new year, the research group <a href=\"https://aiimpacts.org/#gsc.tab=0\" target=\"_blank\">AI Impacts</a> has released the results of their <a href=\"https://blog.aiimpacts.org/p/2023-ai-survey-of-2778-six-things\" target=\"_blank\">most recent outlook survey</a> among AI researchers and engineers. Their <a href=\"https://arxiv.org/abs/2401.02843\" target=\"_blank\">accompanying preprint</a> (not peer reviewed as of press time) details the results. The group’s analysis of their 2023 Expert Survey on Progress in AI summarizes responses of 2,788 AI researchers to a series of questions regarding the present and far future of AI research.</p><p class=\"pull-quote\">“When will particular things happen in the future? Is there a risk of bad things happening? In practice, we’re interested in human extinction.”<br /><strong>—Katja Grace, AI Impacts</strong></p><p>The 2023 survey follows AI Impact’s <a href=\"https://wiki.aiimpacts.org/doku.php?id=ai_timelines:predictions_of_human-level_ai_timelines:ai_timeline_surveys:2022_expert_survey_on_progress_in_ai\" target=\"_blank\">2022 survey</a>, whose median participant reasoned the likelihood of AI-caused “human extinction or similarly permanent and severe disempowerment of the human species” at 5 percent. The likelihood of that same extinction or subjugation resulting from “human inability to control future advanced AI systems” was at a median 10 percent. The median responses to those same questions in the 2023 survey were unchanged, while the median 2023 prediction for AI-driven extinction by the year 2100 was 5 percent.<br /></p><p>AI Impacts has been conducting this survey since 2016. <a href=\"https://www.fhi.ox.ac.uk/team/katja-grace/\" target=\"_blank\">Katja Grace</a>, one of the organization’s cofounders and current lead researcher, started the group to map out potential consequences of advancing AI technology. “We’re trying to answer decision-relevant questions about the future of AI,” says Grace. “When will particular things happen in the future? Is there a risk of bad things happening? In practice, we’re interested in human extinction.” </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A chart showing a curving red line above a curving blue line representing an increase of probability over time.\" class=\"rm-shortcode\" id=\"e6326\" src=\"https://spectrum.ieee.org/media-library/a-chart-showing-a-curving-red-line-above-a-curving-blue-line-representing-an-increase-of-probability-over-time.jpg?id=51164862&amp;width=980\" />
<small class=\"image-media media-caption\">Aggregate and representative responses are graphed here to AI researchers’ projections of the “full automation of labor” (FAOL).  </small><small class=\"image-media media-photo-credit\">AI Impacts</small></p><p>The group runs their now-annual surveys to sample the opinion of the AI research community regarding those consequences. “We are most interested in timelines. We ask about narrow things that will likely happen sooner, which I trust more as straightforward information about what’s plausible,” says Grace. “For longer goals, the numbers are so all over the place that I don’t expect to learn what date they’ll happen, but more expect to learn what the feeling is in the AI community.” Grace goes on to state that mood has some dark corners. “From the survey it’s somewhat hard to judge what the overall mood is, but it seems like there is a fairly widespread belief that there is non-negligible risk of AI destroying humanity in the long run. I have less of a sense of with what mood that belief is held.”</p><p class=\"pull-quote\">“They marketed it, framed it, as ‘the leading AI researchers believe…something,’ when in fact the demographic includes a variety of students.”<br /><strong>—Nirit Weiss-Blatt, author, The Techlash</strong></p><p>Since its founding, AI Impacts has attracted substantial attention for the more alarming results produced from its surveys. The group—currently listing seven contributors on its website—has also received <a href=\"https://openbook.fyi/org/AI%20Impacts\" target=\"_blank\">at least US $2 million in funding</a> as of December 2022. This funding came from a number of individuals and philanthropic associations connected to the <a href=\"https://en.wikipedia.org/wiki/Effective_altruism\" target=\"_blank\">effective altruism movement</a> and concerned with the potential existential risk of artificial intelligence. This includes <a href=\"https://www.openphilanthropy.org/\" target=\"_blank\">Open Philanthropy</a>, technologist <a href=\"https://www.cser.ac.uk/team/jaan-tallinn/\" target=\"_blank\">Jaan Tallinn</a>, and the now-defunct <a href=\"https://www.reuters.com/technology/collapse-ftx-deprives-academics-grants-stokes-fears-forced-repayment-2023-04-06/\" target=\"_blank\">FTX Future Fund</a>. AI Impacts operates within the <a href=\"https://intelligence.org/\" target=\"_blank\">Machine Intelligence Research Institute</a>, an AI existential risk research group codirected by <a href=\"https://en.wikipedia.org/wiki/Eliezer_Yudkowsky\" target=\"_blank\">Eliezer Yudkowsky</a>. Yudkowsky has previously called for bringing a <a href=\"https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/\" target=\"_blank\">decisive and potentially violent end</a> to advanced AI research.</p><p>The 2023 survey also asked participants to estimate the likelihoods and development timelines of a number of AI research milestones. Participants predicted that some AI tasks—generating functional software in <a href=\"https://spectrum.ieee.org/python-programming\" target=\"_blank\">Python</a>, creating a “random video game,” writing a top-40 pop song—were likely achievable by the end of the decade. Arguably, <a href=\"https://spectrum.ieee.org/large-language-models-size\" target=\"_blank\">LLM</a> code generation has already achieved the first of those. Other goals, like <a href=\"https://www.youtube.com/watch?v=a_YGPbWJO5g\" target=\"_blank\">winning a 5K road race as a bipedal robot</a> or <a href=\"https://spectrum.ieee.org/this-year-autonomous-trucks-will-take-to-the-road-with-no-one-on-board\" target=\"_blank\">fully automating the work of long-haul truck drivers</a> were given longer median timeframes by the researchers.</p><p class=\"pull-quote\">“What they are doing is running a well-funded panic campaign. So, that’s not good journalism.”<br /><strong>—Nirit Weiss-Blatt</strong></p><p>The 2022 survey’s participant-selection methods were criticized for being skewed and narrow. AI Impacts sent the survey to 4,271 people—738 responded—whose research was published at the <a href=\"https://nips.cc/Conferences/2021\" target=\"_blank\">2021 machine-learning conferences Neural Information Processing Society</a> (NeurIPS) and the <a href=\"https://icml.cc/\" target=\"_blank\">International Conference on Machine Learning</a> (ICML). Communication researcher and prominent IT <a href=\"https://www.niritweissblatt.com/\" target=\"_blank\">author</a> Nirit Weiss-Blatt, who was <a href=\"https://www.aipanic.news/p/the-ai-panic-campaign-part-1\" target=\"_blank\">publicly critical</a> of the survey, points out that this approach created a skewed survey population. “People that send papers to those conferences, they can be undergrads and grad students,” says Weiss-Blatt. “They marketed it, framed it, as ‘the leading AI researchers believe…something,’ when in fact the demographic includes a variety of students.” AI Impacts changed its selection criteria in the 2023 survey, sending surveys to the participants of a larger number of machine-learning conferences and only to participants with a Ph.D.</p><p>Beyond methodological issues, Weiss-Blatt points out how the survey plays into the current media coverage and public opinion of AI. “The coverage of AI becomes crazy because of <a href=\"https://www.newscientist.com/article/2410839-theres-a-5-chance-of-ai-causing-humans-to-go-extinct-say-scientists/\" target=\"_blank\">headlines</a> like ‘There’s a 5 percent chance of AI causing humans to go extinct, say scientists,’ ” says Weiss-Blatt. “When a regular person sees that, then they think they should panic as well. What they are doing is running a well-funded panic campaign. So, that’s not good journalism. A better representation of this survey would indicate that it was funded, phrased, and analyzed by ‘x-risk’ effective altruists. Behind ‘AI Impacts’ and other ‘AI Safety’ organizations, there’s a well-oiled ‘x-risk’ machine. When the media is covering them, it has to mention it.”</p><p>AI Impacts plans to continue adapting their surveys in response to future criticisms. For the coming 2024 survey, the group has reached out to external sources for advice. “A different thing we’ve done this time was try to run the methodology by more people,” says Grace. “We sent it to Nate Silver because he’s more of an expert in this field than us, probably. He said it was great.” Silver confirmed his involvement when contacted by <em>IEEE Spectrum</em>. </p>",[{'name': 'Michael Nolan'}],"Thu, 25 Jan 2024 13:00:03 +0000"
2270,A How-To Guide on Acquiring AI Systems,https://spectrum.ieee.org/guide-on-acquiring-ai-systems,"<img src=\"https://spectrum.ieee.org/media-library/a-group-of-people-in-front-of-screens-related-to-ai-and-purchasing.jpg?id=51172897&amp;width=1200&amp;height=800&amp;coordinates=126%2C0%2C0%2C0\" /><br /><br /><p><a href=\"https://www.idc.com/getdoc.jsp?containerId=prUS49670322\" rel=\"noopener noreferrer\" target=\"_blank\">International Data Corp.</a> estimated that US $118 billion was spent globally in 2022 to purchase artificial intelligence hardware, software, and data services. IDC has predicted the figure will nearly triple, to $300 billion, by 2026. But <a href=\"https://www.oecd.org/gov/public-procurement/\" rel=\"noopener noreferrer\" target=\"_blank\">public procurement</a> systems are not ready for the challenges of procuring AI systems, which bring with them new risks to citizens.</p><p>To help address this challenge <a href=\"https://standards.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Standards Association</a> has introduced a pioneering standard for AI procurement. The standard, which is in development, can help government agencies be more responsible about how they acquire AI that serves the public interest.</p><p>Governments today are using AI and <a href=\"https://automatingsociety.algorithmwatch.org/wp-content/uploads/2020/12/Automating-Society-Report-2020.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">automated decision-making</a> systems to <a href=\"https://epic.org/wp-content/uploads/2023/09/FINAL-EPIC-Outsourced-Automated-Report-w-Appendix-Updated-9.26.23.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">aid or replace human-made decisions</a>. The ADM systems’ judgments can impact citizens’ access to education, employment, health care, social services, and more.</p><p>The multilayered <a href=\"https://academic.oup.com/edited-volume/41989/chapter-abstract/355438981?redirectedFrom=fulltext&amp;login=false\" rel=\"noopener noreferrer\" target=\"_blank\">complexity</a> of AI systems, and the datasets they’re built on, challenge people responsible for procurement—who rarely <a href=\"https://doi.org/10.1007/s00146-022-01572-2\" rel=\"noopener noreferrer\" target=\"_blank\">understand</a> the systems they’re purchasing and deploying. The vast majority of government procurement models worldwide have yet to adapt their acquisition processes and laws to the systems’ complexity.</p><p>To assist government agencies in being better stewards of public-use technology, in 2021 the IEEE Standards Association approved the development of a new type of socio-technical standard, the IEEE <a href=\"https://standards.ieee.org/ieee/3119/10729/\" rel=\"noopener noreferrer\" target=\"_blank\">P3119 Standard for the Procurement of AI and Automated Decision Systems</a>. The standard was inspired by the findings of the <a href=\"https://archive.nyu.edu/handle/2451/62255\" rel=\"noopener noreferrer\" target=\"_blank\">AI and Procurement: A Primer</a> report from the New York University <a href=\"https://engineering.nyu.edu/research-innovation/centers/center-responsible-ai\" rel=\"noopener noreferrer\" target=\"_blank\">Center for Responsible AI</a>.</p><p>The new, voluntary standard is designed to help strengthen AI procurement approaches with due-diligence processes to ensure that agencies are critically evaluating the kinds of AI services and tools they acquire. The standard can provide agencies with a method to require transparency from AI vendors about associated risks.</p><p>IEEE P3119 also can help governments use their procuring power to <a href=\"https://uploads.dayoneproject.org/2022/02/14125252/Market-Shaping-Primer.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">shape the market</a>—which could increase demand for more responsible AI solutions.</p><h2>A how-to guide</h2><p>The standard aims to help government agencies strengthen their requirements for AI procurement. Added to existing regulations, it offers complementary how-to guidance that can be applied to a variety of processes including pre-solicitation and contract monitoring.</p><p>Existing AI procurement guidelines such as the ones from the <a href=\"https://www.gao.gov/products/gao-21-519sp\" rel=\"noopener noreferrer\" target=\"_blank\">U.S. Government Accountability Office</a>, the <a href=\"https://www.weforum.org/publications/ai-procurement-in-a-box/ai-government-procurement-guidelines/#report-nav\" rel=\"noopener noreferrer\" target=\"_blank\">World Economic Forum</a>, and the <a href=\"https://www.fordfoundation.org/wp-content/uploads/2023/03/final_ford-foundation-guiding-framework-r3-full-document-final2.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Ford Foundation</a> cover AI literacy, best practices, and red flags for vetting technology vendors. The IEEE P3119 standard goes further by providing guidance, for example, on determining whether a problem requires an AI solution. It also can help identify an agency’s risk tolerance, assess a vendor’s answers to questions about AI, recommend <a href=\"https://www.inclusivechange.org/ai-governance-solutions/ai-contract-clauses\" rel=\"noopener noreferrer\" target=\"_blank\">curated AI-specific contract language</a>, and evaluate an AI solution across multiple criteria.</p><p>IEEE is currently developing such an AI procurement guidance, one that moves beyond principles and best practices to detailed process recommendations. IEEE P3119 explicitly addresses the technical complexity of most AI models and the potential risks to society while also considering the systems’ capacity to scale for deployment in much larger populations.</p><p>Discussions in the standards working group centered around ways to identify and evaluate AI risks, how to mitigate risks within procurement needs, and how to provoke transparency about AI governance from vendors, with AI-specific best practices for solicitations and contracts.</p><p>The IEEE P3119 processes are meant to complement and optimize existing procurement requirements. The primary goal for the standard is to offer government agencies and AI vendors ways to adapt their procurement practices and solicited proposals to maximize the benefits of AI while minimizing the risks.</p><p>The standard is meant to become part of the “request for proposals” stage, integrated with solicitations in order to raise the bar for AI procurement so that the public interest and citizens’ civil rights are proactively protected.</p><p>Putting the standard into practice, however, could be challenging for some governments that are dealing with historical regulatory regimes and limited institutional capacity. </p><p>A future article will describe the need to test the standard against existing regulations, known as <a href=\"https://pubmed.ncbi.nlm.nih.gov/32025244/\" rel=\"noopener noreferrer\" target=\"_blank\">regulatory sandboxes</a>. </p>",[{'name': 'Cari Miller'}],"Tue, 23 Jan 2024 22:00:04 +0000"
2271,Deep Learning Picks Apart DNA Data-Copying Puzzles,https://spectrum.ieee.org/ai-genetics-rna-transcription,"<img src=\"https://spectrum.ieee.org/media-library/colorful-structure-of-green-pieces-with-a-group-of-pink-blobs-in-the-center.jpg?id=51058085&amp;width=1200&amp;height=800&amp;coordinates=0%2C71%2C0%2C71\" /><br /><br /><p>DNA, as a data-storage medium, is useful only when read, copied, and sent out elsewhere. The medium for conveying genetic information out of a cell’s nuclei is <a href=\"https://www.genome.gov/genetics-glossary/RNA-Ribonucleic-Acid\" target=\"_blank\">RNA</a>—transcribed from DNA, which itself never leaves the cell’s nuclei. Now, using deep learning, researchers at Northwestern University, in Evanston, Ill., have untangled a complex  part of the RNA transcription process: how cells  know when to stop copying. </p><p>In RNA transcription, knowing when to stop is crucial. The information coded into RNA is used throughout a cell to synthesize proteins and regulate a wide range of metabolic processes. Getting the right message to its intended target requires those RNA strands to say just as much as they need to—and nothing more. If they say more or less than they need, as can be the case in a number of diseases like <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9549512/\" target=\"_blank\">epilepsy</a> or <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC137534/#:~:text=The%20primary%20cause%20of%20Duchenne,changes%20in%20skeletal%20muscle%20pathology.\" target=\"_blank\">muscular dystrophy</a>, then any number of those metabolic processes can break down or malfunction to debilitating effect.     </p><p class=\"pull-quote\">“This is a very useful prescreening tool for investigating genetic variants in a high-throughput manner.”<br /><strong>—Emily Kunce Stroup, Northwestern University</strong> </p><p>Halting the RNA copying process—called <a href=\"https://en.wikipedia.org/wiki/Polyadenylation\" target=\"_blank\">polyadenylation</a> (polyA) for the string of <a href=\"https://en.wikipedia.org/wiki/Adenine\" target=\"_blank\">adenine</a> molecules it ties onto the end of a cut-off RNA strand—involves a range of proteins whose interactions have never been fully understood. </p><p>So to help unravel polyA, researchers <a href=\"https://www.feinberg.northwestern.edu/faculty-profiles/az/profile.html?xid=39642\" target=\"_blank\">Zhe Ji</a> and <a href=\"https://www.researchgate.net/scientific-contributions/Emily-Kunce-Stroup-2155960728\" target=\"_blank\">Emily Kunce Stroup </a>at Northwestern University   developed a machine-learning model that can locate and identify  polyA sites. It works by pairing  <a href=\"https://spectrum.ieee.org/tag/convolutional-neural-networks\" target=\"_self\">convolutional neural networks</a> (CNNs) trained to  match important  sequences in the genetic code with   <a href=\"https://spectrum.ieee.org/the-neural-network-that-remembers\" target=\"_self\">r</a><a href=\"https://spectrum.ieee.org/the-neural-network-that-remembers\" target=\"_self\">ecurrent neural networks</a> (RNNs) trained to study the CNN outputs. <br /></p><p>While previous models had taken a similar approach, using both CNNs and RNNs, these researchers then fed the CNN/RNN model’s outputs into two other  deep-learning models trained to locate and identify polyA sites in the genome. </p><p>The two additional models seem to have helped. “Having those tandem outputs is the really unique thing from our work,” says Stroup. “Having the model go outwards to two separate output branches that we then combine to identify sites at high resolution is what distinguishes us from existing work.”<br /></p><p>From their model, the researchers learned a few important aspects of what   can cause polyA to go well or poorly. The CNN part of the model learned genetic  patterns in DNA known to attract the proteins controlling polyA, while the RNN part of the model  revealed that reliably cutting off transcription requires careful spacing between those patterns. And these researchers could make such precise conclusions because of the model’s per-nucleotide resolution. <a target=\"_blank\"></a>“It’s striking that our model can precisely capture this,” says Ji.</p><p>Moving forward, the team says they plan to apply their model and similar techniques to research identifying key genetic mutations that potentially cause diseases and then to develop from that a possible pipeline of more targeted therapeutic drugs. <a target=\"_blank\"></a>“This is a very useful prescreening tool for investigating genetic variants in a high-throughput manner,” says Stroup. “This will hopefully help whittle down the number of candidate mutations to make the process more efficient.” </p><p>Stroup says the team also plans to re-create their research in other organisms to see how RNA transcription changes between different animals. They hope, she says, to use that knowledge to help control or prevent polyA when its processes are out of control—as in the cases of epilepsy and muscular dystrophy—and causing real harm.<br /></p><p>The researchers published their <a href=\"https://www.nature.com/articles/s41467-023-43266-3\" target=\"_blank\"><u>paper</u></a> in the journal <em>Nature.</em></p>",[{'name': 'Michael Nolan'}],"Mon, 22 Jan 2024 22:05:03 +0000"
2272,"Crop Health Sensor Runs on Solar, Microbe Power",https://spectrum.ieee.org/smart-agriculture-crop-moisture-sensor,"<img src=\"https://spectrum.ieee.org/media-library/apple-trees-in-a-line-with-the-sun-shining.jpg?id=51101330&amp;width=1200&amp;height=800&amp;coordinates=0%2C125%2C0%2C125\" /><br /><br /><p><em>This article is part of our exclusive </em><a href=\"https://spectrum.ieee.org/collections/journal-watch/\" target=\"_self\"><em>IEEE Journal Watch series</em></a><em> in partnership with IEEE Xplore.</em></p><p>As climate change causes many regions of the world to dry up, smart agriculture is one means to adapt to the crisis, and make every last drop of water count. To support this effort, a group of researchers in Italy have created a wearable, low-cost sensor for plants that monitors their water levels, and which is powered via solar energy and electrical energy from microbes in the soil. The sensor is described in a <a href=\"https://ieeexplore.ieee.org/document/10168678\" rel=\"noopener noreferrer\" target=\"_blank\">study</a> published in the December issue of the journal <a href=\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9787768\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on AgriFood Electronics</em></a>. </p><p>Umberto Garlando, an assistant professor at the <a href=\"https://en.wikipedia.org/wiki/Polytechnic_University_of_Turin\" target=\"_blank\">Polytechnic University of Turin</a> in Italy, was involved in the study. He notes that agriculture consumes a considerable amount of water. “Looking directly at the plants to estimate the water needs in agriculture could lead to water savings and a better use of this resource,” he explains, noting this could increase yield and facilitate better food security for everyone. </p><p>Therefore, his team set about creating their small, low-cost sensor that is connected directly to the stem of a crop with stainless steel needles just 0.4 millimeters long, acting as electrodes. The <a href=\"https://en.wikipedia.org/wiki/Electrical_impedance\" target=\"_blank\">sensor measures the electrical impedance</a> of the plant stem, which indirectly measures moisture in the plant based on ions and conductivity. More conductivity along the stem indicates that the plant is better watered. </p><p>The sensor has a miniature  solar panel for energy harvesting and a <a href=\"https://spectrum.ieee.org/micro-supercapacitor\" target=\"_blank\">supercapacitor</a> for energy storage, which Garlando says are enough to power the device and support continuous operation. The data is transmitted down the stem of the plant as an electrical signal to a receiver placed in the soil. The receiver, which is powered by a <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1364032119303223#:~:text=Plant%20microbial%20fuel%20cell%20(PMFC,bioelectricity%20%5B4%2C5%5D.\" target=\"_blank\">Plant Microbial Fuel Cell</a> (PMFC) that extracts energy from the electrical signals of microbes in the soil, reads the signal frequency and then transmits the data to a remote site for processing and analysis.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" style=\"float: left;\">
<img alt=\"ilustration of a green plant with two computer chips on either side with arrows pointing to pot and plant\" class=\"rm-shortcode rm-resized-image\" id=\"bdf73\" src=\"https://spectrum.ieee.org/media-library/ilustration-of-a-green-plant-with-two-computer-chips-on-either-side-with-arrows-pointing-to-pot-and-plant.jpg?id=51101336&amp;width=980\" />
<small class=\"image-media media-caption\">Measuring electrical impedance at the plant stem, a device transmits data to a receiver placed at the base of the plant—which infers water levels and needs of the plant.</small><small class=\"image-media media-photo-credit\">Umberto Garlando</small></p><p>The researchers first tested their sensor in tobacco plants in a controlled environment, where the sensor’s impedance measurements were confirmed using standard laboratory equipment. Garlando says results suggested the sensor can use electrical impendence to infer the water potential of the plant with 85 percent accuracy. After initial validation of the method, Garlando’s team moved the sensor to apple trees for a nearly year-long test in the field, where he says the sensor’s readings clearly correlated with times of water scarcity.</p><p>He notes a lot of advantages of this sensor, including its small dimensions, low power consumption, low cost, wireless capability, and ability to directly monitor plants in the field. “Furthermore, thanks to the flexibility of the designed sensor, it is possible to adapt it to different species of plants. The same device was used both on tobacco plants and apple trees,” he says. </p><p>Garlando notes that more research is still needed before he will consider commercializing this technology. His team is partnering with experts at other research institutes to improve the sensor’s resolution and understand what additional information they can extract from this sensor. For instance, he says, they might also be able to infer the concentration of various nutrients in the plant’s stem. He adds that his team would like to reduce the sensor system’s overall cost to enable sufficient numbers of sensors to be affordably placed across large fields. </p><p>“Another next step will be the introduction of machine learning and artificial intelligence in the data analysis,” says Garlando. “In the long term, microelectronics will be adopted to integrate the sensor into a single chip. In this way, the cost will be reduced, and it will be possible to miniaturize the sensor.”</p>",[{'name': 'Michelle Hampson'}],"Wed, 17 Jan 2024 20:58:00 +0000"
2273,Open-Source AI Is Uniquely Dangerous,https://spectrum.ieee.org/open-source-ai-2666932122,"<img src=\"https://spectrum.ieee.org/media-library/a-glowing-skull-with-colorful-connective-networking-lines-running-through-it-in-an-open-cube-of-cubes.jpg?id=51069635&amp;width=1200&amp;height=800&amp;coordinates=48%2C0%2C48%2C0\" /><br /><br /><p><em>This is a guest post. <em>For the other side of the argument about open-source AI, see the recent guest post “<a href=\"https://spectrum.ieee.org/open-source-ai-good\" target=\"_blank\">Open Source AI Is Good for Us</a>.”</em></em><em></em></p><p>When people think of AI applications these days, they likely think of “closed-source” AI applications like OpenAI’s <a href=\"https://chat.openai.com/\" rel=\"noopener noreferrer\" target=\"_blank\">ChatGPT</a>—where the system’s software is securely held by its maker and a limited set of vetted partners. Everyday users interact with these systems through a Web interface like a chatbot, and business users can access an application programming interface (API) which allows them to embed the AI system in their own applications or workflows. Crucially, these uses allow the company that owns the model to provide access to it as a service, while keeping the underlying software secure. Less well understood by the public is the rapid and uncontrolled release of powerful unsecured (sometimes called open-source) AI systems.</p><p class=\"pull-quote\">A good first step in understanding the threats posed by unsecured AI is to ask secured AI systems like ChatGPT, Bard, or Claude to misbehave. </p><p><a href=\"https://openai.com/\" rel=\"noopener noreferrer\" target=\"_blank\">OpenAI</a>’s brand name adds to the confusion. While the company was originally founded to produce open-source AI systems, its leaders determined in 2019 that it was <a href=\"https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/\" rel=\"noopener noreferrer\" target=\"_blank\">too dangerous</a> to continue releasing its GPT systems’ source code and model weights (the numerical representations of relationships between the nodes in its artificial neural network) to the public. OpenAI worried because these text-generating AI systems can be used to generate massive amounts of well-written but misleading or <a href=\"https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business\" rel=\"noopener noreferrer\" target=\"_blank\">toxic</a> content.</p><p>Companies including <a href=\"https://www.meta.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Meta</a> (my former employer) have moved in the opposite direction, choosing to release powerful unsecured AI systems in the name of <a href=\"https://about.fb.com/news/2023/07/llama-2/\" rel=\"noopener noreferrer\" target=\"_blank\">democratizing</a> access to AI. Other examples of companies releasing unsecured AI systems include <a href=\"https://stability.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Stability AI</a>, <a href=\"https://huggingface.co/\" rel=\"noopener noreferrer\" target=\"_blank\">Hugging Face</a>, <a href=\"https://mistral.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Mistral</a>, <a href=\"https://www.eleuther.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">EleutherAI</a>, and the <a href=\"https://www.tii.ae/\" rel=\"noopener noreferrer\" target=\"_blank\">Technology Innovation Institute</a>. These companies and like-minded advocacy groups have made limited progress in <a href=\"https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683\" rel=\"noopener noreferrer\" target=\"_blank\">obtaining exemptions</a> for some unsecured models in the European Union’s <a href=\"https://artificialintelligenceact.eu/\" rel=\"noopener noreferrer\" target=\"_blank\">AI Act</a>, which is designed to reduce the risks of powerful AI systems. They may push for similar exemptions in the United States via the public comment period recently <a href=\"https://docs.google.com/document/d/1u-MUpA7TLO4rnrhE2rceMSjqZK2vN9ltJJ38Uh5uka4/edit#heading=h.t02rblknwe5\" rel=\"noopener noreferrer\" target=\"_blank\">set forth in</a> the White House’s <a href=\"https://spectrum.ieee.org/biden-ai-executive-order\" target=\"_self\">AI Executive Order</a>.</p><p>I think the <a href=\"https://spectrum.ieee.org/tag/open-source\" rel=\"noopener noreferrer\" target=\"_blank\">open-source</a> movement has an important role in AI. With a technology that brings so many new capabilities, it’s important that no single entity acts as a gatekeeper to the technology’s use. However, as things stand today, unsecured AI poses an enormous risk that we are not yet able to contain.</p><h2>Understanding the Threat of Unsecured AI</h2><p>A good first step in understanding the threats posed by unsecured AI is to ask secured AI systems like ChatGPT, <a href=\"https://bard.google.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Bard</a><u>,</u> or <a href=\"https://claude.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Claude</a> to misbehave. You could ask them to design a more deadly coronavirus, provide instructions for making a bomb, make naked pictures of your favorite actor, or write a series of inflammatory text messages designed to make voters in swing states more angry about immigration. You will likely receive polite refusals to all such requests because <a href=\"https://openai.com/policies/usage-policies\" target=\"_blank\">they violate</a> the <a href=\"https://policies.google.com/terms/generative-ai/use-policy\" rel=\"noopener noreferrer\" target=\"_blank\">usage policies</a> of <a href=\"https://console.anthropic.com/legal/aup\" target=\"_blank\">these AI systems</a>. Yes, it is possible to “jailbreak” these <a href=\"https://arxiv.org/abs/2305.13860\" rel=\"noopener noreferrer\" target=\"_blank\">AI systems</a> and get them to misbehave, but as these vulnerabilities are discovered, they can be fixed.</p><p>Enter the unsecured models. Most famous is Meta’s <a href=\"https://ai.meta.com/llama/\" rel=\"noopener noreferrer\" target=\"_blank\">Llama 2</a>. It was released by Meta with a 27-page “<a href=\"https://ai.meta.com/static-resource/responsible-use-guide/\" rel=\"noopener noreferrer\" target=\"_blank\">Responsible Use Guide</a>,” which was promptly ignored by the creators of “<a href=\"https://huggingface.co/jarradh/llama2_70b_chat_uncensored\" rel=\"noopener noreferrer\" target=\"_blank\">Llama 2 Uncensored</a>,” a derivative model with safety features stripped away, and hosted for free download on the Hugging Face AI repository. Once someone releases an “uncensored” version of an unsecured AI system, the original maker of the system is largely powerless to do anything about it.</p><p class=\"pull-quote\">As things stand today, unsecured AI poses an enormous risk that we are not yet able to contain.</p><p>The threat posed by unsecured AI systems lies in the ease of misuse. They are particularly dangerous in the hands of sophisticated threat actors, who could easily download the original versions of these AI systems and disable their safety features, then make their own custom versions and abuse them for a wide variety of tasks. Some of the abuses of unsecured AI systems also involve taking advantage of vulnerable distribution channels, such as social media and messaging platforms. These platforms cannot yet accurately detect AI-generated content at scale and can be used to distribute massive amounts of personalized misinformation and, of course, <a href=\"https://theconversation.com/ai-scam-calls-imitating-familiar-voices-are-a-growing-problem-heres-how-they-work-208221\" rel=\"noopener noreferrer\" target=\"_blank\">scams</a>. This could have catastrophic effects on the information ecosystem, and on <a href=\"https://spectrum.ieee.org/deepfakes-election\" target=\"_self\">elections</a> in particular. Highly damaging <a href=\"https://www.wired.com/story/deepfake-porn-is-out-of-control/\" rel=\"noopener noreferrer\" target=\"_blank\">nonconsensual deepfake pornography</a> is yet another domain where unsecured AI can have deep negative consequences.</p><p>Unsecured AI also has the potential to facilitate production of dangerous materials, such as <a href=\"https://www.axios.com/2023/06/16/pandemic-bioterror-ai-chatgpt-bioattacks\" rel=\"noopener noreferrer\" target=\"_blank\">biological and chemical weapons</a>. The White House Executive Order references chemical, biological, radiological, and nuclear (<a href=\"https://docs.google.com/document/d/1u-MUpA7TLO4rnrhE2rceMSjqZK2vN9ltJJ38Uh5uka4/edit#heading=h.6fkzizejib9o\" rel=\"noopener noreferrer\" target=\"_blank\">CBRN</a>) risks, and <a href=\"https://www.markey.senate.gov/news/press-releases/sens-markey-budd-announce-legislation-to-assess-health-security-risks-of-ai\" rel=\"noopener noreferrer\" target=\"_blank\">multiple bills</a> are now under consideration by the U.S. Congress to address these threats.</p><h2>Recommendations for AI Regulations</h2><p>We don’t need to specifically regulate unsecured AI—nearly all of the regulations that have been publicly discussed apply to secured AI systems as well. The only difference is that it’s much easier for developers of secured AI systems to comply with these regulations because of the inherent properties of secured and unsecured AI. The entities that operate secured AI systems can actively monitor for abuses or failures of their systems (including bias and the production of dangerous or offensive content) and release regular updates that make their systems more fair and safe.</p><p class=\"pull-quote\">“I think how we regulate open-source AI is THE most important unresolved issue in the immediate term.”<br /><strong>—Gary Marcus, New York University</strong></p><p>Almost all the regulations recommended below generalize to all AI systems. Implementing these regulations would make companies think twice before releasing unsecured AI systems that are ripe for abuse.</p><p><u><strong>Regulatory Action for AI Systems</strong></u></p><ol><li><strong>Pause all new releases</strong> of unsecured AI systems until developers have met the requirements below, and in ways that ensure that safety features cannot be easily removed by bad actors.</li><li><strong>Establish registration and licensing</strong> (both retroactive and ongoing) of all AI systems above a certain capability threshold.</li><li><strong>Create liability </strong>for “reasonably foreseeable misuse” and negligence: Developers of AI systems should be legally liable for harms caused to both individuals and to society.</li><li><strong>Establish risk assessment, mitigation, and independent audit</strong> procedures for AI systems crossing the threshold mentioned above.</li><li><strong>Require watermarking and provenance</strong> best practices so that AI-generated content is clearly labeled and authentic content has metadata that lets users understand its provenance.</li><li><strong>Require transparency of training data</strong> and prohibit training systems on personally identifiable information, content designed to generate hateful content, and content related to biological and chemical weapons.</li><li><strong>Require and fund independent researcher access</strong>, giving vetted researchers and civil society organizations predeployment access to generative AI systems for research and testing.</li><li><strong>Require “know your customer” procedures</strong>, similar to those <a href=\"https://www.swift.com/your-needs/financial-crime-cyber-security/know-your-customer-kyc/meaning-kyc\" rel=\"noopener noreferrer\" target=\"_blank\">used by financial institutions</a><u>,</u> for sales of powerful hardware and cloud services designed for AI use; restrict sales in the same way that weapons sales would be restricted.</li><li><strong>Mandatory incident disclosure</strong>: When developers learn of vulnerabilities or failures in their AI systems, they must be <a href=\"https://csrc.nist.gov/pubs/sp/800/61/r2/final\" rel=\"noopener noreferrer\" target=\"_blank\">legally required to report</a> this to a designated government authority.</li></ol><p><u><strong>Regulatory Action for Distribution Channels and Attack Surfaces</strong></u></p><ol><li><strong>Require content credential implementation</strong> for social media, giving companies a deadline to implement the <a href=\"https://contentcredentials.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Content Credentials labeling standard</a> from C2PA.</li><li><strong>Automate digital signatures</strong> so people can rapidly verify their human-generated content.</li><li><strong>Limit the reach of AI-generated content</strong>: Accounts that haven’t been verified as distributors of human-generated content could have certain features disabled, including viral distribution of their content.</li><li><strong>Reduce chemical, biological, radiological, and nuclear risks</strong> by educating all suppliers of custom nucleic acids or other potentially dangerous substances about best practices.</li></ol><p><u><strong>Government Action</strong></u></p><ol><li><strong>Establish a nimble regulatory body</strong> that can act and enforce quickly and update certain enforcement criteria. This entity would have the power to approve or reject risk assessments, mitigations, and audit results and have the authority to block model deployment.</li><li><strong>Support fact-checking organizations</strong> and civil-society groups (including the “<a href=\"https://ec.europa.eu/commission/presscorner/detail/en/QANDA_20_2348\" rel=\"noopener noreferrer\" target=\"_blank\">trusted flaggers</a>” defined by the <a href=\"https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package\" rel=\"noopener noreferrer\" target=\"_blank\">EU Digital Services Act</a>) and require generative AI companies to work directly with these groups.</li><li><strong>Cooperate internationally</strong> with the goal of eventually creating an international <a href=\"https://www.cigionline.org/articles/voluntary-curbs-arent-enough-ai-risk-requires-a-binding-international-treaty/\" rel=\"noopener noreferrer\" target=\"_blank\">treaty</a> or new international agency to prevent companies from circumventing these regulations. The recent <a href=\"https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023\" rel=\"noopener noreferrer\" target=\"_blank\">Bletchley Declaration</a> was signed by 28 countries, including the home countries of all of the world’s leading AI companies (United States, China, United Kingdom, United Arab Emirates, France, and Germany); this declaration stated shared values and carved out a path for additional meetings.</li><li><strong>Democratize AI access</strong> with public infrastructure: A common concern about regulating AI is that it will limit the number of companies that can produce complicated AI systems to a small handful and tend toward monopolistic business practices. There are many opportunities to democratize access to AI, however, without relying on unsecured AI systems. One is through the creation of <a href=\"https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/412/2023/10/09151836/VPA-AI-Capacity.10.9.23.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">public AI infrastructure</a> with powerful secured AI models.</li></ol><p>“I think how we regulate open-source AI is THE most important unresolved issue in the immediate term,” <a href=\"http://garymarcus.com/index.html\" target=\"_blank\">Gary Marcus</a>, the cognitive scientist, entrepreneur, and professor emeritus at New York University told me in a recent email exchange.<br /></p><p>I agree, and these recommendations are only a start. They would initially be costly to implement and would require that regulators make certain powerful lobbyists and developers unhappy.</p><p>Unfortunately, given the misaligned incentives in the current AI and information ecosystems, it’s unlikely that industry will take these actions unless forced to do so. If actions like these are not taken, companies producing unsecured AI may bring in billions of dollars in profits while pushing the risks posed by their products onto all of us.</p>",[{'name': 'David Evan Harris'}],"Fri, 12 Jan 2024 17:00:02 +0000"
2274,"At CES 2024, AI Is Here to Help",https://spectrum.ieee.org/ai-assistant,"<img src=\"https://spectrum.ieee.org/media-library/a-crowded-tradeshow-floor-with-a-samsung-booth-and-large-glowing-words-saying-ai-for-all.jpg?id=51056355&amp;width=1200&amp;height=800&amp;coordinates=0%2C0%2C226%2C0\" /><br /><br /><p>If you believe the hype, AI will someday generate Hollywood films, cure cancer, and make driving a historical oddity. But at CES 2024, it’s tackling some more immediate and achievable goals.</p><p>LG and Samsung touted AI features that tune your television’s picture quality. Nvidia can use its GPUs to find what you want from hundreds of documents. And dozens of startups pitched AI assistants, avatars, coaches, and tutors.</p><h2>LG and Samsung become AI hub hopefuls</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A man gestures in front of a screen showing a round white robot on two wheels and a chatbot conversation.\" class=\"rm-shortcode\" id=\"6e813\" src=\"https://spectrum.ieee.org/media-library/a-man-gestures-in-front-of-a-screen-showing-a-round-white-robot-on-two-wheels-and-a-chatbot-conversation.jpg?id=51056395&amp;width=980\" />
<small class=\"image-media media-caption\">Henry Kim, team leader for the ThinQ Platform business at LG Electronics U.S., speaks on stage during the 2024 International CES, in Las Vegas, on 8 January 2024.</small><small class=\"image-media media-photo-credit\">James Atoa/UPI/Alamy</small></p><p>LG and Samsung positioned their new televisions as AI powerhouses. That’s not entirely novel: Both have used AI for years to upscale low-resolution content to 4K resolution. For 2024, though, LG hopes its televisions can become an assistant.</p><p>“We want to help people find the settings they need,” says <a href=\"https://www.linkedin.com/in/david-park-63669351\" rel=\"noopener noreferrer\" target=\"_blank\">David Park,</a> head of customer enablement at LG. “This isn’t just a television throwing up a bunch of words at random. It’s much more conversational.”</p><p>LG demonstrated a chatbot interface users can converse with to find settings, optimize image quality, or troubleshoot problems. It’s not unlike the search functions on many devices today. But the chatbot, unlike search, can help you find a setting with a name you can’t remember or recommend settings based on what you’re trying to achieve.</p><p>Samsung went a step further, branding its new televisions as “AI screens.” Many features that fall under this umbrella are meant to improve image quality or motion clarity, but others offer ease-of-use and accessibility. The company demonstrated an on-device, AI-powered optical character recognition (OCR) technology that can serve as a “voice guide” for subtitles. It also showed a mode called <a href=\"https://news.samsung.com/us/samsung-advancing-equity-entertainment-creating-inclusive-tv-experience-relumino-mode-interview/\" rel=\"noopener noreferrer\" target=\"_blank\">Relumino Together</a>, which uses AI to enhance the image for those with low vision.</p><p>Both also came to the show with AI robots for the home. <a href=\"https://news.samsung.com/global/ces-2024-a-glance-at-samsungs-booth-themed-ai-for-all\" rel=\"noopener noreferrer\" target=\"_blank\">Samsung’s is a new iteration of Ballie</a>, first shown at CES 2020, <a href=\"https://www.lgnewsroom.com/2023/12/lg-ushers-in-zero-labor-home-with-its-smart-home-ai-agent-at-ces-2024/\" rel=\"noopener noreferrer\" target=\"_blank\">while LG touted its “two-wheeled AI agent.” </a>The dream is to embody the AI services people might access on a TV, computer, or phone. Ballie even has a built-in projector that lets you bring whatever you’re viewing on a television or laptop with you.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Animated gif of a man moving around a kitchen while a small circular wheeled robot rolls into the frame.\" class=\"rm-shortcode\" id=\"6e9d6\" src=\"https://spectrum.ieee.org/media-library/animated-gif-of-a-man-moving-around-a-kitchen-while-a-small-circular-wheeled-robot-rolls-into-the-frame.gif?id=51056373&amp;width=980\" />
<small class=\"image-media media-caption\">Samsung’s Ballie robot just wants to be helpful.</small><small class=\"image-media media-photo-credit\">Samsung</small></p><p>But these robots also outline the limits of AI at CES 2024. They’re just prototypes for now, and it’s unclear when (or if) they’ll see release.</p><h2>Startup makes AI your instruction manual</h2><p>Of course, it’s not just tech giants looking to get in on the AI buzz. Eureka Park, a hub for startups on the CES show floor, was bursting with AI-powered assistants.</p><p>Among these was <a href=\"https://www.blinkin.io/\" rel=\"noopener noreferrer\" target=\"_blank\">BlinkIn</a>, a German startup building a multimodal “companion experience” called Houston, which is accessed through a smartphone app. Its purpose is similar to the chatbot on LG’s TV, but BlinkIn wants to offer advice for <em>everything </em>in your home, from your coffee maker to your washing machine. You can snap a photo of your device and ask a question about it.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A screenshot showing a multistep process of using the phone to get AI assistance on something in the camera frame.\" class=\"rm-shortcode\" id=\"109d7\" src=\"https://spectrum.ieee.org/media-library/a-screenshot-showing-a-multistep-process-of-using-the-phone-to-get-ai-assistance-on-something-in-the-camera-frame.jpg?id=51056450&amp;width=980\" />
<small class=\"image-media media-caption\">BlinkIn’s AI can help with how-to.</small><small class=\"image-media media-photo-credit\">BlinkIn</small></p><p>This is a task that OpenAI’s ChatGPT, <a href=\"https://spectrum.ieee.org/chatgpt-multimodal\" target=\"_self\">which has multimodal capabilities including image and audio prompts</a>, can already tackle. But ChatGPT can prove an unreliable assistant. If I ask it how to clean my coffee maker, for example, it usually provides a meandering, long-winded answer with only some details relevant to my particular appliance.</p><p>“We want to help you not get a wall of text,” says <a href=\"https://www.linkedin.com/in/akkshayjoshii/?originalSubdomain=de\" rel=\"noopener noreferrer\" target=\"_blank\">Akshay Joshi</a>, senior applied AI scientist at BlinkIn. Joshi told me the company is using open-source multimodal models, such as <a href=\"https://minigpt-4.github.io/\" rel=\"noopener noreferrer\" target=\"_blank\">MiniGPT-4 </a>(which is not affiliated with OpenAI), to tune the app’s replies, although it will use ChatGPT as a fallback.</p><p>BlinkIn also hopes to fill the trust gap with a community-driven approach. Users who feel helpful can provide answers that its AI model will use as training data, and Houston will surface and cite these answers (complete with user profiles). <a href=\"https://www.crunchbase.com/person/josef-suess\" rel=\"noopener noreferrer\" target=\"_blank\">Josef Suess</a>, CEO of BlinkIn, says this will add a communal feel similar to Reddit or YouTube. “Who do you trust more as a user? A content creator, or a brand?” he asks. “We want to build a platform where it’s about helping each other.”</p><h2>Nvidia shows off encyclopedia GPU</h2><p>Everyone knows Nvidia’s hardware is great for AI (and, in case you’d forgotten,<a href=\"https://www.nvidia.com/en-us/geforce/news/geforce-rtx-ces-2024-announcements/#:~:text=It%20arrives%20January%2024th%2C%20starting,with%20performance%2Dmultiplying%20frame%20generation.\" rel=\"noopener noreferrer\" target=\"_blank\"> it came to CES 2024 touting the AI power of three new RTX Super desktop graphics cards</a>). Yet, when it comes to using AI for yourself on your home PC, putting an Nvidia GPU on a task often requires a tour through <a href=\"https://github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a> or <a href=\"https://huggingface.co/\" rel=\"noopener noreferrer\" target=\"_blank\">HuggingFace</a>, and several hours of work.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A screen says Chat with RTX and shows a chatbot with question and answer\" class=\"rm-shortcode\" id=\"6090e\" src=\"https://spectrum.ieee.org/media-library/a-screen-says-chat-with-rtx-and-shows-a-chatbot-with-question-and-answer.jpg?id=51056488&amp;width=980\" />
<small class=\"image-media media-caption\">Nvidia’s desktop GPU can help you find and understand information.</small><small class=\"image-media media-photo-credit\">Nvidia</small></p><p>Nvidia brought a solution to CES 2024: Chat with RTX. It’s a Windows application that lets you prompt a <a href=\"https://spectrum.ieee.org/tag/llms\" target=\"_self\">large language model</a> with questions about a set of documents provided to the app. Chat with RTX currently supports two large language models: Meta’s <a href=\"https://ai.meta.com/llama/\" rel=\"noopener noreferrer\" target=\"_blank\">Llama 2</a> and <a href=\"https://mistral.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Mistral AI’s Mistral</a>. The models load on your PC, and all AI inference occurs on your local Nvidia GPU, which means conversations in the app are kept private.</p><p>I had a chance to use Chat with RTX at the show, and I was immediately struck by its speed. The app responded to my questions with zero delay. I was also able to quickly switch between different sets of documents (the app can read Word documents, PDFs, text files, and XML). It’s a solution I’m eager to try at home, as I have several piles of PDF documents that are a bear to search.</p><p>Chat with RTX, like all the AI demos I saw at CES, still needs work. The interface is barebones and its capabilities limited to specific situations. Still, CES made clear there’s no shortage of interest in custom-tailored AI assistants built to achieve particular goals—expect to see more refined iterations of these ideas appear through 2024.</p>",[{'name': 'Matthew S. Smith'}],"Thu, 11 Jan 2024 15:37:47 +0000"
2275,E-Nose Sniffs Out Coffee Varieties Nearly Perfectly,https://spectrum.ieee.org/e-nose-coffee-classifier,"<img src=\"https://spectrum.ieee.org/media-library/an-overhead-photograph-of-a-steaming-cup-of-coffee-on-a-background-of-coffee-beans.jpg?id=51033984&amp;width=1200&amp;height=800&amp;coordinates=62%2C0%2C63%2C0\" /><br /><br /><p><em>This article is part of our exclusive </em><a href=\"https://spectrum.ieee.org/collections/journal-watch/\" target=\"_self\"><em>IEEE Journal Watch series</em></a><em> in partnership with IEEE Xplore.</em></p><p>Some truly passionate java junkies may be adept at distinguishing between various coffee flavors, but a new e-nose may give these folks a run for their money. The new sensing system, which can distinguish coffee aromas consistently with 98 percent accuracy, is described in a <a href=\"https://ieeexplore.ieee.org/document/10363440\" rel=\"noopener noreferrer\" target=\"_blank\">study</a> published last month in <a href=\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9787768\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on AgriFood Electronics</em></a>.</p><p>E-noses are devices that assess gases to classify the nature of the substance at hand. They are growing in popularity, thanks to their ability to facilitate quality assurance of products (such as <a href=\"https://spectrum.ieee.org/electronic-nose-whiskey\" target=\"_self\">whiskey</a>), provide real-time health assessments (such as <a href=\"https://spectrum.ieee.org/glucose-test-e-nose\" target=\"_self\">an individual’s glucose levels</a>), and to support sustainable agriculture (such as <a href=\"https://spectrum.ieee.org/new-electronic-nose-sniffs-out-perfectly-ripe-peaches-for-harvest\" target=\"_blank\">identifying when a crop is ready for harvesting</a>). </p><p class=\"pull-quote\">“The broader goal is to contribute to the preservation and understanding of aromas in the face of environmental changes.”<br /><strong>—Chung-Hong Lee, National Kaohsiung University of Science and Technology, Taiwan</strong></p><p><a href=\"https://www.researchgate.net/profile/Chung-Hong-Lee\" target=\"_blank\">Chung-Hong Lee,</a> a professor at the Department of Electrical Engineering at the <a href=\"https://eng.nkust.edu.tw/\" target=\"_blank\">National Kaohsiung University of Science and Technology</a>, in Taiwan, is a passionate coffee drinker and was interested in applying e-nose technology in the context of one of his favorite beverages. </p><p>He notes that coffee varieties rely on an array of factors, including growing area, climate, post-harvest processing (such as dry and wet methods), roasting treatment, and the genetic makeup of beans themselves. But, importantly, climate change is altering the local environments that influence bean flavor and aroma.</p><p>“Beyond [my] personal enjoyment of coffee, the broader goal is to contribute to the preservation and understanding of aromas in the face of environmental changes, ensuring consistency in quality and flavor profiles across different crop years,” explains Lee. </p><p>To create their e-nose, Lee’s team used an array of eight commercial metal semiconductor oxide sensors that are sensitive to specific gases. These sensors detect which molecules are present, data that is then sent to an AI algorithm for processing. The researchers then trained and tested several different AI systems that could distinguish among 16 different coffee-bean varieties from around the world. </p><p>All of the AI algorithms performed very well, achieving an accuracy ranging from 81 to 98 percent, depending on the type of coffee. The best performing algorithm—one called a <a href=\"https://spectrum.ieee.org/breakthrough-listen-trained-an-ai-to-spot-illusive-mysterious-radio-bursts\" target=\"_blank\">convolutional neural network</a> (CNN) algorithm—nearly always had an accuracy exceeding 90 percent and reached an accuracy as high as 98 percent for several coffee varieties. </p><p>“Thus, the journey from drinking coffee to unraveling its aromatic secrets becomes a natural fusion of sensory delight and cutting-edge technology,” says Lee.</p><p>However, the value in this work goes beyond simply identifying the cup of coffee at hand. Lee’s team is using these data from their e-nose to build a comprehensive digital library of coffee aromas, capturing the diverse and complex profiles from various coffee-producing regions globally. Notably, this digital library of coffee flavors could create a benchmark for original flavors, and how they are affected over time as climate change affects coffee-bean agriculture. Or, for example, if some deceitful seller tries to market one bean variety as another, this tech could help ensure that bean fiends get the right cup of coffee they ordered.</p><p>Lee says his team is interested in commercializing their e-nose, and they are open to collaboration with enterprises or startups interested in leveraging this technology. As well, he sees the possibility of creating not just e-noses for coffee, but also an electronic tongue for detecting coffee taste, an electronic eye for filtering the best ripe coffee—even a tactile system for assessing the moisture content of coffee beans. “This next step is crucial for establishing and progressing toward addressing issues in coffee-growing areas and benefiting farmers,” Lee emphasizes. </p>",[{'name': 'Michelle Hampson'}],"Wed, 10 Jan 2024 22:40:06 +0000"
2276,CES 2024: Neuchips Demos Low-Power AI Upgrade for PCs,https://spectrum.ieee.org/neuchips-low-power-ai,"<img src=\"https://spectrum.ieee.org/media-library/silver-square-against-a-blue-background-with-llm-above.jpg?id=51029508&amp;width=1200&amp;height=800&amp;coordinates=0%2C50%2C0%2C51\" /><br /><br /><p>What if any desktop PC could become an AI inference beast with a single upgrade? And what if that transformed beast still sipped power like it was enjoying a martini? <br /></p><p>That’s the idea pitched by <a href=\"https://neuchips.ai/\" target=\"_blank\">Neuchips</a>, a Taiwanese startup founded in 2019 and known for delivering<a href=\"https://neuchips.ai/page/mlperf\" target=\"_blank\"> top-class AI efficiency</a>. It came to <a href=\"https://www.ces.tech/events-programs/ces-events/las-vegas.aspx\" target=\"_blank\">CES Unveiled 2024</a>—the media pregame show before the <a href=\"https://www.ces.tech/\" target=\"_blank\">main event</a>—with a PCIe add-on card that can upgrade the AI capabilities of a typical desktop computer while adding just 55 watts to the PC’s power budget. </p><p>It’s not just a concept. The card was plugged into a desktop computer on the show floor and offered real-time, offline conversation with a chatbot powered by <a href=\"https://spectrum.ieee.org/llama-2-llm\" target=\"_self\">Meta’s popular Llama 2 7B large language model</a> (Neuchips says the card will also run Llama 2 13B).</p><p>Neuchips’ card, the Evo PCIe accelerator, is built around the company’s Raptor Gen AI accelerator chip. The Raptor chip delivers up to 200 teraoperations per second measured with <a href=\"https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/\" target=\"_blank\">Meta’s DLRM benchmark</a>, and the company says it’s optimized for transformer-based models.. </p><p>The card that Neuchips demonstrated had the Raptor chip, but a single chip isn’t the card’s final form. <a href=\"https://www.linkedin.com/in/ken-lau-6948662/\" rel=\"noopener noreferrer\" target=\"_blank\">Neuchips’ CEO Ken Lau</a>, an Intel veteran of 26 years, says Raptor can be used to design cards with varying numbers of chips onboard. </p><p>“The chip is actually scalable,” says Lau. “So we start with one chip. And then we have four chips. And then eight chips.” Each chip provides up to 200 trillion operations per second (TOPS), according to <a href=\"https://www.neuchips.ai/news/article/711ZY14mZahw7StF/press-releases\" rel=\"noopener noreferrer\" target=\"_blank\">Neuchip’s press release</a>. The card also carries 32 GB of LPDDR5 memory and reaches 1.6 terabits of memory bandwidth. Memory bandwidth is important, because it’s often a factor when handling AI inference on a single PC.</p><p>Neuchips wants to give owners the tools needed to use the card effectively as well, although with many months until release the details here remain a bit sparse. A Neuchips representative said the company has compiler software and will provide a driver. The demonstration I saw had a custom interface for interacting with the Llama 2 7B model. Neuchips’ card was running, but it appeared bare-bones.</p><h2>A focus on efficiency </h2><p>There’s already hardware that anyone can plug into a desktop’s PCIe slot to greatly improve AI performance. It’s called a GPU, and Nvidia has a stranglehold on the market. Going toe-to-toe with Nvidia on performance would be difficult. In fact, <a href=\"https://nvidianews.nvidia.com/news/geforce-rtx-40-super-series\" rel=\"noopener noreferrer\" target=\"_blank\">Nvidia announced new cards with a focus on AI at CES 2024</a>; the RTX 4080 Super, which will retail for US $999 starting on 31 January, quotes AI performance of up to 836 TOPS.</p><p>Neuchips, however, sees an opening. “We are focused on power efficiency,” says Lau, “and on handling the many different models that are out there.”</p><p>Modern graphics cards are powerful, but also power hungry. The RTX 4080 Super can draw up to 320 W of power and will typically require a computer with a power supply that can deliver at least 750 W. Neuchips’ Evo PCIe accelerator, by contrast, consumes just 55 W of power. It consumes so little power, in fact, that the card Neuchips demonstrated at CES didn’t have an external PCIe power connection. Such connectors are a must for most GPU cards. </p><p>I was also told that the final card, which should ship in the latter half of 2024, will be roughly half the size of the card shown at CES. That’s an important detail, as the card I saw was as large as most current Nvidia GPU cards, and too large to fit most small form-factor desktop computers. A smaller card would make the Evo PCIe accelerator usable in a wide range of modern PC hardware.<br /></p><p>Neuchips’ accelerator, though perhaps the most high-profile AI accelerator card at CES 2024, was far from alone at the show. Several startups came with their own AI accelerators packing unique features. <a href=\"https://panmnesia.com/news_en/#news-en-2023-11-22-ces24-innovation\" rel=\"noopener noreferrer\" target=\"_blank\">Panmnesia won a CES Innovation Award for an AI accelerator</a> that includes a Compute eXpress Link interface for access to huge pools of memory. Other companies with AI accelerators include <a href=\"https://deepx.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">DeepX</a> and <a href=\"https://memryx.com/\" rel=\"noopener noreferrer\" target=\"_blank\">MemryX</a>. <a href=\"https://www.intel.com/content/www/us/en/products/docs/processors/core-ultra/ai-pc.html\" rel=\"noopener noreferrer\" target=\"_blank\">Intel </a>and <a href=\"https://www.amd.com/en/products/processors/consumer/ryzen-ai.html\" rel=\"noopener noreferrer\" target=\"_blank\">AMD </a>are in on it, too; each offers an AI accelerator in its latest CPU architecture. </p><p>Make no mistake: Nvidia remains the 800-pound gorilla in this arena, and that’s not going to change overnight. Still, new AI accelerators like Neuchips’ Raptor and the Evo PCIe card look ready to deliver new options for developers who don’t care about graphics or have a need for improved power efficiency while running AI inference. </p><p>Neuchips’ Evo PCI accelerator is due for full release in the second half of 2024. Pricing remains to be announced. </p><p><em>This post was update on 12 January to clarify benchmark operation speeds and correct the system’s memory bandwidth.</em></p>",[{'name': 'Matthew S. Smith'}],"Tue, 09 Jan 2024 14:00:04 +0000"
2277,Generative AI Has a Visual Plagiarism Problem,https://spectrum.ieee.org/midjourney-copyright,"<img src=\"https://spectrum.ieee.org/media-library/a-grid-of-9-images-produced-by-generative-ai-that-are-recognizable-actors-and-characters-from-movies-video-games-and-televisio.jpg?id=51011919&amp;width=1200&amp;height=800&amp;coordinates=412%2C0%2C181%2C0\" /><br /><br /><p><em>This is a guest post. The views expressed here are solely those of the authors and do not represent positions of </em><a href=\"https://spectrum.ieee.org/\" target=\"_self\">IEEE Spectrum</a><em> or the IEEE.</em></p><p>The degree to which large language models (LLMs) might “memorize” some of their training inputs has long been a question, raised by scholars including Google DeepMind’s <a href=\"https://nicholas.carlini.com/\" target=\"_blank\">Nicholas Carlini</a> and <a href=\"https://arxiv.org/abs/2002.06177\" target=\"_blank\">the first author</a> of this article (Gary Marcus). Recent empirical work has shown that LLMs are in some instances capable of reproducing, or reproducing with minor changes, substantial chunks of text that appear in their training sets. </p><p>For example, a <a href=\"https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html\" target=\"_blank\">2023 paper</a> by Milad Nasr and colleagues showed that LLMs can be prompted into dumping private information such as email addresses and phone numbers. Carlini and coauthors <a href=\"https://arxiv.org/pdf/2202.07646.pdf\" target=\"_blank\">recently showed</a> that larger chatbot models (though not smaller ones) sometimes regurgitated large chunks of text verbatim. </p><h2></h2><p>Similarly, the <a href=\"https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html\" target=\"_blank\">recent lawsuit</a> that <em>The New York Times</em> filed against OpenAI showed many examples in which OpenAI software re-created <em>New York Times</em> stories nearly verbatim (words in red are verbatim):</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Side-by-side images compare output from GPT-4 with a New York Times article. The verbatim copy is in red, and covers almost the entire text.\" class=\"rm-shortcode\" id=\"5e950\" src=\"https://spectrum.ieee.org/media-library/side-by-side-images-compare-output-from-gpt-4-with-a-new-york-times-article-the-verbatim-copy-is-in-red-and-covers-almost-the.jpg?id=51009878&amp;width=980\" />
<small class=\"image-media media-caption\">An exhibit from a lawsuit shows seemingly plagiaristic outputs by OpenAI’s GPT-4.</small><small class=\"image-media media-photo-credit\"><a href=\"https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html\" target=\"_blank\">New York Times</a></small></p><p><span></span>We will call such near-verbatim outputs “plagiaristic outputs,” because if a human created them we would call them <em>prima facie</em>  instances of plagiarism. Aside from a few brief remarks later, we leave it to lawyers to reflect on how such materials might be treated in full legal context.</p><p>In the language of mathematics, these examples of near-verbatim reproduction are existence proofs. They do not directly answer the questions of how often such plagiaristic outputs occur or under precisely what circumstances they occur. </p><p class=\"pull-quote\">These results provide powerful evidence...that at least some generative AI systems may produce plagiaristic outputs, even when not directly asked to do so, potentially exposing users to copyright infringement claims.</p><p>Such questions are hard to answer with precision, in part because LLMs are “black boxes”—systems in which we do not fully understand the relation between input (training data) and outputs. What’s more, outputs can vary unpredictably from one moment to the next. The prevalence of plagiaristic responses likely depends heavily on factors such as the size of the model and the exact nature of the training set. Since LLMs are fundamentally black boxes (even to their own makers, whether open-sourced or not), questions about plagiaristic prevalence can probably only be answered experimentally, and perhaps even then only tentatively.</p><p>Even though prevalence may vary, the mere existence of plagiaristic outputs raises many important questions, including technical questions (can anything be done to suppress such outputs?), sociological questions (what could happen to journalism as a consequence?), legal questions (would these outputs count as copyright infringement?), and practical questions (when an end user generates something with a LLM, can the user feel comfortable that they are not infringing on copyright? Is there any way for a user who wishes not to infringe to be assured that they are not?). </p><p><a href=\"http://spectrum.ieee.org/chatgpt-new-york-times\" target=\"_blank\">The <em>New York Times</em> v. OpenAI lawsuit</a> arguably makes a good case that these kinds of outputs do constitute copyright infringement. Lawyers may of course disagree, but it’s clear that quite a lot is riding on the very existence of these kinds of outputs—as well as on the outcome of that particular lawsuit, which could have significant financial and structural implications for the field of generative AI going forward.</p><p>Exactly parallel questions can be raised in the visual domain. Can image-generating models be induced to produce plagiaristic outputs based on copyright materials?</p><h2>Case study: Plagiaristic visual outputs in Midjourney v6</h2><p>Just before the <em>New York Times</em> v. OpenAI lawsuit was made public, we found that the answer is clearly yes, even without directly soliciting plagiaristic outputs. Here are some examples elicited from the “alpha” version of <a href=\"https://www.midjourney.com/home?callbackUrl=%2Fexplore\" target=\"_blank\">Midjourney V6</a> by the <a href=\"https://rahll.carbonmade.com/\" target=\"_blank\">second author</a> of this article, a visual artist who was worked on a number of major films (including <em>The Matrix Resurrections</em>, <em>Blue Beetle</em>, and <em>The Hunger Games</em>) with many of Hollywood’s best-known studios (including Marvel and Warner Bros.).</p><p>After a bit of experimentation (and in a discovery that led us to collaborate), Southen found that it was in fact easy to generate many plagiaristic outputs, with brief prompts related to commercial films (prompts are shown).</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A collection of side by side images show stills from movies and games and near identical images produced by Midjourney.\" class=\"rm-shortcode\" id=\"86f66\" src=\"https://spectrum.ieee.org/media-library/a-collection-of-side-by-side-images-show-stills-from-movies-and-games-and-near-identical-images-produced-by-midjourney.jpg?id=51013032&amp;width=980\" />
<small class=\"image-media media-caption\">Midjourney produced images that are nearly identical to shots from well-known movies and video games.</small><small class=\"image-media media-photo-credit\">Right side images: Gary Marcus and Reid Southen via Midjourney</small></p><p>We also found that cartoon characters could be easily replicated, as evinced by these generated images of The Simpsons.<br /></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Four images showing yellow skinned cartoon characters from The Simpsons\" class=\"rm-shortcode\" id=\"de9e8\" src=\"https://spectrum.ieee.org/media-library/four-images-showing-yellow-skinned-cartoon-characters-from-the-simpsons.jpg?id=51009893&amp;width=980\" />
<small class=\"image-media media-caption\">Midjourney produced these recognizable images of The Simpsons.</small><small class=\"image-media media-photo-credit\">Gary Marcus and Reid Southen via Midjourney</small></p><p>In light of these results, it seems all but certain that Midjourney V6 has been trained on copyrighted materials (whether or not they have been licensed, we do not know) and that their tools could be used to create outputs that infringe. Just as we were sending this to press, <span style=\"background-color: initial;\">we also found <a href=\"https://arxiv.org/pdf/2301.13188.pdf\" target=\"_blank\">important related work</a> by Carlini on visual images on the <a href=\"https://clipdrop.co/stable-diffusion?utm_campaign=stable_diffusion_promo&amp;utm_medium=cta_button&amp;utm_source=stability_ai\" rel=\"noopener noreferrer\" target=\"_blank\">Stable Diffusion</a> platform that</span> converged on similar conclusions, albeit using a more complex, automated adversarial technique.</p><p>After this, we (Marcus and Southen) began to collaborate, and conduct further experiments.</p><h2>Visual models can produce near replicas of trademarked characters with indirect prompts</h2><p>In many of the examples above, we directly referenced a film (for example, <em>Avengers: Infinity War</em>); this established that Midjourney can re-create copyrighted materials knowingly, but left open a question of whether someone could potentially infringe without the user doing so deliberately.</p><p>In some ways the most compelling part of <em>The New York Times</em> complaint is that the plaintiffs established that plagiaristic responses could be elicited without invoking <em>The New York Times</em> at all. Rather than addressing the system with a prompt like “could you write an article in the style of <em>The New York Times</em> about such-and-such,” the plaintiffs elicited some plagiaristic responses simply by giving the first few words from a <em>Times</em> story, as in this example.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Side by side images compare output from GPT-4 with a New York Times article. The copy is identical.\" class=\"rm-shortcode\" id=\"445a1\" src=\"https://spectrum.ieee.org/media-library/side-by-side-images-compare-output-from-gpt-4-with-a-new-york-times-article-the-copy-is-identical.jpg?id=51009984&amp;width=980\" />
<small class=\"image-media media-caption\">An exhibit from a lawsuit shows that GPT-4 produced seemingly plagiaristic text when prompted with the first few words of an actual article.</small><small class=\"image-media media-photo-credit\"><a href=\"https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html\" rel=\"noopener noreferrer\" target=\"_blank\">New York Times</a></small></p><p>Such examples are particularly compelling because they raise the possibility that an end user might <em>inadvertently</em> produce infringing materials. We then asked whether a similar thing might happen in the visual domain.</p><p>The answer was a resounding yes. In each sample, we present a prompt and an output. In each image, the system has generated clearly recognizable characters (the Mandalorian, Darth Vader, Luke Skywalker, and more) that we assume are both copyrighted and trademarked; in no case were the source films or specific characters directly evoked by name. Crucially, the system was not asked to infringe, but the system yielded potentially infringing artwork anyway.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A collection of prompts and generative AI created images which look like Star Wars characters.\" class=\"rm-shortcode\" id=\"dbdaa\" src=\"https://spectrum.ieee.org/media-library/a-collection-of-prompts-and-generative-ai-created-images-which-look-like-star-wars-characters.jpg?id=51010245&amp;width=980\" />
<small class=\"image-media media-caption\">Midjourney produced these recognizable images of Star Wars characters even though the prompts did not name the movies.</small><small class=\"image-media media-photo-credit\">Gary Marcus and Reid Southen via Midjourney</small></p><p>We saw this phenomenon play out with both movie and video-game characters. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A collection of prompts and generative AI created images which look like characters from Toy Story, Minions, Sonic the Hedgehog and Super Mario Bros.\" class=\"rm-shortcode\" id=\"b9ccd\" src=\"https://spectrum.ieee.org/media-library/a-collection-of-prompts-and-generative-ai-created-images-which-look-like-characters-from-toy-story-minions-sonic-the-hedgehog.jpg?id=51010053&amp;width=980\" />
<small class=\"image-media media-caption\">Midjourney generated these recognizable images of movie and video-game characters even though the movies and games were not named.</small><small class=\"image-media media-photo-credit\">Gary Marcus and Reid Southen via Midjourney</small></p><h2>Evoking filmlike frames without direct instruction<br /></h2><p>In our third experiment with Midjourney, we asked whether it was capable of evoking entire film frames, without direct instruction. Again, we found that the answer was yes. (The top one is from a Hot Toys shoot rather than a film.)</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Three pairs of side by side images show Iron Man, Batman, and the Joker. On the left are image stills, on the right are images created by Midjourney.\" class=\"rm-shortcode\" id=\"f6498\" src=\"https://spectrum.ieee.org/media-library/three-pairs-of-side-by-side-images-show-iron-man-batman-and-the-joker-on-the-left-are-image-stills-on-the-right-are-images-c.jpg?id=51010183&amp;width=980\" />
<small class=\"image-media media-caption\">Midjourney produced images that closely resemble specific frames from well-known films.</small><small class=\"image-media media-photo-credit\">Right side images: Gary Marcus and Reid Southen via Midjourney</small></p><p>Ultimately, we discovered that a prompt of just a single word (not counting routine parameters) that’s not specific to any film, character, or actor yielded apparently infringing content: that word was “screencap.” The images below were created with that prompt.<br /></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A grid of six images created by Midjourney showing famous pop culture characters.\" class=\"rm-shortcode\" id=\"72d3d\" src=\"https://spectrum.ieee.org/media-library/a-grid-of-six-images-created-by-midjourney-showing-famous-pop-culture-characters.jpg?id=51010186&amp;width=980\" />
<small class=\"image-media media-caption\">These images, all produced by Midjourney, closely resemble film frames. They were produced with the prompt “screencap.”</small><small class=\"image-media media-photo-credit\">Gary Marcus and Reid Southen via Midjourney</small></p><p>We fully expect that Midjourney will immediately patch this specific prompt, rendering it ineffective, but the ability to produce potentially infringing content is manifest.<br /></p><p>In the course of two weeks’ investigation we found hundreds of examples of recognizable characters from films and games; we’ll release some further examples soon on YouTube. Here’s a partial list of the films, actors, and games we recognized.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A list of well known films, actors, actresses, and video games.\" class=\"rm-shortcode\" id=\"d6eaf\" src=\"https://spectrum.ieee.org/media-library/a-list-of-well-known-films-actors-actresses-and-video-games.jpg?id=51010189&amp;width=980\" />
<small class=\"image-media media-caption\">The authors’ experiments with Midjourney evoked images that closely resembled dozens of actors, movie scenes, and video games.</small><small class=\"image-media media-photo-credit\">Gary Marcus and Reid Southen</small></p><h2>Implications for Midjourney</h2><p>These results provide powerful evidence that Midjourney has trained on copyrighted materials, and establish that at least some generative AI systems may produce plagiaristic outputs, even when not directly asked to do so, potentially exposing users to copyright infringement claims. <a href=\"https://www.artnews.com/art-news/news/midjourney-ai-artists-database-1234691955/?fbclid=IwAR3CInCjDNu3Oek6be_L_gVj35JwLEzC7wNy7ye-zPvNzv0TdlMeX6Y6pow\" target=\"_blank\">Recent journalism</a> supports the same conclusion; for example, a lawsuit has introduced a <a href=\"https://www.theregister.com/2024/01/04/midjourney_artists_spreadsheet/\" target=\"_blank\">spreadsheet</a> attributed to Midjourney containing a list of more than 4,700 artists whose work is thought to have been used in training, quite possibly without consent. For further discussion of generative AI data scraping, see <a href=\"https://www.createdontscrape.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Create Don’t Scrape</a>.</p><p>How much of Midjourney’s source materials are copyrighted materials that are being used without license? We do not know for sure. Many outputs surely resemble copyrighted materials, but the company has not been transparent about its source materials, nor about what has been properly licensed. (Some of this may come out in legal discovery, of course.) We suspect that at least some has not been licensed.</p><p>Indeed, some of the company’s public comments have been dismissive of the question. When <a href=\"https://www.forbes.com/sites/robsalkowitz/2022/09/16/midjourney-founder-david-holz-on-the-impact-of-ai-on-art-imagination-and-the-creative-economy/?sh=4c1fc9822d2b\" rel=\"noopener noreferrer\" target=\"_blank\">asked by a Forbes reporter</a>, “Did you seek consent from living artists or work still under copyright?”, David Holz, Midjourney’s founder and CEO, expressed a certain lack of concern for the rights of copyright holders:</p><blockquote>No. There isn’t really a way to get a hundred million images and know where they’re coming from. It would be cool if images had metadata embedded in them about the copyright owner or something. But that’s not a thing; there’s not a registry. There’s no way to find a picture on the Internet, and then automatically trace it to an owner and then have any way of doing anything to authenticate it.</blockquote><p>If any of the source material is not licensed, it seems to us (as nonlawyers) that this potentially opens Midjourney to extensive litigation by film studios, video-game publishers, actors, and so on.</p><p>The gist of copyright and trademark law is to limit unauthorized commercial reuse in order to protect content creators. Since Midjourney charges subscription fees, and could be seen as competing with the studios, we can understand why plaintiffs might consider litigation. (Indeed, the company has already been <a href=\"https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart\" target=\"_blank\">sued by some artists</a>.)</p><p class=\"pull-quote\">Midjourney apparently sought to suppress our findings, banning one of this story’s authors after he reported his first results. </p><p>Of course, not every work that uses copyrighted material is illegal. In the United States, for example, a four-part doctrine of <a href=\"https://en.wikipedia.org/wiki/fair_use\" target=\"_blank\">fair use</a> allows potentially infringing works to be used in some instances, such as if the usage is brief and for the purposes of criticism, commentary, scientific evaluation, or parody. Companies like Midjourney might wish to lean on this defense.</p><p>Fundamentally, however, Midjourney is a service that sells subscriptions, at large scale. An individual user might make a case with a particular instance of potential infringement that their specific use of, for example, a character from <em>Dune</em> was for satire or criticism, or their own noncommercial purposes. (Much of what is referred to as “fan fiction” is actually considered copyright infringement, but it’s generally tolerated where noncommercial.) Whether Midjourney can make this argument on a mass scale is another question altogether.</p><p>One user on X <a href=\"https://twitter.com/gordic_aleksa/status/1742136689022103989\" target=\"_blank\">pointed to the fact</a> that Japan has allowed AI companies to train on copyright materials. While this observation is true, it is <a href=\"https://twitter.com/neilturkewitz/status/1742195405767459057\" target=\"_blank\">incomplete and oversimplified</a>, as that training is constrained by limitations on unauthorized use drawn directly from relevant international law (including the <a href=\"https://www.wipo.int/treaties/en/ip/berne/\" target=\"_blank\">Berne Convention</a> and <a href=\"https://www.wto.org/english/tratop_e/trips_e/intel2_e.htm\" target=\"_blank\">TRIPS agreement</a>). In any event, the Japanese stance seems unlikely to be carry any weight in American courts.</p><p>More broadly, some people have expressed the sentiment that information of all sorts ought to be free. In our view, this sentiment does not respect the rights of artists and creators; the world would be the poorer without their work.</p><p>Moreover, it reminds us of arguments that were made in the early days of <a href=\"https://en.wikipedia.org/wiki/Napster\" target=\"_blank\">Napster</a>, when songs were shared over peer-to-peer networks with no compensation to their creators or publishers. Recent <a href=\"https://twitter.com/WorldEverett/status/1742241774406377955?s=20\" target=\"_blank\">statements</a> such as, “In practice, copyright can’t be enforced with such powerful models like [Stable Diffusion] or Midjourney—even if we agree about regulations, it’s not feasible to achieve,” are a modern version of that line of argument.</p><p class=\"pull-quote\">We do not think that large generative AI companies should assume that the laws of copyright and trademark will inevitably be rewritten around their needs.</p><p>Significantly, in the end, Napster’s infringement on a mass scale was shut down by the courts, after lawsuits by <a href=\"https://en.wikipedia.org/wiki/Metallica_v._Napster,_Inc.\" rel=\"noopener noreferrer\" target=\"_blank\">Metallica</a> and the <a href=\"https://en.wikipedia.org/wiki/A%26M_Records,_Inc._v._Napster,_Inc.\" rel=\"noopener noreferrer\" target=\"_blank\">Recording Industry Association of America</a> (RIAA). The new business model of streaming was launched, in which publishers and artists (to a much smaller degree than we would like) received a cut.</p><p>Napster as people knew it essentially disappeared overnight; the company itself went bankrupt, with its assets, including its name, sold to a streaming service. We do not think that large generative AI companies should assume that the laws of copyright and trademark will inevitably be rewritten around their needs.</p><p>If companies like Disney, Marvel, DC, and Nintendo follow the lead of <em>The New York Times</em> and sue over copyright and trademark infringement, it’s entirely possible that they’ll win, much as the RIAA did before.</p><p>Compounding these matters, we have discovered evidence that a senior software engineer at Midjourney took part in a conversation in February 2022 about how to evade copyright law by “<a href=\"https://x.com/nelkmarge/status/1740223308304654514?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">laundering” data</a> “through a <a href=\"https://microsoft.github.io/prompt-engineering/\" target=\"_blank\">fine tuned codex</a>.” Another participant who may or may not have worked for Midjourney then said “at some point it really becomes impossible to trace what’s a derivative work in the eyes of copyright.”</p><blockquote class=\"rm-embed twitter-tweet\">
<div style=\"margin: 1em 0;\"></div> —  (@)
        <a href=\"https://twitter.com/nelkmarge/status/1740223308304654514\"></a>
</blockquote>
<p>As we understand things, punitive damages could be large. As mentioned before, sources have recently reported that Midjourney may have deliberately created an immense list of artists on which to train, perhaps without licensing or compensation. Given how close the current software seems to come to source materials, it’s not hard to envision a class action lawsuit.</p><p>Moreover, Midjourney apparently sought to suppress our findings, banning Southen from its service (without even a refund of his subscription fee) after he reported his first results, and again after he created a new account from which additional results were reported. It then apparently changed its <a href=\"https://docs.midjourney.com/docs/terms-of-service\" rel=\"noopener noreferrer\" target=\"_blank\">terms of service</a> just before Christmas by inserting new language: “You may not use the Service to try to violate the intellectual property rights of others, including copyright, patent, or trademark rights. Doing so may subject you to penalties including legal action or a permanent ban from the Service.” </p><p>This change might be interpreted as discouraging or even precluding the important and common practice of <a href=\"https://en.wikipedia.org/wiki/Red_team\" rel=\"noopener noreferrer\" target=\"_blank\">red-team</a> investigations of the limits of generative AI—a practice that several major AI companies committed to as part of <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/09/Voluntary-AI-Commitments-September-2023.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">agreements</a> with the White House announced in 2023. (Southen created two additional accounts in order to complete this project; these, too, were banned, with subscription fees not returned.)</p><p>We find these practices—banning users and discouraging red-teaming—unacceptable. The only way to ensure that tools are valuable, safe, and not exploitative is to allow the community an opportunity to investigate; this is precisely why the community has generally agreed that red-teaming is an important part of AI development, particularly because these systems are as yet far from fully understood.</p><p class=\"pull-quote\">The very pressure that drives generative AI companies to gather more data and make their models larger may also be making the models more plagiaristic.</p><p>We encourage users to consider using alternative services unless Midjourney retracts these policies that discourage users from investigating the risks of copyright infringement, particularly since Midjourney has been opaque about their sources.</p><p>Finally, as a scientific question, it is not lost on us that Midjourney produces some of the most detailed images of any current image-generating software. An open question is whether the propensity to create plagiaristic images increases along with increases in capability.</p><p>The data on text outputs by Nicholas Carlini that we mentioned above suggests that this might be true, as does our own experience and <a href=\"https://x.com/joybeanns/status/1742334855323779149?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">one informal report we saw on X</a>. It makes intuitive sense that the more data a system has, the better it can pick up on statistical correlations, but also perhaps the more prone it is to re-creating something exactly.</p><p>Put slightly differently, if this speculation is correct, the very pressure that drives generative AI companies to gather more and more data and make their models larger and larger (in order to make the outputs more humanlike) may also be making the models more plagiaristic.<span></span><br /></p><h2>Plagiaristic visual outputs in another platform: DALL-E 3</h2><p>An obvious follow-up question is to what extent are the things we have documented true of of other generative AI image-creation systems? Our next set of experiments asked whether what we found with respect to Midjourney was true on OpenAI’s <a href=\"https://openai.com/dall-e-3\" target=\"_blank\">DALL-E 3</a>, as made available through Microsoft’s Bing.</p><p>As we reported recently <span style=\"background-color: initial;\"><a href=\"https://garymarcus.substack.com/p/things-are-about-to-get-a-lot-worse\" target=\"_blank\">on Substack</a></span>, the answer was again clearly yes. As with Midjourney, DALL-E 3 was capable of creating plagiaristic (near-identical) representations of trademarked characters, even when those characters were not mentioned by name.</p><p>DALL-E 3 also created a whole universe of potential trademark infringements with this single two-word prompt: “animated toys” [bottom right].</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A set of four images, each containing four images. The prompt videogame italian shows images of Mario, videogame hedgehog shows Sonic, a longer prompt about a golden droid shows C3PO, and animated toys shows toys including ones from Disney movies.\" class=\"rm-shortcode\" id=\"3a7d9\" src=\"https://spectrum.ieee.org/media-library/a-set-of-four-images-each-containing-four-images-the-prompt-videogame-italian-shows-images-of-mario-videogame-hedgehog-shows.jpg?id=51010430&amp;width=980\" />
<small class=\"image-media media-caption\">OpenAI’s DALL-E 3, like Midjourney, produced images closely resembling characters from movies and games.</small><small class=\"image-media media-photo-credit\">Gary Marcus and Reid Southen via DALL-E 3</small></p><p>OpenAI’s DALL-E 3, like Midjourney, appears to have drawn on a wide array of copyrighted sources. As in Midjourney’s case, OpenAI seems to be well aware of the fact that its software might infringe on copyright, offering in November to <a href=\"https://www.theguardian.com/technology/2023/nov/06/openai-chatgpt-customers-copyright-lawsuits\" target=\"_blank\">indemnify users</a> (with some restrictions) from copyright-infringement lawsuits. Given the scale of what we have uncovered here, the potential costs are considerable.</p><h2>How hard is it to replicate these phenomena?</h2><p>As with any stochastic system, we cannot guarantee that our specific prompts will lead other users to identical outputs; moreover, there has been <a href=\"https://twitter.com/Cornubot/status/1740844076382265399?s=20\" target=\"_blank\">some speculation</a> that OpenAI has been changing its system in real time to rule out some specific behavior that we have reported on. Nonetheless, the overall phenomenon was widely replicated within two days of our original report, with <a href=\"https://x.com/katieconradks/status/1740872322683449835?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">other trademarked entities</a> and <a href=\"https://x.com/nleseul/status/1741318929262260287?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">even in other languages</a>.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Image shows prompts to create an image of a red can of soda that produces AI generated images of Coca-Cola cans.\" class=\"rm-shortcode\" id=\"6765d\" src=\"https://spectrum.ieee.org/media-library/image-shows-prompts-to-create-an-image-of-a-red-can-of-soda-that-produces-ai-generated-images-of-coca-cola-cans.jpg?id=51011500&amp;width=980\" />
<small class=\"image-media media-caption\">An X user showed this example of Midjourney producing an image that resembles a can of Coca-Cola when given only an indirect prompt.</small><small class=\"image-media media-photo-credit\"><a href=\"https://twitter.com/KatieConradKS/status/1740872322683449835\" rel=\"noopener noreferrer\" target=\"_blank\">Katie ConradKS/X</a></small></p><p>The next question is, how hard is it to solve these problems? </p><h2>Possible solution: removing copyright materials</h2><p>The cleanest solution would be to retrain the image-generating models without using copyrighted materials, or to restrict training to properly licensed datasets.</p><p>Note that one obvious alternative—removing copyrighted materials only post hoc when there are complaints, analogous to takedown requests on YouTube—is much more costly to implement than many readers might imagine. Specific copyrighted materials cannot in any simple way be removed from existing models; large neural networks are not databases in which an offending record can easily be deleted. As things stand now, the equivalent of takedown notices would require (very expensive) retraining in every instance.</p><p>Even though companies clearly could avoid the risks of infringing by retraining their models without any unlicensed materials, many might be tempted to consider other approaches. Developers may well try to avoid licensing fees, and to avoid significant retraining costs. Moreover, results may well be worse without copyrighted materials.</p><p>Generative AI vendors may therefore wish to patch their existing systems so as to restrict certain kinds of queries and certain kinds of outputs. We have already <a href=\"https://x.com/cornubot/status/1740844076382265399?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">seem some signs of this</a> (below), but believe it to be an uphill battle.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Two screenshots show a DALL-E prompt that produced images of C-3PO, and a prompt some time later showing DALL-E not generating images from Star Wars.\" class=\"rm-shortcode\" id=\"eb0c5\" src=\"https://spectrum.ieee.org/media-library/two-screenshots-show-a-dall-e-prompt-that-produced-images-of-c-3po-and-a-prompt-some-time-later-showing-dall-e-not-generating-i.jpg?id=51010860&amp;width=980\" />
<small class=\"image-media media-caption\">OpenAI may be trying to patch these problems on a case-by-case basis in real time. An X user shared a DALL-E-3 prompt that first produced images of C-3PO, and then later produced a message saying it couldn’t generate the requested image.</small><small class=\"image-media media-photo-credit\"><a href=\"https://twitter.com/Cornubot/status/1740844076382265399\" target=\"_blank\">Lars Wilderäng/X</a></small></p><p>We see two basic approaches to solving the problem of plagiaristic images without retraining the models; neither is easy to implement reliably.</p><h2>Possible solution: filtering out queries that might violate copyright</h2><p>For filtering out problematic queries, some low-hanging fruit is trivial to implement (for example, don’t generate Batman). But other cases can be subtle, and can even span more than one query, as in this example from X user <a href=\"https://twitter.com/NLeseul\" target=\"_blank\">NLeseul</a>:</p><blockquote class=\"rm-embed twitter-tweet\">
<div style=\"margin: 1em 0;\"></div> —  (@)
        <a href=\"https://twitter.com/NLeseul/status/1740956607843033374\"></a>
</blockquote>
<p>Experience has shown that guardrails in text-generating systems are often simultaneously too lax in some cases and too restrictive in others. Efforts to patch image- (and eventually video-) generation services are likely to encounter similar difficulties. For instance, a friend, Jonathan Kitzen, recently asked Bing for “<a href=\"https://x.com/garymarcus/status/1741472084545487074?s=12\" target=\"_blank\">a toilet in a desolate sun baked landscape</a>.” Bing refused to comply, instead returning a baffling “unsafe image content detected” flag. Moreover, as Katie Conrad <a href=\"https://twitter.com/katieconradks/status/1740850665033695731?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">has shown</a>, Bing’s replies about whether the content it creates can legitimately used are at times deeply misguided.<br /></p><p>Already, there are online guides with advice on <a href=\"https://x.com/ai_for_success/status/1725457976885186956?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">how to outwit OpenAI’s guardrails</a> for DALL-E 3, with advice like “Include specific details that distinguish the character, such as different hairstyles, facial features, and body textures” and “Employ color schemes that hint at the original but use unique shades, patterns, and arrangements.” The long tail of difficult-to-anticipate cases like the Brad Pitt interchange below (<a href=\"https://www.reddit.com/r/ChatGPT/comments/18wf1ie/public_domain_jailbreak/?rdt=50000\" target=\"_blank\">reported on Reddit</a>) may be endless.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"Prompts to ChatGPT convince it to create an image of Brad Pitt doing gymnastics, despite it originally saying it cannot create an image of Brad Pitt, only someone with a &quot;similar physique.&quot;\" class=\"rm-shortcode\" id=\"d8569\" src=\"https://spectrum.ieee.org/media-library/prompts-to-chatgpt-convince-it-to-create-an-image-of-brad-pitt-doing-gymnastics-despite-it-originally-saying-it-cannot-create-a.jpg?id=51011355&amp;width=980\" />
<small class=\"image-media media-caption\">A Reddit user shared this example of tricking ChatGPT into producing an image of Brad Pitt.</small><small class=\"image-media media-photo-credit\"><a href=\"https://www.reddit.com/r/ChatGPT/comments/18wf1ie/public_domain_jailbreak/?rdt=50000\" target=\"_blank\">lovegov/Reddit</a></small></p><h2>Possible solution: filtering out sources </h2><p>It would be great if art-generation software could list the sources it drew from, allowing humans to judge whether an end product is derivative, but current systems are simply too opaque in their “black box” nature to allow this. When we get an output in such systems, we don’t know how it relates to any particular set of inputs.</p><p class=\"pull-quote\">The very existence of potentially infringing outputs is evidence of another problem: the nonconsensual use of copyrighted human work to train machines. </p><p>No current service offers to deconstruct the relations between the outputs and specific training examples, nor are we aware of any compelling demos at this time. Large neural networks, as we know how to build them, break information into many tiny distributed pieces; reconstructing provenance is known to be extremely difficult.</p><p>As a last resort, the X user <a href=\"https://twitter.com/bartekxx12\" target=\"_blank\">@bartekxx12</a> has experimented with trying to get ChatGPT and Google Reverse Image Search to identify sources, with mixed (but not zero) success. It remains to be seen whether such approaches can be used reliably, particularly with materials that are more recent and less well-known than those we used in our experiments.</p><p>Importantly, although some AI companies and some defenders of the status quo have suggested filtering out infringing outputs as a possible remedy, such filters should in no case be understood as a complete solution. The very existence of potentially infringing outputs is evidence of another problem: the nonconsensual use of copyrighted human work to train machines. In keeping with the intent of international law protecting both intellectual property and human rights, no creator’s work should ever be used for commercial training without consent.</p><h2>Why does all this matter, if everyone already knows Mario anyway?</h2><p>Say you ask for an image of a plumber, and get Mario. As a user, can’t you just discard the Mario images yourself? X user <a href=\"https://x.com/nicky_bonez/status/1741453856632930743?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">@Nicky_BoneZ</a> addresses this vividly:</p><blockquote>… everyone knows what Mario looks Iike. But nobody would recognize Mike Finklestein’s wildlife photography. So when you say “super super sharp beautiful beautiful photo of an otter leaping out of the water” You probably don’t realize that the output is essentially a real photo that Mike stayed out in the rain for three weeks to take. </blockquote><p>As the same user points out, individual artists such as Finklestein are also unlikely to have sufficient legal staff to pursue claims against AI companies, however valid.</p><p>Another X user similarly <a href=\"https://twitter.com/twelvisten/status/1741026732340359636?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">discussed an example</a> of a friend who created an image with a prompt of “man smoking cig in style of 60s” and used it in a video; the friend didn’t know they’d just used a near duplicate of a Getty Image photo of Paul McCartney.</p><p class=\"pull-quote\">These companies may well also court attention from the U.S. Federal Trade Commission and other consumer protection agencies across the globe.</p><p>In a simple drawing program, anything users create is theirs to use as they wish, unless they deliberately import other materials. The drawing program itself never infringes. With generative AI, the software itself is clearly capable of creating infringing materials, and of doing so without notifying the user of the potential infringement.<br /></p><p>With Google Image search, you get back a link, not something represented as original artwork. If you find an image via Google, you can follow that link in order to try to determine whether the image is in the public domain, from a stock agency, and so on. In a generative AI system, the invited inference is that the creation is original artwork that the user is free to use. No manifest of how the artwork was created is supplied.</p><p><span></span>Aside from some language buried in the terms of service, there is no warning that infringement could be an issue. Nowhere to our knowledge is there a warning that any specific generated output potentially infringes and therefore should not be used for commercial purposes. As <a href=\"https://twitter.com/ednewtonrex\" target=\"_blank\">Ed Newton-Rex</a>, a musician and software engineer who recently walked away from Stable Diffusion out of ethical concerns <a href=\"https://x.com/ednewtonrex/status/1741802542118416552?s=46\" target=\"_blank\">put it</a>,<br /></p><blockquote> Users should be able to expect that the software products they use will not cause them to infringe copyright. And in multiple examples currently [circulating], the user could not be expected to know that the model’s output was a copy of someone’s copyrighted work.</blockquote><p>In the words of risk analyst <a href=\"https://twitter.com/biervicki/status/1741150952659300614?s=12\" target=\"_blank\">Vicki Bier</a>,</p><blockquote>“If the tool doesn’t warn the user that the output might be copyrighted how can the user be responsible? AI can help me infringe copyrighted material that I have never seen and have no reason to know is copyrighted.”</blockquote><p>Indeed, there is no publicly available tool or database that users could consult to determine possible infringement, nor any instruction to users as how they might possibly do so.</p><p>In putting an excessive, unusual, and insufficiently explained burden on both users and nonconsenting content providers, these companies may well also court attention from the U.S. Federal Trade Commission and other consumer protection agencies across the globe.</p><h2>Ethics and a broader perspective</h2><p>Software engineer Frank Rundatz recently stated a <a href=\"https://x.com/frankrundatz/status/1683462922389815297?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">broader perspective</a>.</p><blockquote>One day we’re going to look back and wonder how a company had the audacity to copy all the world’s information and enable people to violate the copyrights of those works.<br />All Napster did was enable people to transfer files in a peer-to-peer manner. They didn’t even host any of the content! Napster even developed a system to stop 99.4% of copyright infringement from their users but were still shut down because the court required them to stop 100%.<br />OpenAI scanned and hosts all the content, sells access to it and will even generate derivative works for their paying users.</blockquote><p>Ditto, of course, for Midjourney.</p><p>Stanford Professor Surya Ganguli <a href=\"https://x.com/suryaganguli/status/1741322962249367776?s=61&amp;t=2voLMkhJf6P349CqztWSAQ\" target=\"_blank\">adds</a>:</p><blockquote>Many researchers I know in big tech are working on AI alignment to human values. But at a gut level, shouldn’t such alignment entail compensating humans for providing training data thru their original creative, copyrighted output? (This is a values question, not a legal one).</blockquote><p>Extending Ganguli’s point, there are other worries for image generation beyond intellectual property and the rights of artists. Similar kinds of image-generation technologies are being used for purposes <a href=\"https://wpde.com/news/nation-world/schools-law-enforcement-sound-alarm-over-ais-ability-to-produce-child-sexual-abuse-images-csam-explicit-images-harmful-content-large-scale-artificial-intelligence-open-network-child-porn-illegal-content\" target=\"_blank\">such as creating child sexual abuse materials</a> and nonconsensual deepfaked porn. To the extent that the AI community is serious about aligning software to human values, it’s imperative that laws, norms, and software be developed to combat such uses.</p><h2>Summary</h2><p>It seems all but certain that generative AI developers like OpenAI and Midjourney have trained their image-generation systems on copyrighted materials. Neither company has been transparent about this; Midjourney went so far as to ban us three times for investigating the nature of their training materials.</p><p>Both OpenAI and Midjourney are fully capable of producing materials that appear to infringe on copyright and trademarks. These systems do not inform users when they do so. They do not provide any information about the provenance of the images they produce. Users may not know, when they produce an image, whether they are infringing.</p><p>Unless and until someone comes up with a technical solution that will either accurately report provenance or automatically filter out the vast majority of copyright violations, the only ethical solution is for generative AI systems to limit their training to data they have properly licensed. Image-generating systems should be required to license the art used for training, just as streaming services are required to license their music and video.</p><p class=\"pull-quote\">Both OpenAI and Midjourney are fully capable of producing materials that appear to infringe on copyright and trademarks. These systems do not inform users when they do so.</p><p>We hope that our findings (and similar findings from others who have begun to test related scenarios) will lead generative AI developers to document their data sources more carefully, to restrict themselves to data that is properly licensed, to include artists in the training data only if they consent, and to compensate artists for their work. In the long run, we hope that software will be developed that has great power as an artistic tool, but that doesn’t exploit the art of nonconsenting artists.</p><p>Although we have not gone into it here, we fully expect that similar issues will arise as generative AI is applied to other fields, such as music generation.</p><p>Following up on the <em>New York Times</em> lawsuit, our results suggest that generative AI systems may regularly produce plagiaristic outputs, both written and visual, without transparency or compensation, in ways that put undue burdens on users and content creators. We believe that the potential for litigation may be vast, and that the foundations of the entire enterprise may be built on ethically shaky ground.</p><p><br /></p><p><em>The order of authors is alphabetical; both authors contributed equally to this project. Gary Marcus wrote the first draft of this manuscript and helped guide some of the experimentation, while Reid Southen conceived of the investigation and elicited all the images.</em></p>",[{'name': 'Reid Southen'}],"Sat, 06 Jan 2024 15:00:03 +0000"
2278,The New York Times Wants ChatGPT Gone. Nice Try,https://spectrum.ieee.org/chatgpt-new-york-times,"<img src=\"https://spectrum.ieee.org/media-library/3d-illustration-of-lit-squares-forming-the-letters-gpt-with-wires-intertwined-with-the-logo-of-the-ny-times.jpg?id=51001956&amp;width=1200&amp;height=800&amp;coordinates=0%2C69%2C0%2C69\" /><br /><br /><p><em></em>The battle between copyright holders and generative AI companies is heating up, and <em>The New York Times</em> is leading the charge. </p><p>The publication recently filed a lawsuit against OpenAI and Microsoft<a href=\"https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf\" target=\"_blank\"><u> that claims copyright infringement, trademark dilution, and unfair competition</u></a>. And it’s not pulling its punches. The suit seeks not just monetary compensation but also the destruction of all the defendant’s LLM models and training data, as well as a halt to unlicensed training on the publication’s articles.  </p><p>“When you have these big technology shifts, the law has to adjust,” says <a href=\"https://www.zinitilaw.com\" target=\"_blank\"><u>Cecilia Ziniti, a Silicon Valley attorney</u></a>. “This case is so historic because <em>The New York Times</em> has millions and millions of words that are used for training. So, extrapolating out, now is the time this is going to be regulated and get looked at.” </p><h2>The showdown between copyright holders and AI companies intensifies</h2><p><em>The New York Times</em>’s lawsuit against OpenAI and Microsoft is the latest in a string of complaints against generative AI companies. <a href=\"https://www.reuters.com/legal/getty-images-lawsuit-says-stability-ai-misused-photos-train-ai-2023-02-06/\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Getty Images filed suit against StabilityAI</u></a>, creator of the image generation tool <a href=\"https://spectrum.ieee.org/ai-art-generator\" target=\"_blank\">Stable Diffusion</a>, in early 2023, and<a href=\"https://www.reuters.com/legal/music-publishers-sue-ai-company-anthropic-over-song-lyrics-2023-10-18/\" rel=\"noopener noreferrer\" target=\"_blank\"><u> several music publishers filed suit against Anthropic</u></a>, creator of <a href=\"https://claude.ai/login?returnTo=%2F\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Claude.ai</u></a>, in October.</p><p>But <em>The New York Times</em>’s suit is notable for its scope. It accuses the defendants of “copying and using <em>millions</em> of The Times’s copyrighted [articles].” The claim is supported by<a href=\"https://nytco-assets.nytimes.com/2023/12/Lawsuit-Document-dkt-1-68-Ex-J.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"><u> 100 examples of ChatGPT reproducing near-exact copy from <em>New York Times</em> articles</u></a>. </p><p>“Whenever you have a verbatim copy, that’s a replacement, and that’s going to be pretty colorable [plausible to the court],” says Ziniti. “<em>The New York Times</em> also has enough of a library, going back to 1851, that they can actually say some percentage of the training data was <em>New York Times</em>.” </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">
<img alt=\"A selection of docuements from The New York Times vs. OpenAI / Microsoft lawsuit. The docuements demonstrate that ChatGPT can reproduce sections of text that closely resemble articles published by The New York Times.\" class=\"rm-shortcode\" id=\"9aff4\" src=\"https://spectrum.ieee.org/media-library/a-selection-of-docuements-from-the-new-york-times-vs-openai-microsoft-lawsuit-the-docuements-demonstrate-that-chatgpt-can-re.jpg?id=50996133&amp;width=980\" />
<small class=\"image-media media-caption\">The New York Times’s lawsuit against OpenAI and Microsoft provides examples of ChatGPT producing text similar to the publication’s articles.</small><small class=\"image-media media-photo-credit\">The New York Times</small></p><p>Even so, the suit’s victory isn’t certain. <a href=\"https://www.techdirt.com/user/mmasnick/\" target=\"_blank\">Mike Masnick</a>, founder and editor of the technology policy publication Techdirt, points out that prior cases, such as the Authors Guild lawsuit against Google Books, set a precedent that may protect the use of copyrighted data to train AI.</p><p>“I go back to the most important similar case, which is <a href=\"https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc.\" target=\"_blank\">the Google Books case</a>,” says Masnick. “[Google] scanned books in order to create a giant search engine of books. That was very much a commercial entity, for a commercial purpose...that involved scanning entire copyrighted books and building a massive index of all those works.” Google argued that Google Books was transformative fair use and prevailed. </p><p>And there’s yet another complication: recent agreements between OpenAI and other publishers, such as Axel Springer and the Associated Press. The exact terms of the deals are unknown, <a href=\"https://openai.com/blog/axel-springer-partnership\" rel=\"noopener noreferrer\" target=\"_blank\"><u>but a press release from OpenAI </u></a>states its deal with Axel Springer will help the publisher summarize “selected global news.” OpenAI will in turn obtain content from Axel Springer to use for future AI training. <a href=\"https://apnews.com/article/openai-chatgpt-associated-press-ap-f86f84c5bcc2f3b98074b38521f5f75a\" rel=\"noopener noreferrer\" target=\"_blank\"><u>OpenAI also reached an agreement with the Associated Press</u></a>. </p><p>“The fact that OpenAI made deals with others shows there is a market for this particular use for data,” says Ziniti. Masnick is more skeptical that these agreements will be a factor, but notes that “a judge can decide whatever they want.... It’s not very predictable.”</p><h2>Prepare for years of copyright confusion<br /></h2><p>The lack of clarity on where the rights of copyright holders end, and those of companies creating generative AI begin, makes it impossible to know precisely where the law will settle. That’s not going to change overnight. <em>The Authors Guild, Inc. vs. Google, Inc.</em> took a decade to resolve. </p><p>Legislation can move more quickly. <a href=\"https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai\" rel=\"noopener noreferrer\" target=\"_blank\"><u>The European Parliament has reached a “provisional agreement” for an Artificial Intelligence Act</u></a>, which includes restrictions on how training data can be obtained and used. But even this act is not yet law, and it’s unclear when the regulations it outlines will come into effect.</p><p>In the meantime, companies and organizations training AI face a potential minefield—and may want to keep an eye on the source of data used for training. “From an engineering point of view, when you add a new source to your dataset to train on, you keep track of that, figure out where you looked at it, note the terms of use for the website,” says Ziniti. She notes that training from sources that include a wide variety of data, such as <a href=\"https://commoncrawl.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><u>Common Crawl</u></a>, is more defensible than training on a narrow dataset.</p><p>Developers accessing a third-party AI model (like <a href=\"https://spectrum.ieee.org/gpt-4-calm-down\" target=\"_blank\">GPT-4</a>) to build an app or service have less reason to be concerned. Some major providers of AI models, <a href=\"https://techcrunch.com/2023/11/06/openai-promises-to-defend-business-customers-against-copyright-claims/\" rel=\"noopener noreferrer\" target=\"_blank\"><u>including OpenAI</u></a>, have offered to defend customers against copyright claims that result from using its models. End users probably won’t find themselves on the business end of a lawsuit, either, though the details matter. Purposefully prompting an AI tool to infringe on a copyrighted work isn’t a great idea.</p><p>Whenever it’s resolved, the impact of <em>The New York Times</em>’s suit will be significant. Its failure would allow those looking to train new AI models to proceed as they have in the past with far less concern about future lawsuits. Success wouldn’t entirely halt the training of new AI models, but licensing costs may increase the cost of training beyond the means of all but the most well-funded companies.</p><p>Masnick says if training is deemed not subject to fair use protections, then only the big players will be able to afford it. “Suddenly you’ve wiped out a bunch of smaller players,” he says, “and potentially wiped out open-source AI models.”</p>",[{'name': 'Matthew S. Smith'}],"Sat, 06 Jan 2024 14:00:02 +0000"
2279,LangGraph for Code Generation,https://blog.langchain.dev/code-execution-with-langgraph/,"<p></p><h3 id=\"key-links\">Key Links</h3><ul><li><a href=\"https://github.com/langchain-ai/langgraph/blob/main/examples/code_assistant/langgraph_code_assistant.ipynb?ref=blog.langchain.dev\" rel=\"noreferrer\">LangGraph cookbook</a></li><li><a href=\"https://www.youtube.com/watch?v=MvNdgmM7uyc&amp;ref=blog.langchain.dev\">Video</a></li></ul><h3 id=\"motivation\">Motivation</h3><p>Code generation and analysis are two of most important applications of LLMs, as shown by the ubiquity of products like <a href=\"https://github.com/features/copilot?ref=blog.langchain.dev\">GitHub co-pilot</a> and popularity of projects like <a href=\"https://github.com/gpt-engineer-org/gpt-engineer?ref=blog.langchain.dev\">GPT-engineer</a>. The recent <a href=\"https://arxiv.org/pdf/2401.08500.pdf?ref=blog.langchain.dev\">AlphaCodium</a> work showed that code generation can be <a href=\"https://x.com/karpathy/status/1748043513156272416?s=20&amp;ref=blog.langchain.dev\" rel=\"noopener\">improved by using a <code>flow</code> paradigm</a></p>",[{'name': 'Ankush Gola'}],"Tue, 27 Feb 2024 16:10:00 GMT"
2280,[Week of 2/19] LangChain Release Notes,https://blog.langchain.dev/week-of-2-19-langchain-release-notes/,<h3 id=\"%F0%9F%9A%80-langsmith-launch\"><strong>&#x1f680; </strong>LangSmith Launch!</h3><p>LangSmith is now generally available - no more waitlist! Sign up for free <a href=\"https://smith.langchain.com/?ref=blog.langchain.dev\">here</a>.</p><ul><li>Video resources: <a href=\"https://www.youtube.com/watch?v=jx7xuHlfsEQ&amp;ref=blog.langchain.dev\">LangSmith in 10 minutes</a> &amp; <a href=\"https://www.youtube.com/watch?v=3wAON0Lqviw&amp;ref=blog.langchain.dev\">In Depth Platform Overview</a></li><li>Our <a href=\"https://blog.langchain.dev/langsmith-ga/\">release blog</a> covers all of the latest features in LangSmith</li><li>We&#x2019;ve shipped TypeScript improvements. It&#x2019;s now easier</li></ul>,[{'name': 'LangChain'}],"Fri, 23 Feb 2024 16:20:43 GMT"
2281,Reflection Agents,https://blog.langchain.dev/reflection-agents/,"Reflection is a prompting strategy used to improve the quality and success rate of agents and similar AI systems. This post outlines how to build 3 reflection techniques using LangGraph, including implementations of Reflexion and Language Agent Tree Search.",[{'name': 'Ankush Gola'}],"Wed, 21 Feb 2024 09:29:10 GMT"
2282,JSON agents with Ollama & LangChain,https://blog.langchain.dev/json-based-agents-with-ollama-and-langchain/,"<h2 id=\"learn-to-implement-an-open-source-mixtral-agent-that-interacts-with-a-graph-database-neo4j-through-a-semantic-layer\">Learn to implement an open-source Mixtral agent that interacts with a graph database Neo4j through a semantic layer</h2><p><strong>Editor&apos;s note: This post is written by </strong><a href=\"https://twitter.com/tb_tomaz?ref=blog.langchain.dev\"><strong>Tomaz Bratanic</strong></a><strong> from Neo4j</strong></p><p>By now, we all have probably recognized that we can significantly enhance the capabilities of LLMs by providing them</p>",[{'name': 'LangChain'}],"Tue, 20 Feb 2024 17:24:29 GMT"
2283,Supercharging If-Statements With Prompt Classification Using Ollama and LangChain,https://blog.langchain.dev/supercharging-if-statements-with-prompt-classification-using-ollama-and-langchain/,"<p><strong>Editor&apos;s Note: </strong><a href=\"https://medium.com/@andrewnguonly?ref=blog.langchain.dev\"><strong>Andrew Nguonly</strong></a><strong> has been building one of the more impressive projects we&apos;ve seen recently - an LLM co-pilot for browsing the web, powered by local LLMs. There are a lot of small architectural decisions made that contain a ton of nuance, and so we&</strong></p>",[{'name': 'LangChain'}],"Mon, 19 Feb 2024 17:16:07 GMT"
2284,Winning in AI means mastering the new stack,https://blog.langchain.dev/winning-in-ai-means-mastering-the-new-stack/,"<p>Authors: Edo Liberty, Guillermo Rauch, Ori Goshen, Robert Nishihara, Harrison Chase</p><h2 id=\"ai-in-2030\">AI in 2030</h2><p>AI is rapidly changing. Too rapidly for most. Ten years ago it was all about big data and ML. Deep Learning was a &#x201c;buzzy&#x201d; term that was just picking up steam. The term &#x201c;</p>",[{'name': 'Harrison Chase'}],"Fri, 16 Feb 2024 20:02:46 GMT"
2285,Announcing the General Availability of LangSmith and Our Series A Led By Sequoia Capital,https://blog.langchain.dev/langsmith-ga/,"<p>Today, we&#x2019;re thrilled to announce the <strong>general availability of LangSmith</strong> &#x2014; our solution for LLM application development, monitoring, and testing. We initially launched LangSmith in closed beta in July 2023. Since then, we&#x2019;ve received invaluable feedback from our early users and customers, and made significant improvements</p>",[{'name': 'Ankush Gola'}],"Thu, 15 Feb 2024 16:00:38 GMT"
2286,Rakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients and employees,https://blog.langchain.dev/rakuten-group-builds-with-langchain-and-langsmith-to-deliver-premium-products-for-its-business-clients-and-employees/,"<p>Rakuten Group is well known for operating one of the largest online shopping malls in Japan. The company has 70+ businesses in fields such as e-commerce, travel, digital content, fintech, communications and more.</p><p>Adopting new technologies to push the frontiers of what&#x2019;s possible is in the DNA of</p>",[{'name': 'LangChain'}],"Wed, 14 Feb 2024 20:20:31 GMT"
2287,How Dataherald Makes Natural Language to SQL Easy,https://blog.langchain.dev/dataherald/,"<p><strong>Editor&apos;s Note: we&apos;re excited to feature this guest post from the </strong><a href=\"https://www.dataherald.com/?ref=blog.langchain.dev\"><strong>Dataherald</strong></a><strong> team. Text-to-SQL is a HUGE use case, and Dataherald is the open-source leader in the space. This is a great look behind the curtains to see what makes it tick.</strong></p><p>When ChatGPT came out</p>",[{'name': 'LangChain'}],"Wed, 14 Feb 2024 17:09:09 GMT"
2288,Plan-and-Execute Agents,https://blog.langchain.dev/planning-agents/,"Plan and execute agents promise faster, cheaper, and more performant task execution over previous agent designs. Learn how to build 3 types of planning agents in LangGraph in this post.",[{'name': 'LangChain'}],"Tue, 13 Feb 2024 16:35:24 GMT"
2289,"BCG X Releases AgentKit, a Full-Stack Starter Kit for Building Constrained Agents",https://blog.langchain.dev/bcg-x-releases-agentkit-a-full-stack-starter-kit-for-building-constrained-agents/,"<p><strong>Editor&apos;s Note: We&apos;re very excited to share this work by BCG. We&apos;ve worked closely with the BCG over the past year to help support companies bring GenAI initiatives into production. We were intrigued to hear about their AgentKit platform, and once we got a</strong></p>",[{'name': 'LangChain'}],"Mon, 12 Feb 2024 16:38:19 GMT"
2290,[Week of 2/5] LangChain Release Notes,https://blog.langchain.dev/week-of-2-5-24-langchain-release-notes/,"<p>We&#x2019;ve been busy shipping &#x1f6a2;! Next Thursday Feb 15th at noon PT, LangChain Co-founder Ankush Gola will host a webinar to share some exciting updates on LangSmith, and we promise everyone will have access to the platform by then! Sign up <a href=\"https://www.crowdcast.io/c/langsmith?ref=blog.langchain.dev\" rel=\"noreferrer\">here</a> to join and ask questions about</p>",[{'name': 'LangChain'}],"Fri, 09 Feb 2024 18:54:56 GMT"
2291,LangChain Partners with CommandBar on their Copilot User Assistant,https://blog.langchain.dev/langchain-partners-with-commandbar-on-their-copilot-user-assistant/,"<p><a href=\"https://commandbar.com/?ref=blog.langchain.dev\"><u>CommandBar</u></a> is a user assistance platform that helps software companies make their products easy to use by capturing and predicting user intent, and then delivering personalized in-product help. CommandBar&#x2019;s Copilot widget, which companies embed into their applications, goes beyond a typical chatbot. It can answer user questions, trigger</p>",[{'name': 'LangChain'}],"Thu, 08 Feb 2024 21:10:49 GMT"
2292,Human-in-the-loop with OpenGPTs and LangGraph,https://blog.langchain.dev/human-in-the-loop-with-opengpts-and-langgraph/,"<p><strong>TLDR; Today we&#x2019;re launching two &#x201c;human in the loop&#x201d; features in OpenGPTs, Interrupt and Authorize, both powered by LangGraph.</strong></p><p>We&apos;ve recently launched LangGraph, a library to help developers build multi-actor, multi-step, stateful LLM applications. That&apos;s a lot words packed into a short</p>",[{'name': 'Nuno Campos'}],"Thu, 08 Feb 2024 16:56:41 GMT"
2293,Self-Reflective RAG with LangGraph,https://blog.langchain.dev/agentic-rag-with-langgraph/,"<h3 id=\"key-links\">Key Links</h3><ul><li>Cookbooks for <a href=\"https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb?ref=blog.langchain.dev\">Self-RAG</a> and <a href=\"https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb?ref=blog.langchain.dev\">CRAG</a></li><li><a href=\"https://youtu.be/pbAd8O1Lvm4?ref=blog.langchain.dev\">Video</a></li></ul><h3 id=\"motivation\">Motivation</h3><p>Because most LLMs are only periodically trained on a large corpus of public data, they lack recent information and / or private data that is inaccessible for training. <strong>R</strong>etrieval <strong>a</strong>ugmented <strong>g</strong>eneration (RAG) is a central paradigm in LLM application</p>",[{'name': 'Ankush Gola'}],"Wed, 07 Feb 2024 16:47:25 GMT"
2294,I used generative AI to turn my story into a comic—and you can too,https://www.technologyreview.com/2024/03/05/1089458/generative-ai-turn-my-story-into-comic-images-lore-machine/,"Thirteen years ago, as an assignment for a journalism class, I wrote a stupid short story about a man who eats luxury cat food. This morning, I sat and watched as a generative AI platform called Lore Machine brought my weird words to life. I fed my story into a text box and got this&#8230;",[{'name': 'Will Douglas Heaven'}],"Tue, 05 Mar 2024 14:01:11 +0000"
2295,"The Download: rise of the robots, and what organoids can teach us",https://www.technologyreview.com/2024/03/05/1089451/the-download-rise-of-the-robots-and-what-organoids-can-teach-us/,"This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. The robots are coming. And that’s a good thing. —This is an excerpt from a new book, The Heart and the Chip: Our Bright Future with Robots, by MIT CSAIL director Daniela Rus&#160;&#8230;",[{'name': 'Rhiannon Williams'}],"Tue, 05 Mar 2024 13:10:00 +0000"
2296,Nobody knows how AI works,https://www.technologyreview.com/2024/03/05/1089449/nobody-knows-how-ai-works/,"This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. I’ve been experimenting with using AI assistants in my day-to-day work. The biggest obstacle to their being useful is they often get things blatantly wrong. In one case, I used an&#8230;",[{'name': 'Melissa Heikkilä'}],"Tue, 05 Mar 2024 10:31:28 +0000"
2297,The robots are coming. And that’s a good thing.,https://www.technologyreview.com/2024/03/05/1087646/the-robots-are-coming-and-thats-a-good-thing-2/,"In this excerpt from the new book, The Heart and the Chip: Our Bright Future with Robots, CSAIL Director Daniela Rus explores how robots can extend the reach of human capabilities. Years ago, I befriended the biologist Roger Payne at a meeting of MacArthur Foundation fellows. Roger, who died in 2023, was best known for&#8230;","[{'name': 'Daniela Rus, Gregory Mone'}]","Tue, 05 Mar 2024 05:01:00 +0000"
2298,Roundtables: The AI Economy,https://www.technologyreview.com/2024/03/04/1088983/roundtables-the-ai-economy/,"Recorded on August 10, 2023 The AI Economy Speakers: Mat Honan, Editor in chief and David Rotman, Editor at large There’s no doubt that generative AI will impact the economy—but how, exactly, remains an open question. Despite fears that these AI tools will upend workers and exacerbate wealth inequality, early evidence suggests the technology could&#8230;",[{'name': 'MIT Technology Review'}],"Mon, 04 Mar 2024 18:12:30 +0000"
2299,Roundtables: How should we regulate AI?,https://www.technologyreview.com/2024/03/04/1088979/roundtables-how-should-we-regulate-ai/,"Recorded on September 12, 2023 How should we regulate AI? Speakers: Melissa Heikkilä, Senior reporter for AI and Charlotte Jee, News editor There’s little doubt that artificial intelligence will be subject to more regulation in the years ahead. Major tech companies have requested it, and multiple countries and regions are now moving forward with plans&#8230;",[{'name': 'MIT Technology Review'}],"Mon, 04 Mar 2024 18:11:32 +0000"
2300,Roundtables: How does AI work?,https://www.technologyreview.com/2024/03/04/1088977/roundtables-how-does-ai-work/,"Recorded on October 11, 2023 How does AI work? Speakers: Mary Beth Griggs, Science editor and Will Douglas Heaven, Sr Editor for AI Everyone’s talking about large language models and image generators built on artificial intelligence. Many people have tested out tools like ChatGPT or DALL-E 2 and been amazed at the results, or disturbed&#8230;",[{'name': 'MIT Technology Review'}],"Mon, 04 Mar 2024 18:10:37 +0000"
2301,Roundtables: Future of Families: How reproductive technology can reverse population decline,https://www.technologyreview.com/2024/03/04/1088968/roundtables-future-of-families-how-reproductive-technology-can-reverse-population-decline/,"Recorded on November 28, 2023 Future of Families: How reproductive technology can reverse population decline Speakers: Antonio Regalado, Sr Editor of biomedicine and special guest Martín Varsavsky, Founder of Prelude Fertility Birth rates have been plummeting in wealthy countries, well below the “replacement” rate. Even in China, a dramatic downturn in the number of babies&#8230;",[{'name': 'MIT Technology Review'}],"Mon, 04 Mar 2024 18:09:32 +0000"
2302,Organoids made from amniotic fluid will tell us how fetuses develop,https://www.technologyreview.com/2024/03/04/1089419/organoids-made-from-amniotic-fluid-will-tell-us-how-fetuses-develop/,"As a fetus grows in the womb, it sheds cells into the amniotic fluid surrounding and protecting it. Now researchers have demonstrated that they can use those cells to grow organoids, three-dimensional structures that have some of the properties of human organs—in this case kidneys, small intestines, and lungs. These organoids could give doctors even&#8230;",[{'name': 'Cassandra Willyard'}],"Mon, 04 Mar 2024 16:00:00 +0000"
2303,Advancing AI innovation with cutting-edge solutions,https://www.technologyreview.com/2024/03/04/1089020/advancing-ai-innovation-with-cutting-edge-solutions/,"AI is helping organizations in nearly every industry increase productivity, engage customers, realize operational efficiencies, and gain a competitive edge. Advances in supercomputing in the cloud and the ability to achieve processing at an exascale level are major catalysts for this new era of AI innovation. Common AI use cases today include personalized healthcare and&#8230;",[{'name': 'Lachlan Ainley'}],"Mon, 04 Mar 2024 14:00:00 +0000"
2304,Robot trained to read braille at twice the speed of humans,https://www.sciencedaily.com/releases/2024/01/240129122413.htm,Researchers have developed a robotic sensor that incorporates artificial intelligence techniques to read braille at speeds roughly double that of most human readers.,[],"Mon, 29 Jan 2024 12:24:13 EST"
2305,A long-lasting neural probe,https://www.sciencedaily.com/releases/2024/01/240126171626.htm,An interdisciplinary team of researchers has developed a soft implantable device with dozens of sensors that can record single-neuron activity in the brain stably for months.,[],"Fri, 26 Jan 2024 17:16:26 EST"
2306,Transparent brain implant can read deep neural activity from the surface,https://www.sciencedaily.com/releases/2024/01/240111113149.htm,"Researchers have developed a neural implant that provides information about activity deep inside the brain while sitting on its surface. The implant is made up of a thin, transparent and flexible polymer strip that is packed with a dense array of graphene electrodes. The technology, tested in transgenic mice, brings the researchers a step closer to building a minimally invasive brain-computer interface (BCI) that provides high-resolution data about deep neural activity by using recordings from the brain surface.",[],"Thu, 11 Jan 2024 11:31:49 EST"
2307,"Cognitive strategies for augmenting the body with a wearable, robotic arm",https://www.sciencedaily.com/releases/2023/12/231213143711.htm,"Scientists show that breathing may be used to control a wearable extra robotic arm in healthy individuals, without hindering control of other parts of the body.",[],"Wed, 13 Dec 2023 14:37:11 EST"
2308,Deep neural networks show promise as models of human hearing,https://www.sciencedaily.com/releases/2023/12/231213143706.htm,"In the largest study yet of deep neural networks trained to perform auditory tasks, researchers found most of these models generate internal representations that share properties of representations seen in the human brain when people are listening to the same sounds.",[],"Wed, 13 Dec 2023 14:37:06 EST"
2309,Artificial intelligence makes gripping more intuitive,https://www.sciencedaily.com/releases/2023/12/231205144408.htm,Artificial hands can be operated via app or with sensors placed in the muscles of the forearm. New research shows: a better understanding of muscle activity patterns in the forearm supports a more intuitive and natural control of artificial limbs. This requires a network of 128 sensors and artificial intelligence based techniques.,[],"Tue, 05 Dec 2023 14:44:08 EST"
2310,Scientists use A.I.-generated images to map visual functions in the brain,https://www.sciencedaily.com/releases/2023/11/231130145431.htm,Researchers have demonstrated the use of AI-selected natural images and AI-generated synthetic images as neuroscientific tools for probing the visual processing areas of the brain. The goal is to apply a data-driven approach to understand how vision is organized while potentially removing biases that may arise when looking at responses to a more limited set of researcher-selected images.,[],"Thu, 30 Nov 2023 14:54:31 EST"
2311,Brain implant may enable communication from thoughts alone,https://www.sciencedaily.com/releases/2023/11/231106134844.htm,"A speech prosthetic developed by a collaborative team of neuroscientists, neurosurgeons and engineers can translate a person's brain signals into what they're trying to say. The new technology might one day help people unable to talk due to neurological disorders regain the ability to communicate through a brain-computer interface.",[],"Mon, 06 Nov 2023 13:48:44 EST"
2312,Nanowire 'brain' network learns and remembers 'on the fly',https://www.sciencedaily.com/releases/2023/11/231101134804.htm,"Like a collection of 'Pick Up Sticks', this neural network has passed a critical step for developing machine intelligence. For the first time, a physical neural network has successfully been shown to learn and remember 'on the fly', in a way inspired by and similar to how the brain's neurons work. The result opens a pathway for developing efficient and low-energy machine intelligence for more complex, real-world learning and memory tasks.",[],"Wed, 01 Nov 2023 13:48:04 EDT"
2313,Adaptive optical neural network connects thousands of artificial neurons,https://www.sciencedaily.com/releases/2023/10/231023124404.htm,"Physicists working with computer specialists have developed a so-called event-based architecture, using photonic processors. In a similar way to the brain, this makes possible the continuous adaptation of the connections within the neural network.",[],"Mon, 23 Oct 2023 12:44:04 EDT"
2314,"Robotic prosthetic ankles improve 'natural' movement, stability",https://www.sciencedaily.com/releases/2023/10/231018161856.htm,"Robotic prosthetic ankles that are controlled by nerve impulses allow amputees to move more 'naturally,' improving their stability, according to a new study.",[],"Wed, 18 Oct 2023 16:18:56 EDT"
2315,Efficient training for artificial intelligence,https://www.sciencedaily.com/releases/2023/09/230922110755.htm,New physics-based self-learning machines could replace the current artificial neural networks and save energy.,[],"Fri, 22 Sep 2023 11:07:55 EDT"
2316,Evolution wired human brains to act like supercomputers,https://www.sciencedaily.com/releases/2023/09/230914103332.htm,"Scientists have confirmed that human brains are naturally wired to perform advanced calculations, much like a high-powered computer, to make sense of the world through a process known as Bayesian inference.",[],"Thu, 14 Sep 2023 10:33:32 EDT"
2317,Brain signals transformed into speech through implants and AI,https://www.sciencedaily.com/releases/2023/08/230828130347.htm,"Researchers have succeeded in transforming brain signals into audible speech. By decoding signals from the brain through a combination of implants and AI, they were able to predict the words people wanted to say with an accuracy of 92 to 100%.",[],"Mon, 28 Aug 2023 13:03:47 EDT"
2318,How artificial intelligence gave a paralyzed woman her voice back,https://www.sciencedaily.com/releases/2023/08/230823122530.htm,Researchers have developed a brain-computer interface (BCI) that has enabled a woman with severe paralysis from a brainstem stroke to speak through a digital avatar.,[],"Wed, 23 Aug 2023 12:25:30 EDT"
2319,Robotic exoskeletons and neurorehabilitation for acquired brain injury: Determining the potential for recovery of overground walking,https://www.sciencedaily.com/releases/2023/08/230815131855.htm,"Developing a framework for future research requires a comprehensive approach based on diagnosis, stage of recovery, and domain.",[],"Tue, 15 Aug 2023 13:18:55 EDT"
2320,Modified virtual reality tech can measure brain activity,https://www.sciencedaily.com/releases/2023/08/230804140510.htm,The research team at The University of Texas at Austin created a noninvasive electroencephalogram (EEG) sensor that they installed in a Meta VR headset that can be worn comfortably for long periods. The EEG measures the brain's electrical activity during the immersive VR interactions.,[],"Fri, 04 Aug 2023 14:05:10 EDT"
2321,Future AI algorithms have potential to learn like humans,https://www.sciencedaily.com/releases/2023/07/230720124956.htm,"Memories can be as tricky to hold onto for machines as they can be for humans. To help understand why artificial agents develop holes in their own cognitive processes, electrical engineers have analyzed how much a process called 'continual learning' impacts their overall performance.",[],"Thu, 20 Jul 2023 12:49:56 EDT"
2322,AI-guided brain stimulation aids memory in traumatic brain injury,https://www.sciencedaily.com/releases/2023/07/230718164310.htm,"AI-guided electrical stimulation in the brains of patients with traumatic brain injury improved memory, a collaborative new study shows. This builds on previous research involving epilepsy patients without traumatic brain injury. Brain injuries can result in profound memory loss, and the current study provides a proof-of-concept for future AI-guided brain stimulation therapies.",[],"Tue, 18 Jul 2023 16:43:10 EDT"
2323,Surgical and engineering innovations enable unprecedented control over every finger of a bionic hand,https://www.sciencedaily.com/releases/2023/07/230712165138.htm,"For the first time, a person with an arm amputation can manipulate each finger of a bionic hand as if it was his own. Thanks to revolutionary surgical and engineering advancements that seamlessly merge humans with machines, this breakthrough offers new hope and possibilities for people with amputations worldwide. A study presents the first documented case of an individual whose body was surgically modified to incorporate implanted sensors and a skeletal implant. A.I. algorithms then translated the user's intentions into movement of the prosthesis.",[],"Wed, 12 Jul 2023 16:51:38 EDT"
2324,A varied life boosts the brain's functional networks,https://www.sciencedaily.com/releases/2023/07/230711133136.htm,"That experiences leave their trace in the connectivity of the brain has been known for a while, but a pioneering study now shows how massive these effects really are. The findings in mice provide unprecedented insights into the complexity of large-scale neural networks and brain plasticity. Moreover, they could pave the way for new brain-inspired artificial intelligence methods.",[],"Tue, 11 Jul 2023 13:31:36 EDT"
2325,Growing bio-inspired polymer brains for artificial neural networks,https://www.sciencedaily.com/releases/2023/07/230705105850.htm,"A new method for connecting neurons in neuromorphic wetware has been developed. The wetware comprises conductive polymer wires grown in a three-dimensional configuration, done by applying square-wave voltage to electrodes submerged in a precursor solution. The voltage can modify wire conductance, allowing the network to be trained. This fabricated network is able to perform unsupervised Hebbian learning and spike-based learning.",[],"Wed, 05 Jul 2023 10:58:50 EDT"
2326,Robotic glove that 'feels' lends a 'hand'  to relearn playing piano after a stroke,https://www.sciencedaily.com/releases/2023/06/230630130152.htm,"A new soft robotic glove is lending a 'hand' and providing hope to piano players who have suffered a disabling stroke or other neurotrauma. Combining flexible tactile sensors, soft actuators and AI, this robotic glove is the first to 'feel' the difference between correct and incorrect versions of the same song and to combine these features into a single hand exoskeleton. Unlike prior exoskeletons, this new technology provides precise force and guidance in recovering the fine finger movements required for piano playing and other complex tasks.",[],"Fri, 30 Jun 2023 13:01:52 EDT"
2327,How the brain processes numbers -- New procedure improves measurement of human brain activity,https://www.sciencedaily.com/releases/2023/06/230627225142.htm,"Measuring human brain activity down to the cellular level: until now, this has been possible only to a limited extent. With a new approach it will now be much easier. The method relies on microelectrodes along with the support of brain tumor patients, who participate in studies while undergoing 'awake' brain surgery. This enabled the team to identify how our brain processes numbers.",[],"Tue, 27 Jun 2023 22:51:42 EDT"
2328,Brain activity decoder can reveal stories in people's minds,https://www.sciencedaily.com/releases/2023/05/230501114006.htm,"A new AI-based system called a semantic decoder can translate a person's brain activity -- while listening to a story or silently imagining telling a story -- into a continuous stream of text. Unlike other thought decoding systems in development, this system does not require subjects to have surgical implants, making the process noninvasive.",[],"Mon, 01 May 2023 11:40:06 EDT"
2329,Nanowire networks learn and remember like a human brain,https://www.sciencedaily.com/releases/2023/04/230421195040.htm,Scientists have demonstrated nanowire networks can exhibit both short- and long-term memory like the human brain.,[],"Fri, 21 Apr 2023 19:50:40 EDT"
2330,Table tennis brain teaser: Playing against robots makes our brains work harder,https://www.sciencedaily.com/releases/2023/04/230410132157.htm,Brain scans taken during table tennis reveal differences in how we respond to human versus machine opponents.,[],"Mon, 10 Apr 2023 13:21:57 EDT"
2331,Mind-control robots a reality?,https://www.sciencedaily.com/releases/2023/03/230320102104.htm,"Researchers have developed biosensor technology that will allow you to operate devices, such as robots and machines, solely through thought control.",[],"Mon, 20 Mar 2023 10:21:04 EDT"
2332,Will future computers run on human brain cells?,https://www.sciencedaily.com/releases/2023/02/230228075739.htm,"A 'biocomputer' powered by human brain cells could be developed within our lifetime, according to researchers who expect such technology to exponentially expand the capabilities of modern computing and create novel fields of study.",[],"Tue, 28 Feb 2023 07:57:39 EST"
2333,Computational modeling sheds light on human cognition and the origins of brain disorders,https://www.sciencedaily.com/releases/2023/02/230215143606.htm,Researchers used computational modeling to uncover mutations in the human genome that likely influenced the evolution of human cognition. This groundbreaking research in human genomics could lead to a better understanding of human health and the discovery of novel treatments for complex brain disorders. The study is to be published in Science Advances.,[],"Wed, 15 Feb 2023 14:36:06 EST"
2334,A neuro-chip to manage brain disorders,https://www.sciencedaily.com/releases/2023/01/230130103022.htm,"Researchers have combined low-power chip design, machine learning algorithms, and soft implantable electrodes to produce a neural interface that can identify and suppress symptoms of various neurological disorders.",[],"Mon, 30 Jan 2023 10:30:22 EST"
2335,Clinical trial results indicate low rate of adverse events associated with implanted brain computer interface,https://www.sciencedaily.com/releases/2023/01/230114142750.htm,"There were no safety events that required removal of the device, no infections of the brain or nervous system, and no adverse events resulting in permanently increased disability related to the investigational device.",[],"Sat, 14 Jan 2023 14:27:50 EST"
2336,"A soft, stimulating scaffold supports brain cell development ex vivo",https://www.sciencedaily.com/releases/2023/01/230105151247.htm,"Brain-computer interface companies like Neuralink are in the news a lot these days for their potential to revolutionize how humans interact with machines, but electrodes are not the most brain-friendly materials -- they're hard and stiff, while brains are soft and squishy, which limits their efficacy and increases the risk of damaging brain tissue.  A new hydrogel-based electrode developed at the Wyss Institute solves that problem by providing a tunable, conductive scaffold that human neurons and other cell types feel right at home in. Not only does the scaffold mimic the soft, porous conditions of brain tissue, it supported the growth and differentiation of human neural progenitor cells (NPCs) into multiple different brain cell types for up to 12 weeks. The achievement is reported in Advanced Healthcare Materials. Not only can the new electrode be used to study the formation of human neural networks in vitro, it could enable the creation of implantable devices that more seamlessly integrate with a patient's brain tissue, improving performance and decreasing risk of injury.",[],"Thu, 05 Jan 2023 15:12:47 EST"
2337,Human brain organoids implanted into mouse cortex respond to visual stimuli for first time,https://www.sciencedaily.com/releases/2022/12/221229115657.htm,"A team of engineers and neuroscientists has demonstrated for the first time that human brain organoids implanted in mice have established functional connectivity to the animals' cortex and responded to external sensory stimuli. The implanted organoids reacted to visual stimuli in the same way as surrounding tissues, an observation that researchers were able to make in real time over several months thanks to an innovative experimental setup that combines transparent graphene microelectrode arrays and two-photon imaging.",[],"Thu, 29 Dec 2022 11:56:57 EST"
2338,Artificial neural networks learn better when they spend time not learning at all,https://www.sciencedaily.com/releases/2022/11/221118160305.htm,"Researchers discuss how mimicking sleep patterns of the human brain in artificial neural networks may help mitigate the threat of catastrophic forgetting in the latter, boosting their utility across a spectrum of research interests.",[],"Fri, 18 Nov 2022 16:03:05 EST"
2339,"With training, people in mind-controlled wheelchairs can navigate normal, cluttered spaces",https://www.sciencedaily.com/releases/2022/11/221118114824.htm,"A mind-controlled wheelchair can help a paralyzed person gain new mobility by translating users' thoughts into mechanical commands. Researchers now demonstrate that tetraplegic users can operate mind-controlled wheelchairs in a natural, cluttered environment after training for an extended period.",[],"Fri, 18 Nov 2022 11:48:24 EST"
2340,Engineers light the way to nerve-operated prosthetics of the future,https://www.sciencedaily.com/releases/2022/10/221026103143.htm,"A multi-disciplinary team has found a way to convert nerve impulses into light, opening the way for more scalable neural implants.",[],"Wed, 26 Oct 2022 10:31:43 EDT"
2341,How the brain develops: A new way to shed light on cognition,https://www.sciencedaily.com/releases/2022/09/220920115627.htm,Researchers introduce a new neurocomputational model of the human brain that could bridge the gap in understanding AI and the biological mechanisms underlying mental disorders.,[],"Tue, 20 Sep 2022 11:56:27 EDT"
2342,How the sounds we hear help us predict how things feel,https://www.sciencedaily.com/releases/2022/08/220824102948.htm,"Researchers have made an important discovery about the way our brains process the sensations of sound and touch. The new study reveals how the brain's different sensory systems are all closely interconnected -- with regions that respond to touch also involved when we listen to sounds associated with touching objects (for example the sound of typing on a keyboard or crushing paper). It is hoped that understanding this key area of brain function may in future help people who are neurodiverse, or with conditions such as schizophrenia or anxiety. And it could lead to developments in brain-inspired computing and AI.",[],"Wed, 24 Aug 2022 10:29:48 EDT"
2343,Realistic computer models of brain cells,https://www.sciencedaily.com/releases/2022/08/220809141159.htm,Investigators have created the most bio-realistic and complex computer models of individual brain cells -- in unparalleled quantity. Their research details how these models could one day answer questions about neurological disorders -- and even human intellect -- that aren't possible to explore through biological experiments.,[],"Tue, 09 Aug 2022 14:11:59 EDT"
2344,Advancing dynamic brain imaging with AI,https://www.sciencedaily.com/releases/2022/08/220801133143.htm,"New research introduces a novel, AI-based dynamic brain imaging technology alternative which could map out rapidly changing electrical activity in the brain with high speed, high resolution, and low cost.",[],"Mon, 01 Aug 2022 13:31:43 EDT"
2345,A new model sheds light on how we learn motor skills,https://www.sciencedaily.com/releases/2022/06/220624092344.htm,"Researchers have developed a mathematical model of motor learning that reflects the motor learning process in the human brain. Their findings suggest that motor exploration -- that is, increased variability in movements -- is important when learning a new task. These results may lead to improved motor rehabilitation in patients after injury or disease.",[],"Fri, 24 Jun 2022 09:23:44 EDT"
2346,How the brain interprets motion while in motion,https://www.sciencedaily.com/releases/2022/06/220621155127.htm,New research provides insights into a neural mechanism involved in how the brain interprets sensory information. The research may have applications for treating brain disorders and designing artificial intelligence.,[],"Tue, 21 Jun 2022 15:51:27 EDT"
2347,Learning and remembering movement,https://www.sciencedaily.com/releases/2022/06/220609173627.htm,"Researchers examining the brain at a single-neuron level found that computation happens not just in the interaction between neurons, but within each individual neuron. Each of these cells, it turns out, is not a simple switch, but a complicated calculating machine. This discovery promises changes not only to our understanding of how the brain works, but better understanding of conditions ranging from Parkinson's disease to autism. The findings are also expected to advance machine learning, offering inspiration for new architectures.",[],"Thu, 09 Jun 2022 17:36:27 EDT"
2348,Researchers investigate the links between facial recognition and Alzheimer's disease,https://www.sciencedaily.com/releases/2022/05/220531102702.htm,"In recent years Alzheimer's disease has been on the rise throughout the world and is rarely diagnosed at an early stage when it can still be effectively controlled. Using artificial intelligence, researchers conducted a study to identify whether human-computer interfaces could be adapted for people with memory impairments to recognize a visible object in front of them.",[],"Tue, 31 May 2022 10:27:02 EDT"
2349,Significant energy savings using neuromorphic hardware,https://www.sciencedaily.com/releases/2022/05/220524100612.htm,New research illustrates neuromorphic technology is up to sixteen times more energy-efficient for large deep learning networks than other AI systems.,[],"Tue, 24 May 2022 10:06:12 EDT"
2350,Neuromorphic memory device simulates neurons and synapses,https://www.sciencedaily.com/releases/2022/05/220520132904.htm,"Researchers have reported a nano-sized neuromorphic memory device that emulates neurons and synapses simultaneously in a unit cell, another step toward completing the goal of neuromorphic computing designed to rigorously mimic the human brain with semiconductor devices.",[],"Fri, 20 May 2022 13:29:04 EDT"
2351,Component for brain-inspired computing,https://www.sciencedaily.com/releases/2022/05/220518130721.htm,Researchers have developed a new material for an electronic component that can be used in a wider range of applications than its predecessors. Such components will help create electronic circuits that emulate the human brain and that are more efficient at performing machine-learning tasks.,[],"Wed, 18 May 2022 13:07:21 EDT"
2352,Energy-efficient AI hardware technology via a brain-inspired stashing system?,https://www.sciencedaily.com/releases/2022/05/220517210435.htm,"Researchers have proposed a novel system inspired by the neuromodulation of the brain, referred to as a 'stashing system,' that requires less energy consumption. Computer scientists have now developed a technology that can efficiently handle mathematical operations for artificial intelligence by imitating the continuous changes in the topology of the neural network according to the situation.",[],"Tue, 17 May 2022 21:04:35 EDT"
2353,'Nanomagnetic' computing can provide low-energy AI,https://www.sciencedaily.com/releases/2022/05/220505114646.htm,Researchers have shown it is possible to perform artificial intelligence using tiny nanomagnets that interact like neurons in the brain.,[],"Thu, 05 May 2022 11:46:46 EDT"
2354,Engineers get under the skin of ionic skin,https://www.sciencedaily.com/releases/2022/04/220428142837.htm,"In the quest to build smart skin that mimics the sensing capabilities of natural skin, ionic skins have shown significant advantages. They're made of flexible, biocompatible hydrogels that use ions to carry an electrical charge. These hydrogels can generate voltages when touched, but scientists did not clearly understand how -- until a team of researchers devised a unique experiment.",[],"Thu, 28 Apr 2022 14:28:37 EDT"
2355,The ethics of research on 'conscious' artificial brains,https://www.sciencedaily.com/releases/2022/04/220412095354.htm,Authors lay out an ethical framework that assumes brain organoids already have consciousness. The paper argues that this framework is not exclusive to brain organoids and can be applied to anything that is perceived to hold consciousness.,[],"Tue, 12 Apr 2022 09:53:54 EDT"
2356,Rational neural network advances machine-human discovery,https://www.sciencedaily.com/releases/2022/04/220405171749.htm,"Math is the language of the physical world, and some see mathematical patterns everywhere: in weather, in the way soundwaves move, and even in the spots or stripes zebra fish develop in embryos.",[],"Tue, 05 Apr 2022 17:17:49 EDT"
2357,Honey holds potential for making brain-like computer chips,https://www.sciencedaily.com/releases/2022/04/220405084610.htm,"Honey might be a sweet solution for developing environmentally friendly components for neuromorphic computers, systems designed to mimic the neurons and synapses found in the human brain.",[],"Tue, 05 Apr 2022 08:46:10 EDT"
2358,A new brain-computer interface with a flexible backing,https://www.sciencedaily.com/releases/2022/03/220315165029.htm,"Engineering researchers have invented an advanced brain-computer interface with a flexible and moldable backing and penetrating microneedles. Adding a flexible backing to this kind of brain-computer interface allows the device to more evenly conform to the brain's complex curved surface and to more uniformly distribute the microneedles that pierce the cortex. The microneedles, which are 10 times thinner than the human hair, protrude from the flexible backing, penetrate the surface of the brain tissue without piercing surface venules, and record signals from nearby nerve cells evenly across a wide area of the cortex. This novel brain-computer interface has thus far been tested in rodents.",[],"Tue, 15 Mar 2022 16:50:29 EDT"
2359,Entanglement unlocks scaling for quantum machine learning,https://www.sciencedaily.com/releases/2022/02/220224125214.htm,The field of machine learning on quantum computers got a boost from new research removing a potential roadblock to the practical implementation of quantum neural networks.,[],"Thu, 24 Feb 2022 12:52:14 EST"
2360,Can machine-learning models overcome biased datasets?,https://www.sciencedaily.com/releases/2022/02/220221115403.htm,"Researchers have applied the tools of neuroscience to study when and how an artificial neural network can overcome bias in a dataset. They found that data diversity, not dataset size, is key and that the emergence of certain types of neurons during training plays a major role in how well a neural network is able to overcome dataset bias.",[],"Mon, 21 Feb 2022 11:54:03 EST"
2361,Neuroscientists use deep learning model to simulate brain topography,https://www.sciencedaily.com/releases/2022/02/220203161125.htm,"A more accurate model of the visual system may help neuroscientists and clinicians develop better treatments for alexia, prosopagnosia and agnosia.",[],"Thu, 03 Feb 2022 16:11:25 EST"
2362,The brain’s secret to life-long learning can now come as hardware for artificial intelligence,https://www.sciencedaily.com/releases/2022/02/220203160544.htm,"As companies use more and more data to improve how AI recognizes images, learns languages and carries out other complex tasks, a recent article shows a way that computer chips could dynamically rewire themselves to take in new data like the brain does, helping AI to keep learning over time.",[],"Thu, 03 Feb 2022 16:05:44 EST"
2363,2D materials could be used to simulate brain synapses in computers,https://www.sciencedaily.com/releases/2022/01/220128100738.htm,"Computers could mimic neural networks in the brain -- and be much more energy efficient -- with a new computer component that mimics how the brain works by acting like a synaptic cell. It's called an electrochemical random access memory (ECRAM), and researchers have developed materials that offer a commercially-viable way to build these components.",[],"Fri, 28 Jan 2022 10:07:38 EST"
2364,New Video: Pioneering Climate Tech and Mitigating the Impact of Natural Disasters,https://developer.nvidia.com/blog/new-video-pioneering-climate-tech-and-mitigating-the-impact-of-natural-disasters/,"<img alt=\"Photo of a flooded town.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/climate-tech-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"climate-tech-featured\" width=\"768\" />In 2022, the city of Lismore, Australia bore the brunt of devastating floods, leaving over 3K homes damaged and communities shattered. With $6B in losses, this...",[{'name': 'Kristen Perez'}],2024-03-05T19:17:25Z
2365,Spotlight: Honeywell Accelerates Industrial Process Simulation with NVIDIA cuDSS,https://developer.nvidia.com/blog/spotlight-honeywell-accelerates-industrial-process-simulation-with-nvidia-cudss/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/industrial-processes-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"industrial-processes\" width=\"768\" />For over a decade, traditional industrial process modeling and simulation approaches have struggled to fully leverage multicore CPUs or acceleration devices to...",[{'name': 'Jeffrey Renfro'}],2024-03-05T19:00:00Z
2366,Solve Complex AI Tasks with Leaderboard-Topping Smaug 72B from NVIDIA AI Foundation Models,https://developer.nvidia.com/blog/solve-complex-ai-tasks-with-leaderboard-topping-smaug-72b-from-nvidia-ai-foundation-models/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/llm-chatbot-graphic-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"llm-chatbot-graphic\" width=\"768\" />This week’s model release features the NVIDIA-optimized language model Smaug 72B, which you can experience directly from your browser. NVIDIA AI Foundation...",[{'name': 'Chintan Patel'}],2024-03-04T21:22:47Z
2367,Featured Energy Sessions at NVIDIA GTC 2024,https://nvda.ws/49Sl1UF#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/top-energy-sessions-gtc24-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"top-energy-sessions-gtc24\" width=\"768\" />Hear from ExxonMobil, Honeywell, Siemens Energy, and more as they explore AI and HPC innovation in oil, gas, power, and utilities.",[{'name': 'Tanya Lenz'}],2024-03-01T21:30:00Z
2368,Explainer: What Is Stream Processing?,https://nvda.ws/48AGiBw#new_tab,"<img alt=\"Decorative image of colorful pixels in a grid pattern.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"243\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/Stream-Processing-in-Python.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"Stream-Processing-in-Python\" width=\"432\" />Stream processing is the continuous processing of new data events as they’re received. A lot of data is produced as a stream of events, for example financial...",[{'name': 'Michelle Horton'}],2024-03-01T20:00:00Z
2369,"Make the Most of NVIDIA GTC 2024 with In-Person, Hands-On Learning",https://developer.nvidia.com/blog/make-the-most-of-nvidia-gtc-2024-with-in-person-hands-on-learning/,"<img alt=\"Picture of people at Connect with the Experts hall at NVIDIA GTC.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/nvidia-gtc-developer-days-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-gtc-developer-days-featured\" width=\"768\" />We are so excited to be back in person at GTC this year at the San Jose Convention Center. With thousands of developers, industry leaders, researchers, and...",[{'name': 'Richard Kerris'}],2024-03-01T18:08:30Z
2370,Top Telecom Sessions at NVIDIA GTC 2024,https://nvda.ws/3TeSV0q#new_tab,"<img alt=\"Image of a car with light streams connected to different towers along the street.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/top-telecom-sessions-gtc24-hero-image-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"top-telecom-sessions-gtc24-hero-image\" width=\"768\" />Hear from Amdocs, Indosat, KT, NTT, ServiceNow, Singtel, SoftBank, and Verizon, plus a special address from NVIDIA at GTC. Explore AI transforming customer...",[{'name': 'Ronnie Vasishta'}],2024-03-01T18:00:00Z
2371,Top Synthetic Data Generation Sessions at NVIDIA GTC 2024,https://nvda.ws/49QuDze#new_tab,"<img alt=\"Collage of four computer vision images.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/synthetic-data-webinar-thumbnail-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"synthetic-data-webinar-thumbnail\" width=\"768\" />Learn how synthetic data is supercharging 3D simulation and computer vision workflows, from visual inspection to autonomous machines.",[{'name': 'Nate Bradford'}],2024-02-29T23:31:18Z
2372,Video Series: Getting Started with Universal Scene Description (OpenUSD),https://nvda.ws/3P0Kxis#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/cube-blocks-circle-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"cube-blocks-circle\" width=\"768\" />Gain a foundational understanding of USD, the open and extensible framework for creating, editing, querying, rendering, collaborating, and simulating within 3D...",[{'name': 'Nate Bradford'}],2024-02-29T22:00:00Z
2373,Scalable Federated Learning with NVIDIA FLARE for Enhanced LLM Performance,https://developer.nvidia.com/blog/scalable-federated-learning-with-nvidia-flare-for-enhanced-llm-performance/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"431\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/abstract-image-circle-with-rays-squares-768x431.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"abstract-image-circle-with-rays-squares\" width=\"768\" />In the ever-evolving landscape of large language models (LLMs), effective data management is a key challenge. Data is at the heart of model performance. While...",[{'name': 'Ziyue Xu'}],2024-02-29T21:00:00Z
2374,Event: Speech and Generative AI Developer Day at NVIDIA GTC 2024,https://nvda.ws/49yqIar#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/generative-ai-graphic-gtc-logo-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"generative-ai-graphic-gtc-logo\" width=\"768\" />Learn how to build a RAG-powered application with a human voice interface at NVIDIA GTC 2024 Speech and Generative AI Developer Day.,[{'name': 'Tanya Lenz'}],2024-02-29T21:00:00Z
2375,Optimizing OpenFold Training for Drug Discovery,https://developer.nvidia.com/blog/optimizing-openfold-training-for-drug-discovery/,"<img alt=\"Decorative image of colorful protein structures.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/openfold-training-drug-discovery-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"openfold-training-drug-discovery-featured\" width=\"768\" />Predicting 3D protein structures from amino acid sequences has been an important long-standing question in bioinformatics. In recent years, deep...",[{'name': 'Feiwen Zhu'}],2024-02-28T19:29:02Z
2376,Event: Cybersecurity Developer Day at NVIDIA GTC 2024,https://nvda.ws/3waljI7#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/gtc24-spring-security-cyber-dev-day-nm-bleed-1920x1080-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"gtc24-spring-security-cyber-dev-day-nm-bleed-1920x1080\" width=\"768\" />Join us on March 20 for Cybersecurity Developer Day at GTC to gain insights on leveraging generative AI for cyber defense.,[{'name': 'Michelle Horton'}],2024-02-28T17:00:00Z
2377,Unlock Your LLM Coding Potential with StarCoder2,https://developer.nvidia.com/blog/unlock-your-llm-coding-potential-with-starcoder2/,"<img alt=\"Illustration representing LLMs.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/llm-translation-e1709081778625-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"llm-translation\" width=\"768\" />Coding is essential in the digital age, but it can also be tedious and time-consuming. That's why many developers are looking for ways to automate and...",[{'name': 'Chia-Chih Chen'}],2024-02-28T14:00:00Z
2378,Top Public Sector Developer Sessions at NVIDIA GTC 2024,https://nvda.ws/48BsW80#new_tab,"<img alt=\"Split image of two landscapes with a mapping overlay.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/gtc24-public-sector-blog-1920x1080-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"gtc24-public-sector-blog-1920x1080\" width=\"768\" />Join experts from NVIDIA and the public sector industry to learn how cybersecurity, generative AI, digital twins, and more are impacting the way that government...",[{'name': 'Michelle Horton'}],2024-02-27T22:26:13Z
2379,Video: Build a RAG-Powered Chatbot in Five Minutes,https://developer.nvidia.com/blog/video-build-a-rag-powered-chatbot-in-five-minutes/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/rag-chatbot-video-thumbnail-v2-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"rag-chatbot-video-thumbnail-v2 (1)\" width=\"768\" />Retrieval-augmented generation (RAG) is exploding in popularity as a technique for boosting large language model (LLM) application performance. From highly...,[{'name': 'Jess Nguyen'}],2024-02-27T21:30:00Z
2380,"Unlock the Power of Small Language Model Phi-2 for Chat, Research, Coding, and More",https://developer.nvidia.com/blog/unlock-the-power-of-small-language-model-phi-2-for-chat-research-coding-and-more/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/five-icons-blue-background-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"five-icons-blue-background\" width=\"768\" />This week’s model release features the NVIDIA-optimized language model Phi-2, which can be used for a wide range of natural language processing (NLP) tasks....",[{'name': 'Chintan Patel'}],2024-02-27T18:00:39Z
2381,Detecting Real-Time Waste Contamination Using Edge Computing and Video Analytics,https://developer.nvidia.com/blog/detecting-real-time-waste-contamination-using-edge-computing-and-video-analytics/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/scene-with-waste-and-labels-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"scene-with-waste-and-labels\" width=\"768\" />The past few decades have witnessed a surge in rates of waste generation, closely linked to economic development and urbanization. This escalation in waste...",[{'name': 'Umair Iqbal'}],2024-02-26T21:00:00Z
2382,Developer Days at NVIDIA GTC 2024,https://nvda.ws/3UHD5fY#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/fantastical-world-content-creation-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"fantastical-world-content-creation\" width=\"768\" />Connect with industry leaders, learn from technical experts, and collaborate with peers at NVIDIA GTC 2024 Developer Days.",[{'name': 'Tanya Lenz'}],2024-02-26T20:30:00Z
2383,Ray-Tracing Validation at the Driver Level,https://developer.nvidia.com/blog/ray-tracing-validation-at-the-driver-level/,"<img alt=\"Decorative image of code block with green lightbeams shining on a figure walking on a computer chip between monitors.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/DALL-E-RT-Validation-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"DALL-E RT Validation\" width=\"768\" />For developers working on Microsoft DirectX ray-tracing applications, ray-tracing validation is here to help you improve performance, find hard-to-debug issues,...",[{'name': 'Andrew Allan'}],2024-02-26T18:00:00Z
2384,Top Student Sessions at NVIDIA GTC 2024,https://nvda.ws/3IbDAre#new_tab,<img alt=\"Photo of students sitting together with a laptop.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/HER_GTC24_Students-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"HER_GTC24_Students\" width=\"768\" />Discover a wide variety of AI tools and resources designed to equip students with practical solutions for real-world problem-solving.&nbsp;Join experts from...,[{'name': 'Michelle Horton'}],2024-02-26T17:24:28Z
2385,Explainer: What Is Energy Efficiency?,https://developer.nvidia.com/blog/explainer-what-is-energy-efficiency/,"<img alt=\"Idealized photo of solar panels and wind turbines in the sunshine, with a city in the background.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/sustainable-computing-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"sustainable-computing-featured\" width=\"768\" />Energy efficiency refers to a system or device’s ability to use as little energy as possible to perform a particular task or function within acceptable...",[{'name': 'Michelle Horton'}],2024-02-23T20:00:00Z
2386,Evaluating Retriever for Enterprise-Grade RAG,https://developer.nvidia.com/blog/evaluating-retriever-for-enterprise-grade-rag/,"<img alt=\"Illustration demonstrating RAG.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/RAG-Retriever-LLM-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"RAG-Retriever-LLM\" width=\"768\" />The conversation about designing and evaluating Retrieval-Augmented Generation (RAG) systems is a long, multi-faceted discussion. Even when we look at retrieval...",[{'name': 'Benedikt Schifferer'}],2024-02-23T19:02:26Z
2387,Featured Researcher and Educator Sessions at NVIDIA GTC 2024,https://nvda.ws/3uxLFTX#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/students-teachers-computers-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"students-teachers-computers\" width=\"768\" />Join experts from Stanford, Cornell, Meta, and more to learn about the latest in AI for academia and what’s next in cutting-edge research.",[{'name': 'Tanya Lenz'}],2024-02-22T22:30:00Z
2388,"Benchmarking NVIDIA Spectrum-X for AI Network Performance, Now Available from Supermicro",https://developer.nvidia.com/blog/benchmarking-nvidia-spectrum-x-for-ai-network-performance-now-available-from-supermicro/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/image-panels-with-multicolor-cat-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"image-panels-with-multicolor-cat\" width=\"768\" />NVIDIA Spectrum-X is swiftly gaining traction as the leading networking platform tailored for AI in hyperscale cloud infrastructures. Spectrum-X networking...,[{'name': 'Brian Sparks'}],2024-02-22T17:54:05Z
2389,"Enhance Immersive Experiences with the New Varjo XR-4 Series Headsets, Powered by NVIDIA",https://developer.nvidia.com/blog/enhance-immersive-experiences-with-the-new-varjo-xr-4-series-headsets-powered-by-nvidia/,"<img alt=\"Car model shown recorded inside of the Varjo XR-4\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/varjo-xr-car-model.gif\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"varjo-xr-car-model\" width=\"600\" />Developers and enterprises can now deploy lifelike virtual and mixed reality experiences with Varjo's latest XR-4 series headsets, which are integrated with...",[{'name': 'David Weinstein'}],2024-02-22T17:43:03Z
2390,Top Computer Vision/Video Analytics Sessions at NVIDIA GTC 2024,https://nvda.ws/48qKHH1#new_tab,"<img alt=\"Computer-generated image of a canal with bounding boxes for houses, trees, boats, and people.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/GTC-600x338-1.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"GTC 600x338\" width=\"600\" />Discover the transformative power of computer vision and video analytics at GTC. Dive into cutting-edge techniques such as vision transformers, AI agents,...",[{'name': 'Michelle Horton'}],2024-02-21T22:00:00Z
2391,Build an LLM-Powered API Agent for Task Execution,https://developer.nvidia.com/blog/build-an-llm-powered-api-agent-for-task-execution/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/magnifying-glass-with-icons-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"magnifying-glass-with-icons\" width=\"768\" />Developers have long been building interfaces like web apps to enable users to leverage the core products being built. To learn how to work with data in your...,[{'name': 'Tanay Varshney'}],2024-02-21T21:30:00Z
2392,Spotlight: HOMEE AI Delivers AI-Powered Spatial Planning to Your Living Room,https://developer.nvidia.com/blog/spotlight-homee-ai-delivers-ai-powered-spatial-planning-to-your-living-room/,"<img alt=\"Image of a livingroom with a couch that is partially dissolved into pixels.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/homee-ai-featured-b-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"homee-ai-featured-b\" width=\"768\" />HOMEE AI, an NVIDIA Inception member based in Taiwan, has developed an “AI-as-a-service” spatial planning solution to disrupt the $650B global home decor...",[{'name': 'Don Johnson'}],2024-02-21T21:00:14Z
2393,Podcast: NVIDIA and the Future of 3D Development with Aaron Luk,https://nvda.ws/3UIRZCJ#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"315\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/openusd-podcast.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"openusd-podcast\" width=\"560\" />Discover why OpenUSD is central to the future of 3D development with Aaron Luk, a founding developer of Universal Scene Description.",[{'name': 'Nate Bradford'}],2024-02-21T18:30:00Z
2394,Limiting CPU Threads for Better Game Performance,https://developer.nvidia.com/blog/limiting-cpu-threads-for-better-game-performance/,"<img alt=\"Decorative image of scissors near a CPU with green light streaming out.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/limit-thread-count-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"limit-thread-count-featured\" width=\"768\" />Many PC games are designed around an eight-core console with an assumption that their software threading system ‘just works’ on all PCs, especially...",[{'name': 'Jon Kennedy'}],2024-02-21T17:38:17Z
2395,Webinar: Accelerate Edge AI Development With NVIDIA Metropolis Microservices For Jetson,https://nvda.ws/3uJG90r#new_tab,"<img alt=\"Decorative image of avatars working in different office locations.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/metropolis-iva-microservices-kv-devblog-1920x1080-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"metropolis-iva-microservices-kv-devblog-1920x1080\" width=\"768\" />On March 5, 8am PT, learn how NVIDIA Metropolis microservices for Jetson Orin helps you modernize your app stack, streamline development and deployment, and...",[{'name': 'Michelle Horton'}],2024-02-21T17:30:00Z
2396,NVIDIA TensorRT-LLM Revs Up Inference for Google Gemma,https://developer.nvidia.com/blog/nvidia-tensorrt-llm-revs-up-inference-for-google-gemma/,"<img alt=\"An illustration representing LLM optimization.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/llm-summerization-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"llm-summerization\" width=\"768\" />NVIDIA is collaborating as a launch partner with Google in delivering Gemma, a newly optimized family of open models built from the same research and technology...",[{'name': 'Anjali Shah'}],2024-02-21T13:00:00Z
2397,Event: NVIDIA at GDC 2024,https://nvda.ws/3xVpGnG#new_tab,"<img alt=\"Rich image of a carnival at night, with the NVIDIA logo as a pond sculpture in the foreground.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/RTPT_AmusementPark-featured-c-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"RTPT_AmusementPark-featured-c\" width=\"768\" />Join us at the Game Developers Conference March 18-22 to discover how the latest generative AI and NVIDIA RTX technologies are accelerating game development.",[{'name': 'Diego Farinha'}],2024-02-20T22:42:55Z
2398,Build an LLM-Powered Data Agent for Data Analysis,https://developer.nvidia.com/blog/build-an-llm-powered-data-agent-for-data-analysis/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/gear-icons-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"gear-icons\" width=\"768\" />An AI agent is a system consisting of planning capabilities, memory, and tools to perform tasks requested by a user. For complex tasks such as data analytics or...",[{'name': 'Tanay Varshney'}],2024-02-20T19:30:00Z
2399,Experience NVIDIA cuOpt Accelerated Optimization to Boost Operational Efficiency,https://developer.nvidia.com/blog/experience-nvidia-cuopt-accelerated-optimization-to-boost-operational-efficiency/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/city-block-graphic-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"city-block-graphic\" width=\"768\" />This week’s model release features NVIDIA cuOpt, a world-record-breaking accelerated optimization engine that helps teams solve complex routing problems and...",[{'name': 'Moon Chung'}],2024-02-19T19:30:00Z
2400,Explainer: What Is a Virtual Assistant?,https://nvda.ws/48vNa3e#new_tab,<img alt=\"Person sitting at a desk having a conversation with a speech ai chatbot.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/speech-ai-riva-fsi-abm-devnews-1920x10801-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"SpeechAI Riva speech recognition\" width=\"768\" />A virtual digital assistant is a program that understands natural language and can answer questions or complete tasks based on voice commands.,[{'name': 'Michelle Horton'}],2024-02-16T20:00:00Z
2401,Featured Developer Sessions at NVIDIA GTC 2024,https://nvda.ws/42DkWSk#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/developer-gtc-2024-sessions-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"developer-gtc-2024-sessions\" width=\"768\" />Advances in AI are rapidly transforming every industry. Join us in person or virtually to learn about the latest technologies, from retrieval-augmented...",[{'name': 'Tanya Lenz'}],2024-02-15T21:00:00Z
2402,Accelerating Drug Discovery at Receptor.AI with NVIDIA BioNeMo Cloud APIs,https://developer.nvidia.com/blog/accelerating-drug-discovery-at-receptor-ai-with-nvidia-bionemo-cloud-apis/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/stylized-3d-structure-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"stylized-3d-structure\" width=\"768\" />The quest for new, effective treatments for diseases that remain stubbornly resistant to current therapies is at the heart of drug discovery. This traditionally...",[{'name': 'Alan Nafiiev'}],2024-02-14T21:00:00Z
2403,Featured Cybersecurity Sessions at NVIDIA GTC 2024,https://nvda.ws/4bL7WhV#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/gtc24-spring-cybersecurity-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"gtc24-spring-cybersecurity\" width=\"768\" />Discover how generative AI is powering cybersecurity solutions with enhanced speed, accuracy, and scalability.",[{'name': 'Tanya Lenz'}],2024-02-14T20:26:51Z
2404,Release: NVIDIA DOCA 2.6,https://nvda.ws/3uyp2P3#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/nvidia-doca-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-doca\" width=\"768\" />The NVIDIA DOCA 2.6 release includes support for NVIDIA Spectrum-X reference architecture with the NVIDIA BlueField-3 SuperNIC and enhances DOCA host-based...,[{'name': 'David Wills'}],2024-02-13T20:30:00Z
2405,Upcoming Event: OpenUSD Day at NVIDIA GTC 2024,https://nvda.ws/3HUMgSw%20#new_tab,"<img alt=\"Picture of a kitchen modeled in OpenUSD.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/Pixar-Kitchen-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"Pixar Kitchen featured\" width=\"768\" />On March 19, learn how to build generative AI-enabled 3D pipelines and tools using Universal Scene Description for industrial digitalization.",[{'name': 'Nate Bradford'}],2024-02-13T18:00:00Z
2406,Top Inference for Large Language Models Sessions at NVIDIA GTC 2024,https://nvda.ws/3SzYNzV#new_tab,"<img alt=\"Decorative image of inference steps: LLM, optimize, deploy. The GTC logo is in one corner.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/press-gtc24-llm-inference-1920x1080-full-bleed-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"press-gtc24-llm-inference-1920x1080-full-bleed\" width=\"768\" />Learn how inference for LLMs is driving breakthrough performance for AI-enabled applications and services.",[{'name': 'Michelle Horton'}],2024-02-13T17:00:00Z
2407,Performance-Efficient Mamba-Chat from NVIDIA AI Foundation Models,https://developer.nvidia.com/blog/performance-efficient-mamba-chat-from-nvidia-ai-foundation-models/,"<img alt=\"Decorative image of groups of people using speech AI in different ways standing around a globe.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/11/exploring-speech-ai-possibilities-video-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"exploring-speech-ai-possibilities-video-featured\" width=\"768\" />This week’s release features the NVIDIA-optimized Mamba-Chat model, which you can experience directly from your browser. This post is part of Model Mondays, a...",[{'name': 'Chintan Patel'}],2024-02-12T21:24:04Z
2408,New Workshops and Certification at NVIDIA GTC 2024,https://developer.nvidia.com/blog/new-workshops-and-certification-at-nvidia-gtc-2024/,"<img alt=\"People sitting in a classroom.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/DLI-DEV-Lifestyle-0868-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"DLI-DEV-Lifestyle-0868\" width=\"768\" />With the GTC session catalog now live, it’s time to start building your personalized agenda for the conference. For those of you who will be joining us in San...",[{'name': 'Ann Sheridan'}],2024-02-12T20:28:17Z
2409,Explainer: What Is Clustering?,https://nvda.ws/4aFMzxF#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2022/12/ai-for-dev-devnews-faster-hdbscan-soft-clustering-blog-1920x1080-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"ai-for-dev-devnews-faster-hdbscan-soft-clustering-blog-1920x1080\" width=\"768\" />Cluster analysis is the grouping of objects such that objects in the same cluster are more similar to each other than they are to objects in another cluster.,[{'name': 'Michelle Horton'}],2024-02-09T20:00:00Z
2410,Featured Large Language Models Sessions at NVIDIA GTC 2024,https://nvda.ws/487B5R9#new_tab,"<img alt=\"Image generation, video generation and code generation talks at NVIDIA GTC 2024\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/press-gtc24-llm-playlist-1920x1080-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"NVIDIA GTC LLM sessions\" width=\"768\" />Speakers from NVIDIA, Meta, Microsoft, OpenAI, and ServiceNow will be talking about the latest tools, optimizations, trends and best practices for large...",[{'name': 'Brad Nemire'}],2024-02-08T02:09:25Z
2411,CUDA Quantum Introduces More Capabilities for Quantum Accelerated Supercomputing,https://developer.nvidia.com/blog/cuda-quantum-introduces-more-capabilities-for-quantum-accelerated-supercomputing/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/abstract-image-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"abstract-image\" width=\"768\" />CUDA Quantum is an open-source programming model for building quantum-classical applications. Useful quantum computing workloads will run on heterogeneous...,[{'name': 'Efrat Shabtai'}],2024-02-07T19:00:00Z
2412,Generative AI Research Spotlight: Personalizing Text-to-Image Models,https://developer.nvidia.com/blog/generative-ai-research-spotlight-personalizing-text-to-image-models/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/woman-sitting-at-desktop-computer-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"woman-sitting-at-desktop-computer\" width=\"768\" />Visual generative AI is the process of creating images from text prompts. The technology is based on vision-language foundation models that are pretrained on...,[{'name': 'Gal Chechik'}],2024-02-06T23:41:01Z
2413,Top Retrieval-Augmented Generation (RAG) Sessions at NVIDIA GTC 2024 Sessions,https://nvda.ws/49khUoR#new_tab,"<img alt=\"Retrieval-Augmented Generation Conference Sessions at GTC\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-GTC-RAG-sessions-recommendations-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"NVIDIA GTC RAG sessions recommendations\" width=\"768\" />Join us in-person or virtually and learn about the power of RAG with insights and best practices from experts at NVIDIA, visionary CEOs, data scientists, and...",[{'name': 'Brad Nemire'}],2024-02-06T19:38:44Z
2414,"Generate Code, Answer Queries, and Translate Text with New NVIDIA AI Foundation Models",https://developer.nvidia.com/blog/generate-code-answer-queries-and-translate-text-with-leading-generative-ai-models/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/02/ai-image-generation-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"ai-image-generation-graphic\" width=\"768\" />This week’s Model Monday release features the NVIDIA-optimized code Llama, Kosmos-2, and SeamlessM4T, which you can experience directly from your browser....",[{'name': 'Chintan Patel'}],2024-02-05T18:48:17Z
2415,Deploy an AI Coding Assistant with NVIDIA TensorRT-LLM and NVIDIA Triton,https://developer.nvidia.com/blog/deploy-an-ai-coding-assistant-with-nvidia-tensorrt-llm-and-nvidia-triton/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/llm-optimize-deploy-graphic-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"llm-optimize-deploy-graphic\" width=\"768\" />Large language models (LLMs) have revolutionized the field of AI, creating entirely new ways of interacting with the digital world. While they provide a good...",[{'name': 'Amit Bleiweiss'}],2024-02-01T21:00:00Z
2416,Just Released: NVIDIA HPC SDK v24.1,https://nvda.ws/3vVy3Cc#new_tab,"<img alt=\"Illustration representing HPC.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/HPC_SW_KV-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"HPC_SW_KV\" width=\"768\" />This NVIDIA HPC SDK update includes the cuBLASMp preview library, along with minor bug fixes and enhancements.",[{'name': 'Jay Gould'}],2024-02-01T16:36:12Z
2417,Just Released: NVIDIA Modulus 24.01,https://nvda.ws/3OppBSb,<img alt=\"Image of windvanes over water at night.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/modulus-release-windvanes-over-water-night-featured.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"modulus-release-windvanes-over-water-night-featured\" width=\"600\" />NVIDIA Modulus 24.01 updates distributed utilities and samples for physics informing DeepONet and GNNs.,[{'name': 'Bhoomi Gadhia'}],2024-01-31T22:31:12Z
2418,New Self-Paced Course: Synthetic Tabular Data Generation Using Transformers,https://nvda.ws/3vUDGRd#new_tab,<img alt=\"Three examples of synthetic tabular data generation visuals.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/dli-tech-blog-synthetic-data-generation-1920x1080-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"dli-tech-blog-synthetic-data-generation-1920x1080\" width=\"768\" />Synthetic data generation is a data augmentation technique necessary for increasing the robustness of models by supplying training data. Explore the use of...,[{'name': 'Michelle Horton'}],2024-01-31T17:00:00Z
2419,"Create, Share, and Scale Enterprise AI Workflows with NVIDIA AI Workbench, Now in Beta",https://developer.nvidia.com/blog/create-share-and-scale-enterprise-ai-workflows-with-nvidia-ai-workbench-now-in-beta/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-ai-workbench-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-ai-workbench-graphic\" width=\"768\" />NVIDIA AI Workbench is now in beta, bringing a wealth of new features to streamline how enterprise developers create, use, and share AI and machine learning...",[{'name': 'Shruthii Sathyanarayanan'}],2024-01-30T20:02:55Z
2420,Modernizing the Data Center with Accelerated Networking,https://developer.nvidia.com/blog/modernizing-the-data-center-with-accelerated-networking/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/highway-lights-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"highway-lights\" width=\"768\" />Accelerated networking combines CPUs, GPUs, DPUs (data processing units), or SuperNICs into an accelerated computing fabric specifically designed to optimize...",[{'name': 'Tim Lustig'}],2024-01-30T20:00:00Z
2421,Emulating the Attention Mechanism in Transformer Models with a Fully Convolutional Network,https://developer.nvidia.com/blog/emulating-the-attention-mechanism-in-transformer-models-with-a-fully-convolutional-network/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/NVIDIA-Convolution-Self-Attention-Blocks-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"NVIDIA Convolution Self-Attention Blocks\" width=\"768\" />The past decade has seen a remarkable surge in the adoption of deep learning techniques for computer vision (CV) tasks. Convolutional neural networks (CNNs)...,[{'name': 'John Yang'}],2024-01-29T17:00:00Z
2422,New Self-Paced Course: Augment Your LLM Using Retrieval-Augmented Generation,https://nvda.ws/3u4liEM#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/retrieval-augmented-generation-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"retrieval-augmented-generation-graphic\" width=\"768\" />Learn the basics of retrieval-augmented generation (RAG), an end-to-end architecture used to optimize the output of an LLM.",[{'name': 'Tanya Lenz'}],2024-01-26T18:00:00Z
2423,Announcing NVIDIA Metropolis Microservices for Jetson for Rapid Edge AI Development,https://developer.nvidia.com/blog/announcing-metropolis-microservices-on-nvidia-jetson-orin-for-rapid-edge-ai-development/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/metropolis-iva-microservices-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"metropolis-iva-microservices-graphic\" width=\"768\" />Building vision AI applications for the edge often comes with notoriously long and costly development cycles. At the same time, quickly developing edge AI...",[{'name': 'Chintan Shah'}],2024-01-25T18:30:00Z
2424,Advancing Production AI with NVIDIA AI Enterprise,https://developer.nvidia.com/blog/advancing-production-ai-with-nvidia-ai-enterprise/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-ai-enterprise-production-branch-graphic-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-ai-enterprise-production-branch-graphic\" width=\"768\" />While harnessing the potential of AI is a priority for many of today’s enterprises, developing and deploying an AI model involves time and effort. Often,...",[{'name': 'Phoebe Lee'}],2024-01-25T18:00:00Z
2425,Build Enterprise-Grade AI with NVIDIA AI Software,https://developer.nvidia.com/blog/build-enterprise-grade-ai-with-nvidia-ai-software/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-production-ai-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-production-ai-graphic\" width=\"768\" />Following the introduction of ChatGPT, enterprises around the globe are realizing the benefits and capabilities of AI, and are racing to adopt it into their...",[{'name': 'Nirmal Kumar Juluru'}],2024-01-24T20:30:00Z
2426,"Delivering Efficient, High-Performance AI Clouds with NVIDIA DOCA 2.5",https://developer.nvidia.com/blog/delivering-efficient-high-performance-ai-clouds-with-nvidia-doca-2-5/,"<img alt=\"Image shows the range of applications available for delivery on an NVIDIA BlueField networking platform with the NVIDIA DOCA SDK and acceleration framework.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/tech-blog-doca-2.5-1920x1080-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"tech-blog-doca-2.5-1920x1080\" width=\"768\" />As a comprehensive software framework for data center infrastructure developers, NVIDIA DOCA has been adopted by leading AI, cloud, enterprise, and ISV...",[{'name': 'David Wills'}],2024-01-24T19:31:39Z
2427,Webinar: Improve Spear Phishing Detection with AI,https://nvda.ws/48FJ4pR#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/security-spear-phish-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"security-spear-phish-graphic\" width=\"768\" />Learn how generative AI can help defend against spear phishing in this January 30 webinar.,[{'name': 'Nicola Sessions'}],2024-01-24T18:00:00Z
2428,Using the Power of AI to Make Factories Safer,https://developer.nvidia.com/blog/using-the-power-of-ai-to-make-factories-safer/,"<img alt=\"Decorative image of a robotic assembly line with bounding boxes.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/power-ai-factory-safety-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"power-ai-factory-safety\" width=\"768\" />As industrial automation increases, safety becomes a greater challenge and top priority for enterprises.&nbsp; Safety encompasses multiple aspects:&nbsp; System...",[{'name': 'Riccardo Mariani'}],2024-01-24T17:00:00Z
2429,Simplifying Network Operations for AI with NVIDIA Quantum InfiniBand,https://developer.nvidia.com/blog/simplifying-network-operations-for-ai-with-nvidia-quantum-infiniband/,"<img alt=\"Photo of a person standing at a computer terminal in a data center.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/quantum-infiniband-guide-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"quantum-infiniband-guide-featured\" width=\"768\" />A common technological misconception is that performance and complexity are directly linked. That is, the highest-performance implementation is also the most...",[{'name': 'Taylor Allison'}],2024-01-23T18:00:00Z
2430,Build Vision AI Applications at the Edge with NVIDIA Metropolis Microservices and APIs,https://developer.nvidia.com/blog/how-to-build-vision-ai-applications-at-the-edge-with-nvidia-metropolis-microservices-and-apis/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/metropolis-icon-shuffle-gif.gif\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"metropolis-icon-shuffle-gif\" width=\"600\" />NVIDIA Metropolis microservices provide powerful, customizable, cloud-native APIs and microservices to develop vision AI applications and solutions. The...",[{'name': 'Bhanu Pisupati'}],2024-01-23T17:00:00Z
2431,Bringing Generative AI to the Edge with NVIDIA Metropolis Microservices for Jetson,https://developer.nvidia.com/blog/bringing-generative-ai-to-the-edge-with-nvidia-metropolis-microservices-for-jetson/,"<img alt=\"GIF of factory floor with people, pallets, and equipment in bounding boxes.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/metropolis-iva-gen-ai-featured.gif\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"metropolis-iva-gen-ai-featured\" width=\"600\" />NVIDIA Metropolis Microservices for Jetson provides a suite of easy-to-deploy services that enable you to quickly build production-quality vision AI...",[{'name': 'Samuel Ochoa'}],2024-01-23T17:00:00Z
2432,Query Graphs with Optimized DePlot Model,https://developer.nvidia.com/blog/query-graphs-with-optimized-deplot-model/,"<img alt=\"Decorative image.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/ngc-tech-blog-deplot-blog-1920x1080-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"ngc-tech-blog-deplot-blog-1920x1080\" width=\"768\" />NVIDIA AI Foundation Models and Endpoints provides access to a curated set of community and NVIDIA-built generative AI models to experience, customize, and...",[{'name': 'Shashank Verma'}],2024-01-23T00:34:34Z
2433,Benchmarking Camera Performance on Your Workstation with NVIDIA Isaac Sim,https://developer.nvidia.com/blog/benchmarking-camera-performance-on-your-workstation-with-nvidia-isaac-sim/,"<img alt=\"A fisheye camera view of a manufacturing plant.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/Isaac-Sim-Workstation-Benchmark-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"Isaac-Sim-Workstation-Benchmark\" width=\"768\" />Robots are typically equipped with cameras. When designing a digital twin simulation, it’s important to replicate its performance in a simulated environment...",[{'name': 'Raffaello Bonghi'}],2024-01-22T15:00:00Z
2434,Generate Synthetic Data for Deep Object Pose Estimation Training with NVIDIA Isaac ROS,https://developer.nvidia.com/blog/generate-synthetic-data-for-deep-object-pose-estimation-training-with-nvidia-isaac-ros/,"<img alt=\"An image of the inside of an industrial manufacturing building.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/Isaac-ROS-DOPE-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"Isaac-ROS-DOPE\" width=\"768\" />For robotic agents to interact with objects in their environment, they must know the position and orientation of objects around them. This information describes...",[{'name': 'Asawaree Bhide'}],2024-01-18T21:45:18Z
2435,Webinar: Quantum ESPRESSO on GPUs: Porting Strategy and Results,https://bit.ly/openacc_QEnvn#new_tab,<img alt=\"Decorative image of two block matrices with connections against a shadowed background.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/quantum-espresso-webinar-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"quantum-espresso-webinar-featured\" width=\"768\" />Explore the status of Quantum ESPRESSO porting strategies that enable state-of-the-art performance on HPC systems.,[{'name': 'Michelle Horton'}],2024-01-18T18:00:00Z
2436,Release: PyTorch Geometric Container for GNNs on NGC,https://nvda.ws/3SgrAdP#new_tab,"<img alt=\"PyG and Accelerated with NVIDIA logos on a white background.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"414\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/pyg-container-ngc-release-featured-1.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"pyg-container-ngc-release-featured\" width=\"736\" />The NVIDIA PyG container, now generally available, packages PyTorch Geometric with accelerations for GNN models, dataloading, and pre-processing using...",[{'name': 'Rishi Puri'}],2024-01-17T23:05:40Z
2437,Simulating Railroads with OpenUSD,https://developer.nvidia.com/blog/simulating-railroads-with-openusd/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/trains-on-tracks-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"trains-on-tracks\" width=\"768\" />Railroad simulation is important in modern transportation and logistics, providing a virtual testing ground for the intricate interplay of tracks, switches, and...",[{'name': 'Marc-Michael Horstmann'}],2024-01-17T21:00:00Z
2438,New Support for Dutch and Persian Released by NVIDIA NeMo ASR,https://developer.nvidia.com/blog/new-support-for-dutch-and-persian-released-by-nemo-asr/,"<img alt=\"Person sitting at a desk having a conversation with a speech ai chatbot.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/speech-ai-riva-fsi-abm-devnews-1920x10801-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"SpeechAI Riva speech recognition\" width=\"768\" />Breaking barriers in speech recognition, NVIDIA NeMo proudly presents pretrained models tailored for Dutch and Persian—languages often overlooked in the AI...",[{'name': 'Piotr Żelasko'}],2024-01-16T18:29:16Z
2439,Robust Scene Text Detection and Recognition: Inference Optimization,https://developer.nvidia.com/blog/robust-scene-text-detection-and-recognition-inference-optimization/,"<img alt=\"Decorative image of a workflow and the text &quot;Part 3&quot;.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/wipro-series-featured-part3-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"wipro-series-featured-part3\" width=\"768\" />In this post, we delve deeper into the inference optimization process to improve the performance and efficiency of our machine learning models during the...",[{'name': 'Vishal Chavan'}],2024-01-16T17:02:00Z
2440,Robust Scene Text Detection and Recognition: Implementation,https://developer.nvidia.com/blog/robust-scene-text-detection-and-recognition-implementation/,"<img alt=\"Decorative image of a workflow and the text &quot;Part 2&quot;.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/wipro-series-featured-part2-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"wipro-series-featured-part2\" width=\"768\" />To make scene text detection and recognition work on irregular text or for specific use cases, you must have full control of your model so that you can do...",[{'name': 'Vishal Chavan'}],2024-01-16T17:01:00Z
2441,Robust Scene Text Detection and Recognition: Introduction,https://developer.nvidia.com/blog/robust-scene-text-detection-and-recognition-introduction/,"<img alt=\"Decorative image of a workflow and the text &quot;Part 1&quot;.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/wipro-series-featured-part1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"wipro-series-featured-part1\" width=\"768\" />Identification and recognition of text from natural scenes and images become important for use cases like video caption text recognition, detecting signboards...",[{'name': 'Vishal Chavan'}],2024-01-16T17:00:00Z
2442,Webinar: State of Ray Tracing and NvRTX 5.3,https://gateway.on24.com/wcc/experience/elitenvidiabrill/1407606/3849291/level-up-with-nvidia#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/game-dev-ray-tracing-nvrtx-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"game-dev-ray-tracing-nvrtx\" width=\"768\" />Get up to speed on the current state of ray tracing in the NVIDIA RTX Branch of Unreal Engine and what’s coming next.,[{'name': 'Diego Farinha'}],2024-01-12T21:00:00Z
2443,Just Released: cuBLASDx,https://nvda.ws/3SdQyKO#new_tab,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"335\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/cublasdx-featured.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"cublasdx-featured\" width=\"596\" />cuBLASDx allows you to perform BLAS calculations inside your CUDA kernel, improving the performance of your application. Available to download in Preview...",[{'name': 'Robert Jensen'}],2024-01-12T18:58:48Z
2444,Free Digital Webinar Series: How to Get Started with AI Inference,https://nvda.ws/48NqBXI#new_tab,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/inference-graphic-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"inference-graphic\" width=\"768\" />Learn how to improve your AI model performance with this series of expert-led talks on the NVIDIA AI inference platform.,[{'name': 'Tanya Lenz'}],2024-01-11T19:00:00Z
2445,Experience Real-Time Audio and Video Communication with NVIDIA Maxine,https://developer.nvidia.com/blog/experience-real-time-audio-and-video-communication-with-nvidia-maxine/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-maxine-live-portrait-input-video-animating-2d-image-1-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-maxine-live-portrait-input-video-animating-2d-image (1)\" width=\"768\" />The NVIDIA Maxine developer platform redefines video conferencing and editing by providing developers and businesses with a variety of low-code implementation...,[{'name': 'Greg Jones'}],2024-01-10T19:00:00Z
2446,Enhancing Phone Customer Service with ASR Customization,https://developer.nvidia.com/blog/enhancing-phone-customer-service-with-asr-customization/,<img alt=\"Decorative image.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/polyai-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"polyai-featured\" width=\"768\" />At the core of understanding people correctly and having natural conversations is automatic speech recognition (ASR). To make customer-led voice assistants and...,[{'name': 'Paweł Budzianowski'}],2024-01-09T17:00:00Z
2447,New Models MolMIM and DiffDock Power Molecule Generation and Molecular Docking in NVIDIA BioNeMo,https://developer.nvidia.com/blog/new-models-molmim-and-diffdock-power-molecule-generation-and-molecular-docking-in-bionemo/,"<img alt=\"Decorative image of molecular displays.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/hc-tech-blog-jpm24-bionemo-1920x1080-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"hc-tech-blog-jpm24-bionemo-1920x1080\" width=\"768\" />The search for viable drugs is one of the most formidable challenges at the intersection of science, technology, and medicine.&nbsp; Mathematically, the odds of...",[{'name': 'Abraham Stern'}],2024-01-08T19:00:00Z
2448,New Stable Diffusion Models Accelerated with NVIDIA TensorRT,https://developer.nvidia.com/blog/new-stable-diffusion-models-accelerated-with-nvidia-tensorrt/,"<img alt=\"Photo of a dog racing through a snowy forest.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/ces-stable-diffusion-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"ces-stable-diffusion-featured\" width=\"768\" />At CES, NVIDIA shared that SDXL Turbo, LCM-LoRA, and Stable Video Diffusion are all being accelerated by NVIDIA TensorRT. These enhancements allow GeForce RTX...",[{'name': 'Ayesha Asif'}],2024-01-08T16:31:00Z
2449,Contest: Build Generative AI on NVIDIA RTX PCs,https://nvda.ws/3ROt4KC#new_tab,<img alt=\"Decorative image of RTX GPU.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-ai-on-rtx-owned-web-module-bb580_440-l-copy-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvidia-ai-on-rtx-owned-web-module-bb580_440-l copy\" width=\"768\" />NVIDIA is announcing the Generative AI on RTX PCs Developer Contest - designed to inspire innovation within the developer community. Build and submit your next...,[{'name': 'Annamalai Chockalingam'}],2024-01-08T16:30:00Z
2450,Building Lifelike Digital Avatars with NVIDIA ACE Microservices,https://developer.nvidia.com/blog/building-lifelike-digital-avatars-with-nvidia-ace-microservices/,"<img alt=\"Still image from Kairos demo, of an NPC at a bar.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/ces-ace-microservices-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"ces-ace-microservices-featured\" width=\"768\" />Generative AI technologies are revolutionizing how games are produced and played. Game developers are exploring how these technologies can accelerate their...",[{'name': 'Seth Schneider'}],2024-01-08T16:30:00Z
2451,Supercharging LLM Applications on Windows PCs with NVIDIA RTX Systems,https://developer.nvidia.com/blog/supercharging-llm-applications-on-windows-pcs-with-nvidia-rtx-systems/,"<img alt=\"Decorative image of an open laptop with a lightbulb leaning on it, on a purple background.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/genai-blog-2936009-1920x1080-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"genai-blog-2936009-1920x1080\" width=\"768\" />Large language models (LLMs) are fundamentally changing the way we interact with computers. These models are being incorporated into a wide range of...",[{'name': 'Annamalai Chockalingam'}],2024-01-08T16:30:00Z
2452,Spotlight: Convai Reinvents Non-Playable Character Interactions,https://developer.nvidia.com/blog/spotlight-convai-reinvents-non-playable-character-interactions/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/two-characters-in-front-of-buildings-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"two-characters-in-front-of-buildings\" width=\"768\" />Convai is a versatile developer platform for designing characters with advanced multimodal perception abilities. These characters are designed to integrate...,[{'name': 'Yasmina Benkhoui'}],2024-01-08T16:30:00Z
2453,Get Started with Generative AI Development for Windows PCs with NVIDIA RTX,https://developer.nvidia.com/blog/get-started-with-generative-ai-development-for-windows-pcs-with-rtx-systems/,<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/01/graphic-generative-ai-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"graphic-generative-ai\" width=\"768\" />Generative AI and large language models (LLMs) are changing human-computer interaction as we know it. Many use cases would benefit from running LLMs locally on...,[{'name': 'Jesse Clayton'}],2024-01-08T16:30:00Z
2454,Improving CUDA Initialization Times Using cgroups in Certain Scenarios,https://developer.nvidia.com/blog/improving-cuda-initialization-times-using-cgroups-in-certain-scenarios/,"<img alt=\"Decorative image of light fields in green, purple, and blue.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/hpc-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"hpc-featured\" width=\"768\" />Many CUDA applications running on multi-GPU platforms usually use a single GPU for their compute needs. In such scenarios, a performance penalty is paid by...",[{'name': 'Rahul Ramasubramanian'}],2024-01-05T22:14:41Z
2455,Develop ML and AI with Metaflow and Deploy with NVIDIA Triton Inference Server,https://developer.nvidia.com/blog/develop-ml-ai-with-metaflow-deploy-with-triton-inference-server/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/metaflow-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"metaflow-featured\" width=\"768\" />There are many ways to deploy ML models to production. Sometimes, a model is run once per day to refresh forecasts in a database. Sometimes, it powers a...",[{'name': 'Eddie Mattia'}],2024-01-05T19:23:39Z
2456,Video Encoding at 8K60 with Split-Frame Encoding and NVIDIA Ada Lovelace Architecture,https://developer.nvidia.com/blog/video-encoding-at-8k60-with-split-frame-encoding-and-nvidia-ada-lovelace-architecture/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/nvenc-comparison-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"nvenc-comparison\" width=\"768\" />Capturing video footage and playing games at 8K resolution with 60 frames per second (FPS) is now possible, thanks to advances in camera and display...",[{'name': 'Ricardo Monteiro'}],2024-01-05T19:00:00Z
2457,Accelerating Inference on End-to-End Workflows with H2O.ai and NVIDIA,https://developer.nvidia.com/blog/accelerating-inference-on-end-to-end-workflows-with-h2o-ai-and-nvidia/,"<img alt=\"Decorative image.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/h20ai-featured-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"h20ai-featured\" width=\"768\" />Data scientists are combining generative AI and predictive analytics to build the next generation of AI applications. In financial services, AI modeling and...",[{'name': 'Prabhu Ramamoorthy'}],2024-01-04T14:00:00Z
2458,Webinar: Accelerating Large-Scale Genomics Research,https://info.nvidia.com/parabricks-academic-webinar-emea/?nvid=nv-int-tblg-465186-vt16#new_tab,"<img alt=\"Graphic of two people in white coats standing in front of monitors and keyboards.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/hc-social-launchpad-parabricks-2048x1024-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"hc-social-launchpad-parabricks-2048x1024\" width=\"768\" />Learn how the Francis Crick Institute is using NVIDIA Clara Parabricks to enable key parts of TRACERx EVO, a new program that builds on the discoveries made in...",[{'name': 'Michelle Horton'}],2024-01-02T17:00:00Z
2459,Q&amp;A: Looking Back to When 1997’s Quake II Got a Path Tracing Update,https://developer.nvidia.com/blog/q-and-a-looking-back-to-when-1997s-quake-2-got-a-path-tracing-update/,"<img alt=\"Still from Quake II RTX.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/qa-quake-rtx-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"qa-quake-rtx-featured\" width=\"768\" />In 2019, if you wanted to check out the cutting edge in video game graphics, you needed an NVIDIA GeForce RTX 20 Series GPU and a copy of a game that was...",[{'name': 'Ethan Einhorn'}],2023-12-20T22:15:39Z
2460,Q&amp;A: Real-Time Ray Tracing in a Cinematic Scene,https://developer.nvidia.com/blog/qa-real-time-ray-tracing-in-a-cinematic-scene/,"<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/game-dev-press-rtx-500-project-sol-1920x1080-1-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"rtx-500-project-sol-1920x1080\" width=\"768\" />Six years ago, real-time ray tracing was seen as a pipe dream. Back then, cinematic-quality rendering required computer farms to slowly bake every frame...",[{'name': 'Ethan Einhorn'}],2023-12-20T21:10:44Z
2461,New Release: NVIDIA TAO 5.2,https://nvda.ws/47brM22#new_tab,"<img alt=\"Decorative image.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/gtc-s23-promo-tao-blender-kv-2716100-blog-1920x1080-1-768x432.jpg\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"gtc-s23-promo-tao-blender-kv-2716100-blog-1920x1080\" width=\"768\" />With the latest NVIDIA TAO 5.2, you can now run zero-shot inference for panoptic segmentation with ODISE, create custom 3D object pose models, and boost...",[{'name': 'Michelle Horton'}],2023-12-20T19:03:54Z
2462,Just Released: cuBLASMp,https://nvda.ws/3v8CJ7h#new_tab,"<img alt=\"Logo for cuBLAS\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/cuBLASMp-featured-image.gif\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"cuBLASMp-featured-image\" width=\"600\" />cuBLASMp is a high-performance, multi-process, GPU-accelerated library for distributed basic dense linear algebra. It is available to download in Preview now.",[{'name': 'Robert Jensen'}],2023-12-20T18:00:00Z
2463,Breakthrough in Functional Annotation with HiFi-NN,https://developer.nvidia.com/blog/breakthrough-in-functional-annotation-with-hifi-nn/,"<img alt=\"A triptych of digital graphics showcasing biomolecular structures resembling biomes, DNA, cells, and data points.\" class=\"webfeedsFeaturedVisual wp-post-image\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/hifi-nn-featured-768x432.png\" style=\"display: block; margin-bottom: 5px; clear: both;\" title=\"hifi-nn-featured\" width=\"768\" />Enzymes are vital biological catalysts for a multitude of processes, from cellular metabolism to industrial manufacturing. The applications of artificial...",[{'name': 'Bruno Trentini'}],2023-12-19T19:00:00Z
2464,Video generation models as world simulators,https://openai.com/research/video-generation-models-as-world-simulators,"We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",[],"Thu, 15 Feb 2024 08:00:00 GMT"
2465,Disrupting malicious uses of AI by state-affiliated threat actors,https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors,"We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",[],"Wed, 14 Feb 2024 08:00:00 GMT"
2466,Memory and new controls for ChatGPT,https://openai.com/blog/memory-and-new-controls-for-chatgpt,We’re testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You’re in control of ChatGPT’s memory.,[],"Tue, 13 Feb 2024 08:00:00 GMT"
2467,Building an early warning system for LLM-aided biological threat creation,https://openai.com/research/building-an-early-warning-system-for-llm-aided-biological-threat-creation,"We’re developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat. In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",[],"Wed, 31 Jan 2024 08:00:00 GMT"
2468,New embedding models and API updates,https://openai.com/blog/new-embedding-models-and-api-updates,"We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",[],"Thu, 25 Jan 2024 08:00:00 GMT"
2469,Democratic inputs to AI grant program: lessons learned and implementation plans,https://openai.com/blog/democratic-inputs-to-ai-grant-program-update,"We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",[],"Tue, 16 Jan 2024 08:00:00 GMT"
2470,How OpenAI is approaching 2024 worldwide elections,https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections,"We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",[],"Mon, 15 Jan 2024 08:00:00 GMT"
2471,Introducing the GPT Store,https://openai.com/blog/introducing-the-gpt-store,We’re launching the GPT Store to help you find useful and popular custom versions of ChatGPT.,[],"Wed, 10 Jan 2024 08:00:00 GMT"
2472,Introducing ChatGPT Team,https://openai.com/blog/introducing-chatgpt-team,"We’re launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",[],"Wed, 10 Jan 2024 08:00:00 GMT"
2473,OpenAI and journalism,https://openai.com/blog/openai-and-journalism,"We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",[],"Mon, 08 Jan 2024 08:00:00 GMT"
2474,Superalignment Fast Grants,https://openai.com/blog/superalignment-fast-grants,"We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",[],"Thu, 14 Dec 2023 08:00:00 GMT"
2475,Practices for Governing Agentic AI Systems,https://openai.com/research/practices-for-governing-agentic-ai-systems,,[],"Thu, 14 Dec 2023 08:00:00 GMT"
2476,Weak-to-strong generalization,https://openai.com/research/weak-to-strong-generalization,"We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",[],"Thu, 14 Dec 2023 08:00:00 GMT"
2477,Partnership with Axel Springer to deepen beneficial use of AI in journalism,https://openai.com/blog/axel-springer-partnership,Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.,[],"Wed, 13 Dec 2023 08:00:00 GMT"
2478,"Sam Altman returns as CEO, OpenAI has a new initial board",https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board,"Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",[],"Wed, 29 Nov 2023 08:00:00 GMT"
2479,OpenAI announces leadership transition,https://openai.com/blog/openai-announces-leadership-transition,,[],"Fri, 17 Nov 2023 08:00:00 GMT"
2480,OpenAI Data Partnerships,https://openai.com/blog/data-partnerships,Working together to create open-source and private datasets for AI training.,[],"Thu, 09 Nov 2023 08:00:00 GMT"
2481,Introducing GPTs,https://openai.com/blog/introducing-gpts,"You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",[],"Mon, 06 Nov 2023 08:00:00 GMT"
2482,New models and developer products announced at DevDay,https://openai.com/blog/new-models-and-developer-products-announced-at-devday,"GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API, and more.",[],"Mon, 06 Nov 2023 08:00:00 GMT"
2483,Frontier risk and preparedness,https://openai.com/blog/frontier-risk-and-preparedness,"To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",[],"Thu, 26 Oct 2023 07:00:00 GMT"
2484,Frontier Model Forum updates,https://openai.com/blog/frontier-model-forum-updates,"Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",[],"Wed, 25 Oct 2023 07:00:00 GMT"
2485,DALL·E 3 is now available in ChatGPT Plus and Enterprise,https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise,We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.,[],"Thu, 19 Oct 2023 07:00:00 GMT"
2486,DALL·E 3 system card,https://openai.com/research/dall-e-3-system-card,,[],"Tue, 03 Oct 2023 07:00:00 GMT"
2487,"ChatGPT can now see, hear, and speak",https://openai.com/blog/chatgpt-can-now-see-hear-and-speak,"We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.",[],"Mon, 25 Sep 2023 07:00:00 GMT"
2488,GPT-4V(ision) system card,https://openai.com/research/gpt-4v-system-card,,[],"Mon, 25 Sep 2023 07:00:00 GMT"
2489,OpenAI Red Teaming Network,https://openai.com/blog/red-teaming-network,We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI’s models to join our efforts.,[],"Tue, 19 Sep 2023 07:00:00 GMT"
2490,Confidence-Building Measures for Artificial Intelligence: Workshop proceedings,https://openai.com/research/confidence-building-measures-for-artificial-intelligence,,[],"Tue, 01 Aug 2023 07:00:00 GMT"
2491,Frontier AI regulation: Managing emerging risks to public safety,https://openai.com/research/frontier-ai-regulation,,[],"Thu, 06 Jul 2023 07:00:00 GMT"
2492,Improving mathematical reasoning with process supervision,https://openai.com/research/improving-mathematical-reasoning-with-process-supervision,"We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",[],"Wed, 31 May 2023 07:00:00 GMT"
2493,Language models can explain neurons in language models,https://openai.com/research/language-models-can-explain-neurons-in-language-models,We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.,[],"Tue, 09 May 2023 07:00:00 GMT"
2494,GPTs are GPTs: An early look at the labor market impact potential of large language models,https://openai.com/research/gpts-are-gpts,,[],"Fri, 17 Mar 2023 07:00:00 GMT"
2495,GPT-4,https://openai.com/research/gpt-4,"We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",[],"Tue, 14 Mar 2023 07:00:00 GMT"
2496,Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk,https://openai.com/research/forecasting-misuse,"OpenAI researchers collaborated with Georgetown University’s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report here.",[],"Wed, 11 Jan 2023 08:00:00 GMT"
2497,Point-E: A system for generating 3D point clouds from complex prompts,https://openai.com/research/point-e,,[],"Fri, 16 Dec 2022 08:00:00 GMT"
2498,Scaling laws for reward model overoptimization,https://openai.com/research/scaling-laws-for-reward-model-overoptimization,,[],"Wed, 19 Oct 2022 07:00:00 GMT"
2499,Introducing Whisper,https://openai.com/research/whisper,We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition.,[],"Wed, 21 Sep 2022 07:00:00 GMT"
2500,Efficient training of language models to fill in the middle,https://openai.com/research/efficient-training-of-language-models-to-fill-in-the-middle,,[],"Thu, 28 Jul 2022 07:00:00 GMT"
2501,A hazard analysis framework for code synthesis large language models,https://openai.com/research/a-hazard-analysis-framework-for-code-synthesis-large-language-models,,[],"Mon, 25 Jul 2022 07:00:00 GMT"
2502,DALL·E 2 pre-training mitigations,https://openai.com/research/dall-e-2-pre-training-mitigations,"In order to share the magic of DALL·E 2 with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various guardrails in place to prevent generated images from violating our content policy.",[],"Tue, 28 Jun 2022 07:00:00 GMT"
2503,Learning to play Minecraft with Video PreTraining,https://openai.com/research/vpt,"We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using agents.",[],"Thu, 23 Jun 2022 07:00:00 GMT"
2504,Graph neural networks in TensorFlow,https://blog.tensorflow.org/2024/02/graph-neural-networks-in-tensorflow.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmB2uY1xF7sEeT_0hkfCj1oQypkcE9ksjrPXfoOS6hWe6MjNa6OdIZLdu8m8Z2IAx0gk4EhD6fQH5EpOobdT4z0E4w1iSw5YCI7IaRU6jUIL9RpHaU-BEufRlz5Cw2bF6ww4mF6_0N43tSFSkKXVTuy2hvmcx6xYd_hPKzJ_1QvYnKdt3kLNH2iffSmbs/s1600/TFgraph-netural-networks-social.png\" style=\"display: none;\" />

<em>Posted by Dustin Zelle – Software Engineer, Research and Arno Eigenwillig – Software Engineer, CoreML</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFzx_P7ogIv5kpZcabEMbL5hkABibribiGZtH-aiI6UPSBeXFD392VF7p30Aq57Jj4LxIxVcpeOQdpm-5pGDzk1kLG5Dj85pktgsNX1f7FC8sbTWnR6iS8H2WkW0ESZAn30OcDvWRcaUA1e7FgTKD0PzHRk-8Yn73eiePFnoN78uB2tmIF06ySty1_N3I/s1600/TFgraph-netural-networks-header.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFzx_P7ogIv5kpZcabEMbL5hkABibribiGZtH-aiI6UPSBeXFD392VF7p30Aq57Jj4LxIxVcpeOQdpm-5pGDzk1kLG5Dj85pktgsNX1f7FC8sbTWnR6iS8H2WkW0ESZAn30OcDvWRcaUA1e7FgTKD0PzHRk-8Yn73eiePFnoN78uB2tmIF06ySty1_N3I/s1600/TFgraph-netural-networks-header.png\" /></a>

<a name=\"more\"></a><p></p>

<p><em>This article is also shared on the&nbsp;<a href=\"https://blog.research.google/2024/02/graph-neural-networks-in-tensorflow.html\" target=\"_blank\">Google Research Blog</a></em></p><p><em><br /></em></p>



<p>Objects and their relationships are ubiquitous in the world around us, and relationships can be as important to understanding an object as its own attributes viewed in isolation — for example: transportation networks, production networks, knowledge graphs, or social networks.  Discrete mathematics and computer science have a long history of formalizing such networks them as <a href=\"https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29\" target=\"_blank\"><i>graphs</i></a>, consisting of <i>nodes</i> arbitrarily connected by <i>edges</i> in various irregular ways. Yet most machine learning (ML) algorithms allow only for regular and uniform relations between input objects, such as a grid of pixels, a sequence of words, or no relation at all.</p> 
  
<p><a href=\"https://distill.pub/2021/gnn-intro/\" target=\"_blank\">Graph neural networks</a>, or GNNs for short, have emerged as a powerful technique to leverage both the graph’s connectivity (as in the older algorithms <a href=\"http://perozzi.net/projects/deepwalk/\" target=\"_blank\">DeepWalk</a> and <a href=\"https://snap.stanford.edu/node2vec/\" target=\"_blank\">Node2Vec</a>) and the input features on the various nodes and edges. GNNs can make predictions for graphs as a whole (Does this molecule react in a certain way?), for individual nodes (What’s the topic of this document, given its citations?) or for potential edges (Is this product likely to be purchased together with that product?). Apart from making predictions about graphs, GNNs are a powerful tool used to bridge the chasm to more typical neural network use cases. They encode a graph's <i>discrete</i>, <i>relational</i> information in a <i>continuous</i> way so that it can be included naturally in another deep learning system.</p>


<p>We are excited to announce the release of <a href=\"https://github.com/tensorflow/gnn\" target=\"_blank\">TensorFlow GNN 1.0</a>&nbsp;(TF-GNN), a production-tested library for building GNNs at large scale. It supports both modeling and training in TensorFlow as well as the extraction of input graphs from huge data stores. TF-GNN is built from the ground up for heterogeneous graphs where types and relations are represented by distinct sets of nodes and edges. Real-world objects and their relations occur in distinct types and TF-GNN's heterogeneous focus makes it natural to represent them.</p>

<p>Inside TensorFlow, such graphs are represented by objects of type <code>tfgnn.GraphTensor</code>. This is a composite tensor type (a collection of tensors in one Python class) accepted as a <a href=\"https://en.wikipedia.org/wiki/First-class_citizen\" target=\"_blank\">first-class citizen</a> in <code>tf.data.Dataset</code>,&nbsp;<code>tf.function</code>, etc. It stores both the graph structure and its features attached to nodes, edges and the graph as a whole. Trainable transformations of GraphTensors can be defined as Layers objects in the high-level <a href=\"https://www.tensorflow.org/guide/keras\" target=\"_blank\">Keras API</a>, or directly using the <code>tfgnn.GraphTensor</code> primitive.</p>

<h2>GNNs: Making predictions for an object in context</h2>


<p>For illustration, let’s look at one typical application of TF-GNN: predicting a property of a certain type of node in a graph defined by cross-referencing tables of a huge database. For example, a citation database of Computer Science (CS) arXiv papers with one-to-many cites and many-to-one cited relationships where we would like to predict the subject area of each paper.</p>

<p>Like most neural networks, a GNN is trained on a dataset of many labeled examples (~millions), but each training step consists only of a much smaller batch of training examples (say, hundreds). To scale to millions, the GNN gets trained on a stream of reasonably small subgraphs from the underlying graph. Each subgraph contains enough of the original data to compute the GNN result for the labeled node at its center and train the model. This process — typically referred to as subgraph sampling — is extremely consequential for GNN training. Most existing tooling accomplishes sampling in a batch way, producing static subgraphs for training. TF-GNN provides tooling to improve on this by sampling dynamically and interactively. </p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"moving image illustrating the process of subgraph sampling where small, tractable subgraphs are sampled from a larger graph to create input examples for GNN training.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdcxMo1kRE6OY7Xi_6sz1iah067JWj5Ic4-myeZwcwpqOVH9raRXhuxxp3xkra5arDS_IZHB6H_Aiwyjd-4daydjwFxtD9YohzAd7axB3260lTjwLo7PuQ1BxIBGZ83IK8WGKcwDyXJlGIPLOivTqG8FR3kzRUi8vOhlwxF-URAts2Vbc8ZXoEAwBxq50/s1600/image2.gif\" style=\"width: auto;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Pictured, the process of subgraph sampling where small, tractable subgraphs are sampled from a larger graph to create input examples for GNN training.</i></td></tr></tbody></table></div>


<p>TF-GNN 1.0 debuts a flexible Python API to configure dynamic or batch subgraph sampling at all relevant scales: interactively in a Colab notebook (like <a href=\"https://colab.research.google.com/github/tensorflow/gnn/blob/master/examples/notebooks/ogbn_mag_e2e.ipynb\" target=\"_blank\">this one</a>), for efficient sampling of a small dataset stored in the main memory of a single training host, or distributed by <a href=\"https://beam.apache.org/\" target=\"_blank\">Apache Beam</a> for huge datasets stored on a network filesystem (up to hundreds of millions of nodes and billions of edges). For details, please refer to our user guides for <a href=\"https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/inmemory_sampler.md\" target=\"_blank\">in-memory</a> and <a href=\"https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/beam_sampler.md\" target=\"_blank\">beam-based</a> sampling, respectively.</p>

<p>On those same sampled subgraphs, the GNN’s task is to compute a hidden (or latent) state at the root node; the hidden state aggregates and encodes the relevant information of the root node's neighborhood. One classical approach is <a href=\"https://research.google/pubs/neural-message-passing-for-quantum-chemistry/\" target=\"_blank\">message-passing neural networks</a>. In each round of message passing, nodes receive messages from their neighbors along incoming edges and update their own hidden state from them. After <i>n</i> rounds, the hidden state of the root node reflects the aggregate information from all nodes within <i>n</i> edges (pictured below for <i>n</i> = 2). The messages and the new hidden states are computed by hidden layers of the neural network. In a heterogeneous graph, it often makes sense to use separately trained hidden layers for the different types of nodes and edges.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"moving image illustrating the process of subgraph sampling where small, tractable subgraphs are sampled from a larger graph to create input examples for GNN training.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjtpQadw1OPvgGJC11NfogydDRpg6-XBK_Cm3E9qq-9J5MYSe7_P8IR-0Yn8puV0Xmq4PifMOZtuKWxfran3yMuYK5YwBRV8Ut_3MNFlxdB-9-L7OTePqy3fUQi3X5PptSyiUjhgihynm5r3NBH0mrjbmW4B3j7H08xXruud7tLFhR-1FE_wQifcLt9ku8/s1600/image1.gif\" style=\"width: auto;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Pictured, a simple message-passing neural network where, at each step, the node state is propagated from outer to inner nodes where it is pooled to compute new node states. Once the root node is reached, a final prediction can be made.</i></td></tr></tbody></table></div>

<p>The training setup is completed by placing an output layer on top of the GNN’s hidden state for the labeled nodes, computing the loss (to measure the prediction error), and updating model weights by backpropagation, as usual in any neural network training.</p> 

<p>Beyond supervised training (i.e., minimizing a loss defined by labels), GNNs can also be trained in an unsupervised way (i.e., without labels). This lets us compute a <i>continuous</i> representation (or <i>embedding</i>) of the <i>discrete</i> graph structure of nodes and their features. These representations are then typically utilized in other ML systems. In this way, the discrete, relational information encoded by a graph can be included in more typical neural network use cases. TF-GNN supports a fine-grained specification of unsupervised objectives for heterogeneous graphs.</p>

<h2>Building GNN architectures</h2>

<p>The TF-GNN library supports building and training GNNs at various levels of abstraction.</p>

<p>At the highest level, users can take any of the predefined models bundled with the library that are expressed in Keras layers. Besides a small collection of models from the research literature, TF-GNN comes with a highly configurable model template that provides a curated selection of modeling choices that we have found to provide strong baselines on many of our in-house problems. The templates implement GNN layers; users need only to initialize the Keras layers.</p>


<div style=\"background: rgb(248, 248, 248); border: 0px; overflow: auto; width: auto;\"><pre style=\"line-height: 125%; margin: 0px;\"><span style=\"color: #444444; font-family: courier;\">import tensorflow_gnn as tfgnn
from tensorflow_gnn<span>.</span>models import mt_albis

def model_fn(graph_tensor_spec<span>:</span> tfgnn<span>.</span>GraphTensorSpec)<span>:</span>
  \"\"\"Builds a GNN as a Keras model<span>.\"\"\"</span>
  graph <span>=</span> inputs <span>=</span> tf<span>.</span>keras<span>.</span>Input(type_spec<span>=</span>graph_tensor_spec)

  # Encode input features (callback omitted <span>for</span> brevity)<span>.</span>
  graph <span>=</span> tfgnn<span>.</span>keras<span>.</span>layers<span>.</span>MapFeatures(
      node_sets_fn<span>=</span>set_initial_node_states)(graph)

  # <span>For</span> each <span>round</span> of message passing<span>...</span>
  <span>for</span> _ in range(<span>2</span>)<span>:</span>
    # <span>...</span> create <span>and</span> apply a Keras layer<span>.</span>
    graph <span>=</span> mt_albis<span>.</span>MtAlbisGraphUpdate(
        units<span>=128</span>, message_dim<span>=64</span>,
        attention_type<span>=\"</span>none\", simple_conv_reduce_type<span>=</span><span>\"mean\"</span>,
        normalization_type<span>=</span><span>\"layer\"</span>, next_state_type<span>=</span><span>\"residual\"</span>,
        state_dropout_rate<span>=0.2</span>, l2_regularization<span>=1e-5</span>,
    )(graph)

  <span>return</span> tf<span>.</span>keras<span>.</span>Model(inputs, graph)</span>
</pre></div>

<p>At the lowest level, users can write a GNN model from scratch in terms of primitives for passing data around the graph, such as broadcasting data from a node to all its outgoing edges or pooling data into a node from all its incoming edges (e.g., computing the sum of incoming messages). TF-GNN’s graph data model treats nodes, edges and whole input graphs equally when it comes to features or hidden states, making it straightforward to express not only node-centric models like the MPNN discussed above but also more general forms of <a href=\"https://arxiv.org/abs/1806.01261\" target=\"_blank\">GraphNets</a>. This can, but need not, be done with Keras as a modeling framework on the top of core TensorFlow. For more details, and intermediate levels of modeling, see the TF-GNN <a href=\"https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/gnn_modeling.md\" target=\"_blank\">user guide</a> and <a href=\"https://github.com/tensorflow/gnn/tree/main/tensorflow_gnn/models\" target=\"_blank\">model collection</a>.</p>

<h2>Training orchestration</h2>

<p>While advanced users are free to do custom model training, the <a href=\"https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/runner.md\" target=\"_blank\">TF-GNN Runner</a> also provides a succinct way to orchestrate the training of Keras models in the common cases. A simple invocation may look like this:</p>

<div style=\"background: rgb(248, 248, 248); border: 0px; overflow: auto; width: auto;\"><pre style=\"line-height: 125%; margin: 0px;\"><span style=\"color: #444444; font-family: courier;\">from tensorflow_gnn import runner

runner<span>.</span><span>run</span>(
   task<span>=</span>runner<span>.</span>RootNodeBinaryClassification(\"papers\", <span>...</span>),
   model_fn<span>=</span>model_fn,
   trainer<span>=</span>runner<span>.</span>KerasTrainer(tf<span>.</span>distribute<span>.</span>MirroredStrategy(), model_dir<span>=</span><span>\"</span><span>/</span>tmp<span>/</span>model\"),
   optimizer_fn<span>=</span>tf<span>.</span>keras<span>.</span>optimizers<span>.</span>Adam,
   epochs<span>=10</span>,
   global_batch_size<span>=128</span>,
   train_ds_provider<span>=</span>runner<span>.</span>TFRecordDatasetProvider(\"<span>/</span>tmp<span>/</span>train<span>*\"</span>),
   valid_ds_provider<span>=</span>runner<span>.</span>TFRecordDatasetProvider(\"<span>/</span>tmp<span>/</span>validation<span>*\"</span>),
   gtspec<span>=...</span>,
)</span>
</pre></div>

<p>The Runner provides ready-to-use solutions for ML pains like distributed training and <code>tfgnn.GraphTensor</code> padding for fixed shapes on Cloud TPUs. Beyond training on a single task (as shown above), it supports joint training on multiple (two or more) tasks in concert. For example, unsupervised tasks can be mixed with supervised ones to inform a final continuous representation (or embedding) with application specific inductive biases. Callers only need substitute the task argument with a mapping of tasks:</p>

<div style=\"background: rgb(248, 248, 248); border: 0px; overflow: auto; width: auto;\"><pre style=\"line-height: 125%; margin: 0px;\"><span style=\"color: #444444; font-family: courier;\">from tensorflow_gnn import runner
from tensorflow_gnn<span>.</span>models import contrastive_losses

runner<span>.</span><span>run</span>(
     task<span>=</span>{
        <span>\"classification\"</span><span>:</span> runner<span>.</span>RootNodeBinaryClassification(\"papers\", <span>...</span>),
        <span>\"dgi\"</span><span>:</span> contrastive_losses<span>.</span>DeepGraphInfomaxTask(<span>\"papers\"</span>),
      },
    <span>...</span>
)</span>
</pre></div>

<p>Additionally, the TF-GNN Runner also includes an implementation of <a href=\"https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\" target=\"_blank\">integrated gradients</a> for use in model attribution. Integrated gradients&nbsp;output is a GraphTensor with the same connectivity as the observed GraphTensor but its features replaced with gradient values where larger values contribute more than smaller values in the GNN prediction. Users can inspect gradient values to see which features their GNN uses the most.</p> 

<h2>Conclusion</h2>

<p>In short, we hope TF-GNN will be useful to advance the application of GNNs in TensorFlow at scale and fuel further innovation in the field. If you’re curious to find out more, please try our <a href=\"https://colab.sandbox.google.com/github/tensorflow/gnn/blob/master/examples/notebooks/ogbn_mag_e2e.ipynb\" target=\"_blank\">Colab demo</a> with the popular OGBN-MAG benchmark (in your browser, no installation required), browse the rest of our <a href=\"https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/overview.md\" target=\"_blank\">user guides and Colabs</a>, or take a look at our <a href=\"https://arxiv.org/abs/2207.03522\" target=\"_blank\">paper</a>.</p>


<h3>Acknowledgements</h3>
<p><em>The TF-GNN release 1.0 was developed by a collaboration between <b>Google Research</b> (Sami Abu-El-Haija, Neslihan Bulut, Bahar Fatemi, Johannes Gasteiger, Pedro Gonnet, Jonathan Halcrow, Liangze Jiang, Silvio Lattanzi, Brandon Mayer, Vahab Mirrokni, Bryan Perozzi, Anton Tsitsulin, Dustin Zelle), <b>Google Core ML</b> (Arno Eigenwillig, Oleksandr Ferludin, Parth Kothari, Mihir Paradkar, Jan Pfeifer, Rachael Tamakloe), and <b>Google DeepMind</b> (Alvaro Sanchez-Gonzalez and Lisa Wang).</em></p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 06 Feb 2024 19:00:00 +0000"
2505,TensorFlow 2.15 update: hot-fix for Linux installation issue,https://blog.tensorflow.org/2023/12/tensorflow-215-update-hot-fix-linux-installation-issue.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVyX9h9jqUfN0LpVCwPg0iWNd4XDkKWd5hL7Wn9CwGLBZ5NyrEFTHHXu6yCxCaLL2szdaQMCkDuRdV4-JapbV329DYTjaH6ThpbzJlbvgunZK9dUgii1kAqcs-4zhyphenhyphenccaLsfffj7K3-8HFLybyOeaHjVl_n7jdPmD33o0TERamUgTdH7H3qhBLS2GuwtY/s1600/Tensorflow-septmber-update-social%20%282%29%20%281%29.png\" style=\"display: none;\" />

<em>Posted by the TensorFlow team</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEja7X29KGgTQBVvr3Xl2pyRZ-KQZJOM1-rq5XUr7AKu1vc_umj40H8y3mMoYq3wccQlA9XZ8OPtSx8SFJOOy8uSeX_MpoIAz7x44Cov-P95v9h85TLGgWCW2gqL6x3fbFfL1Xg6gZYkhylQKMQG7_8ilCTsm81bG87vT-3ttwn8IGdCPU1KfVVDjatuofs/s1600/Tensorflow-septmber-update-header%20%284%29.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEja7X29KGgTQBVvr3Xl2pyRZ-KQZJOM1-rq5XUr7AKu1vc_umj40H8y3mMoYq3wccQlA9XZ8OPtSx8SFJOOy8uSeX_MpoIAz7x44Cov-P95v9h85TLGgWCW2gqL6x3fbFfL1Xg6gZYkhylQKMQG7_8ilCTsm81bG87vT-3ttwn8IGdCPU1KfVVDjatuofs/s1600/Tensorflow-septmber-update-header%20%284%29.png\" /></a>

<a name=\"more\"></a><p></p>

<p>We are releasing a hot-fix for an installation issue affecting the TensorFlow installation process. The TensorFlow 2.15.0 Python package was released such that it requested <code>tensorrt</code>-related packages that cannot be found unless the user installs them beforehand or provides additional installation flags. This dependency affected anyone installing TensorFlow 2.15 alongside NVIDIA CUDA dependencies via <code>pip install tensorflow[and-cuda]</code>. Depending on the installation method, TensorFlow 2.14 would be installed instead of 2.15, or users could receive an installation error due to those missing dependencies.</p>
  
<p>To solve this issue as quickly as possible, we have released TensorFlow 2.15.0.post1 for the Linux x86_64 platform. This version removes the <code>tensorrt</code> Python package dependencies from the <code>tensorflow[and-cuda]</code> installation method. Support for TensorRT is otherwise unaffected as long as TensorRT is already installed on the system. Now, <code>pip install tensorflow[and-cuda]</code> works as originally intended for TensorFlow 2.15.</p>
  
<p>Using .post1 instead of a full minor release allowed us to push this release out quickly. However, please be aware of the following caveat: for users wishing to pin their Python dependency in a requirements file or other situation, under Python's version specification rules, <code>tensorflow[and-cuda]==2.15.0</code> will not install this fixed version. Please use <code>==2.15.0.post1</code> to specify this exact version on Linux platforms, or a fuzzy version specification, such as <code>==2.15.<sup>*</sup></code>, to specify the most recent compatible version of TensorFlow 2.15 on all platforms.</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 05 Dec 2023 22:00:00 +0000"
2506,Half-precision Inference Doubles On-Device Inference Performance,https://blog.tensorflow.org/2023/11/half-precision-inference-doubles-on-device-inference-performance.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjLe00EnYz8eKv0IaUn3KfPZnEa4ubDV7Ay2qqIFnOYEMLOh6ybHdH9RhUUrwhYgaccnNkTLe8pID8hvyyKd88JqJL2jK6-ePMxmsddBPcGPktJ_i_EUKmJI1x_YMv6gK3DHZzMqtWIw7Zc5Rx5eHDJH0zNSc-Cnp92ue4WYVWX9P5ATGCnOVeFx-jsI2c/s1600/TensorFlow_HalfPrecisionInference_1024x512.png\" style=\"display: none;\" />

<p><em>Posted by Marat Dukhan and Frank Barchard, Software Engineers</em></p><p>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoSV-IQalCzvy3lhcb61AXM4IyP_t2Gwj8nBK1IhvH4fbi0nRB7f3ljwOBCxbRnu_xZwAtZUREerXmSclm8Q09hpTdha_i1-Bvoyw3grtqhW0RrdtDGNMebc7BVZPb6wsBBF_pIYKqnse03TFW07K7OBSPuB_TuuDyn06cmDRKkB2c0lN0-fv3wJO0xKk/s1600/TensorFlow_HalfPrecisionInference_4209x1253.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoSV-IQalCzvy3lhcb61AXM4IyP_t2Gwj8nBK1IhvH4fbi0nRB7f3ljwOBCxbRnu_xZwAtZUREerXmSclm8Q09hpTdha_i1-Bvoyw3grtqhW0RrdtDGNMebc7BVZPb6wsBBF_pIYKqnse03TFW07K7OBSPuB_TuuDyn06cmDRKkB2c0lN0-fv3wJO0xKk/s1600/TensorFlow_HalfPrecisionInference_4209x1253.png\" /></a>

</p><a name=\"more\"></a><p></p>

<p>CPUs deliver the widest reach for ML inference and remain the default target for TensorFlow Lite. Consequently, improving CPU inference performance is a top priority, and we are excited to announce that we <b>doubled</b> floating-point inference performance in TensorFlow Lite’s <a href=\"https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html\" target=\"_blank\">XNNPack backend</a> by enabling half-precision inference on ARM CPUs. This means that more AI powered features may be deployed to older and lower tier devices.</p>

<p>Traditionally, TensorFlow Lite supported two kinds of numerical computations in machine learning models: a) floating-point using IEEE 754 single-precision (32-bit) format and b) quantized using low-precision integers. While single-precision floating-point numbers provide maximum flexibility and ease of use, they come at the cost of 4X overhead in storage and memory and exhibit a performance overhead compared to 8-bit integer computations. In contrast, half-precision (FP16) floating-point numbers pose an interesting alternative balancing ease-of-use and performance: the processor needs to transfer twice fewer bytes and each vector operation produces twice more elements. By virtue of this property, FP16 inference paves the way for 2X speedup for floating-point models compared to the traditional FP32 way.</p>

<p>For a long time FP16 inference on CPUs primarily remained a research topic, as the lack of hardware support for FP16 computations limited production use-cases. However, around 2017 new mobile chipsets started to include support for native FP16 computations, and by now most mobile phones, both on the high-end and the low-end. Building upon this broad availability, we are pleased to announce the general availability for half-precision inference in TensorFlow Lite and XNNPack.</p>

<h2>Performance Improvements</h2>

<p>Half-precision inference has already been battle-tested in production across Google Assistant, Google Meet, YouTube, and ML Kit, and <b>demonstrated close to 2X speedups</b> across a wide range of neural network architectures and mobile devices. Below, we present benchmarks on nine public models covering common computer vision tasks:</p>
<ol>
<li><a href=\"https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html\" target=\"_blank\">MobileNet v2</a> image classification [<a href=\"https://tfhub.dev/tensorflow/lite-model/mobilenet_v2_1.0_224/1/default/1\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://ai.googleblog.com/2019/11/introducing-next-generation-on-device.html\" target=\"_blank\">MobileNet v3-Small</a> image classification [<a href=\"https://storage.googleapis.com/mobilenet_v3/checkpoints/v3-small_224_1.0_float.tgz\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://ai.googleblog.com/2018/03/semantic-image-segmentation-with.html\" target=\"_blank\">DeepLab v3</a> segmentation [<a href=\"https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/1\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://google.github.io/mediapipe/solutions/face_detection.html\" target=\"_blank\">BlazeFace</a> face detection [<a href=\"https://github.com/google/mediapipe/blob/master/mediapipe/models/face_detection_front.tflite\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://arxiv.org/abs/1801.04381\" target=\"_blank\">SSDLite</a> 2D object detection [<a href=\"https://github.com/google/mediapipe/blob/master/mediapipe/models/ssdlite_object_detection.tflite\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html\" target=\"_blank\">Objectron</a> 3D object detection [<a href=\"https://github.com/google/mediapipe/blob/master/mediapipe/models/object_detection_3d_chair.tflite\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://google.github.io/mediapipe/solutions/face_mesh\" target=\"_blank\">Face Mesh</a> landmarks  [<a href=\"https://github.com/google/mediapipe/blob/master/mediapipe/models/face_landmark.tflite\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://google.github.io/mediapipe/solutions/hands.html\" target=\"_blank\">MediaPipe Hands</a> landmarks [<a href=\"https://github.com/google/mediapipe/blob/master/mediapipe/models/hand_landmark.tflite\" target=\"_blank\">download</a>]</li>
<li><a href=\"https://developers.googleblog.com/2020/04/mediapipe-knift-template-based-feature-matching.html\" target=\"_blank\">KNIFT</a> local feature descriptor [<a href=\"https://github.com/google/mediapipe/blob/master/mediapipe/models/knift_float.tflite\" target=\"_blank\">download</a>]</li>
</ol>

<p>These models were benchmarked on 5 popular mobile devices, including recent and older devices (Pixel 3a, Pixel 5a, Pixel 7, Galaxy M12 and Galaxy S22). The average speedup is shown below.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Graph of Average speedup for fp16 vs fp32\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9Jr2e_1Pg03j5uR3HDCiwIL7XPkVnVm4rfvGcZWzfZbE3yubuCmbmf2mxnOaj2lvbCUXRQLjkhkdAo7gPYQlmsud_hzIMoQz9-I-PLwnRngauGZf3dNZRAofs-EXyXNnK-nFa-rPAIOBz_AeB-H2k8PdLhqe2vv6yoO-FqfF3iMWhvbYskNSfWFK8fOg/s1600/image2.png\" style=\"width: auto;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Single-threaded inference speedup with half-precision (FP16) inference compared to single-precision (FP32) across 5 mobile devices. Higher numbers are better.</i></td></tr></tbody></table></div>



<p>The same models were also benchmarked on three laptop computers (MacBook Air M1, Surface Pro X and Surface Pro 9)</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOymbNjV4dNtIyoBJOEc0akMN8crCQ-Yb5LdEu1SRfzE0038Prb8zRtwI7J9tUF8fY_d5aSllTXa_ff0IeTc7UNDW-ezY4PI4-AC7SrpNa7x_VK7pKleZUb7IUz8Q6_wiV_NiLhOKq3sUnkuEsJXszdrI70wqpEgXYjwMr4sr31sJO-L48ZBg9hTpwZTI/s1600/image1.png\" style=\"width: auto;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Single-threaded inference speedup with half-precision (FP16) inference compared to single-precision (FP32) across 3 laptop computers. Higher numbers are better.</i></td></tr></tbody></table></div>

<p>Currently, the FP16-capable hardware supported in XNNPack is limited to ARM &amp; ARM64 devices with ARMv8.2 FP16 arithmetics extension, which includes Android phones starting with Pixel 3, Galaxy S9 (Snapdragon SoC), Galaxy S10 (Exynos SoC), iOS devices with A11 or newer SoCs, all Apple Silicon Macs, and Windows ARM64 laptops based with Snapdragon 850 SoC or newer.</p>

<h3>How Can I Use It?</h3>

<p>To benefit from the half-precision inference in XNNPack, the user must provide a floating-point (FP32) model with FP16 weights and special \"reduced_precision_support\" metadata to indicate model compatibility with FP16 inference. The metadata can be added during model conversion using the <code>_experimental_supported_accumulation_type</code> attribute of the <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/lite/TargetSpec\" target=\"_blank\">tf.lite.TargetSpec</a></code> object:</p>

<div style=\"background: rgb(255, 255, 255); border: 0px; overflow: auto; width: auto;\"><pre style=\"line-height: 125%; margin: 0px;\"><span style=\"font-family: courier;\"><span style=\"color: #666666;\">...</span>
converter<span style=\"color: #666666;\">.</span>target_spec<span style=\"color: #666666;\">.</span>supported_types <span style=\"color: #666666;\">=</span> [tf<span style=\"color: #666666;\">.</span>float16]
converter<span style=\"color: #666666;\">.</span>target_spec<span style=\"color: #666666;\">.</span>_experimental_supported_accumulation_type <span style=\"color: #666666;\">=</span> tf<span style=\"color: #666666;\">.</span>dtypes<span style=\"color: #666666;\">.</span>float16</span>
</pre></div>

<p>When the compatible model is delegated to XNNPack on a hardware with native support for FP16 computations, XNNPack will transparently replace FP32 operators with their FP16 equivalents, and insert additional operators to convert model inputs from FP32 to FP16 and convert model outputs back from FP16 to FP32. If the hardware is not capable of FP16 arithmetics, XNNPack will perform model inference with FP32 calculations. Therefore, a single model can be transparently deployed on both recent and legacy devices.</p>

<p>Additionally, the XNNPack delegate provides an option to force FP16 inference regardless of the model metadata. This option is intended for development workflows, and in particular for testing end-to-end accuracy of the model when FP16 inference is used. In addition to devices with native FP16 arithmetics support, forced FP16 inference is supported on x86/x86-64 devices with AVX2 extension in emulation mode: all elementary floating-point operations are computed in FP32, then converted to FP16 and back to FP32. Note that such simulation is slow and not a bit-exact equivalent to native FP16 inference, but simulates the effects of restricted mantissa precision and exponent range in the native FP16 arithmetics. To force FP16 inference, either build TensorFlow Lite with <code>--define xnnpack_force_float_precision=fp16</code> Bazel option, or apply XNNPack delegate explicitly and add <code>TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16</code> flag to the <code>TfLiteXNNPackDelegateOptions.flags</code> bitmask passed into the <code>TfLiteXNNPackDelegateCreate</code> call:</p>

<div style=\"background: rgb(248, 248, 248); border: 0px; overflow: auto; width: auto;\"><pre style=\"line-height: 125%; margin: 0px;\"><span style=\"font-family: courier;\"><span style=\"color: #4285f4;\">TfLiteXNNPackDelegateOptions</span> xnnpack_options <span style=\"color: #666666;\">=</span>
    <span style=\"color: #4285f4;\">TfLiteXNNPackDelegateOptionsDefault</span><span style=\"color: #666666;\">()<span style=\"font-style: italic;\">;</span></span>
<span style=\"color: #666666;\">...</span>
xnnpack_options<span style=\"color: #666666;\">.</span>flags <span style=\"color: #666666;\">|=</span> TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16<span style=\"color: #666666; font-style: italic;\">;</span>
<span style=\"color: #4285f4;\">TfLiteDelegate</span><span style=\"color: #666666;\">*</span> xnnpack_delegate <span style=\"color: #666666;\">=</span>
    <span style=\"color: #4285f4;\">TfLiteXNNPackDelegateCreate</span><span style=\"color: #666666;\">(<span>&amp;</span></span>xnnpack_options<span style=\"color: #666666;\">)<span style=\"font-style: italic;\">;</span></span></span>
</pre></div>

<p>XNNPack provides <b>full feature parity between FP32 and FP16 operators</b>: all operators that are supported for FP32 inference are also supported for FP16 inference, and vice versa. In particular, <a href=\"https://blog.research.google/2021/03/accelerating-neural-networks-on-mobile.html\" target=\"_blank\">sparse inference</a> operators are supported for FP16 inference on ARM processors. Therefore, users can combine the performance benefits of sparse and FP16 inference in the same model.</p>

<h3>Future Work</h3>

<p>In addition to most ARM and ARM64 processors, the most recent Intel processors, code-named Sapphire Rapids, support native FP16 arithmetics via the AVX512-FP16 instruction set, and the recently announced AVX10 instruction set promises to make this capability widely available on x86 platform. We plan to optimize XNNPack for these instruction sets in a future release.</p><br />

<h3>Acknowledgements</h3>

<p><em>We would like to thank Alan Kelly, Zhi An Ng, Artsiom Ablavatski, Sachin Joglekar, T.J. Alumbaugh, Andrei Kulik, Jared Duke, Matthias Grundmann for contributions towards half-precision inference in TensorFlow Lite and XNNPack.</em></p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Wed, 29 Nov 2023 18:00:00 +0000"
2507,What's new in TensorFlow 2.15,https://blog.tensorflow.org/2023/11/whats-new-in-tensorflow-2-15.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVyX9h9jqUfN0LpVCwPg0iWNd4XDkKWd5hL7Wn9CwGLBZ5NyrEFTHHXu6yCxCaLL2szdaQMCkDuRdV4-JapbV329DYTjaH6ThpbzJlbvgunZK9dUgii1kAqcs-4zhyphenhyphenccaLsfffj7K3-8HFLybyOeaHjVl_n7jdPmD33o0TERamUgTdH7H3qhBLS2GuwtY/s1600/Tensorflow-septmber-update-social%20%282%29%20%281%29.png\" style=\"display: none;\" />

<em>Posted by the TensorFlow team</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEja7X29KGgTQBVvr3Xl2pyRZ-KQZJOM1-rq5XUr7AKu1vc_umj40H8y3mMoYq3wccQlA9XZ8OPtSx8SFJOOy8uSeX_MpoIAz7x44Cov-P95v9h85TLGgWCW2gqL6x3fbFfL1Xg6gZYkhylQKMQG7_8ilCTsm81bG87vT-3ttwn8IGdCPU1KfVVDjatuofs/s1600/Tensorflow-septmber-update-header%20%284%29.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEja7X29KGgTQBVvr3Xl2pyRZ-KQZJOM1-rq5XUr7AKu1vc_umj40H8y3mMoYq3wccQlA9XZ8OPtSx8SFJOOy8uSeX_MpoIAz7x44Cov-P95v9h85TLGgWCW2gqL6x3fbFfL1Xg6gZYkhylQKMQG7_8ilCTsm81bG87vT-3ttwn8IGdCPU1KfVVDjatuofs/s1600/Tensorflow-septmber-update-header%20%284%29.png\" /></a>

<a name=\"more\"></a><p></p>

<p>TensorFlow 2.15 has been released! Highlights of this release (and 2.14) include a much simpler installation method for NVIDIA CUDA libraries for Linux, oneDNN CPU performance optimizations for Windows x64 and x86, full availability of <code>tf.function</code> types, an upgrade to Clang 17.0.1, and much more!&nbsp;For the full release note, please check&nbsp;<a href=\"https://github.com/tensorflow/tensorflow/blob/r2.15/RELEASE.md\">here</a>.</p><div><b>Note:</b> Release updates on the new multi-backend Keras will be published on <a href=\"http://keras.io\" target=\"_blank\">keras.io</a> starting with Keras 3.0. For more information, please check <a href=\"https://keras.io/keras_core/announcement/.\" target=\"_blank\">here</a>.</div> 

<h2>TensorFlow Core</h2>

<h4>NVIDIA CUDA libraries for Linux</h4>

<p>The <code>tensorflow</code> pip package has a new, optional installation method for Linux that installs necessary NVIDIA CUDA libraries through pip. As long as the NVIDIA driver is already installed on the system, you may now run <code>pip install tensorflow[and-cuda]</code> to install TensorFlow's NVIDIA CUDA library dependencies in the Python environment. Aside from the NVIDIA driver, no other pre-existing NVIDIA CUDA packages are necessary. In TensorFlow 2.15, CUDA has been upgraded to version 12.2.</p>

<h4><a href=\"https://github.com/tensorflow/community/blob/master/rfcs/20210930-enable-onednn-ops.md\" target=\"_blank\">oneDNN CPU performance optimizations</a></h4>

<p>For Windows x64 &amp; x86 packages, oneDNN optimizations are now enabled by default on X86 CPUs. These optimizations can be enabled or disabled by setting the environment variable <code>TF_ENABLE_ONEDNN_OPTS</code> to <code>1</code> (enable) or <code>0</code> (disable) before running TensorFlow. To fall back to default settings, simply unset the environment variable.</p>
  
<h4>tf.function</h4>
  
<p><code>tf.function</code> types are now fully available.</p>
<ul><blockquote> 
<li><code>tf.types.experimental.TraceType</code> now allows custom tf.function inputs to declare Tensor decomposition and type casting support.&nbsp;</li></blockquote><blockquote>
<li>Introducing <code>tf.types.experimental.FunctionType</code> as the comprehensive representation of the signature of tf.function callables. It can be accessed through the <code>function_type</code> property of <code>tf.function’s</code> and <code>ConcreteFunctions</code>. See the <code>tf.types.experimental.FunctionType</code> documentation for more details.&nbsp;</li></blockquote><blockquote>
<li>Introducing <code>tf.types.experimental.AtomicFunction</code> as the fastest way to perform TF computations in Python. This capability can be accessed through the <code>inference_fn</code> property of <code>ConcreteFunctions</code>. (Does not support gradients.) See the <code>tf.types.experimental.AtomicFunction</code> documentation for how to call and use it.</li>
</blockquote></ul>

<h4>Upgrade to Clang 17.0.1 and CUDA 12.2</h4>

<p>TensorFlow PIP packages are now being built with Clang 17 and CUDA 12.2 to improve performance for NVIDIA Hopper-based GPUs. Moving forward, Clang 17 will be the default C++ compiler for TensorFlow. We recommend upgrading your compiler to Clang 17 when building TensorFlow from source.</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Fri, 17 Nov 2023 18:55:00 +0000"
2508,Join us at the third Women in ML Symposium!,https://blog.tensorflow.org/2023/11/join-us-at-third-women-in-ml-symposium.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjtd2GtibClrQS_fEHuU5Y8j25qKKsKNxCet5OOhia8zI09w7WmspXpsXQIV7I7HTNPtEqkP7wnlmE-gSj05yrIWaFKxYiocXH-pOsVen-Aq2dPb7AgtMz4lmGzHnXiLerzl8IHcajiwrkJkP-wIV5IPppznk_3BCi2AWQzcv4cW9B0AaXGIgzDCRFmiQE/s1600/WiML-2023-Social.png\" style=\"display: none;\" />

<em>Posted by Sharbani Roy – Senior Director, Product Management, Google </em>

<a name=\"more\"></a><p></p>

<div style=\"text-align: left;\"><br /></div><div>We're back with the third annual&nbsp;<a href=\"https://aidevelopers.withgoogle.com/events/wiml-symposium-2023?utm_source=tf&amp;utm_medium=embedded&amp;utm_campaign=reg\" target=\"_blank\">Women in Machine Learning Symposium</a>&nbsp;on&nbsp;<b>December 7, 2023</b>! Join us virtually<b> </b>from 9:30 am to 1:00 pm PT for an immersive and insightful&nbsp;set of deep dives for every level of Machine Learning experience.</div><div style=\"text-align: left;\"><br /></div>



<p>The <a href=\"https://aidevelopers.withgoogle.com/events/women-in-machine-learning-2022\" target=\"_blank\">Women in ML Symposium</a> is an inclusive event for anyone passionate about the transformative fields of Machine Learning (ML) and Artificial Intelligence (AI). Dive into the latest advancements in generative AI, explore the intricacies of privacy-preserving AI, dig into the underlying accelerators and ML frameworks that power models, and uncover practical applications of ML across multiple industries.</p>

<p>Our event offers sessions for all expertise levels, from beginners to advanced practitioners. Hear about what’s new in ML and building with Google AI from  our keynote speakers, gain insights from seasoned industry leaders across Google Health, Nvidia,  Adobe, and more – and discover a wealth of knowledge on topics ranging from foundational AI concepts to open source tools, techniques, and beyond.</p>

<p><a href=\"https://aidevelopers.withgoogle.com/events/wiml-symposium-2023?utm_source=tf&amp;utm_medium=embedded&amp;utm_campaign=reg\" target=\"_blank\">RSVP today</a> to secure your spot and explore our exciting agenda. We can't wait to see you there!</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Fri, 17 Nov 2023 17:00:00 +0000"
2509,Simulated Spotify Listening Experiences for Reinforcement Learning with TensorFlow and TF-Agents,https://blog.tensorflow.org/2023/10/simulated-spotify-listening-experiences-reinforcement-learning-tensorflow-tf-agents.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhP2qHWHXHUPcXak3sVnIQK59EBep2I4SxODdtyTmFFgkOujyn5Si1AHZTh9-xru72ZPZ_mFziQQX11NGawnhMh1EikNP1hTPgSKCX1EbPOeNU0Y1_UV7ZCQ8XFNROKmlffOcv5IXDzM6b3ckRYy1PaDKTUNgMttlHiU4CWOQwaHlh-Y3EbX8nrtxOZXJg/s1600/TensorFlowSimulated-Spotify-Listening-Experiences-social-V2.png\" style=\"display: none;\" />

<em>Posted by Surya Kanoria, Joseph Cauteruccio, Federico Tomasi, Kamil Ciosek, Matteo Rinaldi, and Zhenwen Dai – Spotify</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8rdkHFZg7bozT_90hTvkhtGf5w03xXaSnmIPq-v1phY0UK3QXvxyfSjvtepuHA3-32CUbdowZsTSx3QqMy37kh1t2iEj_uusIQgSd2z_7UuuoSH2A5qxNrwIFWub3oItpU12ZKj65PWnfbGfsxUp9DPTJ0jZaKPMYEO_CuhV2EQpIXsHQHwJzQwyPCdk/s1600/TensorFlowSimulated-Spotify-Listening-Experiences-header-V2.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8rdkHFZg7bozT_90hTvkhtGf5w03xXaSnmIPq-v1phY0UK3QXvxyfSjvtepuHA3-32CUbdowZsTSx3QqMy37kh1t2iEj_uusIQgSd2z_7UuuoSH2A5qxNrwIFWub3oItpU12ZKj65PWnfbGfsxUp9DPTJ0jZaKPMYEO_CuhV2EQpIXsHQHwJzQwyPCdk/s1600/TensorFlowSimulated-Spotify-Listening-Experiences-header-V2.png\" /></a>

<a name=\"more\"></a><p></p>

<h2>Introduction</h2>

<p>Many of our music recommendation problems involve providing users with ordered sets of items that satisfy users’ listening preferences and intent at that point in time. We base current recommendations on previous interactions with our application and, in the abstract, are faced with a sequential decision making process as we continually recommend content to users.</p>

<p>Reinforcement Learning (RL) is an established tool for sequential decision making that can be leveraged to solve sequential recommendation problems. We decided to explore how RL could be used to craft listening experiences for users. Before we could start training Agents, we needed to pick a RL library that allowed us to easily prototype, test, and potentially deploy our solutions.</p>

<p>At Spotify we leverage <a href=\"https://www.tensorflow.org/\" target=\"_blank\">TensorFlow</a> and the extended TensorFlow Ecosystem (<a href=\"https://www.tensorflow.org/tfx\" target=\"_blank\">TFX</a>, <a href=\"https://www.tensorflow.org/tfx/guide/serving?hl=en\" target=\"_blank\">TensorFlow Serving</a>, and so on) as part of our production Machine Learning Stack. We made the decision early on to leverage <a href=\"https://www.tensorflow.org/agents/overview\" target=\"_blank\">TensorFlow Agents</a> as our RL Library of choice, knowing that integrating our experiments with our production systems would be vastly more efficient down the line.</p>

<p>One missing bit of technology we required was an offline Spotify environment we could use to prototype, analyze, explore, and train Agents offline prior to online testing. The flexibility of the TF-Agents library, coupled with the broader advantages of TensorFlow and its ecosystem, allowed us to cleanly design a robust and extendable offline Spotify simulator. </p>

<p>We based our simulator design on TF-Agents <a href=\"https://www.tensorflow.org/agents/tutorials/2_environments_tutorial\" target=\"_blank\">Environment</a> primitives and using this simulator we developed, trained and evaluated sequential models for item recommendations, vanilla RL Agents (PPG, DQN) and a modified deep Q-Network, which we call the Action-Head DQN (AH-DQN), that addressed the specific challenges imposed by the large state and action space of our RL formulation. </p>

<p>Through live experiments we were able to show that our offline performance estimates were strongly correlated with online results. This then opened the door for large scale experimentation and application of Reinforcement Learning across Spotify, enabled by the technological foundations unlocked by TensorFlow and TF-Agents. </p>

<p>In this post we’ll provide more details about our RL problem and how we used TF-Agents to enable this work end to end.</p>

<h3>The RL Loop and Simulated Users</h3>

<div style=\"text-align: center;\"><img alt=\"Reinforcement Learning loop\" border=\"0\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbXOZI7T4iiAGjYNVId68JaJLtGqjk4g7a1058T3zuagJlm-cEBd2gNGUFYwnDu369omim5LVQL-1p0-SmbTRP6MsmziihreYJtH4trTsvkF50h2HyQMFZ-fkhkx_shg6JPZp2SMMCsC7fMreQkNxIxMBnnhl3pe-UaqAHU69IaWQsvBSePq_EDs1DzaA/s1600/TensorFlowSimulated%20Spotify%20Listening%20Experiences-charts-02.png\" width=\"100%\" /></div><div style=\"text-align: left;\">In RL, Agents interact with the environment continuously. At a given time step the Agent consumes an observation from the environment and, using this observation, produces an action given its policy at time t. The environment then processes the action and emits both a reward and the next observation (note that although typically used interchangeably, State is the complete information required to summarize the environment post action, Observation is the portion of this information actually exposed to the Agent). </div>

<p>In our case the reward emitted from the environment is the response of a user to music recommendations driven by the Agent’s action. In the absence of a simulator we would need to expose real users to Agents to observe rewards. We utilize a model-based RL approach to avoid letting an untrained Agent interact with real users (with the potential of hurting user satisfaction in the training process).</p>

<p>In this model-based RL formulation the Agent is not trained online against real users. Instead, it makes use of a user model that predicts responses to a list of tracks derived via the Agent’s action. Using this model we optimize actions in such a way as to maximize a (simulated) user satisfaction metric. During the training phase the environment makes use of this user model to return a predicted user response to the action recommended by the Agent.</p> 

<p>We use <a href=\"https://keras.io/\" target=\"_blank\">Keras</a> to design and train our user model. The serialized user model is then unpacked by the simulator and used to calculate rewards during Agent training and evaluation.</p>

<h3>Simulator Design</h3>
  
<p>In the abstract, what we needed to build was clear. We needed a way to simulate user listening sessions for the Agent. Given a simulated user and some content, instantiate a listening session and let the Agent drive recommendations in that session. Allow the simulated user to “react” to these recommendations and let the Agent adjust its strategy based on this result to drive some expected cumulative reward. </p>

<p>The TensorFlow Agents environment design guided us in developing the modular components of our system, each of which was responsible for different parts of the overall simulation.</p> 

<p>In our codebase we define an environment abstraction that requires the following be defined for every concrete instantiation:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class<span>&nbsp;</span></span><span class=\"hljs-title class_\">AbstractEnvironment</span>(<span class=\"hljs-title class_ inherited__\">ABC</span>):</span></code><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span>&nbsp;&nbsp; &nbsp;</span>_user_model: AbstractUserModel = <span class=\"hljs-literal\">None</span>
<span>&nbsp;&nbsp; &nbsp;</span>_track_sampler: AbstractTrackSampler = <span class=\"hljs-literal\">None</span>
<span>&nbsp;&nbsp; &nbsp;</span>_episode_tracker: EpisodeTracker = <span class=\"hljs-literal\">None</span>
<span>&nbsp;&nbsp; &nbsp;</span>_episode_sampler: AbstractEpisodeSampler = <span class=\"hljs-literal\">None</span>

<span class=\"hljs-meta\"><span>&nbsp;&nbsp; &nbsp;</span>@abstractmethod</span>
<span class=\"hljs-keyword\"><span>&nbsp;&nbsp; &nbsp;</span>def</span> <span class=\"hljs-title function_\">reset</span>(<span class=\"hljs-params\">self</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">float</span>]:
      <span class=\"hljs-keyword\">pass</span>

<span class=\"hljs-meta\"><span>&nbsp;&nbsp; &nbsp;</span>@abstractmethod</span>
<span class=\"hljs-keyword\"><span>&nbsp;&nbsp; &nbsp;</span>def</span> <span class=\"hljs-title function_\">step</span>(<span class=\"hljs-params\">self, action: <span class=\"hljs-built_in\">float</span></span>) -&gt; (<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">float</span>], <span class=\"hljs-built_in\">float</span>, <span class=\"hljs-built_in\">bool</span>):
      <span class=\"hljs-keyword\">pass</span>

<span class=\"hljs-keyword\"><span>&nbsp;&nbsp; &nbsp;</span>def</span> <span class=\"hljs-title function_\">observation_space</span>(<span class=\"hljs-params\">self</span>) -&gt; <span class=\"hljs-type\">Dict</span>:
      <span class=\"hljs-keyword\">pass</span>

<span class=\"hljs-meta\"><span>&nbsp;&nbsp; &nbsp;</span>@abstractmethod</span>
<span class=\"hljs-keyword\"><span>&nbsp;&nbsp; &nbsp;</span>def</span> <span class=\"hljs-title function_\">action_space</span>(<span class=\"hljs-params\">self</span>) -&gt; <span class=\"hljs-type\">Dict</span>:
      <span class=\"hljs-keyword\">pass</span></span></code></td></tr></tbody></table>

<h4>Set-Up</h4>

<div style=\"text-align: left;\">At the start of Agent training we need to instantiate a simulation environment that has representations of hypothetical users and the content we’re looking to recommend to them. We base these instantiations on both real and hypothetical Spotify listening experiences. The critical information that defines these instantiations is passed to the environment via <code>_episode_sampler</code>. As mentioned, we also need to provide the simulator with a trained user model, in this case via <code>_user_model</code>.</div>

<div style=\"text-align: center;\"><img alt=\"Flow chart of agent training set up\" border=\"0\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMM94Ox1CCXpjzz9O4z922a6nVp89j-1gpPxob5myKJ3oywvkUqy9zhktuRGc0042_Tebmi9sU1rMe_8lbDnrBkulgMzgJ_95X0-rUKPzUmrh8U6QpysOMSaODqc-ZznPq8Api7PSOYfCAH5rKeyy8qqG7iGSQOzOFgOXxS65IQ15K-uhEuZr6OtNVFkU/s1600/TensorFlowSimulated-Spotify-Listening-Experiences-charts-03-V2.png\" width=\"100%\" /></div>
  
<h4>Actions and Observations</h4>

<p>Just like any Agent environment, our simulator requires that we specify the <code>action_spec</code> and <code>observation_spec</code>. Actions in our case may be continuous or discrete depending both on our Agent selection and how we propose to translate an Agent’s action into actual recommendations. We typically recommend ordered lists of items drawn from a pool of potential items. Formulating this action space directly would lead to it being combinatorially complex. We also assume the user will interact with multiple items, and as such previous work in this area that relies on single choice assumptions doesn’t apply.</p>

<div style=\"text-align: left;\">In the absence of a discrete action space consisting of item collections we need to provide the simulator with a method for turning the Agent’s action into actual recommendations. This logic is contained in the via <code>_track_sampler</code>. The “example play modes” proposed by the episode sampler contains information on items that can be presented to the simulated user. The track sampler consumes these and the agent’s action and returns actual item recommendations. </div>

<div style=\"text-align: center;\"><img alt=\"Flow chart of Agent actions_spec and observation_spec combining to create a recommendation\" border=\"0\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiTslPiZ4ITRLSNrcBCLxVGyfmbDu0mxRj-iKGfNqnJoNw472CQg0YTdZHF2iE_pYwfUSw8kPtKCdMl4lCLXX0nYffYDMXU2l8wlnUfdlV_z9KTqPA8l6p3DOqAqL-ks2ZcwruY6f0qt5cXOVme9udBpsIsbqgCNlt4bKN71UnTOq4-9i9BHVA3O_xzUUo/s1600/TensorFlowSimulated%20Spotify%20Listening%20Experiences-charts-01.png\" width=\"100%\" /></div>

<h4>Termination and Reset</h4>

<p>We also need to handle the episode termination dynamics. In our simulator, the reset rules are set by the model builder and based on empirical investigations of interaction data relevant to a specific music listening experience. As a hypothetical, we may determine that 92% of listening sessions terminate after 6 sequential track skips and we’d construct our simulation termination logic to match. It also requires that we design abstractions in our simulator that allow us to check if the episode should be terminated after each step. </p>

<p>When the episode is reset the simulator will sample a new hypothetical user listening session pair and begin the next episode. </p>

<h4>Episode Steps</h4>

<p>As with standard TF Agents Environments we need to define the step dynamics for our simulation. We have optional dynamics of the simulation that we need to make sure are enforced at each step. For example, we may desire that the same item cannot be recommended more than once. If the Agent’s action indicates a recommendation of an item that was previously recommended we need to build in the functionality to pick the next best item based on this action.</p> 

<p>We also need to call the termination (and other supporting functions) mentioned above as needed at each step. </p>

<h4>Episode Storage and Replay</h4>
  
<p>The functionality mentioned up until this point collectively created a very complex simulation setup. While the TF Agents <a href=\"https://www.tensorflow.org/agents/tutorials/5_replay_buffers_tutorial\" target=\"_blank\">replay buffer</a> provided us with the functionality required to store episodes for Agent training and evaluation, we quickly realized the need to be able to store more episode data for debugging purposes, and more detailed evaluations specific to our simulation distinct from standard Agent performance measures. </p>

<p>We thus allowed for the inclusion of an expanded <code>_episode_tracker</code> that would store additional information about the user model predictions, information noting the sampled users/content pairs, and more.</p>

<h4>Creating TF-Agent Environments</h4>
  
<p>Our environment abstraction gives us a template that matches that of a standard TF-Agents Environment class. Some inputs to our environment need to be resolved before we can actually create the concrete TF-Agents environment instance. This happens in three steps. </p>

<p>First we define a specific simulation environment that conforms to our abstraction. For example:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">PlaylistEnvironment</span>(<span class=\"hljs-title class_ inherited__\">AbstractEnvironment</span>):
    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">
        self,
        user_model: AbstractUserModel,
        track_sampler: AbstractTrackSampler,
        episode_tracker: EpisodeTracker,
        episode_sampler: AbstractEpisodeSampler,
	 ....
    </span>):

...</span></code></td></tr></tbody></table>

<p>Next we use an <i>Environment Builder Class</i> that takes as input a user model, track sampler, etc. <i>and</i> an environment class like <code>PlaylistEnvironment</code>. The builder creates a concrete instance of this environment:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">self.playlist_env: PlaylistEnvironment = environment_ctor(
            user_model=user_model,
            track_sampler=track_sampler,
            episode_tracker=episode_tracker,
            episode_sampler=self._eps_sampler,
        )</span></code></td></tr></tbody></table>

<p>Lastly, we utilize a conversion class that constructs a TF-Agents <i>Environment</i> from a concrete instance of ours:</p><div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">TFAgtPyEnvironment</span>(py_environment.PyEnvironment):
  <span>&nbsp;&nbsp; &nbsp;</span><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, environment: AbstractEnvironment</span>):
        <span>&nbsp;&nbsp;</span><span class=\"hljs-built_in\">super</span>().__init__()
        <span>&nbsp;&nbsp;</span>self.env = environment</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\">
</span></code></td></tr></tbody></table><p>This is then executed internally to our Environment Builder:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">EnvironmentBuilder</span>(<span class=\"hljs-title class_ inherited__\">AbstractEnvironmentBuilder</span>):

<span class=\"hljs-keyword\"><span>&nbsp;&nbsp; &nbsp;<span>&nbsp;&nbsp;</span></span>def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, ...</span>):
    <span>&nbsp;&nbsp;<span>&nbsp;&nbsp; &nbsp;</span></span>...

<span class=\"hljs-keyword\"><span>&nbsp;&nbsp; &nbsp;<span>&nbsp;&nbsp;</span></span>def</span> <span class=\"hljs-title function_\">get_tf_env</span>(<span class=\"hljs-params\">self</span>):
   <span>&nbsp;&nbsp; <span>&nbsp;&nbsp; &nbsp;</span></span>...
    <span>&nbsp;&nbsp;<span>&nbsp;&nbsp; &nbsp;</span></span>tf_env: TFAgtPyEnvironment = TFAgtPyEnvironment(
          <span>&nbsp;&nbsp; &nbsp;</span>self.playlist_env
        <span>&nbsp;&nbsp;<span>&nbsp;&nbsp; &nbsp;</span></span>)
    <span>&nbsp;&nbsp; &nbsp;<span>&nbsp;&nbsp;</span></span><span class=\"hljs-keyword\">return</span> tf_env</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\">
</span></code></td></tr></tbody></table>
  
  <div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">The resulting TensorFlow Agents environment can then be used for Agent training. </div>

<div style=\"text-align: center;\"><img alt=\"Flow chart showing simulator design\" border=\"0\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBJEpC0OzUfjzQTfbHYiqJ_cmQXg6gIxXkQKbZu7a-ER7ciyDcRu4ZTimAzlex7hxRnVwgNGOLDS7kxidsoqObJfYIkA6G3PLZ-01vj5Uw22T7FWxTiaDIzFUROU4X5bzFwPakxVLDhb6v5V6q728Q8xEbs13TYDzpkCw1rqOarUWGn0g4CD9rL6S7iwM/s1600/TensorFlowSimulated%20Spotify%20Listening%20Experiences-charts-04.png\" width=\"100%\" /></div>
  
<div style=\"text-align: left;\">This simulator design allows us to easily create and manage multiple environments with a variety of different configurations as needed. </div>

<p>We next discuss how we used our simulator to train RL Agents to generate Playlists. </p>
  
  <h3>A Customized Agent for Playlist Generation</h3>

<p>As mentioned, Reinforcement Learning provides us with a method set that naturally accommodates the sequential nature of music listening; allowing us to adapt to users’ ever evolving preferences as sessions progress.</p>

<p>One specific problem we can attempt to use RL to solve is that of automatic music playlist generation. Given a (large) set of tracks, we want to learn how to create one optimal playlist to recommend to the user in order to maximize satisfaction metrics. Our use case is different from standard slate recommendation tasks, where usually the target is to select at most one item in the sequence. In our case, we assume we have a user-generated response for multiple items in the slate, making slate recommendation systems not directly applicable. Another complication is that the set of tracks from which recommendations are drawn is ever changing. </p>
  
<div style=\"text-align: left;\">We designed a DQN variant capable of handling these constraints that we called an Action Head DQN (AHDQN). </div>

<div style=\"text-align: center;\"><img alt=\"Moving image of AH-DQN network creating recommendations based on changing variables\" border=\"0\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhNP6pB_bKP170hXMVf20NPQjUzkLattEawfZwtUcXrDAl2mkcBT1Bqp1eMcnEdnT78D3m2IQQjOjKoZfje8cXgXh1ZV0BgQ66hS96rM3RRkeFWQfUWnRs8VCtiv0NFU_aqWiye3W5GVFaArVaisiaiU0yJ6tF_KkzBkOg89B4qLzgZ2f0VyYR0x5MQzgk/s1600/image3.gif\" width=\"100%\" /></div>
  

<div style=\"text-align: left;\">The AH-DQN network takes as input the current state and an available action to produce a single Q value for the input action. This process is repeated for every possible item in the input. Finally, the item with the highest Q value is selected and added to the slate, and the process continues until the slate is full.</div>
  
<h4>Experiments In Brief</h4>

<div style=\"text-align: left;\">We tested our approach both offline and online at scale to assess the ability of the Agent to power our real-world recommender systems. In addition to testing the Agent itself we were also keen to assess the extent to which our offline performance estimates for various policies returned by our simulator matched (or at least directionally aligned) with our online results.</div><div class=\"separator\" style=\"clear: both; float: left;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6CsH-cNX-i8iHq9Yif6iFykOfd5YY8Z5vbx9yu4bfhbN4oZdiL_EBC9Fxa9PLXh6JOzFF8FeH5lzuCagEAFymWTtueBD6MVhhCUTTwS4-lgulTRjHeq28lTT0U64cVw88m9zY5UEnNbkqyDzZk4HGWughW7Ju-pekqH59uITWKIhwoDvcHk4YeBRXn9A/s463/image5.png\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 1em;\"><img alt=\"Graph measuring simulated performance assessment by scaled online reward for different policies\" border=\"0\" height=\"270\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6CsH-cNX-i8iHq9Yif6iFykOfd5YY8Z5vbx9yu4bfhbN4oZdiL_EBC9Fxa9PLXh6JOzFF8FeH5lzuCagEAFymWTtueBD6MVhhCUTTwS4-lgulTRjHeq28lTT0U64cVw88m9zY5UEnNbkqyDzZk4HGWughW7Ju-pekqH59uITWKIhwoDvcHk4YeBRXn9A/w400-h270/image5.png\" style=\"width: auto;\" width=\"400\" /></a></div><div style=\"text-align: left;\"><br /></div><p>We observed this directional alignment for numerous naive, heuristic, model driven, and RL policies.</p>

<p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p>Please refer to our KDD paper for more information on the specifics of our model-based RL approach and Agent design.</p><div style=\"text-align: left;\"><br /></div>


<div style=\"text-align: left;\"><a href=\"https://research.atspotify.com/2023/07/automatic-music-playlist-generation-via-simulation-based-reinforcement-learning/\" target=\"_blank\">Automatic Music Playlist Generation via Simulation-based Reinforcement Learning</a></div>
<div style=\"text-align: left;\">Federico Tomasi, Joseph Cauteruccio, Surya Kanoria, Kamil Ciosek, Matteo Rinaldi, and Zhenwen Dai</div>
<div style=\"text-align: left;\">KDD 2023</div><br />

  <h2>Acknowledgements</h2>

<p>We’d like to thank all our Spotify teammates past and present who contributed to this work. Particularly, we’d like to thank Mehdi Ben Ayed for his early work in helping to develop our RL codebase. We’d also like to thank the <a href=\"https://github.com/tensorflow/agents/blob/master/tf_agents/AUTHORS\" target=\"_blank\">TensorFlow Agents team</a> for their support and encouragement throughout this project (and for the <a href=\"https://github.com/tensorflow/agents\" target=\"_blank\">library</a> that made it possible).</p>
</div><p></p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Thu, 19 Oct 2023 19:00:00 +0000"
2510,Building a board game with the TFLite plugin for Flutter,https://blog.tensorflow.org/2023/10/building-board-game-with-tflite-plugin-for-flutter.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOOPfPbEUuINDsxtTqIQnxPMLg_ThHYU0PSK5n12pt0hHAESQem0lIsnv-LO6LFCv8sq68n0dua5wPoXqiKvP8KF-WFF1s1-vpnTD3DMBrbL0IA019h1UWREjSCDEE2CEkImJ71OFBmchJWt8X5jtZkJiVIV06Ogxqhp12hzvvinVDNh1rMTecH9KIjZ8/s1600/SOCIAL-Building-a-board-game-with-the-TFlite-plugin-for-Flutter.png\" style=\"display: none;\" />

<p><em>Posted by Wei Wei, Developer Advocate</em></p><p>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9dGb3glYqGGek7G5cko5_R9dDez1txACGP5qt-dmn7EGgxdjGrt7ZIjNXmeu3KudSTHFs-Euh3xybYplG3arzRIcA8J9jx1gneCUEh_I9QRTMUWkvShjNW9ilbQLxd49Ocvts_w0T-FKCmjFn3lewlxbnkY0QGgzLKGofMwuHRR1bzamk7USpW0LnJmQ/s1600/HEADER-Building-a-board-game-with-the-TFlite-plugin-for-Flutter.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9dGb3glYqGGek7G5cko5_R9dDez1txACGP5qt-dmn7EGgxdjGrt7ZIjNXmeu3KudSTHFs-Euh3xybYplG3arzRIcA8J9jx1gneCUEh_I9QRTMUWkvShjNW9ilbQLxd49Ocvts_w0T-FKCmjFn3lewlxbnkY0QGgzLKGofMwuHRR1bzamk7USpW0LnJmQ/s1600/HEADER-Building-a-board-game-with-the-TFlite-plugin-for-Flutter.png\" /></a>

</p><a name=\"more\"></a><p></p>

<p>In our previous blog posts <a href=\"https://blog.tensorflow.org/2021/10/building-board-game-app-with-tensorflow.html\" target=\"_blank\">Building a board game app with TensorFlow: a new TensorFlow Lite reference app</a> and <a href=\"https://blog.tensorflow.org/2022/09/building-reinforcement-learning-agent-with-JAX-and-deploying-it-on-android-with-tensorflow-lite.html\" target=\"_blank\">Building a reinforcement learning agent with JAX, and deploying it on Android with TensorFlow Lite</a>, we demonstrated how to train a reinforcement learning (RL) agent with TensorFlow, TensorFlow Agents and JAX respectively, and then deploy the converted TFLite model in an Android app using TensorFlow Lite, to play a simple board game ‘Plane Strike’.</p>

<div style=\"text-align: left;\">While these end-to-end tutorials are helpful for Android developers, we have heard from the Flutter developer community that it would be interesting to make the app cross-platform. Inspired by the officially released <a href=\"https://blog.tensorflow.org/2023/08/the-tensorflow-lite-plugin-for-flutter-officially-available.html\" target=\"_blank\">TensorFlow Lite Plugin for Flutter</a> recently, we are going to write one last tutorial and port the app to Flutter.</div>

<div style=\"text-align: center;\"><img alt=\"Flow Chart illustrating training a Reinforncement Learning (RL) Agent with TensorFlow, TensorFlow Agents and JAX, deploying the converted model in an Android app and Flutter using the TensorFlow Lite plugin\" border=\"0\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQDl4Xa2yqwJdBabBma9TpiDP6oOt9DApNSnBd0u3dammHHQV5QuMS8WYj0h2xEMPWyG4bZKSDK0pFzjavXn7XscaIItUytQ-6GAtV2PBGyUZg0T7z_DXSHAhDDu8YgDeZxomS0ingTQI2llhqShlFPMVqgAK3UtgbaxKa-AE05RPabKfVFK_ezxyh5pc/s1600/CHART-Building-a-board-game-with-the-TFlite-plugin-for-Flutter.png\" width=\"100%\" /></div>

<p style=\"text-align: left;\">Since we already have the model trained with TensorFlow and converted to TFLite, we can just load the model with TFLite interpreter:</p>

<div style=\"text-align: left;\"><span id=\"docs-internal-guid-01acc8ad-7fff-b6f6-b598-e154539fd1a6\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"718\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #f0f0f0; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span style=\"color: #444444; font-size: 12pt; font-weight: 700; vertical-align: baseline;\">void</span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\"> _loadModel() </span><span style=\"color: #444444; font-size: 12pt; font-weight: 700; vertical-align: baseline;\">async</span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\"> {</span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\"><br /></span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\">&nbsp; </span><span style=\"color: #888888; font-size: 12pt; vertical-align: baseline;\">// Create the interpreter</span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\"><br /></span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\">&nbsp; _interpreter = </span><span style=\"color: #444444; font-size: 12pt; font-weight: 700; vertical-align: baseline;\">await</span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\"> Interpreter.fromAsset(_modelFile);</span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\"><br /></span><span style=\"color: #444444; font-size: 12pt; vertical-align: baseline;\">}</span></span></p></td></tr></tbody></table></div>
  
<p>Then we pass in the user board state and help the game agent identify the most promising position to strike next (please refer to our previous blog posts if you need a refresher on the game rules) by running TFLite inference:</p><p><span id=\"docs-internal-guid-1fd4a4ed-7fff-d43b-dab8-fcc9246ae083\"></span></p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"718\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #f0f0f0; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">int</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> predict(</span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">List</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">List</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">double</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&gt;&gt; boardState) {</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">var</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> input = [boardState];</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">var</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> output = </span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">List</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.filled(_boardSize * _boardSize, </span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; .reshape([</span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">1</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, _boardSize * _boardSize]);</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #888888; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// Run inference</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; _interpreter.run(input, output);</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #888888; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// Argmax</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">double</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> max = output[</span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">][</span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0</span>
<span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">];</span>
<span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span>
<span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">int</span>
<span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> maxIdx = </span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">for</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> (</span><span style=\"background-color: #f0f0f0; color: #397300; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">int</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> i = </span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">1</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">; i &lt; _boardSize * _boardSize; i++) {</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; </span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">if</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> (max &lt; output[</span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">][i]) {</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; maxIdx = i;</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; max = output[</span><span style=\"background-color: #f0f0f0; color: #880000; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">][i];</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; }</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; }</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; </span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> maxIdx;</span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span style=\"background-color: #f0f0f0; color: #444444; font-size: 12pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p></td></tr></tbody></table></div></span></div>

<p>That's it! With some <a href=\"https://github.com/tensorflow/flutter-tflite/blob/main/example/reinforcement_learning/lib/main.dart\" target=\"_blank\">additional Flutter frontend code</a> to render the game boards and track game progress, we can immediately run the game on both Android and iOS (currently the plugin only supports these two mobile platforms). You can find the complete code on <a href=\"https://github.com/tensorflow/flutter-tflite/tree/main/example/reinforcement_learning\" target=\"_blank\">GitHub</a>.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6OW57o43rPY9TavqdgnkbUoNqI1x0Fm57Avpuazd7DD4syTVW3NUWnvc6noNebb56Vm62EojXZBRhyphenhyphenj87JZVXSACv6BfIUAiiKnioK2Iy2wgKInFi0u_41Cnpkv9ZJUkPyfG2EhzxE1ckQuqJmZ1rRbogk0Tkdb-8gEzDDUGUgeQtoz0dy0h_YX0fxyw/s1600/Board-game-TF-Lite-Flutter%20%282%29.gif\" style=\"width: 80%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"></td></tr></tbody></table></div>

<div style=\"text-align: left;\">If you want to dig digger, there are a couple of things you can try:</div>
<ol><blockquote>
<li>Convert the TFAgents-trained model to TFLite and run it with the plugin</li>
<li>Leverage the RL technique we have used and build a new agent for the tic tac toe game in the Flutter <a href=\"https://docs.flutter.dev/resources/games-toolkit\" target=\"_blank\">Casual Games Toolkit</a>. You will need to create a new RL environment and train the model from scratch before deployment, but the core concept and technique are pretty much the same.</li>
  </blockquote></ol>

<p>This concludes this mini-series of blogs on leveraging TensorFlow/JAX to build games for Android and Flutter. And we very much look forward to all the exciting things you build with our tooling, so be sure to share them with <a href=\"https://twitter.com/googledevs\" target=\"_blank\">@googledevs</a>, <a href=\"https://twitter.com/TensorFlow\" target=\"_blank\">@TensorFlow</a>, and your developer communities!</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Wed, 18 Oct 2023 17:00:00 +0000"
2511,People of AI: Season 2,https://blog.tensorflow.org/2023/10/people-of-ai-season-2.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBAa6kNgbBM4T86yJ0ftJUiLg_Z2cJbcrk_rmCJ_RQwiqwWTurWvIqbZoFgm6u_r1uLV56dTm1FljgiLYYUB33WMtJV8oWLW_i9AF0_DI-lP1CajHpnaobp-OpbrtsVbYfjEbIef0fBVtPqZjIKhuILcMEMOwXSL0w6H3SXIauKVfSTTcGoecfSMzPxOs/s1600/People-With-AI-Season-2-Social.png\" style=\"display: none;\" />

<p><em>Posted by <a href=\"https://www.linkedin.com/in/ashleyoldacre/\" target=\"_blank\">Ashley Oldacre</a></em></p><p>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiN5m9hnI-bY5xpmSLfczy02-dG2_82dr1ZR_HAF-XJUhmR1AjFPMDhhYQQPTdilLepav4hB84xTo0RPUj1pDpQKiBiVCyx_fzp1uxsgwXm6X05c99r32nzZQTDSYwIM9-32jOP3ENkII029UTbGhCRDTf3ShuXpgfh8BiiFrbQY0YhGHSmaL_hYBWBOHE/s1600/People-of-AI-Season-2-Banner.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiN5m9hnI-bY5xpmSLfczy02-dG2_82dr1ZR_HAF-XJUhmR1AjFPMDhhYQQPTdilLepav4hB84xTo0RPUj1pDpQKiBiVCyx_fzp1uxsgwXm6X05c99r32nzZQTDSYwIM9-32jOP3ENkII029UTbGhCRDTf3ShuXpgfh8BiiFrbQY0YhGHSmaL_hYBWBOHE/s1600/People-of-AI-Season-2-Banner.png\" /></a>

</p><a name=\"more\"></a><p></p>

<p><em>If you are joining us for the first time, you can <a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">binge listen to our amazing 8 episodes</a> from Season 1 wherever you get your podcasts.</em></p> 

<p>We are back for another season of People of AI with a new lineup of incredible guests! I am so excited to introduce my new co-host <a href=\"https://www.linkedin.com/in/gus-martins-64ab5891/\" target=\"_blank\">Luiz Gustavo Martins</a> as we meet inspiring people with interesting stories in the field of Artificial Intelligence.</p>

<p><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Last season</a> we focused on the incredible journeys that our guests took to get into the field of AI. Through our stories, we highlighted that no matter who you are, what your interests are, or what you work on, there is a place for anyone to get into this field. We also explored how much more accessible the technology has become over the years, as well as the importance of building AI-related products responsibly and ethically. It is easier than ever to use tools, platforms and services powered by machine learning to leverage the benefits of AI, and break down the barrier of entry.</p>

<p>For <b>season 2</b>, we will feature amazing conversations, focusing on Generative AI! Specifically, we will be discussing the explosive growth of Generative AI tools and the major technology shift that has happened in recent months. We will dive into various topics to explore areas where Generative AI can contribute tremendous value, as well as boost both productivity and economic growth. We will also continue to explore the personal paths and career development of this season’s guests as they share how their interest in technology was sparked, how they worked hard to get to where they are today, and explore what it is that they are currently working on. </p>

<p>Starting today, we will release one new episode of season 2 per week. Listen to the first episode on the <a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">People of AI</a> site or wherever you get your podcasts. And stay tuned for later in the season when we premiere our first video podcasts as well!</p>
<ul><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 1</a></b>: meet your hosts, <b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Ashley</a></b> and <b><a href=\"https://www.linkedin.com/in/gus-martins-64ab5891/\" target=\"_blank\">Gus</a></b> and learn about Generative AI, Bard and the big shift that has dramatically changed the industry.&nbsp;</li></blockquote><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 2</a></b>: meet <b><a href=\"https://www.linkedin.com/in/sunita-verma-1a4491/\" target=\"_blank\">Sunita Verma</a></b>, a long-time Googler, as she shares her personal journey from Engineering to CS, and into Google. As an early pioneer of AI and Google Ads, we will talk about the evolution of AI and how Generative AI will transform the way we work.&nbsp;</li></blockquote><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 3</a></b>: meet <b><a href=\"https://sayak.dev/\" target=\"_blank\">Sayak Paul</a></b>, a Google Developer Expert (GDE) as we explore what it means to be a GDE and how to leverage the power of your community through community contributions.&nbsp;</li></blockquote></ul><ul><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 4</a></b>: meet <b><a href=\"https://www.linkedin.com/in/crispinvz/\" target=\"_blank\">Crispin Velez</a></b>, the lead for Cloud’s Vertex AI as we dig into his experience in Cloud working with customers and partners on how to integrate and deploy AI. We also learn how he grew his AI developer community in LATAM from scratch.&nbsp;</li></blockquote></ul><ul><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 5</a></b>: meet <b><a href=\"https://www.joyceshen.com/about/\" target=\"_blank\">Joyce Shen</a></b>, venture capital/private equity investor. She shares her fascinating career in AI and how she has worked with businesses to spot AI talent, incorporate AI technology into workflows and implement responsible AI into their products.&nbsp;</li></blockquote><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 6</a></b>: meet <b><a href=\"https://www.linkedin.com/in/anne-simonds/\" target=\"_blank\">Anne Simonds</a></b> and <b>Brian Gary</b>, founders of Muse https://www.museml.com. Join us as we talk about their recent journeys into AI and their new company which uses the power of Generative AI to spark creativity.&nbsp;</li></blockquote></ul><ul><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 7</a></b>: meet <b><a href=\"https://www.linkedin.com/in/tulsee-doshi/\" target=\"_blank\">Tulsee Doshi</a></b>, product lead for <a href=\"https://ai.google/responsibility/responsible-ai-practices/\" target=\"_blank\">Google’s Responsible AI</a> efforts as we discuss the development of Google-wide resources and best practices for developing more inclusive, diverse, and ethical algorithm driven products.&nbsp;</li></blockquote><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 8</a></b>: meet<b> <a href=\"https://www.linkedin.com/in/winner/\" target=\"_blank\">Jeanine Banks</a></b>, Vice President and General Manager of Google Developer X and Head of Developer Relations. Join us as we debunk AI and get down to what Generative AI really is, how it has changed over the past few months and will continue to change the developer landscape.&nbsp;</li></blockquote><blockquote>
<li><b><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Episode 9</a></b>: meet <b>Simon Tokumine</b>, Director of Product Management at Google. We will talk about how AI has brought us into the era of task-orientated products and is fueling a new community of makers.</li></blockquote></ul>

<p><a href=\"https://peopleofai.libsyn.com/\" target=\"_blank\">Listen now</a> to the first episode of Season 2. We can’t wait to share the stories of these exceptional People of AI with you!</p>


<p><em><small>This podcast is sponsored by Google. Any remarks made by the speakers are their own and are not endorsed by Google.</small></em></p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 17 Oct 2023 17:00:00 +0000"
2512,Pre-processing temporal data made easier with TensorFlow Decision Forests and Temporian,https://blog.tensorflow.org/2023/09/forecasting-with-tensorflow-decision-forests-and-temporian.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgO4WDCWDuV4LT0FtXw_qBaJKOFjEkHrFOBQ0z4WZaA6keEQEtFc4ZNwmZTyP2eCPHjN_qIA41VzgJeVCnYT6pTWCic-9gy5hjwknTEqGKfyWrJjtdH20lcxRkI7_N-UEPVgGxvDGvJDeeVm8h4QxVIa2mknX0l2WyG0WAs5Y259erSlTsQpbO8q3umCAI/s1600/TensorFlow-Training-model-on-temporal-data-with-TensorFlow-and-Temporian-header-social-v2.png\" style=\"display: none;\" />

<em>Posted by Google: Mathieu Guillame-Bert, Richard Stotz, Robert Crowe, Luiz GUStavo Martins (Gus), Ashley Oldacre, Kris Tonthat, Glenn Cameron, and Tryolabs: Ian Spektor, Braulio Rios, Guillermo Etchebarne, Diego Marvid, Lucas Micol, Gonzalo Marín, Alan Descoins, Agustina Pizarro, Lucía Aguilar, Martin Alcala Rubi</em>

<a href=\"\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXMzZM-8kD4Hv3XAwSxdZl1k5jAUCzDkfKdog5XWfPE8l-cfcDLmAPxhG8nd_ZbuGeyeulW9LsbSVsSkAQf3i_-DV6o71xrb57ZfVQ6cUClvMB-h1_rXjVIM4FK9V2GCRkWsIofgZ3hdaoJiYjRyzk-Mrf31-FEPJ6C4VhCoAjiCttPP1Sja53g-Tzz9Y/s1600/TensorFlow-Training-model-on-temporal-data-with-TensorFlow-and-Temporian-header-v2.png\" /></a>

<a name=\"more\"></a><p></p>

<b>Temporal data</b> is <b>omnipresent</b> in applied machine learning applications. Data often changes over time or is only available or valuable at a certain point in time. For example, market prices and weather conditions change constantly. Temporal data is also often <b>highly discriminative</b> in decision-making tasks. For example, the rate of change and interval between two consecutive heartbeats provides valuable insights into a person's physical health, and temporal patterns of network logs are used to detect configuration issues and intrusions. Hence, it is essential to incorporate temporal data and temporal information in ML applications.<div><br /></div><div><span id=\"docs-internal-guid-7da84d0c-7fff-5126-247c-2149c93220d4\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"719\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #fff2cc; border-bottom: solid #f1c232 1pt; border-color: rgb(241, 194, 50); border-left: solid #f1c232 1pt; border-right: solid #f1c232 1pt; border-style: solid; border-top: solid #f1c232 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; font-weight: 700; vertical-align: baseline;\">INFO:&nbsp; </span><a href=\"https://github.com/google/temporian\"><span style=\"background-color: transparent; color: #1155cc; vertical-align: baseline;\">Temporian</span></a><span style=\"background-color: transparent; vertical-align: baseline;\"> is a new open-source Python library for preprocessing and feature engineering </span><span style=\"background-color: transparent; font-weight: 700; vertical-align: baseline;\">temporal data</span><span style=\"background-color: transparent; vertical-align: baseline;\"> for machine learning applications. It is developed in collaboration between Google and </span><a href=\"https://tryolabs.com/\"><span style=\"background-color: transparent; color: #1155cc; vertical-align: baseline;\">Tryolabs</span></a><span style=\"background-color: transparent; vertical-align: baseline;\">. Check the sister </span><a href=\"https://tryolabs.com/blog/tryolabs-google-introducing-temporian\"><span style=\"background-color: transparent; color: #1155cc; vertical-align: baseline;\">blog post</span></a><span style=\"background-color: transparent; vertical-align: baseline;\"> for more details.</span></span></p></td></tr></tbody></table></div></span></div><div><br /><div>This blog post demonstrates how to train a forecasting model on transactional data. Specifically, we will show how to forecast the total weekly sales from individual sales records. For the modeling part, we will use <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow Decision Forests</a> as they are well suited to handle temporal data. To feed the transaction data to our model, and to compute temporal specific features, we will use <a href=\"https://temporian.readthedocs.io/en/latest/\" target=\"_blank\"><b>Temporian</b></a>, <b>a newly released library</b> designed for ingesting and aggregating transactional data from multiple non-synchronized sources.

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj71gkz0PpC-9zI8sxLx-pU6b3C7ph-A6QXTKDSEpwiiMjSPXiAzYxfw7zvrucntmhqRMkjVke9eKdBTAxR6xSbArO9NT0WN93S8L9RSbTyIsGjX-bXvJ3gvqrwLiMpV0NRWLRQPboGuKRW_f1qu1IMDAXFd4-mfl_o8pM1iVIOJRE_aSjmBdelqtoPpgo/s1600/image6.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>Time series are the most commonly used representation for temporal data. They consist of uniformly sampled values, which can be useful for representing aggregate signals. However, time series are sometimes not sufficient to represent the richness of available data. Instead, multivariate time series can represent multiple signals together, while time sequences or event sets can represent non-uniformly sampled measurements. Multi-index time sequences can be used to represent relations between different time sequences. In this blog post, we will use the <b>multivariate multi-index time sequence</b>, also known as <b>event sets</b>. Don’t worry, they’re not as complex as they sound.</p>

<p><span id=\"docs-internal-guid-1e2295cf-7fff-2efb-0717-597d19036c23\"></span></p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"719\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #fff2cc; border-bottom: solid #f1c232 1pt; border-color: rgb(241, 194, 50); border-left: solid #f1c232 1pt; border-right: solid #f1c232 1pt; border-style: solid; border-top: solid #f1c232 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><span style=\"font-family: inherit;\">Examples of temporal data include:</span></span></p><ul style=\"margin-bottom: 0px; margin-top: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Weather and other environmental data</span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> for weather forecasting, soil profile forecasting and crop yield optimization, temperature tracking, and climate change characterization.</span></span></p></li><li dir=\"ltr\" style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Sensory data </span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">for</span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">quality monitoring, and predictive maintenance.</span></span></p></li><li dir=\"ltr\" style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Health data</span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> for early treatment, personalized medicine, and epidemic detection.</span></span></p></li><li dir=\"ltr\" style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Retail customer data</span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> for sales forecasting, sales optimization, and targeted advertising</span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span></span></p></li><li dir=\"ltr\" style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Banking customer data </span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">for fraud detection and loan risk analysis.</span></span></p></li><li dir=\"ltr\" style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Economic and financial data</span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> for risk analysis, budgetary analysis, stock market analysis, and yield projections.</span></span></p></li></ul></td></tr></tbody></table></div>

<h3>A simple example</h3>

<p>Let's start with a simple example. We have collected sales records from a fictitious online shop. Each time a client makes a purchase, we record the following information: time of the purchase, client id, product purchased, and price of the product.</p>

<p>The dataset is stored in a single CSV file, with one transaction per line:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"color: #0d904f;\">$ head -n <span class=\"hljs-number\">5</span> sales.csv
timestamp,client,product,price
<span class=\"hljs-number\">2010</span>-<span class=\"hljs-number\">10</span>-05 <span class=\"hljs-number\">11</span>:09:<span class=\"hljs-number\">56</span>,c64,p35,<span class=\"hljs-number\">405.35</span>
<span class=\"hljs-number\">2010</span>-09-<span class=\"hljs-number\">27</span> <span class=\"hljs-number\">15</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">49</span>,c87,p29,<span class=\"hljs-number\">605.35</span>
<span class=\"hljs-number\">2010</span>-09-09 <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">58</span>:<span class=\"hljs-number\">33</span>,c97,p10,<span class=\"hljs-number\">108.99</span>
<span class=\"hljs-number\">2010</span>-09-06 <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">43</span>:<span class=\"hljs-number\">45</span>,c60,p85,<span class=\"hljs-number\">443.35</span></span>
</code></td></tr></tbody></table><p>Looking at data is crucial to understand the data and spot potential issues. Our first task is to load the sales data into an <a href=\"https://temporian.readthedocs.io/en/latest/3_minutes/#events-and-eventsets\" target=\"_blank\"><code style=\"padding: 0;\">EventSet</code></a> and plot it.</p><p><span id=\"docs-internal-guid-6bf70412-7fff-e7a7-495f-16a548305b1b\"></span></p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"719\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #fff2cc; border-bottom: solid #f1c232 1pt; border-color: rgb(241, 194, 50); border-left: solid #f1c232 1pt; border-right: solid #f1c232 1pt; border-style: solid; border-top: solid #f1c232 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">INFO: </span><span style=\"background-color: transparent; color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">A Temporian </span></span><span style=\"font-family: inherit;\"><a href=\"https://temporian.readthedocs.io/en/latest/3_minutes/#events-and-eventsets\" target=\"_blank\"><code style=\"padding: 0;\">EventSet</code></a><span style=\"background-color: transparent; color: black; font-family: inherit; vertical-align: baseline;\"> is a general-purpose container for temporal data. It can represent multivariate time series, time sequences, and indexed data.</span></span></p></td></tr></tbody></table></div>

<div style=\"text-align: left;\"><br /></div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Import Temporian</span></span>
<span class=\"hljs-keyword\"><span style=\"color: #0b5394;\">import</span></span> temporian <span class=\"hljs-keyword\"><span style=\"color: #0b5394;\">as</span></span> tp

<span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Load the csv dataset</span></span>
sales = tp.from_csv(<span class=\"hljs-string\">\"/tmp/sales.csv\"</span>)

<span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Print details about the EventSet</span></span>
sales

</code></td></tr></tbody></table><p>This code snippet load and print the data:</p>

<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHQtAZEIVQ0PgkUZHNo_Y2qEjekwVzzFX6O5RrZcNPF0paAqMN4c5X81974WzLIOAtahk9_HQNfTCOmr2QP8Xv9G-wOXjZJU4gcgCPOIYfkL-2Af6F_T1r1TG15Mv-tqODNsUgUDBPemlHw-Lv_ojNyuNYLv9Qt1z7znqJyyadd-JnXqGjc4A9GOjDprE/s366/image9.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHQtAZEIVQ0PgkUZHNo_Y2qEjekwVzzFX6O5RrZcNPF0paAqMN4c5X81974WzLIOAtahk9_HQNfTCOmr2QP8Xv9G-wOXjZJU4gcgCPOIYfkL-2Af6F_T1r1TG15Mv-tqODNsUgUDBPemlHw-Lv_ojNyuNYLv9Qt1z7znqJyyadd-JnXqGjc4A9GOjDprE/s16000/image9.png\" style=\"margin: auto; width: auto;\" /></a></div><br />

<div>We can also plot the data:</div>

<div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Plot \"price\" feature of the EventSet</span>
</span>sales[<span class=\"hljs-string\">\"price\"</span>].plot()
</code></td></tr></tbody></table><br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg1w0FmzajBeYuBJPG0TqQPcmRHAGSsK1D0RphUZWU00JwG8X_izxgWeZ_5LPUxTzAc_Ysb5pqvWYEYn4sxZ5oPpNeYuMU7rm-tockW5DlB8djAMbDvu3MKjR_BhBYVGYR4uVSDdFXIdfKswprCOjEZU_6KW3FGSPtD8xasGC9ThuMDXoF8rebofAZndTs/s1600/image3.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>We have shown how to load and visualize temporal data in just a few lines of code. However, the resulting plot is very busy, as it shows all transactions for all clients in the same view.</p>

<p>A common operation on temporal data is to calculate the moving sum. Let's calculate and plot the sum of sales for each transaction in the previous seven days. The moving sum can be computed using the <a href=\"https://temporian.readthedocs.io/en/latest/reference/temporian/operators/window/moving_sum/\" target=\"_blank\"><code style=\"padding: 0;\">moving_sum</code></a> operator.</p>

<div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\">weekly_sales = sales[<span class=\"hljs-string\">\"price\"</span>].moving_sum(tp.duration.days(<span class=\"hljs-number\"><span style=\"color: red;\">7</span></span>))

weekly_sales.plot()
</code></td></tr></tbody></table><br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhF-PoY7wh6aeTHCn5tb97pGfU85iayXAl2OeRXjJv9VdTMFFg-FUeV5EOarKUJiubKyzDZ3A3-JcU92WONvqTTljQWBe2gCGKUCOwnIqUd4pWQy_kPBmF5YE9Zm8Q0B85t9tQvZebL17HSyNaZ4ttfUMTMNbvNVRwzs1mUUSadsggQea84qhyQQRVy1LU/s1600/image3.png\" style=\"width: 100%;\" /></center></td></tr></tbody></table></div><span id=\"docs-internal-guid-44015182-7fff-1d6d-c040-36d083e29ff0\" style=\"font-weight: normal;\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><span id=\"docs-internal-guid-32debacd-7fff-b177-6f07-739e46812001\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"719\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #fff2cc; border-bottom: solid #f1c232 1pt; border-color: rgb(241, 194, 50); border-left: solid #f1c232 1pt; border-right: solid #f1c232 1pt; border-style: solid; border-top: solid #f1c232 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; font-weight: 700; vertical-align: baseline;\">BONUS: </span><span style=\"background-color: transparent; vertical-align: baseline;\">To make the plots interactive,&nbsp;you can add the </span><code style=\"padding: 0;\">interactive=True</code><span style=\"background-color: transparent; font-family: inherit;\"> argument </span></span><span style=\"background-color: transparent; font-family: inherit;\">to the </span><code style=\"padding: 0;\">plot</code><span style=\"background-color: transparent; font-family: inherit;\"> function.&nbsp;</span></p></td></tr></tbody></table></div></span>
  
<h3>Sales per products</h3>

<p>In the previous step, we computed the overall moving sum of sales for the entire shop. However, what if we wanted to calculate the rolling sum of sales for each product or client separately?</p>

<p>For this task, we can use an index.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Index the data by \"product\"</span></span>
sales_per_product = sales.add_index(<span class=\"hljs-string\">\"product\"</span>)

<span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Compute the moving sum for each product</span></span>
weekly_sales_per_product = sales_per_product[<span class=\"hljs-string\">\"price\"</span>].moving_sum(
<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;&nbsp; &nbsp;</span>tp.duration.days(<span class=\"hljs-number\"><span style=\"color: red;\">7</span></span>)
)

<span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Plot the results</span></span>
weekly_sales_per_product.plot()

</code></td></tr></tbody></table>

<div><br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6xexNKR1lXwC3dxWvhFUZnVUc7IvQcE_96MsqzwmLt8eh-ETtbYSgJf9X-1NtKSuot1liNjnCyxi4MRjM51IKyByuReZCZCMLk3PgpxhDER40mVjU4Qj6fTa1800GHz2WeNvkFpOQm43PwkSSRmEMfiqncL5MmeT1j-fv-0HJSnBTL3uV7jcCzppo8gI/s1600/image8.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table><br /></div>
  
<span id=\"docs-internal-guid-d345409c-7fff-0df4-caeb-afc399f65ea3\" style=\"font-weight: normal;\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><span id=\"docs-internal-guid-c921cad8-7fff-2bb7-b624-9c9bfa1b2574\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"719\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #fff2cc; border-bottom: solid #f1c232 1pt; border-color: rgb(241, 194, 50); border-left: solid #f1c232 1pt; border-right: solid #f1c232 1pt; border-style: solid; border-top: solid #f1c232 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; font-weight: 700; vertical-align: baseline;\">NOTE: </span><span style=\"background-color: transparent; vertical-align: baseline;\">Many operators such as <a href=\"https://temporian.readthedocs.io/en/latest/reference/temporian/operators/window/moving_sum/\" target=\"_blank\"><code style=\"padding: 0;\">moving_sum</code></a><span style=\"background-color: transparent; vertical-align: baseline;\"><span style=\"font-family: inherit;\"> applied independently on each index.</span></span></span></span></p></td></tr></tbody></table></div></span></div><h3 style=\"margin-left: 0pt;\">Aggregate transactions into time series</h3></span>

<p>Our dataset contains individual client transactions. To use this data with a machine learning model, it is often useful to aggregate it into time series, where the data is sampled uniformly over time. For example, we could aggregate the sales weekly, or calculate the total sales in the last week for each day.</p>

<p>However, it is important to note that aggregating transaction data into time series can result in some data loss. For example, the individual transaction timestamps and values would be lost. This is because the aggregated time series would only represent the total sales for each time period.</p>

<p>Let's compute the total sales in the last week for each day for each product individually.</p>


<div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span class=\"hljs-comment\"><span style=\"color: #b80672;\"># The data is sampled daily</span></span>
daily_sampling = sales_per_product.tick(tp.duration.days(<span class=\"hljs-number\"><span style=\"color: red;\">1</span></span>))

weekly_sales_daily = sales_per_product[<span class=\"hljs-string\">\"price\"</span>].moving_sum(
<span>&nbsp;&nbsp; &nbsp;</span>tp.duration.days(<span class=\"hljs-number\"><span style=\"color: red;\">7</span></span>),
<span>&nbsp;&nbsp; &nbsp;</span>sampling=daily_sampling,  <span class=\"hljs-comment\"><span style=\"color: #b80672;\"># The new bit</span></span>
)

weekly_sales_daily.plot()
</code></td></tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnXTVdhUOnSrT-z520RCWLb8i_TYuS0pZk6M9Egp9rvVB8Zg_wOHudt53bAZxXUrGKnIqoFtRiZIuMXfMfpByjwMMOEpT8xY07v0wzQOdhPHTJLvjyrpbtwTtrNyaMGSupEm30LX2JX99xbxsb4ABzq77xnSWyYumLztxWgT3GiDt-R45IYSSyr1dPMMw/s1600/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p><span id=\"docs-internal-guid-be009cac-7fff-b376-0084-268a6bca1bba\"></span></p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><span id=\"docs-internal-guid-83754c62-7fff-2032-66bf-ff17d019d5d3\"><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\"><table style=\"border-collapse: collapse; border: none;\"><colgroup><col width=\"719\" /></colgroup><tbody><tr style=\"height: 0pt;\"><td style=\"background-color: #fff2cc; border-bottom: solid #f1c232 1pt; border-color: rgb(241, 194, 50); border-left: solid #f1c232 1pt; border-right: solid #f1c232 1pt; border-style: solid; border-top: solid #f1c232 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: inherit;\"><span style=\"background-color: transparent; font-weight: 700; vertical-align: baseline;\">NOTE: </span><span style=\"background-color: transparent; vertical-align: baseline;\">The current plot is a continuous line, while the previous plots have markers. This is because Temporian uses continuous lines by default when the data is uniformly sampled, and markers otherwise.</span></span></p></td></tr></tbody></table></div></span></div><p>After the data preparation stage is finished, the data can be exported to a Pandas DataFrame as a final step.</p><div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\">tp.to_pandas(weekly_sales_daily)
</code></td></tr></tbody></table><br /><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgc5UGbsDXrqRgB93gWVQAlVQyTOLOatGAUqpxTHbKwvfgtsxiY_7VDol2M-8ned5Hf1S-AJTskaJst9zSdSQLW5zTI-Pn790thkiMvgAuCJNWIUfyiA3It2IvyKUXg6plk4RQOo3N_eLMHZgZyNCurPgJzlLLVvExzNfHljTux3PYyG2Ud0NMARN2xA4k/s410/image10.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgc5UGbsDXrqRgB93gWVQAlVQyTOLOatGAUqpxTHbKwvfgtsxiY_7VDol2M-8ned5Hf1S-AJTskaJst9zSdSQLW5zTI-Pn790thkiMvgAuCJNWIUfyiA3It2IvyKUXg6plk4RQOo3N_eLMHZgZyNCurPgJzlLLVvExzNfHljTux3PYyG2Ud0NMARN2xA4k/s16000/image10.png\" style=\"margin: auto; width: auto;\" /></a></div>

<h3>Train a forecasting model with TensorFlow model</h3>

<p>A key application of Temporian is to clean data and perform feature engineering for machine learning models. It is well suited for forecasting, anomaly detection, fraud detection, and other tasks where data comes continuously.</p>

<p>In this example, we show how to train a TensorFlow model to predict the next day's sales using past sales for each product individually. We will feed the model various levels of aggregations of sales as well as calendar information.</p>

<p>Let's first augment our dataset and convert it to a dataset compatible with a tabular ML model.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\">sales_per_product = sales.add_index(<span class=\"hljs-string\"><span style=\"color: #0d904f;\">\"product\"</span></span>)

<span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Create one example per day</span></span>
daily_sampling = sales_per_product.tick(tp.duration.days(<span class=\"hljs-number\">1</span>))

<span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Compute moving sums with various window length.</span>
<span class=\"hljs-comment\"># Machine learning models are able to select the ones that matter.</span></span>
features = []
<span class=\"hljs-keyword\"><span style=\"color: #3d85c6;\">for</span></span> w <span class=\"hljs-keyword\"><span style=\"color: #3d85c6;\">in</span></span> [<span class=\"hljs-number\"><span style=\"color: red;\">3</span></span>, <span class=\"hljs-number\"><span style=\"color: red;\">7</span></span>, <span class=\"hljs-number\"><span style=\"color: red;\">14</span></span>, <span class=\"hljs-number\"><span style=\"color: red;\">28</span></span>]:
    features.append(sales_per_product[<span class=\"hljs-string\"><span style=\"color: #0d904f;\">\"price\"</span></span>]
        .moving_sum(
            tp.duration.days(w),
            sampling=daily_sampling)
        .rename(<span class=\"hljs-string\">f\"moving_sum_<span class=\"hljs-subst\">{w}</span><span style=\"color: #0d904f;\">\"</span></span><span style=\"color: #0d904f;\">))

<span class=\"hljs-comment\"># Calendar information such as the day of the week are</span>
<span class=\"hljs-comment\"># very informative of human activities.</span>
features.append(daily_sampling.calendar_day_of_week())

<span class=\"hljs-comment\"># The label is the daly sales shifted / leaked one days in the future.</span>
</span><span>label = (sales_per_product[</span><span class=\"hljs-string\"><span>\"</span>price<span>\"</span></span>]
    .leak(tp.duration.days(<span class=\"hljs-number\"><span style=\"color: red;\">1</span></span>))
    .moving_sum(
        tp.duration.days(<span class=\"hljs-number\"><span style=\"color: red;\">1</span></span>),
        sampling=daily_sampling,
        )
    .rename(<span class=\"hljs-string\"><span style=\"color: #0d904f;\">\"label\"</span></span>))

<span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Collect the features and labels together.</span>
</span>dataset = tp.glue(*features, label)

dataset
</code></td></tr></tbody></table>

<div><br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFBQzNJ3TQJh1i3MJgyUtVs7u7-AK7kZZNa_m_idEJcVUc2jeZrVQNIN5ixoAp_9pLA-Bpk7EiNRNtFtqwX7GDkM1ue83SU95-OWC8Pp3aoZ_gh7cumkynmG553soJlNdrOCm_ciz9isSZT5hsMmN0DoDlyYpW99-g6om4YayES3NimzR3lw2izMy3d1k/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>We can then convert the dataset from <code style=\"padding: 0;\">EventSet</code> to TensorFlow Dataset format, and train a Random Forest.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span class=\"hljs-keyword\"><span style=\"color: #3d85c6;\">import</span></span> tensorflow_decision_forests <span class=\"hljs-keyword\"><span style=\"color: #3d85c6;\">as</span></span> tfdf

<span class=\"hljs-keyword\"><span style=\"color: #3d85c6;\">def</span></span> <span class=\"hljs-title function_\">extract_label</span>(<span class=\"hljs-params\">example</span>):
    example.pop(<span class=\"hljs-string\">\"timestamp\"</span>) <span class=\"hljs-comment\"><span style=\"color: #b80672;\"># Don't use use the timestamps as feature</span></span>
    label = example.pop(<span class=\"hljs-string\">\"label\"</span>)
    <span class=\"hljs-keyword\"><span style=\"color: #3d85c6;\">return</span></span> example, label

tf_dataset = tp.to_tensorflow_dataset(dataset).<span class=\"hljs-built_in\"><span style=\"color: #3d85c6;\">map</span></span>(extract_label).batch(<span class=\"hljs-number\"><span style=\"color: red;\">100</span></span>)

model = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION,verbose=<span class=\"hljs-number\"><span style=\"color: red;\">2</span></span>)
model.fit(tf_dataset)
</code></td></tr></tbody></table>

<p>And that’s it, we have a model trained to forecast sales. We now can look at the variable importance of the model to understand what features matter the most.</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\">model.summary()
</code></td></tr></tbody></table><p>In the summary, we can find the <a href=\"https://ydf.readthedocs.io/en/latest/cli_user_manual.html#variable-importances\" target=\"_blank\"><code style=\"padding: 0;\">INV_MEAN_MIN_DEPTH</code></a> variable importance:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"color: #0d904f;\"><span class=\"hljs-type\">Type</span>: <span class=\"hljs-string\">\"RANDOM_FOREST\"</span>
Task: REGRESSION
...
Variable Importance: INV_MEAN_MIN_DEPTH:
    <span class=\"hljs-number\">1.</span>        <span class=\"hljs-string\">\"moving_sum_28\"</span>  <span class=\"hljs-number\">0.342231</span> <span class=\"hljs-comment\">################</span>
    <span class=\"hljs-number\">2.</span>              <span class=\"hljs-string\">\"product\"</span>  <span class=\"hljs-number\">0.294546</span> <span class=\"hljs-comment\">############</span>
    <span class=\"hljs-number\">3.</span> <span class=\"hljs-string\">\"calendar_day_of_week\"</span>  <span class=\"hljs-number\">0.254641</span> <span class=\"hljs-comment\">##########</span>
    <span class=\"hljs-number\">4.</span>        <span class=\"hljs-string\">\"moving_sum_14\"</span>  <span class=\"hljs-number\">0.197038</span> <span class=\"hljs-comment\">######</span>
    <span class=\"hljs-number\">5.</span>         <span class=\"hljs-string\">\"moving_sum_7\"</span>  <span class=\"hljs-number\">0.124693</span> <span class=\"hljs-comment\">#</span>
    <span class=\"hljs-number\">6.</span>         <span class=\"hljs-string\">\"moving_sum_3\"</span>  <span class=\"hljs-number\">0.098542</span></span>
</code></td></tr></tbody></table><p>We see that <code style=\"padding: 0;\">moving_sum_28</code> is the feature with the highest importance (0.342231). This indicates that the sum of sales in the last 28 days is very important to the model. To further improve our model, we should probably add more temporal aggregation features. The <code style=\"padding: 0;\">product</code> feature also matters a lot.</p>

<p>And to get an idea of the model itself, we can plot one of the trees of the Random Forest.</p><div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\">tfdf.model_plotter.plot_model_in_colab(model, tree_idx=<span class=\"hljs-number\"><span style=\"color: red;\">0</span></span>, max_depth=<span class=\"hljs-number\"><span style=\"color: red;\">2</span></span>)
</code></td></tr></tbody></table>
  
<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5Hy66U7TQyFZVjyIJo4ZQMf52R8KCfyFgTY6thKhmlpiknmF_MtQoCt_ssAAOczBwUmcm4j6an92WjBP1HW3sBroSkwazzl-uAyCbFl-0mZvtNsE2jxvXHvfEzwHwy2f8mE8QcJqxcdY11CtiI2fYBXKD0rSXZ8p3Bygkw-LIqHRnr0UXYyA9ILC34JQ/s1600/moving_sum%20model%20tree%20%281000%20%C3%97%20550%20px%29.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<h3>More on temporal data preprocessing</h3>

<p>We demonstrated some simple data preprocessing. If you want to see other examples of temporal data preprocessing on different data domains, check the <a href=\"https://temporian.readthedocs.io/en/latest/tutorials/\" target=\"_blank\">Temporian tutorials</a>. Notably:</p>
<ul><blockquote>
<li><b>Heart rate analysis</b> ❤️  detects individual heartbeats and derives heart rate related features on raw ECG signals from Physionet.</li>
<li><b>M5 Competition</b> 🛒 predicts retail sales in the M5 Makridakis Forecasting competition.</li>
<li><b>Loan outcomes prediction</b> 🏦 prepares relational SQL data to predict outcomes for finished loans.</li>
<li><b>Detecting payment card fraud</b> 💳 detects fraudulent payment card transactions in real time.</li>
<li><b>Supervised and unsupervised anomaly detection</b> 🔎 perform data analysis and feature engineering to detect anomalies in a group of server’s resource usage metrics.</li>
</blockquote></ul>

<h3>Next Steps</h3>

<p>We demonstrated how to handle temporal data such as transactions in TensorFlow using the Temporian library. Now you can try it too!</p>
<ul><blockquote>
<li>Join <a href=\"https://discord.gg/Zqa4BY5uV8\" target=\"_blank\">our Discord server</a>, to share your feedback or ask for help.</li>
<li>Read the <a href=\"https://temporian.readthedocs.io/en/latest/3_minutes/\" target=\"_blank\">3 minutes to Temporian guide</a> for a quick introduction.</li>
<li>Check the <a href=\"https://temporian.readthedocs.io/en/latest/user_guide/\" target=\"_blank\">User guide</a>.</li>
<li>Visit the <a href=\"https://github.com/google/temporian\" target=\"_blank\">GitHub repository</a>.</li></blockquote></ul><p>To learn more about model training with TensorFlow Decision Forests:</p>
<ul><blockquote>
<li>Visit the <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">official website</a>.</li>
<li>Follow the <a href=\"https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\" target=\"_blank\">beginner notebook</a>.</li>
<li>Check the <a href=\"https://www.tensorflow.org/decision_forests/tutorials\" target=\"_blank\">various guides and tutorials</a>.</li>
<li>Check the <a href=\"https://discuss.tensorflow.org/\" target=\"_blank\">TensorFlow Forum</a>.</li>
</blockquote></ul></div></span></div></div>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Mon, 11 Sep 2023 20:14:00 +0000"
2513,Distributed Fast Fourier Transform in TensorFlow,https://blog.tensorflow.org/2023/08/distributed-fast-fourier-transform-in-tensorflow.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYIMKKNGUkhWyF3gL1qLpn7cQ3iQu5GleP-36OHbTJwn90YdRUk8vGTefc9ctjwPcJhyBbFlprd581nDsWEKfMAeAo9xuX8zKfxti8Fvl2f2v69Qmvt695cCJY1dfVPbMIlfWqMFKMEyBCgIaRLXypYCrHlob-OiAb0mvVbhmBEt65-agfmRWDMuaI/s1600/image1.png\" style=\"display: none;\" />

<em>Posted by <a href=\"https://www.linkedin.com/in/ruijiao-sun\" target=\"_blank\">Ruijiao Sun</a>, Google Intern - DTensor team</em>
  
<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRgwmbW2Tp7Q_Y3GTKSmkfboFNHuUizDaYh1uLrQSCZarfkvs1mK7OodevH9l318Ls8ddEmKNPewlpVhMJzKvtpktP6TeKniEEMAzgRrHq-D-kIEsoQnZyvc7n4pUVsn1RkFF066dnujQZ1htprWST0uSJftVZxQyc2Qm8aijQTMhrtJlj7rrEc6s7/s1600/Tensorflow-septmber-update-header%20%282%29.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRgwmbW2Tp7Q_Y3GTKSmkfboFNHuUizDaYh1uLrQSCZarfkvs1mK7OodevH9l318Ls8ddEmKNPewlpVhMJzKvtpktP6TeKniEEMAzgRrHq-D-kIEsoQnZyvc7n4pUVsn1RkFF066dnujQZ1htprWST0uSJftVZxQyc2Qm8aijQTMhrtJlj7rrEc6s7/s1600/Tensorflow-septmber-update-header%20%282%29.png\" /></a>

<a name=\"more\"></a><p></p>

<p><a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" target=\"_blank\">Fast Fourier Transform</a> is an important method of signal processing, which is commonly used in a number of ways, including speeding up convolutions, extracting features, and regularizing models. Distributed Fast Fourier Transform (Distributed FFT) offers a way to compute Fourier Transforms in models that work with image-like datasets that are too large to fit into the memory of a single accelerator device.  In a previous Google Research Paper,  “<a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465154\" target=\"_blank\"><i>Large-Scale Discrete Fourier Transform on TPUs</i></a>” by Tianjian Lu, a Distributed FFT algorithm was implemented for TensorFlow v1 as a library. This work presents the newly added native support in TensorFlow v2 for Distributed FFT, through the new TensorFlow distribution API, DTensor.</p>

<h2>About DTensor</h2>

<p><a href=\"https://www.tensorflow.org/guide/dtensor_overview\" target=\"_blank\">DTensor</a> is an extension to TensorFlow for synchronous distributed computing. It distributes the program and tensors through a procedure called <a href=\"https://en.wikipedia.org/wiki/SPMD\" target=\"_blank\">Single program, multiple data (SPMD)</a> extension. DTensor offers an uniform API for traditional data and model parallelism patterns used widely in Machine Learning. </p>

<h2>Example Usage</h2>

<p>The API interface for distributed FFT is the same as the original FFT in TensorFlow. Users just need to pass a sharded tensor as an input to the existing FFT ops in TensorFlow, such as <a href=\"https://www.tensorflow.org/api_docs/python/tf/signal/fft2d\" target=\"_blank\">tf.signal.fft2d</a>. The output of a distributed FFT becomes sharded too.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">import</span> TensorFlow <span class=\"hljs-keyword\">as</span> tf
<span class=\"hljs-keyword\">from</span> TensorFlow.experimental <span class=\"hljs-keyword\">import</span> dtensor


<span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Set up devices</span>
</span>device_type = dtensor.preferred_device_type()
<span class=\"hljs-keyword\">if</span> device_type == <span class=\"hljs-string\">'CPU'</span>:
cpu = tf.config.list_physical_devices(device_type)
tf.config.set_logical_device_configuration(cpu[<span class=\"hljs-number\">0</span>], [tf.config.LogicalDeviceConfiguration()] * <span class=\"hljs-number\">8</span>)
<span class=\"hljs-keyword\">if</span> device_type == <span class=\"hljs-string\">'GPU'</span>:
gpu = tf.config.list_physical_devices(device_type)
tf.config.set_logical_device_configuration(gpu[<span class=\"hljs-number\">0</span>], [tf.config.LogicalDeviceConfiguration(memory_limit=<span class=\"hljs-number\">1000</span>)] * <span class=\"hljs-number\">8</span>)
dtensor.initialize_accelerator_system()


<span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Create a mesh</span>
</span>mesh = dtensor.create_distributed_mesh(mesh_dims=[(<span class=\"hljs-string\">'x'</span>, <span class=\"hljs-number\">1</span>), (<span class=\"hljs-string\">'y'</span>, <span class=\"hljs-number\">2</span>), (<span class=\"hljs-string\">'z'</span>, <span class=\"hljs-number\">4</span>)], device_type=device_type)


<span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Set up a distributed input Tensor</span>
</span><span class=\"hljs-built_in\">input</span> = tf.<span class=\"hljs-built_in\">complex</span>(
tf.random.stateless_normal(shape=(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>), seed=(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>), dtype=tf.float32),
tf.random.stateless_normal(shape=(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>), seed=(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>), dtype=tf.float32))
init_layout = dtensor.Layout([<span class=\"hljs-string\">'x'</span>, <span class=\"hljs-string\">'y'</span>, <span class=\"hljs-string\">'z'</span>], mesh)
d_input = dtensor.relayout(<span class=\"hljs-built_in\">input</span>, layout=init_layout)


<span style=\"color: #b80672;\"><span class=\"hljs-comment\"># Run distributed fft2d. DTensor determines the most efficient</span>
<span class=\"hljs-comment\">#</span></span><span class=\"hljs-comment\"> </span><span class=\"hljs-comment\">layout of of d_output.</span>
d_output = tf.signal.fft2d(d_input)</span></code></td></tr></tbody></table>

<h2>Performance Analysis</h2>

<p>The following experiment demonstrates that the distributed FFT can process more data than the non-distributed one by utilizing memory across multiple devices. The tradeoff is spending additional time on communication and data transposes that slow down the calculation speed. </p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Graph of performance on different machines, measuri8ng wall clock time in seconds by size per dimension across single GPU, Distributed FFT and Undistributed FFT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigTOJgosBdpn5Wr7djYt3eYpmcxmRy3nn_UQbG1aW5nO96v5fMFFzsx9p-ahhpTuWJPNRQ5IMRvUjdon-CollI87lu6mAEnnW7KcaIHyrZVLK0tUMQJ2jDBVxtYz9zcXBH2FI5kou775n-Yt4iBGVfzO3rAwaCo4vgkXrWU3BWqv-_YPKf2mkU8kihSxc/s1600/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>This phenomenon is shown in detail from the profiling result of the 10K*10K distributed FFT experiment. The current implementation of distributed FFT in TensorFlow follows the simple shuffle+local FFT method, which is also used by other popular distributed FFT libraries such as <a href=\"https://ieeexplore.ieee.org/document/681704\" target=\"_blank\">FFTW</a> and <a href=\"https://epubs.siam.org/doi/abs/10.1137/120885887\" target=\"_blank\">PFFT</a>.  Notably, the two local FFT ops only take 3.6% of the total time (15ms). This is around 1/3 of the time for non-distributed fft2d. Most of the computing time is spent on data shuffling, represented by the ncclAllToAll Operation. Note that these experiments were conducted on an 8xV100 GPU system.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Table of Top 10 TensorFlow operations on GPU highlighting two local FFT ops in the top 3\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhNIgERau2VMVV1Uz5jqsjNow9OVkfhd_WI0Irr424u7sUAEo-iILbMOxhrp_dbjMsKhssjCw6iYfe8m5OCBGsldiqM-6_SjAjY0ZamWkBSJUGuW7Xwubw5fYfrNVY9WSr9B2SXX2m0fQHRS7Gqr-jjKMNxIzTax2xz5ntAGZhIMMb4biWvK98tqd4M7H4/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<h2>Next steps</h2>

<p>The feature is new and we have adopted a simplest distributed FFT algorithm. A few ideas to fine tune or improve the performance are:</p>
<ul><blockquote>
<li>Switch to a different DFT/FFT algorithm.</li>
<li>Tweaks on the NCCL communication settings for the particular FFT sizes may improve utilization of the network bandwidth and increase the speed.</li>
<li>Reducing the number of collectives to minimize bandwidth requirements.</li>
<li>Use N-d local FFTs, rather than multiple 1-d local FFTs.</li>
</blockquote></ul>

<p>Try the new distributed FFT! We welcome your feedback on the <a href=\"https://discuss.tensorflow.org/\" target=\"_blank\">TensorFlow Forum</a> and look forward to working with you on improving the performance. Your input would be invaluable!</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Thu, 24 Aug 2023 17:00:00 +0000"
2514,The TensorFlow Lite Plugin for Flutter is Officially Available,https://blog.tensorflow.org/2023/08/the-tensorflow-lite-plugin-for-flutter-officially-available.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEir6TpBti1i4y8JWJ0JdadWBI-dV8iziJhCeUDFq7-KzRm_KzbWtUDw2sL7drCRP77A1H1fkgw-N0saaGLtUsxXbUApCiW-A5M7IbKUovycgIknEcLAJq6qut5Ov6ec7QALMFQJC2srGzFMHRvUN856QGju3qR8f71XSRNFYJwBOFS-3s84Gmvz-Q3k2_Q/s1600/Tensorflow-Jax-on-the-Web-02%20%281%29.png\" style=\"display: none;\" />

<em>Posted by <a href=\"https://twitter.com/ptruiz_dev\" target=\"_blank\">Paul Ruiz</a>, Developer Relations Engineer</em><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2kHOZOCF_yXCqaxxvQWHY3Gd3sR7xJ0P5NSRDABUCzAHTDZ69kv6ofmUVY-amjyZnxOmj3Mt66xwnKtqR6ftOOHkCLckkMRlawpniZwCwcqEvExyMHoaMfyQJqvw-vi63OcWqAcLCJKDPHaWrPVJW-U8aTvNHwXWDVa6PLbhAUgYxyjdFuKHnT6ISqwY/s1600/Tensorflow-Jax-on-the-Web-01%20%281%29.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2kHOZOCF_yXCqaxxvQWHY3Gd3sR7xJ0P5NSRDABUCzAHTDZ69kv6ofmUVY-amjyZnxOmj3Mt66xwnKtqR6ftOOHkCLckkMRlawpniZwCwcqEvExyMHoaMfyQJqvw-vi63OcWqAcLCJKDPHaWrPVJW-U8aTvNHwXWDVa6PLbhAUgYxyjdFuKHnT6ISqwY/s1600/Tensorflow-Jax-on-the-Web-01%20%281%29.png\" /></a>

<a name=\"more\"></a><p></p>

<p>We're excited to announce that the TensorFlow Lite plugin for Flutter has been officially migrated to the TensorFlow GitHub account and released!

</p><p>Three years ago, <a href=\"https://github.com/am15h\" target=\"_blank\">Amish Garg</a>, one of our talented Google Summer of Code contributors, wrote a widely used TensorFlow Lite plugin for Flutter. The plugin was so popular that we decided to migrate it to our official repo, making it easier to maintain directly by the Google team. We are grateful to Amish for his contributions to the TensorFlow Lite Flutter plugin.</p>

<p>Through the efforts of developers in the community, the plugin has been updated to the latest version of TensorFlow Lite, and a collection of new features and example apps have been added, such as object detection through a live camera feed.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Moving image of a live camera feed showing several objects on a work desk being detected\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgzl-IA2HrigPggyplfe6fsfCxuW8URlGxY_qYI5i9x1JcYjRXUHQX6iRSML-tfojxIYP35nEOgdQ3e0VQevPjlwL0l0rG-obAIgXYqJOU77ZuM-G_ZeB0S66_aoVcU02WQLjrbGdj22zdp3JhEvL08rVOrq3G0jc0NUgRyUu2uDWL-1-RyFwIqj1E7e88/s1600/image2.gif\" style=\"width: 55%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>So what is TensorFlow Lite? TensorFlow Lite is a way to run TensorFlow models on devices locally, supporting mobile, embedded, web, and edge devices. TensorFlow Lite’s cross-platform support and on-device performance optimizations make it a great addition to the Flutter development toolbox. Our goal with this plugin is to make it easy to integrate TensorFlow Lite models into Flutter apps across mobile platforms, with desktop support currently in development through the efforts of our developer community. Find pre-trained TensorFlow Lite models on model repos like <a href=\"https://www.kaggle.com/models?framework=tfLite\" target=\"_blank\">Kaggle Models</a> or <a href=\"https://www.kaggle.com/models?framework=tfLite\" target=\"_blank\">create your own custom TensorFlow Lite models</a>. </p>

<p>Let’s take a look at how you could use the Flutter TensorFlow Lite plugin for image classification:</p>

<h2>TensorFlow Lite Image Classification with Flutter</h2>

<p>First you will need to install the plugin from <a href=\"https://pub.dev/packages/tflite_flutter\" target=\"_blank\">pub.dev</a>. Once the plugin is installed, you can load a TensorFlow Lite model into your Flutter app and define the input and output tensor shapes. If you’re using the MobileNet model, then the input tensor will be a 224 by 224 RGB image, and the output will be a list of confidence scores for the trained labels.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\">// Load model</span>
Future&lt;<span class=\"hljs-keyword\">void</span>&gt; <span class=\"hljs-title function_\">_loadModel</span><span class=\"hljs-params\">()</span> async {
    <span class=\"hljs-type\">final</span> <span class=\"hljs-variable\">options</span> <span class=\"hljs-operator\">=</span> InterpreterOptions();

    <span class=\"hljs-comment\">// Load model from assets</span>
    interpreter = await Interpreter.fromAsset(modelPath, options: options);
    <span class=\"hljs-comment\">// Get tensor input shape [1, 224, 224, 3]</span>
    inputTensor = interpreter.getInputTensors().first;
    <span class=\"hljs-comment\">// Get tensor output shape [1, 1001]</span>
    outputTensor = interpreter.getOutputTensors().first;
}</span></code></td></tr></tbody></table><p style=\"text-align: left;\">To make things a bit more organized, you can also load in the labels for the 1000 items that MobileNet is trained for:</p><div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\">// Load labels from assets</span>
Future&lt;<span class=\"hljs-keyword\">void</span>&gt; <span class=\"hljs-title function_\">_loadLabels</span><span class=\"hljs-params\">()</span> async {
    <span class=\"hljs-type\">final</span> <span class=\"hljs-variable\">labelTxt</span> <span class=\"hljs-operator\">=</span> await rootBundle.loadString(labelsPath);
    labels = labelTxt.split(<span class=\"hljs-string\">'\\n'</span>);
}</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\">
</span></code></td></tr></tbody></table></div><div><p>For the sake of being succinct, let’s go ahead and skip some of the pre-processing steps, though you can find them in the repo’s image classification example here.</p>

<p>When you’re ready to run inference, you can create a new input and output based on the tensor shapes that you defined earlier, then call run on the interpreter to get your final results.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\">// Run inference</span>
 Future&lt;<span class=\"hljs-keyword\">void</span>&gt; <span class=\"hljs-title function_\">runInference</span><span class=\"hljs-params\">(
 </span><span class=\"hljs-params\">List&lt;List&lt;List&lt;</span><span class=\"hljs-params\"><span style=\"color: #792ba1;\">num</span></span><span class=\"hljs-params\">&gt;&gt;&gt; imageMatrix,</span><span class=\"hljs-params\">
 )</span> async {
   <span class=\"hljs-comment\">// Tensor input [1, 224, 224, 3]</span>
   <span class=\"hljs-type\">final</span> <span class=\"hljs-variable\">input</span> <span class=\"hljs-operator\">=</span> [imageMatrix];
   <span class=\"hljs-comment\">// Tensor output [1, 1001]</span>
   <span class=\"hljs-type\">final</span> <span class=\"hljs-variable\">output</span> <span class=\"hljs-operator\">=</span> [List&lt;<span class=\"hljs-type\">int</span>&gt;.filled(<span class=\"hljs-number\">1001</span>, <span class=\"hljs-number\">0</span>)];

<span class=\"hljs-comment\"><span>&nbsp;&nbsp; </span>// Run inference</span>
<span>&nbsp;&nbsp; </span>interpreter.run(input, output);

<span class=\"hljs-comment\"><span>&nbsp;&nbsp; </span>// Get first output tensor</span>
<span class=\"hljs-type\"><span>&nbsp;&nbsp; </span>final</span> <span class=\"hljs-variable\">result</span> <span class=\"hljs-operator\">=</span> output.first;</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\">
</span></code></td></tr></tbody></table>

<p>Now that you have your results, you can match them to your labels and use them in your app.</p>
  
<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Moving image of a live camera feed showing several objects on a work desk being correctly identified in the app\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVgsmqQrHHWe-t2Sh9NYURx7PJXkxCxkVfvNGNOc3VrHyHB3bxCkzUegDWqea9twNo62rQzLngtQ4Tq7L-EhyHJv4RXyewL_hp1xH48JVsg8xfaboptEm-DliMpCB6Qj7v6T7WrAIpPtt9RpK1BAmaxkLsImzkkSuj2X-miVDiauiKKeZi-fFQzgJRU4U/s1600/image1.gif\" style=\"width: 55%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

  <h2>What’s next?</h2>

<p>To explore what else you can do with the Flutter TensorFlow Lite plugin, check out the official <a href=\"https://github.com/tensorflow/flutter-tflite\" target=\"_blank\">GitHub repository</a> where you can find examples for text classification, super resolution, style transfer, and more!</p>

<p>Additionally, we are working on a new plugin specifically for <a href=\"https://developers.google.com/mediapipe\" target=\"_blank\">MediaPipe Tasks</a>, a low-code tool for easily performing common on-device machine learning tasks. This includes image classification and object detection, like you’ve just learned about, as well as audio classification, face landmark detection, and gesture recognition, alongside a whole lot more.</p>

<p>We look forward to all the exciting things you make, so be sure to share them with <a href=\"https://twitter.com/googledevs\" target=\"_blank\">@googledevs</a>, <a href=\"https://twitter.com/TensorFlow\" target=\"_blank\">@TensorFlow</a>, and your developer communities!</p>

<p></p><p></p></div>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Fri, 18 Aug 2023 16:00:00 +0000"
2515,Simpleperf case study: Fast initialization of TFLite’s Memory Arena,https://blog.tensorflow.org/2023/08/simpleperf-case-study-fast.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-46_SfAtZJniOxOGJLavcD545oJnNBs3Q-AhPbzy57QVleiDFyY6-GgS8ABhWdCEXdweomDoLJjIn_GjtQx73iZ2zmccrou5jCRy6_fDrM9LpZlmEbd3x9DV8V2pBxFZNks6ytR9VlmK9Cw_Em1u5_tXp-pvhBjHj2SGjDd39mSAsHA0KrTCAHoTY2uI/s1600/tfsocial%20%281%29.png\" style=\"display: none;\" />

<em>Posted by <a href=\"https://www.linkedin.com/in/alanjkelly\" target=\"_blank\">Alan Kelly</a>, Software Engineer</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNa6_GH3xPgUogQjPA_RUBB5vga9TXVtt6i3TjX9Dqpl4iCzRlpfmtehk3P7f15H0pNVTM3HzZKnGOWB5qICy9BHnDxoRjfRvD5TZXqyH9kEfiSzUADxTalQaJRtmI7CdKMfU73Y-rPb7F9uAYslkzPuwDYuaJyvsjdGSawh2pk2CzrAAdqiKw9W3y1r8/s1600/Simpleperf-TF-Header.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNa6_GH3xPgUogQjPA_RUBB5vga9TXVtt6i3TjX9Dqpl4iCzRlpfmtehk3P7f15H0pNVTM3HzZKnGOWB5qICy9BHnDxoRjfRvD5TZXqyH9kEfiSzUADxTalQaJRtmI7CdKMfU73Y-rPb7F9uAYslkzPuwDYuaJyvsjdGSawh2pk2CzrAAdqiKw9W3y1r8/s1600/Simpleperf-TF-Header.png\" /></a>


<a name=\"more\"></a><p></p>

<p>One of our previous articles, <a href=\"https://blog.tensorflow.org/2020/10/optimizing-tensorflow-lite-runtime.html\" target=\"_blank\">Optimizing TensorFlow Lite Runtime Memory</a>, discusses how TFLite’s memory arena minimizes memory usage by sharing buffers between tensors. This means we can run models on even smaller edge devices. In today’s article, I will describe the performance optimization of the memory arena initialization so that our users get the benefit of low memory usage with little additional overhead.</p>

<p>ML is normally deployed on-device as part of a larger pipeline. TFLite is used because it’s fast and lightweight, but the rest of the pipeline must also be fast. Profiling on the target device with representative data lets us identify the slowest parts of the pipeline so that we can optimize the most important part of the code.</p>

<p>In this article, I will describe the profiling and optimization of TFLite’s memory arena with instructions on how to use <a href=\"https://developer.android.com/ndk/guides/simpleperf\" target=\"_blank\">Simpleperf</a> and visualize the results. Sample commands are given. It is assumed that the <a href=\"https://developer.android.com/ndk\" target=\"_blank\">Android NDK</a> is installed and that you have a development device that you can connect to using <a href=\"https://developer.android.com/studio/command-line/adb\" target=\"_blank\">adb</a>.</p>

<h2>Simpleperf</h2>

<p>Simpleperf comes with some scripts to make it easier to use. <a href=\"https://android.googlesource.com/platform/prebuilts/simpleperf/+/d0669f6130721d9a6f0da8e5d95e4114f535f5a6/run_simpleperf_on_device.py\" target=\"_blank\">run_simpleperf_on_device.py</a> pushes simpleperf to the device and runs your binary with the given arguments.</p>

<p><span style=\"color: #0d904f; font-family: courier;\">/usr/lib/android-ndk/simpleperf/run_simpleperf_on_device.py record –call-graph fp /data/local/tmp/my_binary arg0 arg1 …</span></p>

<p>This will generate the output file <span style=\"color: #0d904f; font-family: courier;\">perf.data</span> which you must then copy back to your computer.</p>

<p><span style=\"color: #0d904f; font-family: courier;\">adb pull /data/local/tmp/perf.data</span></p>

<p>You then generate the binary cache which contains all the information needed later to generate a useful profile.</p>

<p><span style=\"color: #0d904f; font-family: courier;\">/usr/lib/android-ndk/simpleperf/binary_cache_builder.py -lib /your/binarys/folder -i perf.data</span></p>

<p>And generate the proto buffer used for visualization:</p>

<p><span style=\"color: #0d904f; font-family: courier;\">/usr/lib/android-ndk/simpleperf/pprof_proto_generator.py --ndk_path=/path/to/android-ndk -i perf.data -o profile.proto</span></p>

<p>You can then display the results this using <a href=\"https://github.com/google/pprof\" target=\"_blank\">pprof</a>:</p>

<p><span style=\"color: #0d904f; font-family: courier;\">pprof -http :8888 profile.proto</span></p>

<p>And open localhost:8888 in your browser to view the profile. I find flame graphs to be the most useful:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVItxfwNM9arJL4E__71igirLNeD4oEu2Ytfx49k-ty-TXxvS3vd-J53sO2FIPbay0qabdu4CNVSz4olF7xzl6sgAufXhX2Ag5w_8Ak_jt76Dk_GQq7rgmzJ5L-GwS-ZdOVb58EIH9NjC8K74jC1O4BXRWbVhVsUY1yWm1zoAfxJNdOk8z-FYyyKZmhCQ/s1600/image2.png\" target=\"_blank\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVItxfwNM9arJL4E__71igirLNeD4oEu2Ytfx49k-ty-TXxvS3vd-J53sO2FIPbay0qabdu4CNVSz4olF7xzl6sgAufXhX2Ag5w_8Ak_jt76Dk_GQq7rgmzJ5L-GwS-ZdOVb58EIH9NjC8K74jC1O4BXRWbVhVsUY1yWm1zoAfxJNdOk8z-FYyyKZmhCQ/s1600/image2.png\" style=\"width: 100%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiVItxfwNM9arJL4E__71igirLNeD4oEu2Ytfx49k-ty-TXxvS3vd-J53sO2FIPbay0qabdu4CNVSz4olF7xzl6sgAufXhX2Ag5w_8Ak_jt76Dk_GQq7rgmzJ5L-GwS-ZdOVb58EIH9NjC8K74jC1O4BXRWbVhVsUY1yWm1zoAfxJNdOk8z-FYyyKZmhCQ/s1600/image2.png\" target=\"_blank\"><i></i></a></td></tr></tbody></table></div>

<div style=\"text-align: left;\"><br /></div><h2>Optimizing TFLite’s Memory Arena</h2>

<p><span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::ExecuteAllocations</span> accounts for 54.3% of the runtime of this model. I was expecting to find that ML operators such as fully connected layers or convolutions to be the bottleneck of this model, and not runtime overhead. This is a particularly bad case, the memory arena overhead isn’t this bad for every model, but improvements here will impact all models. This model has variable input sizes and many dynamic tensors, whose output size isn’t known until operator evaluation, which trigger frequent tensor re-allocations. This really is as bad as it gets. Let’s zoom in on the profile.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIOKkwSLXtGYzdqHThekCF4VjNgo2LePTK13zrWGU4jPTsi8PfReFGD9HUh0p44FDW-T1ZWW_2lxLNP6_YRFJdTGIxv6W08uDb8ehR98uOWmTyfBBHpfUSRN0vf7DCak-BvturTj-LPITLC3OdcevYJM6sNdRlYZXK1NWzr1XBcFplTwQ_iNbeoi4Qcs0/s1600/image5.png\" target=\"_blank\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIOKkwSLXtGYzdqHThekCF4VjNgo2LePTK13zrWGU4jPTsi8PfReFGD9HUh0p44FDW-T1ZWW_2lxLNP6_YRFJdTGIxv6W08uDb8ehR98uOWmTyfBBHpfUSRN0vf7DCak-BvturTj-LPITLC3OdcevYJM6sNdRlYZXK1NWzr1XBcFplTwQ_iNbeoi4Qcs0/s1600/image5.png\" style=\"width: 100%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p><span style=\"color: #0d904f; font-family: courier;\">InterpreterInfo::num_tensors()</span> accounts for 10.4% of the runtime. The reason this function is so expensive is because it is a virtual function which calls another function and it is called within a loop. I would never have suspected this.</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\"><span style=\"color: #9c27b0;\">for</span></span> (<span class=\"hljs-type\"><span style=\"color: #9c27b0;\">int</span></span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-built_in\"><span style=\"color: #9c27b0;\">static_cast</span></span><span style=\"color: #0d904f;\">&lt;<span class=\"hljs-type\">int</span>&gt;</span>(graph_info_-&gt;<span class=\"hljs-built_in\"><span>num_tensors</span></span>()); ++i) {
  …
}</span></code></td></tr></tbody></table>

<p>Arena planner does not create or destroy tensors so the number of tensors is constant. Let’s cache it. </p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span style=\"color: #9c27b0;\"><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span></span> num_tensors = <span class=\"hljs-built_in\"><span style=\"color: #9c27b0;\">static_cast</span></span><span style=\"color: #0d904f;\">&lt;<span class=\"hljs-type\">int</span>&gt;</span>(graph_info_-&gt;<span class=\"hljs-built_in\">num_tensors</span>());
<span class=\"hljs-keyword\"><span style=\"color: #9c27b0;\">for</span></span> (<span class=\"hljs-type\"><span style=\"color: #9c27b0;\">int</span></span> i = <span class=\"hljs-number\">0</span>; i &lt; num_tensors); ++i) {
  …
}</span></code></td></tr></tbody></table>

<p>Our next piece of low hanging fruit is <span style=\"color: #0d904f; font-family: courier;\">InterpreterInfo::tensor(unsigned long)</span> which is another virtual function which does bounds checking and then returns a pointer to a tensor. Tensors are stored in an array so let’s add a function to get a pointer to this array. The commits are <a href=\"https://github.com/tensorflow/tensorflow/commit/7528df84ad0207ec88eb8324dee8e10cf79fda0d\" target=\"_blank\">here</a> and <a href=\"https://github.com/tensorflow/tensorflow/commit/91cc89a28fcfeef7df3f257bd27086343d438610\" target=\"_blank\">here</a>.</p>

<p>After these simple changes the runtime of this model has reduced by 25% and then overhead of the memory allocator by half. Simpleperf made identifying these inefficiencies easy! Time to profile again to measure the impact of these changes.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5M5lS4MnwYZ7kHG_6c9t3nsipbgiR4gzxBTYaLQeyhuKU0lXx9U15K1x5a4oRpVnH622OPNBAQgbA2YN08BTP7SHxZPGdmZe6SsAsEG-6MVZ95_Vgz3ija9aXGRVmQrWwgVsqiolynHpXm9ljLC3siSXrb7R9_50MBcJT9yF6N_wv9MZUaKxiLwdMLr8/s1600/image1.png\" target=\"_blank\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5M5lS4MnwYZ7kHG_6c9t3nsipbgiR4gzxBTYaLQeyhuKU0lXx9U15K1x5a4oRpVnH622OPNBAQgbA2YN08BTP7SHxZPGdmZe6SsAsEG-6MVZ95_Vgz3ija9aXGRVmQrWwgVsqiolynHpXm9ljLC3siSXrb7R9_50MBcJT9yF6N_wv9MZUaKxiLwdMLr8/s1600/image1.png\" style=\"width: 100%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p><span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::CalculateAllocations</span> is now the most expensive function at 12.7%. This calls two functions: <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::Allocate</span> and <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::CreateTensorAllocationVector</span>.</p>

<p>Although <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::CreateTensorAllocationVector</span> is the cheaper of the two, the code is far simpler so it might be easier to optimize. This function identifies which tensors are allocated between two nodes in the graph and then sorts them by size as a Greedy by Size allocation algorithm is used where the largest tensors are allocated first. The structure of the graph is constant so we can store a map of tensors allocated at each node. Instead of checking each tensor in the model to see if it is allocated between the two nodes, we can identify the tensors to be allocated by iterating through the map. The cost of <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::CreateTensorAllocationVector</span> has gone from 4.8% to 0.8% of the runtime. Code can be seen <a href=\"https://github.com/tensorflow/tensorflow/commit/72c981ec392a4ec8b3e9fcae44c8be3217265437\" target=\"_blank\">here</a>. Sort does not appear in the profile so we ignore it.</p>

<p>The next function to look at is <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::ResolveTensorAllocation</span> which is 10.9% of the runtime after the previous optimizations. This function resets each tensor’s data pointer after allocation. However, these pointers don’t always change. How about keeping track of and only updating the ones which change? After this <a href=\"https://github.com/tensorflow/tensorflow/commit/c9b82169ab767a96aa1bf31556c186c9c91a9fe8\" target=\"_blank\">change</a>, <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::ResolveTensorAllocation</span> doesn’t appear in the profile anymore.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmAbsVuiceykKRiNA-XlEA9R3BLLfvoYZrtd8c5Hd4k97tlHm9tBuMEag4-UDU5439fWZysh2kDJmkQcmeIU4LVYjlQpN_ukTwQC3mFjofKqc09LKKwXpG5VmSPOjsVlr0WV-C0N2J61hkNi3Xpkd9iopSmtgU8sjdE1aECcXtn8wxchnQkfNbfvO-COM/s1600/image3.png\" target=\"_blank\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmAbsVuiceykKRiNA-XlEA9R3BLLfvoYZrtd8c5Hd4k97tlHm9tBuMEag4-UDU5439fWZysh2kDJmkQcmeIU4LVYjlQpN_ukTwQC3mFjofKqc09LKKwXpG5VmSPOjsVlr0WV-C0N2J61hkNi3Xpkd9iopSmtgU8sjdE1aECcXtn8wxchnQkfNbfvO-COM/s1600/image3.png\" style=\"width: 100%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>Let’s now take a look at allocation and deallocation. <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::Allocate</span> accounts for 7% and <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::Deallocate</span> accounts for 6.8% of the runtime. A record of all allocations in the arena are stored in a vector ordered by their offsets within the memory arena. Entries in this sorted data structure are inserted, removed and searched. These operations are all <b>O(N)</b> in a vector. Could an <span style=\"color: #0d904f; font-family: courier;\">std::multimap</span> with the offset as the key be better? A multimap is needed because the records are ordered by their offsets and there may be multiple tensors with the same offset. Removal and insertion are <b>O(logN)</b> but search would still be <b>O(N)</b> as we are searching for the tensor id and not the offset. The best way to find out is to test and profile.</p>

<p>Replacing the vector with a multimap actually slows down the arena code: it is almost three times slower than using a vector! While this goes against intuition, this is commonly found when optimizing code. Operations on a set or a map have linear or logarithmic complexities, however, there is also a constant value in the complexity. This value is higher than the constant value for the complexity of a vector. We also iterate through the records, which is much cheaper for a vector than for a list or multimap. A list was also tested, coming in at twice as slow as a vector.</p> 

<p>Deallocation can still be improved though. <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::Deallocate</span> iterates through the records and when it finds the record to deallocate, it removes it from the vector. This has O(N2) complexity. The <span style=\"color: #0d904f; font-family: courier;\">memcpy</span> seen in the profile above comes from the frequent calls to <span style=\"color: #0d904f; font-family: courier;\">std::vector::erase</span>. It is much more efficient to mark records to be erased and then to erase them in one pass using <span style=\"color: #0d904f; font-family: courier;\">std::remove_if</span>. The second optimization here is to look at how tensors are typically deallocated: <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::ResetAllocationsAfter</span> deallocates all tensors from a node until the end of the graph. To address this, <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::DeallocateAfter(int32_t node)</span> was added which iterates once through all the records, marking those which are allocated after the node. <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::ResolveDeallocations</span> erases these in one pass making deallocation O(N). After these changes, <span style=\"color: #0d904f; font-family: courier;\">ResetAllocationsAfter</span> no longer appears in the profile! Commits are <a href=\"https://github.com/tensorflow/tensorflow/commit/509b811aba38294f451dd7beea3c27558ce1f7da\" target=\"_blank\">here</a> and <a href=\"https://github.com/tensorflow/tensorflow/commit/9e582c01e1a6f813d4c76a845fe3802fbc3140f8\" target=\"_blank\">here</a>.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjcVMdXbVIA-debMqWR-kltkIDR0381nhAGz9No2gHR_tONq4fbSPRrtEr3gO_J0A-hRK2OCiZ7Vb48l7tQjOlixc-Rx1JisMu5cAmxnDoUAAb3UQ_uZswvrwyJrpt2_CmWB7HcrKrzjPCBF9EmEpFMKbwYLNmlnziMxt5ixPu4iFDlpNtRofU2HLHXRA8/s1600/image4.png\" target=\"_blank\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjcVMdXbVIA-debMqWR-kltkIDR0381nhAGz9No2gHR_tONq4fbSPRrtEr3gO_J0A-hRK2OCiZ7Vb48l7tQjOlixc-Rx1JisMu5cAmxnDoUAAb3UQ_uZswvrwyJrpt2_CmWB7HcrKrzjPCBF9EmEpFMKbwYLNmlnziMxt5ixPu4iFDlpNtRofU2HLHXRA8/s1600/image4.png\" style=\"width: 100%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>The profile now looks very different with the overhead of tensor allocation gone from 49.9% of the runtime to 11%. This profile already looks much more reasonable. <span style=\"color: #0d904f; font-family: courier;\">SimpleMemoryArena::Allocate</span> is the last function left to optimize. For each tensor, this function iterates through the vector of records trying to find space for the current allocation. The complexity of this is <b>O(N<sup><small>2</small></sup>)</b>. This is a fundamental limitation of the Greedy By Size algorithm. Efficient use of memory comes at the cost of increased overhead. Although the complexity can’t be reduced, <b>N</b> can. We process nodes in the order in which they are executed. Allocation information for tensors which have been deallocated on already executed nodes is not needed anymore, it is only slowing things down. Records are purged periodically so that only records which are active are considered. On a large model, this significantly reduces <b>N</b>. <span style=\"color: #0d904f; font-family: courier;\">ArenaPlanner::ExecuteAllocations</span> is no longer the most expensive function! It has gone from 11% to 6% and a fully connected operator is now the most expensive function in the profile, which is what we expect when profiling neural network inference.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpwRYUSEqYWG2iBb-jdKpEHB9n7LqmIycVUdbZImZZUX_SsBtcpjnZ4neVsAdzusonvoruTnVMqomuQ7rEo_mnSQTyI8Bp9xN4hMEZibsrVv8LMMu6YMvpWf8AoXeLMNR-txstn66E-hN-QKaGJNjm-bC4wi2gHVx6GTfhcZ2MSoM4VN5ZmkL_ZP2XQ10/s1600/image6.png\" target=\"_blank\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpwRYUSEqYWG2iBb-jdKpEHB9n7LqmIycVUdbZImZZUX_SsBtcpjnZ4neVsAdzusonvoruTnVMqomuQ7rEo_mnSQTyI8Bp9xN4hMEZibsrVv8LMMu6YMvpWf8AoXeLMNR-txstn66E-hN-QKaGJNjm-bC4wi2gHVx6GTfhcZ2MSoM4VN5ZmkL_ZP2XQ10/s1600/image6.png\" style=\"width: 100%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>This is what a neural network profile should look like. Time should be spent running your model’s operators, not in the inference runtime.</p>

<p>The optimized memory arena is now publicly available as part of TensorFlow 2.13.</p>

<h2>Next Steps</h2>

<p>Today’s post walked you through an example of Simpleperf helping to find easy to fix inefficiencies in TFLite’s memory arena that would never have been found by just looking at the code. Pprof can display annotated source code, disassembly and graphs making it easy to find the bottlenecks in your on-device pipelines. </p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Wed, 09 Aug 2023 16:00:00 +0000"
2516,What's new in TensorFlow 2.13 and Keras 2.13?,https://blog.tensorflow.org/2023/07/whats-new-in-tensorflow-213-and-keras-213.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYIMKKNGUkhWyF3gL1qLpn7cQ3iQu5GleP-36OHbTJwn90YdRUk8vGTefc9ctjwPcJhyBbFlprd581nDsWEKfMAeAo9xuX8zKfxti8Fvl2f2v69Qmvt695cCJY1dfVPbMIlfWqMFKMEyBCgIaRLXypYCrHlob-OiAb0mvVbhmBEt65-agfmRWDMuaI/s1600/image1.png\" style=\"display: none;\" />

<em>Posted by the TensorFlow and Keras Teams</em>
  
<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRgwmbW2Tp7Q_Y3GTKSmkfboFNHuUizDaYh1uLrQSCZarfkvs1mK7OodevH9l318Ls8ddEmKNPewlpVhMJzKvtpktP6TeKniEEMAzgRrHq-D-kIEsoQnZyvc7n4pUVsn1RkFF066dnujQZ1htprWST0uSJftVZxQyc2Qm8aijQTMhrtJlj7rrEc6s7/s1600/Tensorflow-septmber-update-header%20%282%29.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRgwmbW2Tp7Q_Y3GTKSmkfboFNHuUizDaYh1uLrQSCZarfkvs1mK7OodevH9l318Ls8ddEmKNPewlpVhMJzKvtpktP6TeKniEEMAzgRrHq-D-kIEsoQnZyvc7n4pUVsn1RkFF066dnujQZ1htprWST0uSJftVZxQyc2Qm8aijQTMhrtJlj7rrEc6s7/s1600/Tensorflow-septmber-update-header%20%282%29.png\" /></a>

<a name=\"more\"></a><p></p>

<p>TensorFlow 2.13 and Keras 2.13 have been released! Highlights of this release include publishing Apple Silicon wheels, the new Keras V3 format being default for .keras extension files and many more!</p>

<h2>TensorFlow Core</h2>

<h4>Apple Silicon wheels for TensorFlow</h4>

<p>TensorFlow 2.13 is the first version to provide Apple Silicon wheels, which means when you install TensorFlow on an Apple Silicon Mac, you will be able to use the latest version of TensorFlow. The nightly builds for Apple Silicon wheels were released in March 2023 and this new support will enable more fine-grained testing, thanks to technical collaboration between Apple, MacStadium, and Google.</p>

<h4>tf.lite</h4>
  
<p>The Python TensorFlow Lite Interpreter bindings now have an option to use  <span style=\"color: #0d904f; font-family: courier;\">experimental_disable_delegate_clustering</span> flag to turn-off delegate clustering during delegate graph partitioning phase. You can set this flag in TensorFlow Lite interpreter Python API</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"color: #444444; font-family: courier;\">interpreter = new Interpreter(file_of_a_tensorflowlite_model, experimental_preserve_all_tensors=<span class=\"hljs-literal\">False</span>)</span></code></td></tr></tbody></table>

<p>The flag is set to <span style=\"color: #0d904f; font-family: courier;\">False</span> by default. This is an advanced feature in experimental that is designed for people who insert explicit control dependencies  via  <code>with tf.control_dependencies()</code>  or need to change graph execution order.</p>

<p>Besides, there are several operator improvements in TensorFlow Lite in 2.13</p>
<ul>
<li><span style=\"color: #0d904f; font-family: courier;\">add</span> operation now supports broadcasting up to 6 dimensions. This will remove explicit broadcast ops from many models. The new implementation is also much faster than the current one which calculates the entire index for both inputs the the input instead of only calculating the part that changes.</li>
  
<li>Improve the coverage for <a href=\"https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8\">16x8 quantization</a> by enabling int16x8 ops for <span style=\"color: #0d904f; font-family: courier;\">exp</span>, <span style=\"color: #0d904f; font-family: courier;\">mirror_pad</span>, <span style=\"color: #0d904f; font-family: courier;\">space_to_batch_nd</span>, <span style=\"color: #0d904f; font-family: courier;\">batch_to_space_nd</span></li> 

<li>Increase the coverage of integer data types</li>
  <ul><li>enabled int16 for <span style=\"color: #0d904f; font-family: courier;\">less</span>, <span style=\"color: #0d904f; font-family: courier;\">greater_than</span>, <span style=\"color: #0d904f; font-family: courier;\">equal</span>, <span style=\"color: #0d904f; font-family: courier;\">bitcast</span>, <span style=\"color: #0d904f; font-family: courier;\">bitwise_xor</span>, <span style=\"color: #0d904f; font-family: courier;\">right_shift</span>, <span style=\"color: #0d904f; font-family: courier;\">top_k</span>, <span style=\"color: #0d904f; font-family: courier;\">mul</span>, and int16 indices for <span style=\"color: #0d904f; font-family: courier;\">gather</span> and <span style=\"color: #0d904f; font-family: courier;\">gather_nd</span></li>
  <li>enabled int8 for <span style=\"color: #0d904f; font-family: courier;\">floor_div</span> and <span style=\"color: #0d904f; font-family: courier;\">floor_mod</span>, <span style=\"color: #0d904f; font-family: courier;\">bitwise_xor</span>, <span style=\"color: #0d904f; font-family: courier;\">bitwise_xor</span></li>
  <li>enabled 32-bit int for <span style=\"color: #0d904f; font-family: courier;\">bitcast</span>, <span style=\"color: #0d904f; font-family: courier;\">bitwise_xor</span>,&nbsp;<span style=\"color: #0d904f; font-family: courier;\">right_shift</span></li></ul>
</ul>

<h4>tf.data</h4>

<p>We have improved usability and added functionality for tf.data APIs.</p>

<p><span style=\"color: #0d904f; font-family: courier;\">tf.data.Dataset.zip</span> now supports Python-style zipping. Previously users were required to provide an extra set of parentheses when zipping datasets as in <span style=\"color: #0d904f; font-family: courier;\">Dataset.zip((a, b, c))</span>. With this change, users can specify the datasets to be zipped simply as <span style=\"color: #0d904f; font-family: courier;\">Dataset.zip(a, b, c)</span> making it more intuitive.</p>

<div>Additionally,&nbsp;<span style=\"color: #0d904f; font-family: courier;\">tf.data.Dataset.shuffle</span>&nbsp;now supports full shuffling. To specify that data should be fully shuffled, use&nbsp;<span style=\"color: #0d904f; font-family: courier;\">dataset = dataset.shuffle(dataset.cardinality())</span>. This will load the full dataset into memory so that it can be shuffled, so make sure to only use this with datasets of filenames or other small datasets.</div>

<p>We have also added a new <span style=\"color: #0d904f; font-family: courier;\">tf.data.experimental.pad_to_cardinality</span> transformation which pads a dataset with zero elements up to a specified cardinality. This is useful for avoiding partial batches while not dropping any data.</p>

<p>Example usage:</p>
<blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px;\"><span style=\"color: #0d904f; font-family: courier;\">ds = tf.data.Dataset.from_tensor_slices({'a': [1, 2]})<br />ds = ds.apply(tf.data.experimental.pad_to_cardinality(3))<br />list(ds.as_numpy_iterator())<br />[{'a': 1, 'valid': True}, {'a': 2, 'valid': True}, {'a': 0, 'valid': False}] <br /><br /></span><div>This can be useful, e.g. during eval, when partial batches are undesirable but it is also important not to drop any data.</div></blockquote>

<h4>oneDNN BF16 Math Mode on CPU</h4>

<p>oneDNN supports <a href=\"https://oneapi-src.github.io/oneDNN/enum_dnnl_fpmath_mode.html#detailed-documentation\" target=\"_blank\">BF16 math mode</a> where full FP32 tensors are implicitly down-converted to BF16 during computations for faster execution time. TensorFlow CPU users can enable this by setting the environment variable <span style=\"color: #0d904f; font-family: courier;\">TF_SET_ONEDNN_FPMATH_MODE</span> to <span style=\"color: #0d904f; font-family: courier;\">BF16</span>. This mode may negatively impact model accuracy. To go back to full FP32 math mode, unset the variable.</p>

<h2>Keras</h2>
  
<h4>Keras Saving format</h4>

<p>The new Keras V3 saving format, released in <a href=\"https://blog.tensorflow.org/2023/03/whats-new-in-tensorflow-212.html\" target=\"_blank\">TF 2.12</a>, is now the default for all files with the <span style=\"color: #0d904f; font-family: courier;\">.keras</span> extension.</p>
<p>You can start using it now by calling <span style=\"color: #0d904f; font-family: courier;\">model.save(“your_model.keras”)</span>.</p>

<p>It provides richer Python-side model saving and reloading with numerous advantages:</p>
<ul><blockquote>
<li>A <b>lightweight, faster</b> format:</li>
</blockquote></ul>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"ALT TEXT\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjXZQ34cVqejCXufc77ohHqz8xlV2B1rLelRk-35axBFELs1gfc1WG8Xs6Xk2KLZ1jzkb-pGqd807UgGTu17ncZ6ioKkogwM8OEh34gH8opFgdFcF0GmaoUtV-R5YBkHFWNoyfqh4kLY69tkiV8dnauiM0FG3cjbnSSIg20Ym50x3Tki20FlAwPEY19PY4/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<ul><blockquote>
<li><b>Human-readable:</b> The new format is <b>name-based</b>, with a more detailed serialization format that makes debugging much easier. What you load is exactly what you saved, from Python’s perspective.</li>
<li><b>Safer</b>: Unlike SavedModel, there is <b>no reliance on loading via bytecode or pickling</b> – a big advancement for secure ML, as pickle files can be exploited to cause arbitrary code execution at loading time.</li>
<li><b>More general</b>: Support for non-numerical states, such as <b>vocabularies</b> and <b>lookup tables</b>, is included in the new format.</li>
<li><b>Extensible</b>: You can add support for saving and loading exotic state elements in custom layers using&nbsp;<span style=\"color: #0d904f; font-family: courier;\">save_assets()</span>, such as a FIFOQueue – or anything else you want. You have full control of disk I/O for custom assets.</li>
</blockquote></ul>

<p>The legacy formats (h5 and Keras SavedModel) will stay supported in perpetuity. However, we recommend that you consider adopting the new Keras v3 format for saving/reloading in Python runtimes, and using&nbsp;<span style=\"color: #0d904f; font-family: courier;\">model.export()</span> for inference in all other runtimes (such as TF Serving).</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 25 Jul 2023 16:00:00 +0000"
2517,On-device fetal ultrasound assessment with TensorFlow Lite,https://blog.tensorflow.org/2023/06/on-device-fetal-ultrasound-assessment-with-tensorflow-lite.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi8sF1ZR3G1VqS2QV_ezdQQUzHHhrj2dArTKxiA1AVgsqfIxwj03tGHKyHOp5KXArD73iI0ddC46hewEPwN9NH4ZEB7g8SMvBnMqnESruQXqxj-U2-iMLUdDlAuyYvsRu-j1QImxa0d95UTq5mQJd9cTn94Oz8ZceRwHTnm79BATrj4ZJg6qqJsA7Et/s1600/Social%20-%20TensorFlow%20-%20Fetal%20ultrasound%20assessment%20with%20TensorFlow%20Lite.png\" style=\"display: none;\" />

<em>Posted by Angelica Willis and Akib Uddin, Health AI Team, Google Research</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLP4cZ-jPTE6AJWMnVjy9Md7BLgc-mIuXbLMPzJ2n9mksPyJJpIHw2mrHoANJHAaTsp4yaXcjegQPHXFm1UgLFSB3V7BrnTZRZn_6lPl-d_Htc1Uvg-2lp5RdTiqVk2jaG4pz6_2VKxaEfnKolND_0yi1bLyb9p2iplrBkklM55G9ZnBnlau7aJ9Ae/s1600/Header%20-%20TensorFlow%20-%20Fetal%20ultrasound%20assessment%20with%20TensorFlow%20Lite.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLP4cZ-jPTE6AJWMnVjy9Md7BLgc-mIuXbLMPzJ2n9mksPyJJpIHw2mrHoANJHAaTsp4yaXcjegQPHXFm1UgLFSB3V7BrnTZRZn_6lPl-d_Htc1Uvg-2lp5RdTiqVk2jaG4pz6_2VKxaEfnKolND_0yi1bLyb9p2iplrBkklM55G9ZnBnlau7aJ9Ae/s1600/Header%20-%20TensorFlow%20-%20Fetal%20ultrasound%20assessment%20with%20TensorFlow%20Lite.png\" /></a>

<a name=\"more\"></a><p></p>

<h1>How researchers at Google are working to expand global access to maternal healthcare with the help of AI</h1>

<p>TensorFlow Lite* is an open-source framework to run machine learning models on mobile and edge devices. It’s popular for use cases ranging from image classification, object detection, speech recognition, natural language tasks, and more. From <a href=\"https://www.youtube.com/watch?v=WC9x3jp_nV8\" target=\"_blank\">helping parents of deaf children learn sign language</a>, to <a href=\"https://blog.tensorflow.org/2019/02/air-cognizer-predicting-air-quality.html\" target=\"_blank\">predicting air quality</a>, projects using TensorFlow Lite are demonstrating how on-device ML could directly and positively impact lives by making these socially beneficial applications of AI more accessible, globally.  In this post, we describe how TensorFlow Lite is being used to help develop ultrasound tools in under-resourced settings.</p>

<h2>Motivation</h2>

<p><a href=\"https://www.who.int/news-room/fact-sheets/detail/maternal-mortality\" target=\"_blank\">According to the WHO</a>, complications from pregnancy and childbirth contribute to roughly 287,000 maternal deaths and 2.4 million neonatal deaths worldwide each year. As many as 95% of these deaths occur in under-resourced settings and many are preventable if detected early. Obstetric diagnostics, such as determining gestational age and fetal presentation, are important indicators in planning prenatal care, monitoring the health of the birthing parent and fetus, and determining when intervention is required. Many of these factors are traditionally determined by ultrasound.</p> 

<p>Advancements in sensor technology have made <a href=\"https://pubmed.ncbi.nlm.nih.gov/26683523/\" target=\"_blank\">ultrasound devices more affordable and portable</a>, integrating directly with smartphones. However, ultrasound requires years of training and experience, and, in many rural or underserved regions, there is a shortage of trained ultrasonography experts, making it difficult for people to access care. Due to this global <a href=\"https://www.thelancet.com/journals/langlo/article/PIIS2214-109X%2821%2900442-3\" target=\"_blank\">lack of availability</a>, it has been estimated that as many as <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5704652/\" target=\"_blank\">two-thirds of pregnant people</a> in these settings do not receive ultrasound screening during pregnancy. </p> 

<h2>Expanding access by enabling non-experts</h2>

<p>Google Research is building AI models to help expand access to ultrasound, including models  to predict gestational age and fetal presentation, to allow health workers with no background in ultrasonography to collect clinically useful ultrasound scans. These models make predictions from ultrasound video obtained using an easy-to-teach operating procedure, a <a href=\"https://ieeexplore.ieee.org/document/6103652\" target=\"_blank\">blind sweep protocol</a>, in which a user blindly sweeps the ultrasound probe over the patient's abdomen. In our <a href=\"https://www.nature.com/articles/s43856-022-00194-5\" target=\"_blank\">recent paper</a>, <i>“A mobile-optimized artificial intelligence system for gestational age and fetal malpresentation assessment”</i>, published in Nature Communications Medicine, we demonstrated that, when utilizing blind sweeps, these models enable these non-experts to match standard of care performance in predicting these diagnostics.</p> 

<h2>Blind Sweep Operating Procedure</h2>

<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQRaFpMQ5oRPg5V-yuJFqnRAyPWS_YTAGQLXSESFJOh8gDuBGrXJwVJQ7WtgBfmcGH_nOI1881OruWG3zeAc3rWpEWXLd-Nu8AO7OZifapLEnJUPp1EFjIFI9eaFN6EKwbLqzSi6nxsaqXqAf2cVCelqqLY727PgD6pdQNMBeQ9ImO0zeYCp7K7z1iKHI/s1600/On-device-fetal-ultrasound-side-by-side-1.gif\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"Moving image illustrating the bind sweep method from a lateral view on the left and arial view on the right\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQRaFpMQ5oRPg5V-yuJFqnRAyPWS_YTAGQLXSESFJOh8gDuBGrXJwVJQ7WtgBfmcGH_nOI1881OruWG3zeAc3rWpEWXLd-Nu8AO7OZifapLEnJUPp1EFjIFI9eaFN6EKwbLqzSi6nxsaqXqAf2cVCelqqLY727PgD6pdQNMBeQ9ImO0zeYCp7K7z1iKHI/s1600/On-device-fetal-ultrasound-side-by-side-1.gif\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>This blind-sweep ultrasound acquisition procedure can be performed by non-experts with only a few hours of ultrasound training.</i></td></tr></tbody></table>

<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFKHCUo8RKKY9QL0OeDrMAzDVDFAwUb1LF5MKuQHHoB-Om1k-rMqAHbcvuslm7Bv-cZ_W_aQHjFez-6Eut0VvOW5lDueZP4JU_ugD-Ty2WWLeBUEiB8kj_HUekqipXw10f5mwldasgHZlh6hkGDUUoMAqB9uOvAgn0Z-NauHnd_R8crkjN0yil2qAEZFw/s1600/TF-Model-Performance-charts%20%281%29.png\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"Graphs showing gestational age model performance on left and fetal presentation model performance on right\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFKHCUo8RKKY9QL0OeDrMAzDVDFAwUb1LF5MKuQHHoB-Om1k-rMqAHbcvuslm7Bv-cZ_W_aQHjFez-6Eut0VvOW5lDueZP4JU_ugD-Ty2WWLeBUEiB8kj_HUekqipXw10f5mwldasgHZlh6hkGDUUoMAqB9uOvAgn0Z-NauHnd_R8crkjN0yil2qAEZFw/s1600/TF-Model-Performance-charts%20%281%29.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i><b>Figure A</b> compares our blind sweep-based gestational age regression model performance with that of the clinical standard of care method for fetal age estimation from fetal biometry measured by expert sonographers. Boxes indicate 25th, 50th, and 75th percentile absolute error in days, and whiskers indicate 5th and 95th percentile absolute error (n = 407 study participants). <b>Figure B</b> shows the Receiver Operating Characteristic (ROC) curves for our blind sweep-based fetal malpresentation classification model, as well as specific performance curves for cases in which blind sweeps were collected by expert sonographers or novices (n = 623 study participants). See our recent <a href=\"https://www.nature.com/articles/s43856-022-00194-5\" target=\"_blank\">paper</a> for further details and additional analysis.</i></td></tr></tbody></table>

<h2>Model development</h2>

<p>Understanding that our target deployment environment is one in which users might not have reliable access to power and internet, we designed these models to be mobile-optimized. Our grouped convolutional LSTM architecture utilizes <a href=\"https://tfhub.dev/s?network-architecture=mobilenet-v2\" target=\"_blank\">MobileNetV2</a> for feature extraction on each video frame as it is received. The final feature layer produces a sequence of image embeddings which are processed by the convolutional LSTM cell state. Since the recurrent connections only operate on the less memory-intensive embeddings, this model can run efficiently in a mobile environment.  </p>

<p>For each subsequence of video frames that make up a sweep, we generate a clip-level diagnostic result, and in the case of gestational age, also produce a model confidence estimate represented as the predicted variance in the detected age. Clip-level gestational age predictions are aggregated via inverse variance weighting to produce a final case-level prediction. </p>

<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgH2p3X83t7oyMYkTrEepL-1cLFz2UzOJuhm1J6iKopYw5Z78LTw1-35u1468TQsrVgPJfb5Kn7q-Tkid4-mceGjTXAMB3Em-BtXekUxgl4KlAsgSaWKZBjjJRtAjefBBLQ177C2E0xYrvX3F2ZayN8cJjFd8lhYDoZFMprBhRJS7KPctBl81wjSwft/s1600/image5.png\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"Flow chart depicting Gestational Age LSTM Video Model\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgH2p3X83t7oyMYkTrEepL-1cLFz2UzOJuhm1J6iKopYw5Z78LTw1-35u1468TQsrVgPJfb5Kn7q-Tkid4-mceGjTXAMB3Em-BtXekUxgl4KlAsgSaWKZBjjJRtAjefBBLQ177C2E0xYrvX3F2ZayN8cJjFd8lhYDoZFMprBhRJS7KPctBl81wjSwft/s1600/image5.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table>

<h4>Optimization through TensorFlow Lite</h4>

<p>On-device ML has many advantages, including providing enhanced privacy and security by ensuring that sensitive input data never needs to leave the device. Another important advantage of on-device ML, particularly for our use case, is the ability to leverage ML offline in regions with low internet connectivity, including where smartphones serve as a stand-in for more expensive traditional devices. Our prioritization of on-device ML made TensorFlow Lite a natural choice for optimizing and evaluating the memory use and execution speed of our existing models, without significant changes to model structure or prediction performance.</p>

<p>After converting our models to TensorFlow Lite using the <a href=\"https://www.tensorflow.org/lite/models/convert/convert_models#python_api_\" target=\"_blank\">converter API</a>, we explored various optimization strategies, including <a href=\"https://www.tensorflow.org/lite/performance/post_training_quantization\" target=\"_blank\">post-training quantization</a> and alternative delegate configurations. Leveraging a TensorFlow Lite GPU delegate, optimized for sustained inference speed, provided the most significant boost to execution speed. There was a roughly 2x speed improvement with no loss in model accuracy, which equated to real-time inference of more than 30 frames/second with both the gestational age and fetal presentation models running in parallel on Pixel devices. We benchmarked model initialization time, inference time and memory usage for various delegate configurations using TensorFlow Lite <a href=\"https://www.tensorflow.org/lite/performance/measurement\" target=\"_blank\">performance measurement tools</a>, finding the optimal configuration across multiple mobile device manufacturers.</p>

<p>These critical speed improvements allow us to leverage the model confidence estimate to provide sweep-quality feedback to the user immediately after the sweep was captured. When low-quality sweeps are detected, users can be provided with tips on how their sweep can be improved (for example, applying more pressure or ultrasound gel), then prompted to re-do the sweep.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgp6xg54KydyzChZ8vhJ8XEyiC2kgHnGeZeuZAkuSkd3CiIqo0odUqcU496DUxtnQN4wE7V213GsSsDgGaWNIQ3V88AEXLIdm6Q-KpXhUufT1wmDL7O2qethVYTDwMvux18tthOIMO-0dSE8yeFQZ6moXR_KIAuG5eJaKBWJUA14muPcB-s0dQ0g1UJDCo/s1600/image4.gif\"><img alt=\"Screen capture of sweep exam being conducted\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgp6xg54KydyzChZ8vhJ8XEyiC2kgHnGeZeuZAkuSkd3CiIqo0odUqcU496DUxtnQN4wE7V213GsSsDgGaWNIQ3V88AEXLIdm6Q-KpXhUufT1wmDL7O2qethVYTDwMvux18tthOIMO-0dSE8yeFQZ6moXR_KIAuG5eJaKBWJUA14muPcB-s0dQ0g1UJDCo/s1600/image4.gif\" style=\"width: 50%;\" /></a></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>We developed a mobile application that demonstrates what a potential user experience could look like and allows us to evaluate our TensorFlow Lite models in realistic environments. This app enables ultrasound video frames to be received directly from portable ultrasound devices that support this use case.</i></td></tr></tbody></table></div>

<h2 style=\"text-align: left;\">Looking ahead</h2>

<p>Our vision is to enable safer pregnancy journeys using AI-driven ultrasound that could broaden access globally. We want to be thoughtful and responsible in how we develop our AI to maximize positive benefits and address challenges, guided by our <a href=\"https://ai.google/principles/\" target=\"_blank\">AI Principles</a>. TensorFlow Lite has helped enable our research team to explore, prototype, and de-risk impactful care-delivery strategies designed with the needs of lower-resource communities in mind.</p>


<p>This research is in its early stages and we look forward to opportunities to expand our work. To achieve our goals and scale this technology for wider reach globally, partnerships are critical. We are excited about our partnerships with <a href=\"https://www.nm.org/\" target=\"_blank\">Northwestern Medicine</a> in the US and <a href=\"https://www.jacarandahealth.org/\" target=\"_blank\">Jacaranda Health</a> in Kenya to further develop and evaluate these models. With more automated and accurate evaluations of maternal and fetal health risks, we hope to lower barriers and help people get timely care.</p>


<h3>Acknowledgements</h3>

<p><em><strong>This work was developed by an interdisciplinary team within Google Research:</strong> Ryan G. Gomes, Chace Lee, Angelica Willis, Marcin Sieniek, Christina Chen, James A. Taylor, Scott Mayer McKinney, George E. Dahl, Justin Gilmer, Charles Lau, Terry Spitz, T. Saensuksopa, Kris Liu, Tiya Tiyasirichokchai, Jonny Wong, Rory Pilgrim, Akib Uddin, Greg Corrado, Lily Peng, Katherine Chou, Daniel Tse, &amp; Shravya Shetty.</em></p>

<div style=\"text-align: left;\"><em><strong>This work was developed in collaboration with:</strong></em></div>
<div style=\"text-align: left;\"><em>Department of Obstetrics and Gynaecology, University of Zambia School of Medicine, Lusaka, Zambia</em></div>
<div style=\"text-align: left;\"><em>Department of Obstetrics and Gynecology, University of North Carolina School of Medicine, Chapel Hill, NC, USA</em></div>
<div style=\"text-align: left;\"><em>UNC Global Projects—Zambia, LLC, Lusaka, Zambia</em></div>
  
<p><em><strong>Special thanks to:</strong> Yun Liu, Cameron Chen, Sami Lachgar, Lauren Winer, Annisah Um’rani, and Sachin Kotwani</em></p>



<p><small>*TensorFlow Lite has not been certified or validated for clinical, medical, or diagnostic purposes. TensorFlow Lite users are solely responsible for their use of the framework and independently validating any outputs generated by their project. </small></p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 20 Jun 2023 16:00:00 +0000"
2518,Augmenting recommendation systems with LLMs,https://blog.tensorflow.org/2023/06/augmenting-recommendation-systems-with.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidaxPxHcwdaf6A0Obz6XG9olWAQyaEaMEV9G0LemGgy2VOnr6LQnHfZJW5xiIsASZtjh12k2fZQjgyexlArNcXf7VlLbgPTe1Is2aPWGZPC0RdFXJGdN829C99bV_vZT71FNADkIdc3HH_TpcNyHyjdwjBSe_--rJ2OM7fokaYLUvh4Tulg2yLq28d/s1600/Social---TensorFlow---Leveraging-LLMs-in-your-recommendation-systems.png\" style=\"display: none;\" />

<em>Posted by Wei Wei, Developer Advocate</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFwce3FRplW_THDff3QhldCkucOxUMLX-webj6doJnJLHaLVnm9v517Zp6q4TH2pFmoCE4JznzsjKU-6w4NOEyYsEOJgVEvk77HuH8-455k9oyX6dbiSPHO0_7ydYrPSaYql12QN9rnGYA6tJUpGcy0Qdu1Y4nItcaTMuPZpni-UfsjTnXKyFyVLWh/s1600/Header%20-%20TensorFlow%20-%20Leveraging%20LLMs%20in%20your%20recommendation%20systems.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFwce3FRplW_THDff3QhldCkucOxUMLX-webj6doJnJLHaLVnm9v517Zp6q4TH2pFmoCE4JznzsjKU-6w4NOEyYsEOJgVEvk77HuH8-455k9oyX6dbiSPHO0_7ydYrPSaYql12QN9rnGYA6tJUpGcy0Qdu1Y4nItcaTMuPZpni-UfsjTnXKyFyVLWh/s1600/Header%20-%20TensorFlow%20-%20Leveraging%20LLMs%20in%20your%20recommendation%20systems.png\" /></a>

<a name=\"more\"></a><p></p>


<p>Large language models (LLMs) are taking the world by storm, thanks to their powerful ability to generate text, translate languages, and answer questions in a coherent and informative way. At Google I/O 2023, we released the <a href=\"https://developers.generativeai.google/guide\" target=\"_blank\">PaLM API</a> as ‘public preview’ so that many developers can start building apps with it. While PaLM API already has excellent documentation on its <a href=\"https://developers.generativeai.google/guide\" target=\"_blank\">extensive usage and best practices</a>, in this blog we are going to take a more focused approach to explore how to leverage LLMs to augment your ML systems in a practical application: recommendation systems.</p>

<p>As a refresher, modern recommendation systems often follow a retrieval-ranking architecture, which enables them to effectively and efficiently filter and rank relevant items to maximize the utility in production. You can go through this <a href=\"https://codelabs.developers.google.com/tfrecommenders-flutter#0\" target=\"_blank\">codelab</a> to learn about building a fullstack movie recommendation system using TensorFlow and Flutter.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Demonstration of the retrieval-ranking architecture where candidate items move from retrieval to ranking, then post-ranking.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhT7_z2Se7OnZTdExokN9Zs2_KevXHdPJ-Y5E4uGNz-5g6l_FMJdma-O1jMA-VWE50rgT3slXCLrtYUgNKq_Jq0ljjQgvloRQ1W_MBEBcquRV-XRpp56Hm3MfP7qEV6zwUkONhucwnO4DumAPVB53KKOOWMCUUgrWsgNIxL4LFcRW8E53gd04sAXJZz/s16000/Chart%201%20-%20TensorFlow%20-%20Leveraging%20LLMs%20in%20your%20recommendation%20systems.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>We will discuss how LLMs can be incorporated into this retrieval-ranking pipeline.</p>

<h3>Conversational recommendations</h3>

<p>
If you already have access to <a href=\"https://bard.google.com/\" target=\"_blank\">Bard</a>, you can ask it to create recommendations for you interactively in a dialogue. Here is an example of asking Bard for movie recommendations:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"A user asks 'I'm in the mood for some drama movies with artistic elements tonight. Could you recommend three? Titles only. No other text' Bard responds 'Sure, here are three drama movies with artistic elements that you might enjoy: The Tree of Life, The Piano Teacher, The Passion of Joan of Arc'\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSqbn9YARgvggZCnYSqYtgSb-Txl5a7Ii_FH9LDwdwcBAGhnJDOYi5AvYA5cMBIElXKBv7v_8iwG_7SHNZn4gwlmqcTQQZopQ83MvORSttQAVwGOs30PGpj0F7ikeOGX10BsZrs-kb6VGU0OVwd01gx8tpAkDLWaBYl_JXlZTLIiYF_dOPlidVeCDc/s1896/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

  
<p>As a developer, you can build a similar functionality in your own applications, using the <a href=\"https://developers.generativeai.google/guide/palm_api_overview#chat_service\" target=\"_blank\">PaLM API Chat service</a> with minimal effort:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">prompt = <span class=\"hljs-string\">\"\"\"You are a movie recommender and your job is to recommend new movies based on user input.
So for user 42, he is in the mood for some drama movies with artistic elements tonight.
Could you recommend three? Output the titles only. Do not include other text.\"\"\"</span>
response = palm.chat(messages=prompt)
<span class=\"hljs-built_in\">print</span>(response.last)

<span class=\"hljs-comment\"># Sure, here are three drama movies with artistic elements that I recommend for user 42:</span>
<span class=\"hljs-comment\">#</span>
<span class=\"hljs-comment\"># 1. The Tree of Life (2011)</span>
<span class=\"hljs-comment\"># 2. 20th Century Women (2016)</span>
<span class=\"hljs-comment\"># 3. The Florida Project (2017)</span>
<span class=\"hljs-comment\">#</span>
<span class=\"hljs-comment\"># I hope you enjoy these movies!</span></span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, Liberation Mono, Courier New, monospace\" style=\"font-size: 12px;\">
</span></code></td></tr></tbody></table>

<p>The PaLM API also allows you to help your user continue the exploration and interactively refine the recommendations (e.g., asking to swap The Florida Project for another one) in a dialogue, which is what <a href=\"https://developers.generativeai.google/guide/palm_api_overview#chat_service\" target=\"_blank\">Chat service</a> is designed for. This kind of conversational recommendation interface (think having a knowledgeable chatbot that guides a customer along the way in your shopping app) provides a fluid and personalized experience for the users, and can sometimes be a very appealing addition to your existing recommendation surfaces.</p>

<h3>Sequential recommendations</h3>

<p>Recommendations would be much more useful if your system knows what your users may like. One way to find out your users’ interest is looking at their historical activities and then extrapolating. This is often called ‘sequential recommendation’ because the recommender looks at the sequence of items that have been interacted with and infers what to recommend. Usually you need to use a ML library (i.e., <a href=\"https://www.tensorflow.org/recommenders/examples/sequential_retrieval\" target=\"_blank\">TensorFlow Recommenders</a>) to achieve this. But now with the power of LLMs, you can also do this with the <a href=\"https://developers.generativeai.google/guide/palm_api_overview#palm_api_for_text_and_chat\" target=\"_blank\">PaLM API Text service</a>:</p>
  
<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">prompt = <span class=\"hljs-string\">\"\"\"You are a movie recommender and your job is to recommend new movies based on the sequence of movies that a user has watched. You pay special attention to the order of movies because it matters.

User 42 has watched the following movies sequentially:

\"Margin Call\",
“The Big Short”,
\"Moneyball\",
\"The Martian\",

Recommend three movies and rank them in terms of priority. Titles only. Do not include any other text.
\"\"\"</span>

response = palm.generate_text(
   model=<span class=\"hljs-string\">\"models/text-bison-001\"</span>, prompt=prompt, temperature=<span class=\"hljs-number\">0</span>
)
<span class=\"hljs-built_in\">print</span>(response.result)

<span class=\"hljs-comment\"># 1. The Wolf of Wall Street</span>
<span class=\"hljs-comment\"># 2. The Social Network</span>
<span class=\"hljs-comment\"># 3. Inside Job</span></span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, Liberation Mono, Courier New, monospace\" style=\"font-size: 12px;\">
</span></code></td></tr></tbody></table>

<p>This example prompts the <a href=\"https://developers.generativeai.google/guide/palm_api_overview#text_service\" target=\"_blank\">Text service</a> with 4 movies that have been watched and asks the PaLM API to generate new recommendations based on the sequence of past movies.</p>

<h3>Rating predictions</h3>

<p>In the ranking phase of modern recommendation engines, a list of candidates needs to be sorted based on certain criteria. This is usually done by using a learning-to-rank library (such as, <a href=\"https://www.tensorflow.org/ranking\" target=\"_blank\">TensorFlow Ranking</a>) to predict the ordering. Now you can do this with the PaLM API. Here is an example of predicting movie ratings:
</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">prompt = <span class=\"hljs-string\">\"\"\"You are a movie recommender and your job is to predict a user's rating (ranging from 1 to 5, with 5 being the highest) on a movie, based on that user's previous ratings.

User 42 has rated the following movies:
\"Moneyball\" 4.5
\"The Martian\" 4
\"Pitch Black\" 3.5
“12 Angry Men” 5

Predict the user's rating on \"The Matrix\". Output the rating score only. Do not include other text.
\"\"\"</span>
response = palm.generate_text(model=<span class=\"hljs-string\">\"models/text-bison-001\"</span>, prompt=prompt)
<span class=\"hljs-built_in\">print</span>(response.result)

<span class=\"hljs-comment\"># 4.5</span></span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, Liberation Mono, Courier New, monospace\" style=\"font-size: 12px;\">
</span></code></td></tr></tbody></table>

<p>The PaLM API predicted a high score for The Matrix. You can ask the PaLM API to predict a rating for a list of candidate movies one by one and then sort them in order before making final recommendations; this process is called ‘<a href=\"https://en.wikipedia.org/wiki/Learning_to_rank#Pointwise_approach\" target=\"_blank\">pointwise ranking</a>’. You can even leverage the PaLM API to do <code><a href=\"https://en.wikipedia.org/wiki/Learning_to_rank#Pairwise_approach\" target=\"_blank\">pairwise ranking</a></code> or <code><a href=\"https://en.wikipedia.org/wiki/Learning_to_rank#Listwise_approach\" target=\"_blank\">listwise ranking</a></code>, if you adjust the prompt accordingly.</p>

<p>For a more comprehensive study on rating prediction with LLMs, you can refer to this <a href=\"https://arxiv.org/pdf/2305.06474.pdf\" target=\"_blank\">paper</a> from Google.</p>

<h3>Text embedding-based recommendations</h3>

<p>At this point you may be asking: all the use cases so far involve well known movies that the LLM is already aware of, so maybe there is a requirement that candidate items need to be captured in LLMs in advance (in the training phase)? What if I have private items not known to LLMs beforehand? How could I use the PaLM API then?</p>

<p>Not to worry. The <a href=\"https://developers.generativeai.google/guide/palm_api_overview#palm_api_for_embeddings\" target=\"_blank\">PaLM API for Embeddings</a> can help you out in this case. The basic idea is to embed text associated with your items (for example, product description, movie plot) into vectors and use <a href=\"https://en.wikipedia.org/wiki/Nearest_neighbor_search#:~:text=Nearest%20neighbor%20search%20(NNS)%2C,the%20larger%20the%20function%20values.\" target=\"_blank\">nearest neighbor search</a> techniques (i.e., using the tf.math.top_k op from TensorFlow for brute force search or <a href=\"https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html\" target=\"_blank\">Google ScaNN</a>/<a href=\"https://developers.generativeai.google/examples/vectordb_with_chroma\" target=\"_blank\">Chroma</a> for approximate search) to identify similar items to recommend, based on a user query. Let’s walk through a simple example.</p>

<p>Suppose you are building a news app and at the bottom of each news article you want to recommend similar news to your users. First you can embed all news articles by calling the PaLM API Embedding service like below:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">embedding = palm.generate_embeddings(model=<span class=\"hljs-string\">'embedding-gecko-001'</span>, text=<span class=\"hljs-string\">'example news article text'</span>)[<span class=\"hljs-string\">'embedding'</span>]</span></code></td></tr></tbody></table>

<p>For simplicity, let’s assume you store all the news texts and their embeddings in a simple Pandas DataFrame with 2 columns: <code>news_text</code> and <code>embedding</code>. Then you can recommend interestings news to your users using the following:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">recommend_news</span>(<span class=\"hljs-params\">query_text, df, topk=<span class=\"hljs-number\">5</span></span>):
  <span class=\"hljs-string\">\"\"\"
  Recommend news based on user query
  \"\"\"</span>
  query_embedding = palm.generate_embeddings(model=<span class=\"hljs-string\">'embedding-gecko-001'</span>, text=query_text)
  dot_products = np.dot(np.stack(df[<span class=\"hljs-string\">'embedding'</span>]), query_embedding[<span class=\"hljs-string\">'embedding'</span>])
  result = tf.math.top_k(dot_products, k=topk)
  indices = result.indices.numpy()
  <span class=\"hljs-keyword\">return</span> df.loc[indices][<span class=\"hljs-string\">'news_text'</span>]

recommend_news(<span class=\"hljs-string\">'news currently being read'</span>, dataframe, <span class=\"hljs-number\">5</span>)</span></code></td></tr></tbody></table>

<p>The <code>recommend_news</code> function computes the query embedding’s <a href=\"https://developers.google.com/machine-learning/clustering/similarity/measuring-similarity\" target=\"_blank\">dot product similarity</a> with all news articles using the pre-computed embeddings, and then identifies 5 news articles most similar to what your user is reading.</p>

<p>This approach is often a quick and effective way to generate candidates and create recommendations based on item similarities. It may be sufficient for many use cases and can be particularly useful in the <a href=\"https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)#New_item\" target=\"_blank\">item cold start situation</a>.</p>

<p>In practice, the candidate generation phase of modern large scale recommenders often consists of multiple sources. For example, you can use a mixer of text embedding-based retrieval, collaborative filtering, users’ subscriptions (i.e., new uploads from followed accounts on YouTube), real time trending items (i.e., breaking news) and etc. Thus, leveraging the <a href=\"https://developers.generativeai.google/guide/palm_api_overview#palm_api_for_embeddings\" target=\"_blank\">PaLM API Embedding service</a> could be a helpful augment for the retrieval stage in your existing recommendation system.</p>


<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"An example of text embedding-based retrieval.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjpOkFgUYaj3rXJiHOxDnKyh4OWUHsS0BCD-PhDuV16zwDoRHvR382KmtDLnv622KRfBd6ONt1c-WcV9EMzKJ74TkfLsDp2gj-umEyzhFiW2HltOszgxPd_1IjFI1WPC945EoH1VayAzKey2gbTW0zIfZ2D87RxZPqM-mMKjPjx4JCp1PZ86U-DeKsR/s16000/Chart%202%20-%20TensorFlow%20-%20Leveraging%20LLMs%20in%20your%20recommendation%20systems.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<h3>Text embeddings as side features</h3>

<p>In addition, you could also use the text embeddings as side features in a recommendation model. The text embeddings capture the semantic information of the candidate items via the description text and can potentially help improve the model accuracy. For example, in this <a href=\"https://www.tensorflow.org/recommenders/examples/featurization#movie_model\" target=\"_blank\">TensorFlow Recommenders feature preprocessing tutorial</a>, if you have pre-computed text embeddings for movie plot using LLMs, it’s fairly easy to inject them into the model as side features, when concatenating all the embeddings:</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MovieModel</span>(tf.keras.Model):

   <span class=\"hljs-comment\"># ......</span>

   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">call</span>(<span class=\"hljs-params\">self, inputs</span>):
       <span class=\"hljs-keyword\">return</span> tf.concat(
           [
               self.title_embedding(inputs[<span class=\"hljs-string\">\"movie_title\"</span>]),
               self.title_text_embedding(inputs[<span class=\"hljs-string\">\"movie_title\"</span>]),
               inputs[<span class=\"hljs-string\">\"movie_plot_embedding\"</span>], <span class=\"hljs-comment\"># inject movie plot embedding</span>
           ],
           axis=<span class=\"hljs-number\">1</span>,
       )</span></code></td></tr></tbody></table>

<p>The default PaLM Embedding service returns a vector of 768 floating numbers for any text, which may be too much. You can reduce the dimensions by initializing a <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\" target=\"_blank\">tf.keras.layers.Embedding</a> layer with the movie plot embedding matrix and then stacking a fully connected layer on top of it to project it down to fewer dimensions.</p>


<h3>Conclusion</h3>


<p>We have shared several ideas on leveraging LLMs to augment recommenders. Obviously, this is just scratching the surface as there are more not covered here. Also note that there may still be a long way before they can make it into production (i.e., latency and cost issues). But we hope this blog inspires you to start thinking about how you can improve your own recommendation systems with LLMs.</p>

<p>Lastly, we are holding an online Developer Summit on Recommendation Systems on June 9, 2023. If you want to learn more about Google products related to building recommendation systems, feel free to sign up <a href=\"https://rsvp.withgoogle.com/events/recommendation-system-dev-summit\" target=\"_blank\">here</a> to attend.</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 06 Jun 2023 21:00:00 +0000"
2519,Visualizing and interpreting decision trees,https://blog.tensorflow.org/2023/06/visualizing-and-interpreting-decision.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4evToPaDZpHLq9vcpFjJ_BTAW2ck5UvZ-awvcQRETQB3omK8PW6KxaZksJz2cX9FQiZAZZ_lGtOh_8eyb4gBmVW6akBpRzn8aBb2y6O8283q_2Qu4xUccI7t5X5oHHKHp37_DuEfc7ccWIvYSJQ3knvaIAN8cXY1bgtQWGeaMyfKBcjGa22CaE0IQ/s1600/Social%20%281%29.png\" style=\"display: none;\" />

<em>Posted by <a href=\"https://explained.ai/\" target=\"_blank\">Terence Parr</a>, Google</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjuxlMytt4e5sTGjF2M5LzU9UbC3LczfNPqLQ9_1MaEHstY3SUrK_85c2CnW7PALKZ3k3DQDeE94gsyKd6GY-TD17_gwlT8SihSANzH9P-wz2o2yN1MJKomv3OHz1e_UlJt4AlVHefORRaQM5gEYjXPEML6o2xbAIagq4E6D6IhU1wgK9NT4AKQXDKy/s1600/Header%20%281%29%20%281%29.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjuxlMytt4e5sTGjF2M5LzU9UbC3LczfNPqLQ9_1MaEHstY3SUrK_85c2CnW7PALKZ3k3DQDeE94gsyKd6GY-TD17_gwlT8SihSANzH9P-wz2o2yN1MJKomv3OHz1e_UlJt4AlVHefORRaQM5gEYjXPEML6o2xbAIagq4E6D6IhU1wgK9NT4AKQXDKy/s1600/Header%20%281%29%20%281%29.png\" /></a>

<a name=\"more\"></a><p></p>

<p>Decision trees are the fundamental building block of Gradient Boosted Trees and Random Forests, the two most popular machine learning models for tabular data. To learn how decision trees work and how to interpret your models, visualization is essential.</p>

<p>TensorFlow recently published a new <a href=\"https://www.tensorflow.org/decision_forests/tutorials/dtreeviz_colab\" target=\"_blank\">tutorial</a> that shows how to use <a href=\"https://github.com/parrt/dtreeviz\" target=\"_blank\">dtreeviz</a>, a state-of-the-art visualization library, to visualize and interpret <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow Decision Forest Trees</a>.</p>

<p>The dtreeviz library, first released in 2018, is now the most popular visualization library for decision trees. The library is constantly being updated and improved, and there is a large community of users who can <a href=\"https://stackoverflow.com/questions/tagged/dtreeviz\" target=\"_blank\">provide support and answer questions</a>. There is a helpful <a href=\"https://www.youtube.com/watch?v=4FC1D9SuDBc\" target=\"_blank\">YouTube video</a> and article on the <a href=\"https://explained.ai/decision-tree-viz/index.html\" target=\"_blank\">design of dtreeviz</a>.</p>

<p>Let’s demonstrate how to use dtreeviz to interpret decision tree predictions.</p>

<p>At a basic level, a decision tree is a machine learning model that learns the relationship between observations and target values by examining and condensing training data into a binary tree. Each leaf in the decision tree is responsible for making a specific prediction. For regression trees, the prediction is a value, such as price. For classifier trees, the prediction is a target category, such as cancer or not-cancer.</p> 

<p>Any path from the root of the decision tree to a specific leaf predictor passes through a series of (internal) decision nodes. Each decision node compares a single feature's value with a specific split point value learned during training. Making a prediction means walking from the root down the tree, comparing feature values, until we reach a leaf. Consider the following simple decision tree that tries to classify animals based upon two features, the number of legs and the number of eyes.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration of a simple decision tree to select an animal based on number of legs (more than or equal to 4; if no = penguin, and/or number of eyes (more than or equal to three; if yes = spider, if no = dog)\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5flFKVZOKjSFkTHzlB7YwDR5uushqWt0gzo_LlYIVMCFMNZLbkZp0FNmPa1zJuKd1-fFtSH9WH9S9W7uIhHjxc1gXzwfWxgRiaUWeGg_waQwfHuSs6ksqdElf-FDu9kZVFvVNVEfpMLvI_05EIXaVzQENFbz5uYB-lIN8SrxCENDCwdS9G5lZluiR/s1600/image3.png\" style=\"width: 60%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>Let's say that our test animal has four legs and two eyes. To classify the test animal, we start at the root of the tree and compare our test animal’s number of legs to four.  Since the number of legs is equal to four, we move to the left.  Next, we test the number of eyes to three. Since our test animal only has two eyes, we move to the right and arrive at a leaf node, which gives us a prediction of <b>dog</b>. To learn more, check out this <a href=\"https://developers.google.com/machine-learning/decision-forests\" target=\"_blank\">class on decision trees</a>.</p>

<p>To interpret decision tree predictions we use dtreeviz to visualize how each decision node in the tree splits up a specific feature's domain, and to show the distribution of training instances in each leaf. For example, here is the first few levels of a classification tree from a Random Forest trained on the <a href=\"https://allisonhorst.github.io/palmerpenguins/articles/intro.html\" target=\"_blank\">Penguin</a> data set:</p>


<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration of the first few levels of a classification tree from a Random Forest trained on the Penguin data set\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjx5qambLYHZh3C7OIpdMrE1t2PtEMOO7W50CJDrz8QaZeXYVO7v4Dk_v1kV7wzuTjwkzxbG_jEk6eRL7mfteYJ9M8R1VLEmJmfaaoSR7R0K5BezRPUKT6m7Pv8YSc7NDTvv7jD5tNaJChxn5SjbV_2MWNnuDJRv89Co5yTfHniOQA5I1BGspddnEyk/s1600/image4.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>To make a prediction for a test penguin, this decision tree first tests the flipper_length_mm feature and if it's less than 206, it descends to the left and then tests the island feature; otherwise, if the flipper length were &gt;= 206, it would descend to the right and test the bill_length_mm feature. (Check out the <a href=\"https://www.tensorflow.org/decision_forests/tutorials/dtreeviz_colab\" target=\"_blank\">tutorial</a> for a description of the visualization elements.)</p>

<p>The code used to generate that tree is short. Given a classifier model called cmodel, we collect and wrap up all of the information about the data and model then ask dtreeviz to visualize the tree:</p>

<div><span id=\"docs-internal-guid-515c23f6-7fff-60f8-64e0-81ba93fe06ce\"><span style=\"font-family: courier;\"><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">penguin_features = [f.name for f in cmodel.make_inspector().features()]</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">penguin_label = \"species\" &nbsp; # Name of the classification target label</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">viz_cmodel = dtreeviz.model(cmodel,</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tree_index=3, # pick tree from forest</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X_train=train_ds_pd[penguin_features],</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y_train=train_ds_pd[penguin_label],</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;feature_names=penguin_features,</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_name=penguin_label,</span></p><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"vertical-align: baseline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class_names=classes)</span></p><span style=\"vertical-align: baseline;\">viz_cmodel.view()</span></span></span><p><span><span style=\"vertical-align: baseline;\"><span style=\"font-family: courier;\"></span></span></span></p></div>

<p>And here are the first few layers of a regressor tree from a Random Forest trained on the <a href=\"https://archive.ics.uci.edu/ml/datasets/abalone\" target=\"_blank\">Abalone</a> data set:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration of the first few layers of a regressor tree from a Random Forest trained on the Abalone data set\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghL8W1zK344tdXR2ZSAX8dU97nFwVGc-w6nG7a9dO6uI8nLx6vk8yLkeoTBSEE8dp94sGPlVk_wV4tt87rsTy6I9Rl9Kl3vGtd5Qs8Acw6j4fb2Zc8IPOZFGjwvOZbrcJxlDHE2XAfKp2fNxXCd83Ccmikr9C-oxGca7YcqGwW6zHkafqzQvwwHmkw/s1600/image5.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>Another useful tool for interpretation is to visualize how a specific test instance (feature vector) weaves its way down the tree from the root to a specific leaf. By looking at the path taken by a decision tree when making a prediction, we learn why a test instance was classified in a particular way. We know which features are tested and against what range of values. Imagine being rejected for a bank loan. Looking at the decision tree could tell us exactly why we were rejected (e.g., credit score too low or debt to income ratio too high). Here's an example showing the decisions made by the decision tree for a specific Penguin instance, with the path highlighted in orange boxes and the test instance features shown at the bottom left:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration of the decisions made by the decision tree for a specific Penguin instance, with the path highlighted in orange boxes and the test instance features\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-Qlam26fG-A9OlFJh8vq_ZvxPMsqYXD0AzHkRTgq_oNfRbO4kEEr_KdLeGtuxO49LLYI3NnmN-MprGn_mvgWX5uIWMxx0X7gI_kTtYKkUfCYrBxVryYiv2Qa79Ktw0lSNJKwmGRCNgqIENri50zgcQxi9iRIjvnzXLMfz4E20ni9iKUoQmMmbFgZh/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>You can also look at information about the leaf contents by calling  <code>viz_cmodel.ctree_leaf_distributions()</code>. For example, here's a plot showing the leaf ID versus samples-per-class for the Penguin dataset:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Bar diagram showing the leaf ID versus samples-per-class for the Penguin dataset\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxLXt1mNGVIv-YQMLbPUI9ISVvB5oVpRVdvJNIVsmF9zhE7-xGksFYa6Ki-1XWhrejN5TWfKgQ4zX0Q5t4JGz59qZzHZ8gBc_mB88599UT0yzMRN5JVZ7cAq53d4YQmw5XL-KatWVI51eFyAVn-9DMF8Q00frEfG0xF54HYNfI9DsADHsP1ztkDT8w/s1600/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>For regressors, the leaf plot shows the distribution of the target (predicted) variable for the instances in each leaf, such as in this plot from an Abalone decision tree:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Plot diagram an Abalone decision tree\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7f3XLxK6ouT4kC6kkcLx-ccdouO_HU3WDyvZFuUso0dtgYq3rS8DPqkH3HChtgelktlIBUvtCUDlZ-9zLVp7n2zDKBTi58Qx_DKX3LFw1SDo4D3WrYWS02RlKRIYKmgerZ4_YYt_VCP4q7rZ3XOLDgHJ1qnIPqQx-Dqe70GmmnA43Xt2V7H8mSYB9/s1600/image6.png\" style=\"width: 75%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>Each “row” in this plot represents a specific leaf and the blue dots indicate the distribution of the rings prediction values for instances associated with that leaf by the training process.</p>

<p>The library can do lots more; this is just a taste. Your next step is to check out the <a href=\"https://www.tensorflow.org/decision_forests/tutorials/dtreeviz_colab\" target=\"_blank\">tutorial</a>!  Then, try dtreeviz on your own tree models. To dig deeper into how decision trees are built and how they carve up feature space to make predictions, you can watch the <a href=\"https://www.youtube.com/watch?v=4FC1D9SuDBc\" target=\"_blank\">YouTube video</a> or the article on the <a href=\"https://explained.ai/decision-tree-viz/index.html\" target=\"_blank\">design of dtreeviz</a>.  Enjoy!</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 06 Jun 2023 17:00:00 +0000"
2520,Attend our first Developer Summit on Recommendation Systems,https://blog.tensorflow.org/2023/05/attend-our-first-developer-summit-on-recommendation-systems.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh27ZNP5A5naq_5gKOuhYyHcc7wntjw-LJg0jyefTiLHptYgbehHHNknQ2_1G0QXYoNWBjG_4GI7GugVNYdGbLj_L3wrwXZrQEHbaTXwIetpBt4pvBnR_Jsmf2boUBOBQTCMJOuqNXPOlJ6Tyep7rxewA92TqovAMJYH-fEK9f78LkS_RfbFerN0s4W/s1600/TF-Eco-Social.png\" style=\"display: none;\" />

<em>Posted by Wei Wei, Developer Advocate</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihLoVASHytpardLVhZuO9imYDYnIEKx3JF6EXHcSCxhEJN_EepJ4S4UbhePH7bZ8d8lVRvqJ17j9GkCPuUJa01P1beFpePzBdEv5Z7crj4POOmpARFRYodhS5FjEuC6pjOh4UN8lJcBN8ujPf4Xvd8Vcj8JDdT0SZle-91HLGMtlgjzvgw6H0Yyd82/s1600/TF%20BLOG%20TF%20eco.jpeg\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihLoVASHytpardLVhZuO9imYDYnIEKx3JF6EXHcSCxhEJN_EepJ4S4UbhePH7bZ8d8lVRvqJ17j9GkCPuUJa01P1beFpePzBdEv5Z7crj4POOmpARFRYodhS5FjEuC6pjOh4UN8lJcBN8ujPf4Xvd8Vcj8JDdT0SZle-91HLGMtlgjzvgw6H0Yyd82/s1600/TF%20BLOG%20TF%20eco.jpeg\" /></a>

<a name=\"more\"></a><p></p>

<p>Register for the Summit <a href=\"https://rsvp.withgoogle.com/events/recommendation-system-dev-summit\" target=\"_blank\">here</a>!</p>

<p>Recommendation systems are everywhere. They power our favorite websites, apps, and services, helping us find the things we enjoy. But how do modern recommenders work? What are the key components and how do they fit together? How can we make them even better?</p>

<p>Since we launched our <a href=\"https://www.tensorflow.org/resources/recommendation-systems\" target=\"_blank\">recommendation system landing page</a> last year, we have heard many positive feedback from our developer community. While many developers find the new consolidated page very useful to get started with our suite of products, they are also eager to learn more about how to best leverage them to build powerful in-house recommenders for their own business needs.</p>

<p>This is why we are very excited to announce our first-ever Developer Summit on Recommendation Systems (<a href=\"https://rsvp.withgoogle.com/events/recommendation-system-dev-summit\" target=\"_blank\">registration</a> is open now). This event will be held online on June 9, 2023 10AM - 12:15PM US Pacific Time and it will bring together many Google engineers who authored our suite of products to share their insights and expertise in recommendation systems. At this summit, we will not only cover specific products (such as <a href=\"https://www.tensorflow.org/recommenders\" target=\"_blank\">TensorFlow Recommenders</a>, <a href=\"https://www.tensorflow.org/ranking\" target=\"_blank\">TensorFlow Ranking</a>, and <a href=\"https://www.tensorflow.org/agents\" target=\"_blank\">TensorFlow Agents</a>), share ideas on augmenting recommenders with Large Language Models (LLMs), but also discuss Google’s cutting edge recommendation system research (e.g., <a href=\"https://shashankrajput.github.io/Generative.pdf\" target=\"_blank\">generative retrieval</a> using generative AI techniques). </p>

<p>This Developer Summit is the perfect event for anyone who wants to learn more about recommendation systems. Whether you're just getting started or a seasoned practitioner in this exciting domain, you're sure to find something valuable at this event. </p>

<p>We look forward to (virtually) meeting you there!</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Fri, 26 May 2023 14:30:00 +0000"
2521,American Sign Language Fingerspelling Recognition,https://blog.tensorflow.org/2023/05/american-sign-language-fingerspelling-recognition.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWi5-x1EvY3iq6DTWLttZ7-Ym0fLpXEuSR5Ctu_jPxHyI8PL7axqyt6iCajI7QuKgVqX15gaiLP_RJr-A6GNINxsRv3noZkyDBaT2pZsoW2BNdxppejifHQRZwdCExYlZLIzIPYyJ_PDJ9z_-HqGse1T_gW8f4sFW4NF5T2mI_UOjT7HCrMXMr7Vor/s1600/GDS_ASL_FingerspellingCompetition_Banners_Metacard.png\" style=\"display: none;\" />

<em>Posted by Thad Starner (Professor, Georgia Tech and Staff Research Scientist, Google), Sam Sepah (ML Research Program Manager), Manfred Georg (Software Engineer, Google), Mark Sherwood (Senior Product Manager, Google), Glenn Cameron (Product Marketing Manager, Google)</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaHD3yzznEbLuhZQ0u9xCJfu6X7CZtDgJy3Fdd3oIAt0uXXrs6wa3fFVp8kLRxFLgfKH0joBLgHi-_ykI7An2gmjLFnjwOEzjMmzX5NDUReJgv4EUnbjBqKsJXHe8TD7gylvW7qSSt58hwUFS9KicowMUo8yKGCaBJG2sFS1-Ol-uPn92JyYQYCmk6/s1600/GDS_ASL_FingerspellingCompetition_Banners_BlogImage.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaHD3yzznEbLuhZQ0u9xCJfu6X7CZtDgJy3Fdd3oIAt0uXXrs6wa3fFVp8kLRxFLgfKH0joBLgHi-_ykI7An2gmjLFnjwOEzjMmzX5NDUReJgv4EUnbjBqKsJXHe8TD7gylvW7qSSt58hwUFS9KicowMUo8yKGCaBJG2sFS1-Ol-uPn92JyYQYCmk6/s1600/GDS_ASL_FingerspellingCompetition_Banners_BlogImage.png\" /></a>

<a name=\"more\"></a><p></p>

<p>
Over <a href=\"https://www.un.org/en/observances/sign-languages-day\" target=\"_blank\">70 million deaf people</a> around the world use sign language to communicate. Collectively, they use more than 300 different sign languages worldwide. And over 1.5 billion people are affected by hearing loss globally. Most Deaf and Hard of Hearing people cannot use their voice to initiate a search or perform actions due to speech limitations.  Additionally, the interfaces used by smart home devices and mobile platforms to respond to speech are generally audio based.
</p>

<p>
Signed languages are sophisticated systems of communication, each with a complete set of language features.  On a surface level, handshapes along with four other \"parameters\" form the basis of signed communication.  An open hand or a closed hand while making the same motion can completely change the meaning of a sign. Likewise, palm orientation, motion/contact, location, and non-manual markers (typically mouth movements and facial expressions) define individual signs.  A number of grammatical constructs, some of which have no analog in spoken languages, allow a signer to produce complex phrases.
</p>

<p>
As we develop translation systems for American Sign Language (ASL) and other sign languages, it is natural to break apart various aspects of the language and attempt to perform tasks using those parts. </p> 
 
<p>To that end, we’re excited to announce the release of one of the largest datasets of ASL fingerspelling and a <a href=\"https://www.kaggle.com/competitions/asl-fingerspelling\" target=\"_blank\">Kaggle ML competition</a> that will award $200k in prizes to ML engineers who develop the most accurate ASL fingerspelling recognition models using MediaPipe and TensorFlow Lite. The winning models will be open sourced to help developers add support for fingerspelling to their apps.
</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><div style=\"text-align: left;\"></div></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Watch These Hands (Kaggle remix) <br />Performed by Sean Forbes, Co-Founder, Deaf Professional Arts Network</i></td></tr></tbody></table></div>

<p>
Fingerspelling communicates words using hand shapes that represent individual letters. While fingerspelling is only a part of sign languages, it is often used for communicating names, addresses, phone numbers, names, and other information that is commonly entered on a mobile phone.  Many Deaf smartphone users can fingerspell words faster than they can type on mobile keyboards. In fact, in our dataset, ASL fingerspelling of phrases averages 57 words per minute, which is substantially faster than the US average of 36 words per minute for an on screen keyboard. But, sign language recognition AI for text entry lags far behind voice-to-text or even gesture-based typing, as robust datasets didn't previously exist.</p>

<p>
Although fingerspelling is just a small part of sign languages, there are many reasons to produce systems which specifically focus on it, even while maintaining an ultimate goal of full translation.  While fingerspelling at full speed (which can peak over 80 words per minute) the handshapes in the fingerspelling co-articulate together and entire words can become lexicalized into different shapes from their slowed down version.  The resulting movements are visually among the fastest used in ASL, and thus stretch particular aspects of any visual recognition system which seeks to perform full translation.</p>

<h3>Big Steps Forward</h3>


<p>
Google Research and the Deaf Professional Arts Network have worked together to create a massive fingerspelling dataset that we will release for this competition to help move sign language recognition forward. The dataset includes over 3 million fingerspelled characters produced by over 100 Deaf signers in the form of continuous phrases, names, addresses, phone numbers, and URLs. This signing was captured using the selfie camera of a smartphone with a variety of backgrounds and lighting conditions and is the largest dataset collection of its kind to date.</p>

<p>
Large language models show increasing promise in a variety of language and speech tasks.  Everything from chat agents to assistant technology is progressing at breathtaking speed.  It is time to ensure that gesture and visual based systems also produce usable interfaces.  Fingerspelling recognition models are part of this larger solution, which will address the widening gap in accessibility for Deaf and Hard of Hearing individuals.
</p>

<h3>How to Get Involved</h3>

<p>
<a href=\"https://www.kaggle.com/competitions/asl-fingerspelling\" target=\"_blank\">Join the Kaggle competition today</a> to help us make AI more accessible for the Deaf and hard of hearing community.
</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Thu, 11 May 2023 18:00:00 +0000"
2522,Google I/O 2023: What’s new in TensorFlow and Keras?,https://blog.tensorflow.org/2023/05/google-io-2023-whats-new-in-tensorflow-and-keras.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAdcrkW0Y7yDr044bRNHL8KNuJzBU5t8AxBSvSTeNa_k26-s2sYnVWNtCM1vJ2AocvbWNwUBr4KUuThHYWdIMmN_nAZr_WcHSS6Toloyb5IGoW4FFCr_LSriSEf7N777wpxajhOFPOcWt7cEjIwxszyARPRtIhbVLDzo-2sTa5-ViMbevKR50YnSaH/s1600/Social%20-%20TensorFlow%20-%20What%27s%20new%20in%20TensorFlow%20and%20Keras%20%281%29.png\" style=\"display: none;\" />

<em>Posted by Ayush Jain, Carlos Araya, and Mani Varadarajan for the TensorFlow team</em>

<a name=\"more\"></a><p></p>



<p>Welcome to TensorFlow and Keras at Google I/O!</p> 

<p>The world of machine learning is changing, faster than ever. The rise of Large Language Models (LLMs) is sparking the imagination of developers worldwide, with new generative AI applications reaching hundreds of millions of people around the world. These models are trained on massive datasets, and used to solve a variety of tasks, from natural language processing to image generation. </p> 

<p>Powering all these new capabilities requires new levels of model efficiency and performance, as well as support for seamless deployment across a growing number of devices – be it on a server, the web, mobile devices, or beyond. As stewards of one of the largest machine learning communities in the world, the TensorFlow team is continually asking how we can better serve you.</p> 

<p>To that end, this post covers a few of the many improvements and additions coming this year to the TensorFlow ecosystem. Let's dive in!</p> 

<h2><strong>A Growing Ecosystem</strong></h2>

<p>New functionality we’re covering today:</p> 

<p><strong>KerasCV and KerasNLP</strong> allows you to access pre-trained, state-of-the-art models in just a few lines of code.</p> 

<p><strong>DTensor</strong> helps you scale up your models and train them efficiently by combining different parallelism techniques.</p> 

<p>With <strong>JAX2TF</strong>, models written with the <a href=\"https://jax.readthedocs.io/en/latest/\" target=\"_blank\">JAX numerical library</a> can be used in the TensorFlow ecosystem.</p> 

<p>We also preview the <strong>TF Quantization API</strong>, which enables you to make your models more cost and resource-efficient without compromising on accuracy.</p> 


<h2><strong>Applied ML with KerasCV &amp; KerasNLP</strong></h2>

<p>KerasCV and KerasNLP are powerful, modularized libraries that give you direct access to the state-of-the-art in computer vision and natural language processing.</p> 

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"The KerasCV + KerasNLP suite, at a glance.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9WdV2Oh8zdilguksOGVZSjjfbknPoj9g38Iswe0PHlaBxIlo6TX_0xWODuHJnQkp8FzgjBpcqd6Y-fJFEjfbYd1bNNKAdWqhOYQTPKrOv7uLiFv8c1FB5kZqSCoM37MI5yq7EBhVTsVpN78jNiZqSZMUlCOQdvKKcxbxBRyVI0-TzpE5MK8S2TmAf/s1600/image5.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>The KerasCV + KerasNLP suite, at a glance.</i></td></tr></tbody></table></div>

<p>Whether you want to classify images, auto-generate text from prompts like with <a href=\"http://bard.google.com\" target=\"_blank\">Bard</a> or anything in between, KerasCV and KerasNLP make it easy with just a few lines of code.  And since it’s a part of Keras, it’s fully integrated with the TensorFlow Ecosystem.</p>

<p> Let's look at some code for image generation. KerasCV is designed to support many models, and in this case we'll use a diffusion model. Despite the complexity of the underlying architecture, you can get it up and running with just a few lines of code.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">from</span> keras_cv.models <span class=\"hljs-keyword\">import</span> (
    StableDiffusion,
)
      
model = StableDiffusion(
    img_width=<span class=\"hljs-number\">512</span>,
    img_height=<span class=\"hljs-number\">512</span>,
)</span></code></td></tr></tbody></table>

<p>With one line to import and another to initialize the model, you can generate completely new images:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">images = model.text_to_image(
    <span class=\"hljs-string\">\"photograph of an astronaut \"</span>
    <span class=\"hljs-string\">\"riding a horse\"</span>,
    batch_size=<span class=\"hljs-number\">3</span>,
)</span></code></td></tr></tbody></table>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"KerasCV-generated images of an astronaut riding a horse\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEggkjw30TnovVUBFIvPZWiM23AaMQGJaompUuEBSSs2GpzIqU8PBDCoCnGVTO6vJG9WGZmfvhItCCIflq16wC08LdEliEPG8LJsxgENZOFzSEjcP65zps47TKMd8EbSWh6zgkeY-m9VW5kIMuS4rOyoVMhQTPUADiFK2MoEx7tpu-w3QLA36Nt--lcb/s1600/image3.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>KerasCV-generated images of an astronaut riding a horse!</i></td></tr></tbody></table></div>

<p>This is just one of many examples. To learn more, check out our <a href=\"https://youtu.be/K2PKZS1fPlY\" target=\"_blank\">full talk on KerasCV and KerasNLP</a> or in-depth toolkit guides at <a href=\"https://keras.io/keras_cv/\" target=\"_blank\">keras.io/keras_cv</a> and <a href=\"https://keras.io/keras_nlp/\" target=\"_blank\">keras.io/keras_nlp</a>.</p>


<h2><strong>Machine Learning at Scale with DTensor</strong></h2>

<p>DTensor enables larger and more performant model training by giving developers the flexibility to combine and fine-tune multiple parallelism techniques.</p>

<p>Traditionally, ML developers have scaled up models through data parallelism, which splits up your data and feeds it to horizontally-scaled model instances. This scales up training but has an important limitation: it requires that the model fits within a single hardware device. </p> 

<p>As models get bigger, fitting into a single device is no longer a guarantee — developers need to be able to scale their models across hardware devices. This is where model parallelism becomes important, allowing for the model to be split up into shards that can be trained in parallel.</p>

<p>With DTensor, data and model parallelism are not only supported, but also can be directly combined to scale models even more efficiently. And it’s completely accelerator agnostic — whether you use TPUs, GPUs, or something else.</p>


<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Diagram illustrating mixed (data + model) parallelism, with DTensor.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7n5JkTotBstwiwVjeqej5EaK7PMiVWbcJctFg9eEm2wLRWj5UJWZiJ1MRg5HrUDH2VqXz6L4jv6IgYt-ybxtf-LrLPo4iVR_HtJQFidDr4Yw1ZxmRUAhfLksUVbajtnhHDzPY8WA5IZkPiArj_8uAoGaeT3uaKMty2bQmcARJtoyiaZ8MOfaQQrn3/s1600/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Mixed (data + model) parallelism, with DTensor.</i></td></tr></tbody></table></div>

<p>Let’s go through an example. Let’s say that you are building with a transformer model, like the Open&nbsp;Pre-trained Transformer (OPT) available through KerasNLP, and training it with some input dataset:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">opt_lm = keras_nlp.models.OPTCasualLM.from_preset(<span class=\"hljs-string\">\"opt_6.7b_en\"</span>)
opt_lm.<span class=\"hljs-built_in\">compile</span>(...)
opt_lm.fit(wiki_text_dataset)</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\" style=\"font-size: 12px;\">
</span></code></td></tr></tbody></table>


<p>But here’s the thing about OPT — it’s <em>big</em>. With variations up to 175 billion parameters, if we tried traditional data parallelism, it would have errored outright — there’s just too many weights to reasonably replicate within a single hardware device. That’s where DTensor comes in.</p>

<p>To work with DTensor, we need to define two things:</p>

<p>First is a <strong>mesh</strong>, where you define (a) a set of hardware devices and (b) a topology, here the batch and model dimensions.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">mesh_dims = [(<span class=\"hljs-string\">\"batch\"</span>, <span class=\"hljs-number\">2</span>), (<span class=\"hljs-string\">\"model\"</span>, <span class=\"hljs-number\">4</span>)]
mesh = dtensor.create_distributed_mesh(mesh_dims, device_type=<span class=\"hljs-string\">\"GPU\"</span>)
dtensor.initialize_accelerator_system(<span class=\"hljs-string\">\"GPU\"</span>)</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\" style=\"font-size: 12px;\">
</span></code></td></tr></tbody></table>

<p>Second is a <strong>layout</strong>, which defines how to shard the Tensor dimension on your defined mesh. Through our Keras domain package integrations, you can do this in just one line.</p><p><span id=\"docs-internal-guid-1dd998c1-7fff-68b6-d1cc-0f854cc22024\"></span></p><p dir=\"ltr\" style=\"line-height: 1.44; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: #eeeeee;\"><span style=\"color: black; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><span style=\"font-family: courier;\">layout_map = keras_nlp.models.OPTCausalLM.create_layout_map(mesh</span></span><span>)</span></span></p><p dir=\"ltr\" style=\"line-height: 1.44; margin-bottom: 0pt; margin-top: 0pt;\"><br /></p>From there, you create the DTensor layout’s context and include your model creation code within it. Note that at no point did we have to make any changes to the model itself!

<div><br /></div><div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">with</span> layout_map.scope():
    opt_lm = keras_nlp.models.OPTCasualLM.from_preset(<span class=\"hljs-string\">\"opt_6.7b_en\"</span>)
opt_lm.<span class=\"hljs-built_in\">compile</span>(...)
opt_lm.fit(wiki_text_dataset)</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\" style=\"font-size: 12px;\">
</span></code></td></tr></tbody></table></div>

<p>Performance for DTensor today is already on par with industry benchmarks, nearly matching the gold-standard implementation of model parallelism offered by NVIDIA’s Megatron for GPUs. Further improvements are in the works to raise the bar even further, across hardware devices.</p>

<p>In the future, DTensor will be fully integrated with key interfaces like <code>tf.distribute</code> and Keras as a whole, with one entry point regardless of hardware and a number of other quality of life features. If you want to learn more, check out the <a href=\"https://www.tensorflow.org/guide/dtensor_overview\" target=\"_blank\">DTensor overview</a> or the <a href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial\" target=\"_blank\">Keras integration guide</a>!</p>


<h2><strong>Bringing Research to Production with JAX2TF</strong></h2>

<p>Many of the ML advancements that are now household names had their beginnings in research. For example, the Transformer architecture, created and published by Google AI, underpins the fantastic advances in language models.</p>

<p>JAX has emerged as a trusted tool for much of this kind of discovery, but productionizing it is hard. To that end, we’ve been thinking about how to bring research more easily into TensorFlow, giving innovations built on JAX the full strength of TensorFlow’s uniquely robust and diverse production ecosystem.</p>

<p>That’s why we’ve built JAX2TF, a lightweight API that provides a pathway from the JAX ecosystem to the TensorFlow ecosystem. There are many examples of how this can be useful - here’s just a few:</p>
<ul><blockquote>
  <li><strong>Inference:</strong> Taking a model written for JAX and deploying it either on a server using TF Serving or on-device using TFLite.</li>
<li><strong>Fine Tuning:</strong> Taking a model that was trained using JAX, we can bring its components to TF using JAX2TF, and continue training it in TensorFlow with your existing training data and setup.</li>
<li><strong>Fusion:</strong> Combining parts of models that were trained using JAX with those trained using TensorFlow for maximum flexibility.</li>
  </blockquote></ul>

<p>The key to enabling this kind of interoperation between JAX and TensorFlow is baked into <code>jax2tf.convert</code>, which takes in model components created on top of JAX (e.g. your loss function, prediction function, etc.) and creates equivalent representations of them as <a href=\"https://www.tensorflow.org/api_docs/python/tf/function\" target=\"_blank\">TensorFlow functions</a>, which can then be exported as a <a href=\"https://www.tensorflow.org/guide/saved_model\" target=\"_blank\">TensorFlow SavedModel</a>.</p>

<p>We’ve created a code walkthrough for one of the examples above: a quick fine-tuning setup, creating a simple model using modeling libraries in the JAX ecosystem (like <a href=\"https://flax.readthedocs.io/en/latest/\" target=\"_blank\">Flax</a> and <a href=\"https://optax.readthedocs.io/en/latest/\" target=\"_blank\">Optax</a>) and bringing it into TF to finish training. Check it out <a href=\"https://www.tensorflow.org/guide/jax2tf\">here.</a></p>

<p>JAX2TF is already baked into various tools in the TensorFlow ecosystem, under the hood. For example, here are code guides for simple conversion <a href=\"https://optax.readthedocs.io/en/latest/\" target=\"_blank\">from JAX to TFLite</a> for mobile devices and <a href=\"https://blog.tensorflow.org/2022/08/jax-on-web-with-tensorflowjs.html\" target=\"_blank\">from JAX to TF.js</a> for web deployment!</p>

<h2><strong>Coming Soon: The TensorFlow Quantization API</strong></h2>

<p>ML developers today face a wide variety of real-world constraints introduced by the settings they’re working in, like the size of a model or where it gets deployed.</p>

<p>With TensorFlow, we want developers to be able to quickly adjust and accommodate for these kinds of constraints, and to do so without sacrificing model quality. To do this,  we’re building the TF Quantization API, a native quantization toolkit for TF2 which will be available publicly later in 2023. </p>

<p>Briefly, quantization is a group of techniques designed to make models faster, smaller, and generally less resource- and infrastructure-intensive to train and serve. </p>

<p>Quantization does this by reducing the precision of a model’s parameters, just like reducing pixel depth in an image like the one of Albert Einstein below. Note that even with reduced precision, we can still make out the key details:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Eight renderings of a photograph of Albert Einstein with increasingly reduced bit precision from 8-bit to 1-bit.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrfUr_P4Nc_S0OqyRFXHlJ-nP5Fxm6fsbbnj9t7ufsopqF6KTPAGz6x64bvccLI6af5Z8HE2Itne1rs7hh1cf0jJWCYmdgsL23A2fJnaOcSN0rUDfJBXbb4aSuA_78xxSD1Pwk8gHdoCyd2rou3hkEJ66FxzLXb3uRV9b0PrHUkH0MyxF0TCfCFNGd/s1600/image4.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Renderings of a photograph of Albert Einstein with increasingly reduced bit precision.</i></td></tr></tbody></table></div>

<p>At a high level, this works by taking a range of values in your starting precision, and mapping that range to a single bucket in your ending precision. Let’s illustrate this with an example:</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Graph showing quantizing float representation to 4-bit integers\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhp94S4Oi7x4ViL0Se5FvPICRqMALH8h19M3XwNKcLWFOlFIVs2u4dRQ__gAxMeP8IyOh94q5kcBBybjtBwH5czfmzTBMJEkExAXWzktaMBT_VbH-_-2bBVK5VCKr09UCkp60BQ2We9Ap7dLZjRZU98VcvJzwKJVuVIH70RlnsBSnUo4uRDAWnHN8dP/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Quantizing float representation to 4-bit integers.</i></td></tr></tbody></table></div>

<p>Take a look at the range [0.27, 0.49] on the x-axis: for float32, the blue line actually represents 7381976 unique numbers! The red line represents the int4 quantization of this range, condensing all of those numbers into a single bucket: 1001 (the number 9 in decimal). </p>

<p>By lowering precision through quantization, we can store model weights in a much more efficient, compressed form.</p>

<p>There’s a few different ways to quantize.</p>
<ul><blockquote>
  <li><strong>Post-Training Quantization (PTQ):</strong> Convert to a quantized model after training. This is as simple as it gets and most readily accessible, but there can be a small quality drop.</li>
<li><strong>Quantization-Aware Training (QAT):</strong> Simulate quantization during just the forward pass, providing for maximal flexibility with a minimal quality tradeoff.</li>
<li><strong>Quantized Training:</strong> Quantize all computations while training. This is still nascent, and needs a lot more testing, but is a powerful tool we want to make sure TensorFlow users have access to.</li>
</blockquote></ul>

<p>TensorFlow previously has had a few tools for developers to quantize their models, like <a href=\"https://www.tensorflow.org/model_optimization/guide/quantization/post_training\" target=\"_blank\">this guide for PTQ</a> and <a href=\"https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide\" target=\"_blank\">this one for QAT</a>. However, these have been limited - with PTQ depending on conversion to TFLite for mobile deployment and QAT requiring you to rewrite your model.</p>

<p>The TF Quantization API is different – it’s designed to work regardless of where you’re deploying, and without you having to rewrite a single line of existing modeling code. We’re building it with flexibility and fidelity in mind, so you get the benefits of a smaller quantized model with new levels of fine-grained control and without any concerns about how it’ll all fit into your stack.</p>

<p>Since you’ve made it this far into the blog, here’s a sneak peek at how it’ll look. We’ll start with a typical setup for a TensorFlow model, just a few layers in Keras. From there, we can load in a predefined quantization schema to apply as a config map to our model.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\"># Step 1: Define your model, just like always.</span>
model = tf.keras.models.Sequential([
 tf.keras.layers.Conv2D(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">3</span>, strides=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-string\">'same'</span>, activation=<span class=\"hljs-string\">'relu'</span>),
 … …])

<span class=\"hljs-comment\"># Step 2: Set up the quantization config, using a predefined schema.</span>
scheme = scheme_registry.get_scheme(<span class=\"hljs-string\">'pixel_8bit_qat'</span>)
config_map = QuantizationConfigurationMap(scheme)</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\" style=\"font-size: 12px;\"></span></code></td></tr></tbody></table>

<p>But if you need more flexibility, TF Quantization API will also let you fully customize how you quantize. There’s built-in support for you to curate your schema to apply different behaviors for every layer, operation, or tensor!</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\"># ...or just as easily configure your own, whether per-layer:</span>
layer_config = LayerConfiguration(
   weight_config=..., activation_config=...)
config_map.set_config(model.layers[<span class=\"hljs-number\">0</span>], layer_config)

<span class=\"hljs-comment\"># per-op:</span>
config_map.set_config(model.layers[<span class=\"hljs-number\">0</span>], op_type=<span class=\"hljs-string\">'matmul'</span>, config={
   <span class=\"hljs-string\">'a'</span>: ..., <span class=\"hljs-string\">'b'</span>: ...,
   <span class=\"hljs-string\">'return'</span>: ...
})

<span class=\"hljs-comment\"># even per-tensor:</span>
_8bit_moving_average = QuantizationConfiguration(...)
per_tensor_config = LayerConfiguration(
   weight_config=..., activation_config=_8bit_moving_average)
config_map.set_config(model.layers[<span class=\"hljs-number\">0</span>], per_tensor_config)</span><span face=\"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace\" style=\"font-size: 12px;\"></span></code></td></tr></tbody></table>

<p>With that, we can directly apply quantization and train or save within a quantization context. Our model still has natural compatibility with the rest of the TF ecosystem, where quantization truly bears fruit.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\"># Now you can generate a quantization-aware model!</span>
tf.quantization.apply_quantization_on_model(model, config_map, …)

<span class=\"hljs-comment\"># From here, you can train and save just as always.</span>
<span class=\"hljs-keyword\">with</span> tf.quantization.scope(config_map):
  model.fit()
  model.save()

<span class=\"hljs-comment\"># You can also export to TFLite, without any changes!</span>
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()</span><span></span></code></td></tr></tbody></table>

<p>We ran a bunch of tests using the <a href=\"https://arxiv.org/abs/1801.04381\" target=\"_blank\">MobileNetV2</a> model on the Pixel 7, and saw up to 16.7x gains in serving throughput versus the non-quantized baseline. This gain comes without any noticeable detriment to quality: both the float32 baseline and the int8 quantized model reported 73% accuracy. </p>

<p>The TF Quantization API isn’t public just yet, but will be available very soon and will continue to evolve to provide even more benefits.</p>

<h2><strong>That’s a wrap!</strong></h2>

<p>Today, we’ve shown you just a few of the key things we’ve been working on, and there’s a lot more to come.  

<p>We can’t wait to see what you’ll build, and we're always inspired by our community’s enduring enthusiasm and continued partnership. Thanks for stopping by!

<h3><strong>Acknowledgements</strong></h3>

<p><em>Special thanks to George Necula, Francois Chollet, Jonathan Bischof, Scott Zhu, Martin Gorner, Dong Li, Adam Koch, Bruce Fontaine, Laurence Moroney, Josh Gordon, Lauren Usui, and numerous others for their contributions to this post.</em></p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Wed, 10 May 2023 20:30:00 +0000"
2523,AI and Machine Learning @ I/O Recap,https://blog.tensorflow.org/2023/05/ai-and-machine-learning-io-recap.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2XCTScVBPnjR48vwMirVfh0rWWKQMxu0V2iGggyIFvPptS4chSE0QJrUKevGGgRz3M4eOzaGwGwrgSy0LeRK7xcFioKpvDGvVirIWLmVePo-SIv37_hcgJCVPgVLviehjUHFMrt0Z1z36IBH4X67yiMFiH0agsCMBjXtPAJVwvZcxD1wxOV8f14W9/s1600/IO23_Blog_metacard_AI@2x.png\" style=\"display: none;\" />

<p><em>Posted by Lauren Usui and Joe Fernandez</em><p>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWop09VTaoPdAEM9iWURzlhJ1rJXlZP9UOhrUokGUTfMx1XfNYRVXn5zggPqiXTFioP6YUGXpM0UUjKaNB_LOuES7MJCRFUJNbDfwn2odKJNNJzwchZ93_Y9B19dQjSixGOBznklMcJoAuTexEfBEHBnWTHfMovcKVot8dqiQ1GzKCTwR2bYP24YWr/s1600/IO23_Blog_Banner_Ai@2x.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWop09VTaoPdAEM9iWURzlhJ1rJXlZP9UOhrUokGUTfMx1XfNYRVXn5zggPqiXTFioP6YUGXpM0UUjKaNB_LOuES7MJCRFUJNbDfwn2odKJNNJzwchZ93_Y9B19dQjSixGOBznklMcJoAuTexEfBEHBnWTHfMovcKVot8dqiQ1GzKCTwR2bYP24YWr/s1600/IO23_Blog_Banner_Ai@2x.png\" /></a>

<a name=\"more\"></a><p></p>

<p>Artificial intelligence is a topic of kitchen table conversations around the world today, and as AI becomes more accessible for users and developers, we want to make it easier and more useful for everyone. This year at Google I/O, we highlighted how we are helping developers like you build with generative AI, use machine learning in spreadsheets and applications, create ML models from the ground up, and scale them up to serve millions of users.</p>

<p>While AI technology is advancing rapidly, we must continue to ensure it is used responsibly. So we also took some time to explain how Google is taking a <a href=\"https://youtu.be/oAc0ZhbCfi8\" target=\"_blank\">principled approach to applying generative AI</a> and how you can apply our guidelines and tools to make sure your AI-powered products and projects are built responsibly to serve all your users. </p>

<p>If you are new to AI and want to get a quick overview of the technology, check out the <a href=\"https://youtu.be/3K1414RwNDU\" target=\"_blank\">getting started video</a> from Google's AI advocate lead, Laurence Moroney.</p>

<h2><strong>Develop generative AI apps with PaLM 2</strong></h2>

<p>Everyone seems to be chatting with—or about—generative AI recently, and we want you to be able to use Google’s latest large language model, PaLM 2, to power new and helpful experiences for your users with the <a href=\"https://developers.generativeai.google/\" target=\"_blank\">PaLM API</a>. Our session on Generative AI reveals more about how you can easily prompt models with MakerSuite to quickly prototype generative AI applications. We demonstrate how you can use the PaLM API for prompting using examples, conversational chat interactions, and using embedding functionality to compress and compare text data in useful ways. We also showed off how to use the PaLM API in Google Colab notebooks with a simple, magical syntax. Check out this talk and sign up to request access to the PaLM API and <a href=\"https://makersuite.google.com/\" target=\"_blank\">MakerSuite</a>!</p>

 

<h2><strong>Crunch numbers with AI-powered spreadsheets</strong></h2>

<p>Hundreds of millions of people use spreadsheets to organize, manage, and analyze data for everything from business transactions, to inventory accounting, to family budgets. We’re making it easy for everyone to bring the power of AI into spreadsheets with <a href=\"https://simplemlforsheets.com/\" target=\"_blank\">Simple ML for Sheets</a>, a Google Sheets add-on. We recently updated this tool to include anomaly detection and forecasting features. Check out the demonstration of how to predict missing data values and  forecast sales with the tool. No coding required!</p>

 

<h2><strong>Simplify on-device ML applications with MediaPipe</strong></h2>

<p>AI is finding its way into applications across multiple platforms and <a href=\"https://developers.google.com/mediapipe\" target=\"_blank\">MediaPipe</a> makes it easy to build, customize, and deploy on-device ML solutions. We upgraded MediaPipe Solutions this year, improving existing solutions and adding new ones, including interactive segmentation to blur the background behind a selected subject and face stylization to render that selfie in your favorite graphic style.</p>




<h2><strong>Do more with Web ML</strong></h2>

<p>Every week, hundreds of thousands of developers build AI-powered applications to run in the browser or Node.js using JavaScript and web technologies. Web ML has advanced in multiple areas, and we provide a round up of the top updates in this year’s I/O talk. We announced Visual Blocks for ML, an open JavaScript framework for quickly and interactively building custom ML pipelines. You can now run machine learning models even faster with improved WebGL performance and the release of WebGPU in Chrome. More tools and resources are also now available for web ML developers, including TensorFlow Decision Forest support, a visual debugger for models, JAX to JS conversion support, and a new Zero to Hero training course to grow your skills in Web ML.</p>
  

  
  
<h2><strong>Find pre-trained models fast with Kaggle Models</strong></h2>

<p>Building machine learning models can take a huge amount of time and effort: collecting data, training, evaluating, and optimizing. Kaggle is making it a whole lot easier for developers to discover and use pretrained models. With <a href=\"https://www.kaggle.com/models\" target=\"_blank\">Kaggle Models</a>, you can search thousands of open-licensed models from leading ML researchers for multiple ML platforms. Find the model you need quickly with filters for tasks, supported data types, model architecture, and more. Combine this new feature with Kaggle's huge repository of over 200K datasets and accelerate your next ML project.</p>

 

<h2><strong>Apply ML to vision and text with Keras</strong></h2>

<p>Lots of developers are exploring AI technologies and many of you are interested in working on computer vision and natural language processing applications. Keras released new, easy-to-use libraries for computer vision and natural language processing with <a href=\"https://keras.io/keras_cv/\" target=\"_blank\">KerasCV</a> and <a href=\"https://keras.io/keras_nlp/\" target=\"_blank\">KerasNLP</a>. Using just a few lines of code, you can apply the latest techniques and models for data augmentation, object detection, image and text generation, and text classification. These new libraries provide modular implementations that are easy to customize and are tightly integrated with the broader TensorFlow ecosystem including TensorFlow Lite, TPUs, and DTensor.</p>



<h2><strong>Build ML flexibly and scalably with TensorFlow</strong></h2>

<p>With one of the largest ML development communities in the world, the <a href=\"https://www.tensorflow.org/\" target=\"_blank\">TensorFlow</a> ecosystem helps hundreds of thousands of developers like you build, train, deploy, and manage machine learning models. ML technology is rapidly evolving, and we’re upgrading TensorFlow with new tools to give you more flexibility, scalability, and efficiency. If you’re using JAX, you can now bring your model components into the TensorFlow ecosystem with JAX2TF. We also improved DTensor support for model parallelization, allowing you to scale up execution of larger models by running portions of a single model, or shards, across multiple machines. We also announced a toolkit for applying quantization techniques to practically any TensorFlow model, helping you gain substantial efficiency improvements for your AI applications. The quantization toolkit will be available later this year.</p>



<h2><strong>Scale large language models with Google Cloud</strong></h2>

<p>When it's time to deploy your AI-powered applications to your business, enterprise, or the world, you need reliable tools and services that scale with you. Google Cloud's <a href=\"https://cloud.google.com/vertex-ai\" target=\"_blank\">Vertex AI</a> is an end-to-end ML platform that helps you develop ML models quickly and easily, and deploy them at any scale. To help you build generative AI technology for your product or business, we've introduced Model Garden and the Generative AI Studio as part of the Vertex AI platform. Model Garden gives you quick access to the latest foundation models such as Google PaLM 2, and many more to build AI-powered applications for text processing, imagery, and code. Generative AI Studio lets you quickly prototype generative AI applications right in your browser, and when you are ready to deploy, Vertex AI and Google Cloud services enable you to scale up to hundreds, thousands, or millions of users. </p>



<h2><strong>Explore new resources to build with Google AI</strong></h2>

<p>As tools, technology, and techniques for AI development rapidly advance, finding what you need to get started or take the next step with your project can be challenging. We're making it easier to find the right resources to accelerate your AI development at <a href=\"https://ai.google/build/machinelearning/\" target=\"_blank\">Build with Google AI</a>. This new site brings together tools, guidance, and community for building, deploying, and managing ML. Whether you are creating AI for on-device apps or deploying AI at scale, we help you navigate the options and find your path. Check out our latest toolkits on <a href=\"https://ai.google/build/machine-learning/toolkits/llm-android\" target=\"_blank\">Building an LLM on Android</a> and <a href=\"https://ai.google/build/machine-learning/toolkits/applied-ml-keras\" target=\"_blank\">Text Classification with Keras</a>.</p>


<h2><strong>Making Generative AI safe and responsible</strong></h2>

<p>AI is a powerful tool, and it's up to all of us to ensure that it is used responsibly and for the benefit of all. We’re committed to ensuring Google's AI systems are developed according to our <a href=\"https://ai.google/principles/\" target=\"_blank\">AI principles</a>. This year at Google I/O, we shared how we've created guidelines and tools for building generative AI safely and responsibly, and how you can apply those same guidelines and tools for your own projects.</p>




<p>Aaannnd that's a wrap! Check out the <a href=\"https://goo.gle/IO23_ai_ml\" target=\"_blank\">full playlist</a> of all the AI-related sessions we mentioned above. We are excited to share these new tools, resources, and technologies with you, and we can't wait to see what you build with them!</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Wed, 10 May 2023 20:30:00 +0000"
2524,Scaling deep retrieval with TensorFlow Recommenders and Vertex AI Matching Engine,https://blog.tensorflow.org/2023/05/scaling-deep-retrieval-with-tensorflow-recommenders-and-vertex-ai-matching-engine.html,"<img src=\"https://blogger.googleusercontent.com/img/a/AVvXsEioxLwPYbbp4dtHj1gVVgUJ3PkqQ7GtRr0VS-DLtuwoUnOWf99F8Cl8lQ2cZpTVLnY-fd6M22hltTa9kzgrlE0tLmt0JVpdNEcz3nv9wNBLEcyPakq0nscIkCimcwi2HwYo0osTOltdpe0bJA1VlQVIgiUz1cJLqfLybKBykoOxQVGhlC9FqYwtVdRB\" style=\"display: none;\" />

<p><em>Posted by Jeremy Wortz, ML specialist, Google Cloud &amp; Jordan Totten, Machine Learning Specialist</em></p><p>

<a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEioxLwPYbbp4dtHj1gVVgUJ3PkqQ7GtRr0VS-DLtuwoUnOWf99F8Cl8lQ2cZpTVLnY-fd6M22hltTa9kzgrlE0tLmt0JVpdNEcz3nv9wNBLEcyPakq0nscIkCimcwi2HwYo0osTOltdpe0bJA1VlQVIgiUz1cJLqfLybKBykoOxQVGhlC9FqYwtVdRB\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEioxLwPYbbp4dtHj1gVVgUJ3PkqQ7GtRr0VS-DLtuwoUnOWf99F8Cl8lQ2cZpTVLnY-fd6M22hltTa9kzgrlE0tLmt0JVpdNEcz3nv9wNBLEcyPakq0nscIkCimcwi2HwYo0osTOltdpe0bJA1VlQVIgiUz1cJLqfLybKBykoOxQVGhlC9FqYwtVdRB\" /></a>

</p><a name=\"more\"></a><p></p>

<p><em> Cross posted from <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/scaling-deep-retrieval-tensorflow-two-towers-architecture\" target=\"_blank\">Google Cloud AI &amp; Machine Learning</a></em></p>

<p>In a previous <a href=\"https://cloud.google.com/blog/topics/developers-practitioners/looking-build-recommendation-system-google-cloud-leverage-following-guidelines-identify-right-solution-you-part-i\" target=\"_blank\">blog</a>, we outlined three approaches for implementing recommendation systems on Google Cloud, including (1) a fully managed solution with <a href=\"https://cloud.google.com/retail/docs\" target=\"_blank\">Recommendations AI</a>, (2) matrix factorization from <a href=\"https://cloud.google.com/bigquery/docs\" target=\"_blank\">BigQuery ML</a>, and (3) custom deep retrieval techniques using two-tower encoders and <a href=\"https://cloud.google.com/vertex-ai/docs/matching-engine/overview\" target=\"_blank\">Vertex AI Matching Engine</a>. In this blog, we dive deep into option (3) and demonstrate how to build a playlist recommendation system by implementing an end-to-end candidate retrieval workflow from scratch with Vertex AI. Specifically, we will cover: </p>
<ul><blockquote>
<li>The evolution of retrieval modeling and why two-tower encoders are popular for deep retrieval tasks</li>
<li>Framing a playlist-continuation use-case using the <a href=\"https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge\" target=\"_blank\">Spotify Million Playlist Dataset</a> (MPD)</li>
<li>Developing custom two-tower encoders with the <a href=\"https://www.tensorflow.org/recommenders\" target=\"_blank\">TensorFlow Recommenders</a> (TFRS) library</li>
<li>Serving candidate embeddings in an approximate nearest neighbors (ANN) index with <a href=\"https://cloud.google.com/vertex-ai/docs/matching-engine/overview\" target=\"_blank\">Vertex AI Matching Engine</a></li></blockquote></ul>

<p>All related code can be found in this <a href=\"https://github.com/jswortz/spotify_mpd_two_tower\" target=\"_blank\">GitHub repository</a>.</p>

<h2>Background</h2>
  
<p>To meet low latency serving requirements, large-scale recommenders are often deployed to production as <a href=\"https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e\" target=\"_blank\">multi-stage systems</a>. The goal of the first stage (candidate retrieval) is to sift through a large (&gt;100M elements) corpus of candidate items and retrieve a relevant subset (~hundreds) of items for downstream ranking and filtering tasks. To optimize this retrieval task, we consider two core objectives:</p><p>
</p><ol><blockquote>
<li>During model training, find the best way to compile all knowledge into <code>query, candidate</code> embeddings.</li>
<li>During model serving, retrieve relevant items fast enough to meet latency requirements</li></blockquote></ol>
  
<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Conceptual components of multi-stage recommendation systems; the focus of this blog is the first stage, candidate retrieval.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihZXbuNoFq-aES9SNyrUqp4pVxkADmpB5sNKWeoa4k5cAokDvc9iBbhyYsDL-OMqP0vxlyWigBOfpgzifz0rlEr6EbsFYh3F0rqJwph714O0QSVZV5o8Aji9KSy1Bl8375DYKPP4ntlKrYkmnRHy-arYFUY_SZBaOntL4YV1_h9yY8AgIIQJtJyv_L/s1600/figure-01_a3ezgV3.max-700x700.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 1: Conceptual components of multi-stage recommendation systems; the focus of this blog is the first stage, candidate retrieval.</i></td></tr></tbody></table></div>
  
<p>Two-tower architectures are popular for retrieval tasks because they capture the semantics of query and candidate entities, and map these to a shared <a href=\"https://developers.google.com/machine-learning/recommendation/overview/candidate-generation#embedding-space\" target=\"_blank\">embedding space</a> such that semantically similar entities cluster closer together. This means, if we compute the <a href=\"https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings\" target=\"_blank\">vector embeddings</a> of a given query, we can search the embedding space for the closest (most similar) candidates. Because these neural network-based retrieval models take advantage of metadata, context, and feature interactions, they can produce highly informative embeddings and offer flexibility to adjust for various business objectives.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Moving image illustrating how a two tower encoder model trains, calculates, and retrieves data from the embedding space\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0OkYOgUiGD1QxMxyGlJPM0VZDOQFhXwW_SwRBeZoRwHsUsI6cFzaB7VDAy5Lgi67O0dnxqoO4TZwyTQ6-SQ2UsEMKcehpgLgntl6mmNkO_CaQp0EThgtIfFd_g1bZNdTiJwcaDE_OOxhmyC1hkjINQMKVrMEIWDSTkLwWm1sQJCmEfS9YIim7XquA/s1600/Figure-02.gif\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 2: The two-tower encoder model is a specific type of embedding-based search where one deep neural network tower produces the query embedding and a second tower computes the candidate embedding. Calculating the <a href=\"https://developers.google.com/machine-learning/recommendation/overview/candidate-generation#dot-product\" target=\"_blank\">dot product</a> between the two embedding vectors determines how close (similar) the candidate is to the query. Source: <a href=\"https://medium.com/mlearning-ai/building-a-multi-stage-recommendation-system-part-1-1-95961ccf3dd8\" target=\"_blank\">Announcing ScaNN: Efficient Vector Similarity Search</a>.</i></td></tr></tbody></table></div>

<p>While these capabilities help achieve useful <code>query, candidate</code> embeddings, we still need to resolve the retrieval latency requirements. To this end, the two-tower architecture offers one more advantage: the ability to decouple inference of query and candidate items. This decoupling means all candidate item embeddings can be precomputed, reducing the serving computation to (1) converting queries to embedding vectors and (2) searching for similar vectors (among the precomputed candidates).</p>

<p>As candidate datasets scale to millions (or billions) of vectors, the similarity search often becomes a computational bottleneck for model serving. Relaxing the search to approximate distance calculations can lead to significant latency improvements, but we need to minimize negatively impacting search accuracy (i.e., relevance, recall).</p>

<p>In the paper <a href=\"https://arxiv.org/abs/1908.10396\" target=\"_blank\">Accelerating Large-Scale Inference with Anisotropic Vector Quantization</a>, Google Researchers address this speed-accuracy tradeoff with a novel compression algorithm that, compared to <a href=\"https://github.com/erikbern/ann-benchmarks#evaluated\" target=\"_blank\">previous state-of-the-art methods</a>, improves both the relevance and speed of retrieval. At Google, this technique is widely-adopted to support deep retrieval use cases across Search, YouTube, Ads, Lens, and others. And while it’s available in an open-sourced library (<a href=\"https://github.com/google-research/google-research/tree/master/scann\" target=\"_blank\">ScaNN</a>), it can still be challenging to implement, tune, and scale. To help teams take advantage of this technology without the operational overhead, Google Cloud offers these capabilities (and more) as a managed service with <a href=\"https://cloud.google.com/vertex-ai/docs/matching-engine/overview\" target=\"_blank\">Vertex AI Matching Engine</a>. </p>

<p>The goal of this post is to demonstrate how to implement these deep retrieval techniques using Vertex AI and discuss the decisions and trade-offs teams will need to evaluate for their use cases.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Reference architecture for two-tower training and deployment on Vertex AI.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiPqPFlV3qId7XO2AAP6fcCawuaCBmkHwV44zj7OCiB4unh7BJYbp27c0qpWY4AMxM62ONYEfrMfG8sZnUMCYX7brI7DRh_ulbpV1pLDP5c1Z3KFiWpQ7mgYmyoszyl8PSvxUiCC7Xd0NrEduCEaePwO9Am3OZw2pT0zVOTYtOxUBWMRa9QV_dRCy4A/s1600/figure-03_7QHFOAX.max-800x800.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 3: Figure 3: A reference architecture for two-tower training and deployment on Vertex AI.</i></td></tr></tbody></table></div>

<h2>Two-towers for deep retrieval</h2>

<p>To better understand the benefits of two-tower architectures, let’s review three key modeling milestones in candidate retrieval.</p>

<h4>Evolution of retrieval modeling</h4>

<p>Traditional information retrieval systems rely heavily on token-based matching, where candidates are retrieved using an inverted index of n-grams. These systems are interpretable, easy to maintain (e.g., no training data), and are capable of achieving high precision. However, they typically suffer poor recall (i.e., trouble finding all relevant candidates for a given query) because they look for candidates having exact matches of key words. While they are still used for select Search use cases, many retrieval tasks today are either adapted with or replaced by embedding-based techniques.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Flow chart illustrating token based retrieval\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhuMjrVtSOfyMbeC5IXiP0dC17TU5UU40IQxORVdafanmIHWmmQDM9McLWjoboCpJVah6fECBnbNplRBlMgcKliKj8NWph6GCKprcs8FJnqgX2s0_XoYTv-1KA3BGH_6l4wFY_t6t5VYLNUsL7UjxGurKaTOIz6OG21vpGHVT9UyGIG-BqZ_LzivtxE/s1600/figure-04_pJByae8.max-1400x1400.jpg\" style=\"width: 50%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 4: Token-based matching selects candidate items by matching key words found in both query and candidate items.</i></td></tr></tbody></table></div>

<p>Factorization-based retrieval introduces a simple embedding-based model that offers much better <a href=\"https://developers.google.com/machine-learning/crash-course/generalization/video-lecture\" target=\"_blank\">generalization</a> by capturing the similarity between <code>query, candidate</code> pairs and mapping them to a shared embedding space. One of the major benefits to this <a href=\"https://developers.google.com/machine-learning/recommendation/collaborative/basics\" target=\"_blank\">collaborative filtering</a> technique is that embeddings are learned automatically from implicit query-candidate interactions. Fundamentally, these models factorize the full query-candidate interaction (co-occurrence) matrix to produce smaller, dense embedding representations of queries and candidates, where the product of these embedding vectors is a good approximation of the interaction matrix. The idea is that by compacting the full matrix into k dimensions the model learns the top k latent factors describing <code>query, candidate</code> pairs with respect to the modeling task.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration of how a factorization based model factoizes a query-candidate interaction matrix intothe product of two lower rank matrices\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9dC-U02ISI-b2s5cHvYdfCvV_gyNisW5D2h-MqgKCGKhe0fxyACGKoA8r9YCcox8OSTBJErdSeUQYtM6rD1n8gtXf185TH05LRrBt41Ju6cdZhzFHJf65RiEVwcLvi5c1P3oAnJ9QcYdCKH_UqJwIdyg0IEhwhonSh-kcvy_vH9RnkaTMy11mbPfM/s1600/figure-05_gXUdrZt.max-1000x1000.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 5: Factorization-based models factorize a query-candidate interaction matrix into the product of two lower-rank matrices that capture the query-candidate interactions.</i></td></tr></tbody></table></div>

<p>The latest modeling paradigm for retrieval, commonly referred to as neural deep retrieval (NDR), produces the same embedding representations, but uses deep learning to create them. NDR models like two-tower encoders apply deep learning by processing input features with successive network layers to learn layered representations of the data. Effectively, this results in a neural network that acts as an information distillation pipeline, where raw, multi-modal features are repeatedly transformed such that useful information is magnified and irrelevant information is filtered. This results in a highly expressive model capable of learning non-linear relationships and more complex feature interactions.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Side-by-side illustrations showing the differences between factorization based retrieval and neural deep retreival\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNsBwfCGqFh9_rm9BcJvE50BI7l4GjfaoboECQtcRtCH5ITjgPW7C-xyDSVDYrA1pzNkr_xZtwNXzRqdrMk3UhNq2ONC1ERi1HPDIPIWCbAnFPspW_mXWubNh15MLI1hcyx1YQkx4tHa_OS9voCxo5cgz34dFrgrfjTPah1qQ-TcstRo3HdnOJ7oJ2/s1600/figure-6_uA0W9dA.max-1100x1100.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 6: NDR architectures like two-tower encoders are conceptually similar to factorization models. Both are embedding-based retrieval techniques computing lower-dimensional vector representations of query and candidates, where the similarity between these two vectors is determined by computing their <a href=\"https://developers.google.com/machine-learning/recommendation/overview/candidate-generation#dot-product\" target=\"_blank\">dot product</a>.</i></td></tr></tbody></table></div>

<p>In a two-tower architecture, each tower is a neural network that processes either query or candidate input features to produce an embedding representation of those features. Because the embedding representations are simply vectors of the same length, we can compute the <a href=\"https://developers.google.com/machine-learning/recommendation/overview/candidate-generation#dot-product\" target=\"_blank\">dot product</a> between these two vectors to determine how close they are. This means the orientation of the embedding space is determined by the dot product of each <code>query, candidate</code> pair in the training examples.</p>

<h2>Decoupled inference for optimal serving</h2>

<p>In addition to increased expressivity and generalization, this kind of architecture offers optimization opportunities for serving. Because each tower only uses its respective input features to produce a vector, the trained towers can be operationalized separately. Decoupling inference of the towers for retrieval means we can precompute what we want to find when we encounter its pair in the wild. It also means we can optimize each inference task differently:</p>
<ul><blockquote>
<li>Run a batch prediction job with a trained candidate tower to precompute embedding vectors for all candidates, attach NVIDIA GPU to accelerate computation</li>
<li>Compress precomputed candidate embeddings to an ANN index optimized for low-latency retrieval; deploy index to an endpoint for serving</li>
<li>Deploy trained query tower to an endpoint for converting queries to embeddings in real time, attach NVIDIA GPU to accelerate computation</li>
</blockquote></ul>
<p>Training two-tower models and serving them with an ANN index is different from training and serving traditional machine learning (ML) models. To make this clear, let’s review the key steps to operationalize this technique.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Side-by-side illustrations showing the differences between factorization based retrieval and neural deep retreival\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnDMV4PhibCuk5h_whxRUp-Keg8pItXANLSJ50S7yxB_R3l7ZSJcOO1X0N5B0aYNUNQgdtH44pTTdHYSiSYKknx47ZPquC-tqV9uKlAQ5MtCmLh1NR0pAC913UlAS8anpJImwa6o7mmbjJPzNjM7eIzKx3vVTzKN-1CmI7NVEr7Ip-o1oE4Ciiu44M/s1600/figure-07_eejzduW.max-1000x1000.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 7: A reference architecture for two-tower training and deployment on Vertex AI.</i></td></tr></tbody></table></div>

<ol><blockquote>
<li>Train combined model (two-towers) offline; each tower is saved separately for different tasks</li>
<li>Upload the query tower to Vertex AI Model Registry and deploy to an online endpoint</li>
<li>Upload the candidate tower to Vertex AI Model Registry</li>
<li>Request candidate tower to predict embeddings for each candidate track, save embeddings in JSON file</li>
<li>Create ANN serving index from embeddings JSON, deploy to online index endpoint</li>
<li>User application calls endpoint.predict() with playlist data, model returns the embedding vector representing that playlist</li>
<li>Use the playlist embedding vector to search for N nearest neighbors (candidate tracks)</li>
<li>Matching Engine returns the product IDs for the N nearest neighbors</li>
  </blockquote></ol>

<h2>Problem Framing</h2>

<p>In this example, we use MPD to construct a recommendation use case, playlist continuation, where candidate tracks are recommended for a given playlist (query). This dataset is publicly available and offers several benefits for this demonstration:</p>
<ul><blockquote>
<li>Includes real relationships between entities (e.g., playlists, tracks, artists) which can be difficult to replicate</li>
<li>Large enough to replicate scalability issues likely to occur in production</li>
<li>Variety of feature representations and data types (e.g., playlist and track IDs, raw text, numerical, datetime); ability to enrich dataset with additional metadata from the <a href=\"https://developer.spotify.com/documentation/web-api\" target=\"_blank\">Spotify Web Developer API</a></li>
<li>Teams can analyze the impact of modeling decisions by listening to retrieved candidate tracks (e.g., generate recommendations for your own Spotify playlists)</li>  
  </blockquote></ul>


<h4>Training examples</h4>

<p>Creating training examples for recommendation systems is a non-trivial task. Like any ML use case, training data should accurately represent the underlying problem we are trying to solve. Failure to do this can lead to poor model performance and unintended consequences for the user experience. One such lesson from the <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" target=\"_blank\">Deep Neural Networks for YouTube Recommendations</a> paper highlights that relying heavily on features such as ‘click-through rate’ can result in recommending clickbait (i.e., videos users rarely complete), as compared to features like ‘watch time’ which better capture a user’s engagement.</p>

<p>Training examples should represent a semantic match in the data. For playlist-continuation, we can think of a semantic match as pairing playlists (i.e., a set of tracks, metadata, etc.) with tracks similar enough to keep the user engaged with their listening session. How does the structure of our training examples influence this? </p>
<ul><blockquote>
<li>Training data is sourced from positive <code>query, candidate</code> pairs</li>
<li>During training, we forward propagate query and candidate features through their respective towers to produce the two vector representations, from which we compute the dot product representing their similarity </li>
<li>After training, and before serving, the candidate tower is called to predict (precompute) embeddings for all candidate items</li>
<li>At serving time, the model processes features for a given playlist and produces a vector embedding</li>
<li>The playlist’s vector embedding is used in a search to find the most similar vectors in the precomputed candidate index</li>
<li>The placement of candidate and playlist vectors in the embedding space, and the distance between them, is defined by the semantic relationships reflected in the training examples</li>
</blockquote></ul>
  
<p>The last point is important. Because the quality of our embedding space dictates the success of our retrieval, the model creating this embedding space needs to learn from training examples that best illustrate the relationship between a given playlist and <code>similar</code> tracks to retrieve.</p>

<p>This notion of similarity being highly dependent on the choice of paired data highlights the importance of preparing features that describe semantic matches. A model trained on <code>playlist title, track title</code> pairs will orient candidate tracks differently than a model trained on <code>aggregated playlist audio features, track audio features</code> pairs. </p>

<p>Conceptually, training examples consisting of <code>playlist title, track title</code> pairs would create an embedding space in which all tracks belonging to playlists of the same or similar titles (e.g., <code>beach vibes</code> and <code>beach tunes</code>) would be closer together than tracks belonging to different playlist titles (e.g., <code>beach vibes</code> vs  <code>workout tunes</code>); and examples consisting of <code>aggregated playlist audio features, track audio features</code> pairs would create an embedding space in which all tracks belonging to playlists with similar audio profiles (e.g., <code>live recordings of instrumental jams</code> and <code>high energy instrumentals</code>) would be closer together than tracks belonging to playlists with different audio profiles (e.g., <code>live recordings of instrumental jams</code> vs <code>acoustic tracks with lots of lyrics</code>). </p>

<p>The intuition for these examples is that when we structure the rich track-playlist features in a format that describes how tracks show up on certain playlists, we can feed this data to a two tower model that learns all of the niche relationships between parent playlist and child tracks. Modern deep retrieval systems often consider user profiles, historical engagements, and context. While we don’t have user and context data in this example, they can easily be added to the query tower.</p>

<h2>Implementing deep retrieval with TFRS</h2>

<p>When building retrieval models with TFRS, the two towers are implemented with <a href=\"https://www.tensorflow.org/guide/keras/custom_layers_and_models\" target=\"_blank\">model subclassing</a>. Each tower is built separately as a callable to process input feature values, pass them through feature layers, and concatenate the results. This means the tower is simply producing one concatenated vector (i.e., the representation of the query or candidate; whatever the tower represents).

First, we define the basic structure of a tower and implement it as a subclassed Keras model:
  
</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Playlist_Tower</span>(tf.keras.Model):
   <span class=\"hljs-string\">'''
   produced embedding represents the features
   of a Playlist known at query time
   '''</span>
   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, layer_sizes, vocab_dict</span>):
       <span class=\"hljs-built_in\">super</span>().__init__()

       <span class=\"hljs-comment\"># <span class=\"hljs-doctag\">TODO:</span> build sequential model for each feature here</span>

   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">call</span>(<span class=\"hljs-params\">self, data</span>):
       <span class=\"hljs-string\">'''
       defines what happens when the model is called
       '''</span>
       all_embs = tf.concat(
           [
               <span class=\"hljs-comment\"># <span class=\"hljs-doctag\">TODO:</span> concatenate output of all features defined above</span>
                           
           ], axis=<span class=\"hljs-number\">1</span>)
      
       <span class=\"hljs-comment\"># pass output to dense/cross layers</span>
       <span class=\"hljs-keyword\">if</span> self._cross_layer <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:
           cross_embs = self._cross_layer(all_embs)
           <span class=\"hljs-keyword\">return</span> self.dense_layers(cross_embs)
       <span class=\"hljs-keyword\">else</span>:
           <span class=\"hljs-keyword\">return</span> self.dense_layers(all_embs)</span></code></td></tr></tbody></table>

<p>We further define the subclassed towers by creating Keras sequential models for each feature being processed by that tower:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\"># Feature: pl_name_src</span>
self.pl_name_src_text_embedding = tf.keras.Sequential(
   [
       tf.keras.layers.TextVectorization(
           vocabulary=vocab_dict[<span class=\"hljs-string\">'pl_name_src'</span>],
           ngrams=<span class=\"hljs-number\">2</span>,
           name=<span class=\"hljs-string\">\"pl_name_src_textvectorizor\"</span>
       ),
       tf.keras.layers.Embedding(
           input_dim=MAX_TOKENS,
           output_dim=EMBEDDING_DIM,
           name=<span class=\"hljs-string\">\"pl_name_src_emb_layer\"</span>,
           mask_zero=<span class=\"hljs-literal\">False</span>
       ),
       tf.keras.layers.GlobalAveragePooling1D(name=<span class=\"hljs-string\">\"pl_name_src_1d\"</span>),
   ], name=<span class=\"hljs-string\">\"pl_name_src_text_embedding\"</span>
)</span></code></td></tr></tbody></table>

<p>Because the features represented in the playlist’s <code>STRUCT</code> are sequence features (lists), we need to reshape the embedding layer output and use 2D pooling (as opposed to the 1D pooling applied for non-sequence features):</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-comment\"># Feature: artist_genres_pl</span>
self.artist_genres_pl_embedding = tf.keras.Sequential(
   [
       tf.keras.layers.TextVectorization(
           ngrams=<span class=\"hljs-number\">2</span>,
           vocabulary=vocab_dict[<span class=\"hljs-string\">'artist_genres_pl'</span>],
           name=<span class=\"hljs-string\">\"artist_genres_pl_textvectorizor\"</span>
       ),
       tf.keras.layers.Embedding(
           input_dim=MAX_TOKENS, 
           output_dim=EMBED_DIM,
           name=<span class=\"hljs-string\">\"artist_genres_pl_emb_layer\"</span>,
           mask_zero=<span class=\"hljs-literal\">False</span>
       ),
       tf.keras.layers.Reshape([-<span class=\"hljs-number\">1</span>, MAX_PL_LENGTH, EMBED_DIM]),
       tf.keras.layers.GlobalAveragePooling2D(name=<span class=\"hljs-string\">\"artist_genres_pl_2d\"</span>),
   ], name=<span class=\"hljs-string\">\"artist_genres_pl_emb_model\"</span>
)</span></code></td></tr></tbody></table>

<p>Once both towers are built, we use the TFRS base model class (<a href=\"https://www.tensorflow.org/recommenders/api_docs/python/tfrs/models/Model\" target=\"_blank\">tfrs.models.Model</a>) to streamline building the combined model. We include each tower in the class <code>__init__</code> and define the <code>compute_loss</code> method:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">TheTwoTowers</span>(tfrs.models.Model):

   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, layer_sizes, vocab_dict, parsed_candidate_dataset</span>):
       <span class=\"hljs-built_in\">super</span>().__init__()
      
       self.query_tower = Playlist_Tower(layer_sizes, vocab_dict)

       self.candidate_tower = Candidate_Track_Tower(layer_sizes, vocab_dict)
      
       self.task = tfrs.tasks.Retrieval(
           metrics=tfrs.metrics.FactorizedTopK(
               candidates=parsed_candidate_dataset.batch(<span class=\"hljs-number\">128</span>).<span class=\"hljs-built_in\">map</span>(
                   self.candidate_tower,
                   num_parallel_calls=tf.data.AUTOTUNE
               ).prefetch(tf.data.AUTOTUNE)
           )
       )

   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">compute_loss</span>(<span class=\"hljs-params\">self, data, training=<span class=\"hljs-literal\">False</span></span>):
      
       query_embeddings = self.query_tower(data)
       candidate_embeddings = self.candidate_tower(data)
      
       <span class=\"hljs-keyword\">return</span> self.task(
           query_embeddings,
           candidate_embeddings,
           compute_metrics=<span class=\"hljs-keyword\">not</span> training,
           candidate_ids=data[<span class=\"hljs-string\">'track_uri_can'</span>],
           compute_batch_metrics=<span class=\"hljs-literal\">True</span>
       )</span></code></td></tr></tbody></table>

<h2>Dense and cross layers</h2>

<p>We can increase the depth of each tower by adding dense layers after the concatenated embedding layer. As this will emphasize learning successive layers of feature representations, this can improve the expressive power of our model. </p>

<p>Similarly, we can add deep and cross layers after our embedding layer to better model feature interactions. Cross layers model explicit feature interactions before combining with deep layers that model implicit feature interactions. These parameters often lead to better performance, but can significantly increase the computational complexity of the model. We recommend evaluating different deep and cross layer implementations (e.g., parallel vs stacked). See the TFRS <a href=\"https://www.tensorflow.org/recommenders/examples/dcn\" target=\"_blank\">Deep and Cross Networks</a> guide for more details.</p>

<h2>Feature engineering</h2>

<p>As the factorization-based models offer a pure collaborative filtering approach, the advanced feature processing with NDR architectures allow us to extend this to also incorporate aspects of <a href=\"https://developers.google.com/machine-learning/recommendation/content-based/basics\" target=\"_blank\">content-based filtering</a>. By including additional features describing playlists and tracks, we give NDR models the opportunity to learn semantic concepts about <code>playlist, track</code> pairs. The ability to include label features (i.e., features about candidate tracks) also means our trained candidate tower can compute an embedding vector for candidate tracks not observed during training (i.e., cold-start). Conceptually, we can think of such a new candidate track embedding compiling all the content-based and collaborative filtering information learned from candidate tracks with the same or similar feature values.</p>

<p>With this flexibility to add multi-modal features, we just need to process them to produce embedding vectors with the same dimensions so they can be concatenated and fed to subsequent deep and cross layers. This means if we use pre-trained embeddings as an input feature, we would pass these through to the concatenation layer (see Figure 8).</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration of feature processing from input to concatenated output.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVmlvZLD8Z3qomGp6PtbDkLVuhVuj-qXJJGiT-Qwo7zXz1-g-kJdcUD0_O-PeTC6MwCDDgZfqrxgBtkzZ9BZwBMqiO3qLzGoFCPXVxoMVkyg2phPmbdpG_XNl6YiAYjXizaOexxkgasIRLkrwZqELfLsL7IC_9tVAuDFPw0Dh3mIJePWgxxX8NzDL0/s1600/figure-08_tNj3ZJ9.max-1400x1400.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 8: Illustration of feature processing from input to concatenated output. Text features are generated via n-grams. Integer indexes of n-grams are passed to an embedding layer. Hashing produces unique integers up to 1,000,000; values passed to an embedding layer. If using pre-trained embeddings, these are passed through the tower without transformation and concatenated with the other embedding representations.</i></td></tr></tbody></table></div>

<strong>Hashing vs StringLookup() layers</strong>

<p>Hashing is generally recommended when fast performance is needed and is preferred over string lookups because it skips the need for a lookup table. Setting the proper bin size for the hashing layer is critical. When there are more unique values than hashing bins, values start getting placed into the same bins, and this can negatively impact our recommendations. This is commonly referred to as a hashing collision, and can be avoided when building the model by allocating enough bins for the unique values. See <a href=\"https://www.tensorflow.org/recommenders/examples/featurization#turning_categorical_features_into_embeddings\" target=\"_blank\">turning categorical features into embeddings</a> for more details. </p>

<div><strong>TextVectorization() layers</strong></div>

<p>The key to text features is to understand if creating additional NLP features with the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\">TextVectorization</a> layer is helpful. If additional context derived from the text feature is minimal, it may not be worth the cost to model training. This layer needs to be adapted from the source dataset, meaning the layer requires a scan of the training data to create lookup dictionaries for the top N n-grams (set by <code>max_tokens</code>). </p>


<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Decision tree to guide feature engineering strategy\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhN6GYCkrSvtDI5cUl-bCWe4ibcJAQnvXsYWHsNeN_GEJ4O7XaNNsN2uCADDN5vvz-Dn_8ofE0CSBMZ-xsdHAG1U5si5cQZjRi02fgqQrcq6O0OQD15ov7BAoO64IQx5AkxXuQdejbr1075mwxwjsRzmuNXLKCW8hMEcLKyAuPuVjC_Qg1mwJCU5pci/s1600/figure-09.max-800x800.jpg\" style=\"width: 80%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 9: Decision tree to guide feature engineering strategy.</i></td></tr></tbody></table></div>

<h2>Efficient retrieval with Matching Engine</h2>

<p>So far we’ve discussed how to map queries and candidates to the shared embedding space. Now let’s discuss how to best use this shared embedding space for efficient serving. </p>

<p>Recall at serving time, we will use the trained query tower to compute the embeddings for a query (playlist) and use this embedding vector in a nearest neighbor search for the most similar candidate (track) embeddings. And, because the candidate dataset can grow to millions or billions of vectors, this nearest neighbor search often becomes a computational bottleneck for low-latency inference. </p>

<p>Many state-of-the-art techniques address the computational bottleneck by compressing the candidate vectors such that ANN calculations can be performed in a fraction of the time needed for an exhaustive search. The novel compression algorithm proposed by Google Research modifies these techniques to also optimize for the nearest neighbor search accuracy. The details of their proposed technique are described <a href=\"https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html\" target=\"_blank\">here</a>, but fundamentally their approach seeks to compress the candidate vectors such that the original distances between vectors are preserved. Compared to previous solutions, this results in a more accurate relative ranking of a vector and its nearest neighbors, i.e., it minimizes distorting the vector similarities our model learned from the training data.</p>

<h4>Fully managed vector database and ANN service </h4>

<p>Matching Engine is a managed solution utilizing these techniques for efficient vector similarity search. It offers customers a highly scalable vector database and ANN service while alleviating the operational overhead of developing and maintaining similar solutions, such as the open sourced <a href=\"https://github.com/google-research/google-research/tree/master/scann\" target=\"_blank\">ScaNN</a> library. It includes several capabilities that simplify production deployments, including:</p>
<ul><blockquote>
<li>Large-scale: supports large embedding datasets with up to 1 billion embedding vectors</li>
<li>Incremental updates: depending on the number of vectors, complete index rebuilds can take hours. With incremental updates, customers can make small changes without building a new index (see <a href=\"https://cloud.google.com/vertex-ai/docs/matching-engine/update-rebuild-index\" target=\"_blank\">Update and rebuild an active index</a> for more details)</li>
<li>Dynamic rebuilds: when an index grows beyond its original configuration, Matching Engine periodically re-organizes the index and serving structure to ensure optimal performance</li>
<li>Autoscaling: underlying infrastructure is autoscaled to ensure consistent performance at scale</li>
<li>Filtering and diversity: ability to include multiple restrict and crowding tags per vector. At query inference time, use boolean predicates to filter and diversify retrieved candidates (see <a href=\"https://cloud.google.com/vertex-ai/docs/matching-engine/filtering\" target=\"_blank\">Filter vector matches</a> for more details)</li>
  </blockquote></ul>

<p>When creating an ANN index, Matching Engine uses the <a href=\"https://arxiv.org/abs/1908.10396\" target=\"_blank\">Tree-AH</a> strategy to build a distributed implementation of our candidate index. It combines two algorithms:</p>
<ul><blockquote>
<li>Distributed search tree for hierarchically organizing the embedding space. Each level of this tree is a clustering of the nodes at the next level down, where the final leaf-level is a clustering of our candidate embedding vectors</li>
<li>Asymmetric hashing (AH) for fast dot product approximation algorithm used to score similarity between a query vector and the search tree nodes</li>
  </blockquote></ul>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Illustration showing the partitioned candidate vector dataset.\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjhgSVYoP9wxnLqHpIwdRjmbDK_C8LnnbyZ0b98Vrm1tSxtzLjYeyR6-V-QOF7VKj8OeTgimX79rkPu-d2OjvZ-rKu8oWTD1G_zFjLd5QFctJIQ19i2aHfy_AiXJj6FmIovekEOxeEZc-1pjv73KKUK9U3TYLNjXYAcDQemu5OUg1EEEY0QJlGBjcT1/s1600/figure-10.max-1000x1000.jpg\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 10: conceptual representation of the partitioned candidate vector dataset. During query inference, all partition centroids are scored. In the centroids most similar to the query vector, all candidate vectors are scored. The scored candidate vectors are aggregated and re-scored, returning the top N candidate vectors.</i></td></tr></tbody></table></div>

<p>This strategy shards our embedding vectors into partitions, where each partition is represented by the centroid of the vectors it contains. The aggregate of these partition centroids form a smaller dataset summarizing the larger, distributed vector dataset. At inference time, Matching Engine scores all the partitioned centroids, then scores the vectors within the partitions whose centroids are most similar to the query vector.</p>

<h2>Conclusion</h2>

<p>In this blog we took a deep dive into understanding critical components of a candidate retrieval workflow using <a href=\"https://www.tensorflow.org/recommenders\" target=\"_blank\">TensorFlow Recommenders</a> and <a href=\"https://cloud.google.com/vertex-ai/docs/matching-engine/overview\" target=\"_blank\">Vertex AI Matching Engine</a>. We took a closer look at the foundational concepts of two-tower architectures, explored the semantics of query and candidate entities, and discussed how things like the structure of training examples can impact the success of candidate retrieval. </p> 

<p>In a subsequent post we will demonstrate how to use Vertex AI and other Google Cloud services to implement these techniques at scale. We’ll show how to leverage BigQuery and Dataflow to structure training examples and convert them to <a href=\"https://www.tensorflow.org/tutorials/load_data/tfrecord\" target=\"_blank\">TFRecords</a> for model training. We’ll outline how to structure a Python application for training two-tower models with the Vertex AI Training service. And we’ll detail the steps for operationalizing the trained towers.</p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Tue, 02 May 2023 17:00:00 +0000"
2525,Serving With TF and GKE: Stable Diffusion,https://blog.tensorflow.org/2023/04/serving-with-tf-and-gke-stable-diffusion.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEguJhniX2FvspHjYxJweJYNTFf1DAveLJuABYaoET7jnheNVQpnXN_twr3CuvTjMUZprSwoqF9QNipAjD985qwRfNpIg1HkPU2iUUfGeGFRkKTJOxpv9l1BWGd11bsrr6spltyp93eiW6XxGtl3foLcZ6zplnnGL617JyimdhzVxxwAhoJuDKtqpsV8/s1600/TF%20Stable%20Diffusion%20%282%29.png\" style=\"display: none;\" />

<p><em>Posted by <a href=\"https://github.com/deep-diver\" target=\"_blank\">Chansung Park</a> and <a href=\"https://github.com/sayakpaul\" target=\"_blank\">Sayak Paul</a> (ML and Cloud GDEs)</em></p><p>

</p><a name=\"more\"></a><p></p>

<p>Generative AI models like <a href=\"https://stability.ai/blog/stable-diffusion-public-release\" target=\"_blank\">Stable Diffusion</a><sup><a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss#fn-1-ref\">1</a></sup> that lets anyone generate high-quality images from natural language text prompts enable different use cases across different industries. These types of models allow people to generate these images not only from images but also condition them with other inputs such as segmentation maps, other images, depth maps, etc. In many ways, an end Stable Diffusion system (such as <a href=\"https://huggingface.co/spaces/stabilityai/stable-diffusion\" target=\"_blank\">this</a>) is often very complete. One gives a free-form text prompt to start the generation process, and in the end, an image (or any data in the continuous modality) gets generated.</p>

<p>In this post, we discuss how TensorFlow Serving (TF Serving) and Google Kubernetes Engine (GKE) can serve such a system with online deployment. Stable Diffusion is just one example of many such systems that TF and GKE can serve with online deployment. We start by breaking down Stable Diffusion into main components and how they influence the subsequent consideration for deployment. Then we dive deep into the deployment-specific bits such as TF Serving deployment and k8s cluster configuration. Our code is open-sourced in <a href=\"https://github.com/deep-diver/keras-sd-serving\" target=\"_blank\">this repository</a>. </p> 

<p>Let’s dive in. </p>

<strong><h2>Stable Diffusion in a nutshell</h2></strong>

<p>Stable Diffusion, is comprised of three sub-models:</p>
<ul><blockquote>
<li><a href=\"https://openai.com/blog/clip/\" target=\"_blank\">CLIP’s</a> text tower as the Text Encoder,</li>
<li>Diffusion Model (UNet), and </li>
<li>Decoder of a Variational Autoencoder</li>
  </blockquote></ul>

<p>When generating images from an input text prompt, the prompt is first embedded into a latent space with the text encoder. Then an initial noise is sampled, which is fed to the Diffusion model along with the text embeddings. This noise is then denoised using the Diffusion model in a continuous manner – the so-called “diffusion” process. The output of this step is a denoise latent, and it is fed to the Decoder for final image generation.  Figure 1 provides an overview. </p>

<p>(For a more complete overview of Stable Diffusion, refer to <a href=\"https://jalammar.github.io/illustrated-stable-diffusion/\" target=\"_blank\">this post</a>.)</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Flow chart illustrating stable diffusion architecture\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQ1OsQLLUKIwVt9yPv0pEuJ7PVJ-QWWUV2AvGkBX5gtHksVNkzlFITMLvV7VmrNTsAP6WL80Tn3X6Z3zdkBs4m1mjqUHletya9b0Ef5wgAvNqVndqKONvmwjWkwPQZsu7Q7OlQRpEKkefJ1ZveKCvVAKzDh4xyzVYIhqgw7SCIsjeqf1Bj4OOmlxwJ/s1600/image3.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 1. Stable Diffusion Architecture</i></td></tr></tbody></table></div>

<p>As mentioned above, three sub-models of Stable Diffusion work in a sequential manner. It’s common to run all three models on a single server (which constructs the end Stable Diffusion system) and serve the system as a whole. </p>

<p>However, because each component is a standalone deep learning model, each one could be served independently. This is particularly useful because each component has different hardware requirements. This can also have potentially improved resource utilization. The text encoder can still be run on moderate CPUs, whereas the other two should be run on GPUs, especially the UNet should be served with larger size GPUs (~3.4 GBs in size). </p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Flow chart illustrating decomposing stable diffusion in three parts\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1YVyDjjKWeQYsnna9cWkty6buXuJql2SA3xjLqji0teVuA_748WQl67s3--TJiusFbApgIW6z_FYMV3WoGCia0RijpaprQfD3pMBRMsVcZBPOB8xhfVdNAR9eWGHkYVGMNpU51S5myEFlp_HOFaM7V_xpwBy0pWLUXSR68LUQmtqOmeEi9Wv50vmz/s1600/image4.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 2. Decomposing Stable Diffusion in three parts</i></td></tr></tbody></table></div>

<p>Figure 2 shows the Stable Diffusion serving architecture that packages each component into a separate container with TensorFlow Serving, which runs on the GKE cluster. This separation brings more control when we think about local compute power and the nature of fine-tuning of Stable Diffusion as shown in Figure 3. </p>

<p><em>NOTE: TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments,  which is widely adopted in industry. The benefits of using it include GPU serving support, dynamic batching, model versioning, RESTful and gRPC APIs, to name but a few.</em></p>

<p>In modern personal devices such as desktops and mobile phones, it is common that they are equipped with moderate CPUs and sometimes GPU/NPUs. In this case, we could selectively run the UNet and/or Decoder in the cloud using high capacity GPUs while running the text encoder locally on the user’s device. In general, this approach allows us to flexibly architect the Stable Diffusion system in a way to maximize the resource utilization.</p>


<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Flow chart illustrating flexible serving structure of stable diffusion\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitUhiVzFClwCI5lUlN6wcIi3d-OkA8mogPW6B5WTSjuq535ELkDR3ziPZHySFk9tNq05Ps_kn7l3gFFP1LL8GAqg4t8_M9fP7ht4SXhX8smPO0k3PTq2DJ3EvJ6wSMHP912xM642eIfr0oiH_FXMBeV5MW8hHHOLrmpcVLVyUKlepKJqMaZz_mmTAE/s1600/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 3. Flexible serving structure of Stable Diffusion</i></td></tr></tbody></table></div>

<p>One more scenario to consider is fine-tuned Stable Diffusion. Many variations such as DreamBooth, Textual Inversion, or style transfer have shown that modifying only one or two components (usually Text Encoder and UNet) can generate images with new concepts or different styles. In this case, we could selectively deploy more of certain fine-tuned models on separate instances or replace existing models without touching other parts.</p>

<strong><h2>Wrapping Stable Diffusion in SavedModels</h2></strong>

<p>In order to serve a TensorFlow/Keras model with TF Serving, it should be saved in the  <a href=\"https://www.tensorflow.org/guide/saved_model\" target=\"_blank\">SavedModel format</a>. After that, the model can be served by TF Serving, a high-performance serving system for machine learning models, specially designed for production environments. The potentially non-trivial parts of making a <code>SavedModel</code> could be divided into three parts: </p>
<ol><blockquote>
<li>defining an appropriate input signature specification of the underlying model, </li>
<li>performing computations with the underlying model so that everything can be compiled in native TensorFlow, and </li>
<li>including most of the pre and post-processing operations within the <code>SavedModel</code> graph itself to reduce training/serving skew (this is optional, but highly recommended). </li>
</blockquote></ol>
  
<p>To make the <a href=\"https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/stable_diffusion/stable_diffusion.py\" target=\"_blank\">Stable Diffusion class</a> shipped in KerasCV compatible with TF Serving, we need to first isolate the sub-networks (as mentioned above) of the class. Recall that we have got three sub-networks here: text encoder, diffusion model, and a decoder. We then have to serialize these networks as <code>SavedModel</code>s. </p>

<p>A diffusion system also involves iterative sampling where a noise vector is gradually turned into an image. KerasCV’s Stable Diffusion class <a href=\"https://github.com/keras-team/keras-cv/blob/421acf209a0ef15808c8c359edb324fd120aca07/keras_cv/models/stable_diffusion/stable_diffusion.py#L206\" target=\"_blank\">implements</a> the sampling process with non-TensorFlow operations.  So, we need to eliminate those operations and ensure that it’s implemented in pure TensorFlow so that there is end-to-end compatibility. This was the single most challenging aspect for us in the whole project. </p>

<p>Since the serialization of the text encoder and the decoder is straightforward, we’ll skip that in this post and instead, focus on the serialization of the diffusion model, including the sampling process. You can find an end-to-end notebook <a href=\"https://colab.research.google.com/github/deep-diver/keras-sd-serving/blob/main/notebooks/tfs_saved_models.ipynb\" target=\"_blank\">here</a>. </p>

<strong><h4>Diffusion Model and Iterative Sampling </h4></strong>

<p>We start by defining an input signature dictionary for the <code>SavedModel</code> to be serialized. In this case, the inputs consist:</p>
<ul><blockquote>
<li><code>context</code>, that denotes embeddings of the input text prompt extracted with the text encoder  </li>
<li><code>unconditional_context</code>, that denotes the embeddings of a so-called “null prompt” (see <a href=\"https://arxiv.org/abs/2207.12598\" target=\"_blank\">classifier-free guidance</a>) </li>
<li><code>num_steps</code>, that denotes the number of sampling steps for the reverse diffusion process </li>
<li><code>batch_size</code>, that denotes the number of images to be returned</li></blockquote></ul><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">from keras_cv.models.stable_diffusion.constants import ALPHAS_CUMPROD_TF
import tensorflow as tf

IMG_HEIGHT = 512
IMG_WIDTH = 512
MAX_PROMPT_LENGTH = 77
ALPHAS_CUMPROD_TF = tf.constant(ALPHAS_CUMPROD_TF)
UNCONDITIONAL_GUIDANCE_SCALE = 7.5
HIDDEN_DIM = 768
SEED = None


signature_dict = {
    <span class=\"hljs-string\">\"context\"</span>: tf.TensorSpec(shape=[None, MAX_PROMPT_LENGTH, HIDDEN_DIM], dtype=tf.float32, name=<span class=\"hljs-string\">\"context\"</span>),
    <span class=\"hljs-string\">\"unconditional_context\"</span>: tf.TensorSpec(
        shape=[None, MAX_PROMPT_LENGTH, HIDDEN_DIM], dtype=tf.float32, name=<span class=\"hljs-string\">\"unconditional_context\"</span>
    ),
    <span class=\"hljs-string\">\"num_steps\"</span>: tf.TensorSpec(shape=[], dtype=tf.int32, name=<span class=\"hljs-string\">\"num_steps\"</span>),
    <span class=\"hljs-string\">\"batch_size\"</span>: tf.TensorSpec(shape=[], dtype=tf.int32, name=<span class=\"hljs-string\">\"batch_size\"</span>),
}</span></code></td></tr></tbody></table>

<p>Next up, we implement the iterative reverse diffusion process that involves the pre-trained diffusion model. <code>diffusion_model_exporter()</code> takes this model as an argument. <code>serving_fn()</code> is the function we use for exporting the final <code>SavedModel</code>. Most of this code is taken from the original KerasCV implementation <a href=\"https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/stable_diffusion/stable_diffusion.py\" target=\"_blank\">here</a>, except it has got all the operations implemented in native TensorFlow. </p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">def diffusion_model_exporter(model: tf.keras.Model):
    @tf.function
    def <span class=\"hljs-built_in\">get_timestep_embedding</span>(timestep, batch_size, dim=<span class=\"hljs-number\">320</span>, max_period=<span class=\"hljs-number\">10000</span>):
        ...
    @tf.<span class=\"hljs-built_in\">function</span>(input_signature=[signature_dict])
    def <span class=\"hljs-built_in\">serving_fn</span>(inputs):
        img_height = tf.<span class=\"hljs-built_in\">cast</span>(tf.math.<span class=\"hljs-built_in\">round</span>(IMG_HEIGHT / <span class=\"hljs-number\">128</span>) * <span class=\"hljs-number\">128</span>, tf.int32)
        img_width = tf.<span class=\"hljs-built_in\">cast</span>(tf.math.<span class=\"hljs-built_in\">round</span>(IMG_WIDTH / <span class=\"hljs-number\">128</span>) * <span class=\"hljs-number\">128</span>, tf.int32)

        batch_size = inputs[<span class=\"hljs-string\">\"batch_size\"</span>]
        num_steps = inputs[<span class=\"hljs-string\">\"num_steps\"</span>]

        context = inputs[<span class=\"hljs-string\">\"context\"</span>]
        unconditional_context = inputs[<span class=\"hljs-string\">\"unconditional_context\"</span>]

        latent = tf.random.<span class=\"hljs-built_in\">normal</span>((batch_size, img_height // <span class=\"hljs-number\">8</span>, img_width // <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">4</span>))

        timesteps = tf.<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1000</span>, <span class=\"hljs-number\">1000</span> // num_steps)
        alphas = tf.<span class=\"hljs-built_in\">map_fn</span>(lambda t: ALPHAS_CUMPROD_TF[t], timesteps, dtype=tf.float32)
        alphas_prev = tf.<span class=\"hljs-built_in\">concat</span>([[<span class=\"hljs-number\">1.0</span>], alphas[:-<span class=\"hljs-number\">1</span>]], <span class=\"hljs-number\">0</span>)

        index = num_steps - <span class=\"hljs-number\">1</span>
        latent_prev = None
        for timestep in timesteps[::-<span class=\"hljs-number\">1</span>]:
            latent_prev = latent
            t_emb = <span class=\"hljs-built_in\">get_timestep_embedding</span>(timestep, batch_size)
            unconditional_latent = <span class=\"hljs-built_in\">model</span>(
                [latent, t_emb, unconditional_context], training=False
            )
            latent = <span class=\"hljs-built_in\">model</span>([latent, t_emb, context], training=False)
            latent = unconditional_latent + UNCONDITIONAL_GUIDANCE_SCALE * (
                latent - unconditional_latent
            )
            a_t, a_prev = alphas[index], alphas_prev[index]
            pred_x0 = (latent_prev - tf.math.<span class=\"hljs-built_in\">sqrt</span>(<span class=\"hljs-number\">1</span> - a_t) * latent) / tf.math.<span class=\"hljs-built_in\">sqrt</span>(a_t)
            latent = (
                latent * tf.math.<span class=\"hljs-built_in\">sqrt</span>(<span class=\"hljs-number\">1.0</span> - a_prev) + tf.math.<span class=\"hljs-built_in\">sqrt</span>(a_prev) * pred_x0
            )
            index = index - <span class=\"hljs-number\">1</span>

        return {\"latent\": latent}

    return serving_fn</span></code></td></tr></tbody></table>

<p>Then, we can serialize the diffusion model as a <code>SavedModel</code> like so:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">tf.saved_model.save(
    diffusion_model,
    path_to_serialize_the_model,
    signatures={<span class=\"hljs-string\">\"serving_default\"</span>: diffusion_model_exporter(diffusion_model)},
)</span></code></td></tr></tbody></table>

<p>Here, <code>diffusion_model</code> is the pre-trained diffusion model initialized like so:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">from keras_cv.models.stable_diffusion.diffusion_model <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">DiffusionModel</span>
<span class=\"hljs-variable\">diffusion_model</span> <span class=\"hljs-operator\">=</span> DiffusionModel(IMG_HEIGHT, IMG_WIDTH, MAX_PROMPT_LENGTH)</span></code></td></tr></tbody></table>

<strong><h2>Deploy Stable Diffusion to GKE</h2></strong>

<p>Once you have successfully created TensorFlow <code>SavedModel</code>s, it is quite straightforward to deploy them with TensorFlow Serving to a GKE cluster in the following steps.</p>
<ol><blockquote>
<li>Write Dockerfiles which are based on the TensorFlow Serving base image </li>
<li>Create a GKE cluster with accelerators attached</li>
<li>Apply NVIDIA GPU driver installation daemon to install the driver on each node</li>
<li>Write deployment manifests with GPU allocation </li>
<li>Write service manifests to expose the deployments</li>
<li>Apply all the manifests</li>
  </blockquote></ol>

<p>The easiest way to wrap a <code>SavedModel</code> in TensorFlow Serving is to leverage the pre-built <a href=\"https://hub.docker.com/r/tensorflow/serving\" target=\"_blank\">TensorFlow Serving Docker images</a>. Depending on the configuration of the machine that you’re deploying to, you should choose either <code>tensorflow/serving:latest</code> or <code>tensorflow/serving:latest-gpu</code>. Because all the steps besides GPU-specific configuration are the same, we will explain this section with an example of the Diffusion Model part only.</p>

<p>By default, TensorFlow Serving recognizes embedded models under <code><a href=\"https://www.tensorflow.org/tfx/serving/docker#serving_with_docker\" target=\"_blank\">/models</a></code>, so the entire <code>SavedModel</code> folder tree should be placed inside <code>/models/{model_name}/{version_num}</code>. A  single TensorFlow Serving instance can serve multiple versions of multiple models, so that is why we need such a <code>{model_name}/{version_num}</code> folder structure. A <code>SavedModel</code> can be exposed as an API by setting a special environment variable <code><a href=\"https://www.tensorflow.org/tfx/serving/docker#serving_with_docker\" target=\"_blank\">MODEL_NAME</a></code>, which is used for TensorFlow Serving to look for which model to serve.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">FROM tensorflow/serving:latest-gpu
...
RUN <span class=\"hljs-built_in\">mkdir</span> -p /models/text-encoder/1
RUN <span class=\"hljs-built_in\">cp</span> -r tfs-diffusion-model/* /models/diffusion-model/1/
ENV MODEL_NAME=diffusion-model
...</span></code></td></tr></tbody></table>

<p>Next step is to create a GKE cluster. You can do this by using either Google Cloud Console or <code>gcloud</code> container CLI as below. If you want accelerators available on each node, you can specify how many of which GPUs to be attached with <code>--accelerator=type={ACCEL_TYPE}, count={ACCEL_NUM}</code> option.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-variable\">$</span> gcloud container clusters create <span class=\"hljs-punctuation\">{</span>CLUSTER_NAME<span class=\"hljs-punctuation\">}</span> \\
  --machine-<span class=\"hljs-keyword\">type</span><span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">{</span>MACHINE_TYPE<span class=\"hljs-punctuation\">}</span> \\                     <span class=\"hljs-comment\"># n1-standard-4</span>
  --accelerator<span class=\"hljs-punctuation\">=</span><span class=\"hljs-keyword\">type</span><span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">{</span>GPU_TYPE<span class=\"hljs-punctuation\">}</span>,count<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">{</span>GPU_NUM<span class=\"hljs-punctuation\">}</span> \\     <span class=\"hljs-comment\"># nvidia-tesla-v100, 1</span>
  <span class=\"hljs-punctuation\">...</span></span></code></td></tr></tbody></table>

<p>Once the cluster is successfully created, and if the nodes in the cluster have accelerators attached, an appropriate driver for them should be installed correctly. This is done by running a special DaemonSet, which tries to install the driver on each node. If the driver has not been successfully installed, and if you try to apply Deployment manifests requiring accelerators, the status of the pod remains as Pending. </p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">DRIVER_URL = https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml</span>
<span class=\"hljs-meta prompt_\">
$ </span><span class=\"language-bash\">kubectl apply -f <span class=\"hljs-variable\">$DRIVER_URL</span></span></span></code></td></tr></tbody></table>

<p>Make sure all the pods are up and running with <code>kubectl get pods -A</code> command. Then, we are ready to apply prepared Deployment manifests. Below is an example of the Deployment manifest for the Diffusion Model. The only consideration you need to take is to specify which resource the pods of the Deployment should consume. Because the Diffusion Model needs to be run on accelerators, <code>resources:limits:nvidia.com/gpu: {ACCEL_NUM}</code> should be set. </p>


<p>Furthermore, if you want to expose gRPC and RestAPI at the same time, you need to set containerPort for both. TensorFlow Serving exposes the two endpoints via 8500 and 8501, respectively, by default, so both ports should be specified. </p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span>
<span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span>
<span class=\"hljs-string\">...</span>
    <span class=\"hljs-attr\">spec:</span>
      <span class=\"hljs-attr\">containers:</span>
      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">image:</span> {<span class=\"hljs-string\">IMAGE_URI</span>}
<span class=\"hljs-string\">...</span>
        <span class=\"hljs-attr\">args:</span> [<span class=\"hljs-string\">\"--rest_api_timeout_in_ms=1200000\"</span>]
        <span class=\"hljs-attr\">ports:</span>
        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">8500</span>
          <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">grpc</span>
        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">8501</span>
          <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">restapi</span>
        <span class=\"hljs-attr\">resources:</span>
          <span class=\"hljs-attr\">limits:</span>
            <span class=\"hljs-attr\">nvidia.com/gpu:</span> <span class=\"hljs-number\">1</span></span></code></td></tr></tbody></table>

<p>One more thing to note is that <code>--rest_api_timeout_in_ms</code> flag is set in args with a huge number. It takes a long time for heavy models to run inference. Since the flag is set to 5,000ms by default which is 5 seconds, sometimes timeout occurs before the inference is done. You can experimentally find out the right number, but we simply set this with a high enough number to demonstrate this project smoothly. </p>


<p>The final step is to apply prepared manifest files to the provisioned GKE cluster. This could be easily done with the <code>kubectl apply -f</code> command. Also, you could apply Service and Ingress depending on your needs. Because we simply used vanilla LoadBalancer type of Service for demonstration purposes, it is not listed in this blog. You can find all the Dockerfiles, and the Deployment and Service manifests in the accompanying <a href=\"https://github.com/deep-diver/keras-sd-serving/tree/main/tfserving\" target=\"_blank\">GitHub repository</a>.</p>

<strong><h2>Let’s generate images!</h2></strong>

<p>Once all the TensorFlow Serving instances are deployed, we could generate images by calling their endpoints. We will show how to do it through RestAPI, but you could do the same with the gRPC channel as well. The image generation process could be done in the following steps:</p>
<ol><blockquote>
<li>Prepare tokens for the prompt of your choice</li>
<li>Send the tokens to the Text Encoder endpoint</li>
<li>Send context and unconditional context obtained from the Text Encoder to the Diffusion Model endpoint</li>
<li>Send latent obtained from the Diffusion Model to the Decoder endpoint</li>
<li>Plot the generated images</li>
  </blockquote></ol>

<p>Since it is non-trivial to embed a tokenizer into the Text Encoder itself, we need to prepare the tokens for the prompt of your choice. KerasCV library provides <code>SimpleTokenizer</code> in the <code>keras_cv.models.stable_diffusion.clip_tokenizer</code> module, so you could simply pass the prompt to it. Since the Diffusion Model is designed to accept <code>77</code> tokens, the tokens are padded with <code>MAX_PROMPT_LENGTH</code> up to <code>77</code> long.</p>
  
<p><em>NOTE: Since KerasCV comes with lots of modules that we don’t need for tokenization, it is not recommended to import the entire library. Instead, you could simply copy the codes for the SimpleTokenizer in your environment. Due to incompatibility issues, the current tokenizer cannot be shipped as a part of the Text Encoder <code>SavedModel</code>. </em></p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">from keras_cv.models.stable_diffusion.clip_tokenizer import SimpleTokenizer

MAX_PROMPT_LENGTH = 77
PADDING_TOKEN = 49407

tokenizer = SimpleTokenizer()

prompt = <span class=\"hljs-string\">\"photograph of an astronaut riding a horse in a green desert\"</span>
tokens = tokenizer.encode(prompt)
tokens = tokens + [PADDING_TOKEN] * (MAX_PROMPT_LENGTH - len(tokens))</span></code></td></tr></tbody></table>

<p>Once the tokens are prepared, we could simply pass it to the Diffusion Model’s endpoint. The headers and the way to call the all endpoints are identical as below, so we will omit it in the following steps. Just keep in mind you set the <code>ADDRESS</code> and the <code>MODEL_NAME</code> correctly, which is identical to the one we set in each Dockerfile. </p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">requests</span>

<span class=\"hljs-variable\">ADDRESS</span> <span class=\"hljs-operator\">=</span> <span class=\"hljs-type\">ENDPOINT_IP_ADDRESS</span>

<span class=\"hljs-variable\">headers</span> <span class=\"hljs-operator\">=</span> {<span class=\"hljs-string\">\"content-type\"</span>: <span class=\"hljs-string\">\"application/json\"</span>}
payload = <span class=\"hljs-type\">ENDPOINT_SPECIFIC</span>

<span class=\"hljs-variable\">response</span> <span class=\"hljs-operator\">=</span> requests.post(
    f<span class=\"hljs-string\">\"http://{ADDRESS}:8501/v1/models/{MODEL_NAME}:predict\"</span>, 
    data=payload, headers=headers
)</span></code></td></tr></tbody></table>

<p>As you see, each payload is dependent on the upstream tasks. For instance, we pass tokens to the Text Encoder’s endpoint, context and <code>unconditional_context</code> retrieved from the Text Encoder to the Diffusion Model’s endpoint, and latent retrieved from the Diffusion Model to Decoder’s endpoint. The <code>signature_name</code> should be the same as when we created <code>SavedModel</code> with the signatures argument.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">import</span> json


BATCH_SIZE = <span class=\"hljs-number\">4</span>

payload_to_text_encoder = json.dumps(
    {
        <span class=\"hljs-string\">\"signature_name\"</span>: <span class=\"hljs-string\">\"serving_default\"</span>, 
        <span class=\"hljs-string\">\"inputs\"</span>: {
            <span class=\"hljs-string\">\"tokens\"</span>: tokens,
            <span class=\"hljs-string\">\"batch_size\"</span>: BATCH_SIZE
        }
})

<span class=\"hljs-comment\"># json_response is from the text_encoder's response</span>
<span class=\"hljs-comment\"># json_response = json.loads(response.text)</span>
payload_to_diffusion_model = json.dumps(
    {
        <span class=\"hljs-string\">\"signature_name\"</span>: <span class=\"hljs-string\">\"serving_default\"</span>, 
        <span class=\"hljs-string\">\"inputs\"</span>: {
            <span class=\"hljs-string\">\"batch_size\"</span>: BATCH_SIZE,
            <span class=\"hljs-string\">\"context\"</span>: json_response[<span class=\"hljs-string\">'outputs'</span>][<span class=\"hljs-string\">'context'</span>],
            <span class=\"hljs-string\">\"num_steps\"</span>: num_steps,
            <span class=\"hljs-string\">\"unconditional_context\"</span>: json_response[<span class=\"hljs-string\">'outputs'</span>][<span class=\"hljs-string\">'unconditional_context'</span>]
        }
})

<span class=\"hljs-comment\"># json_response is from the diffusion_model's response</span>
<span class=\"hljs-comment\"># json_response = json.loads(response.text)</span>
payload_to_decoder = json.dumps(
    {
        <span class=\"hljs-string\">\"signature_name\"</span>: <span class=\"hljs-string\">\"serving_default\"</span>, 
        <span class=\"hljs-string\">\"inputs\"</span>: {
            <span class=\"hljs-string\">\"latent\"</span>: json_response[<span class=\"hljs-string\">'outputs'</span>],
        }
})</span></code></td></tr></tbody></table>

<p>The final response from the Decoder’s endpoint contains a full of pixel values in a list, so we need to convert those into a format that the environment of your choice could understand as images. For demonstration purposes, we used the <code>tf.convert_to_tensor()</code> utility function that turns the Python list into TensorFlow’s Tensor. However, you could plot the images in different languages, too, with your most familiar methods.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">import matplotlib<span class=\"hljs-selector-class\">.pyplot</span> as plt

def <span class=\"hljs-built_in\">plot_images</span>(images):
    plt.<span class=\"hljs-built_in\">figure</span>(figsize=(<span class=\"hljs-number\">20</span>, <span class=\"hljs-number\">20</span>))
    for i in <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(images)):
        ax = plt.<span class=\"hljs-built_in\">subplot</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-built_in\">len</span>(images), i + <span class=\"hljs-number\">1</span>)
        plt.<span class=\"hljs-built_in\">imshow</span>(images[i])
        plt.<span class=\"hljs-built_in\">axis</span>(<span class=\"hljs-string\">\"off\"</span>)

<span class=\"hljs-built_in\">plot_images</span>(
    tf.<span class=\"hljs-built_in\">convert_to_tensor</span>(json_response[<span class=\"hljs-string\">'outputs'</span>]).<span class=\"hljs-built_in\">numpy</span>()
)</span></code></td></tr></tbody></table>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"Four AI generated images of an astronaut riding a horse\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8I4T52Q1T_QQBucX3djNEXFlkSWYXp1nvoQDzH61M3eDD54Z9AlUvxNTsnJheY0CSxX_W6zddB0vHBiXzsO4eF2RbD2mcjRb2fZanp3hR2lTXUMuZ_JB5N7pkJV1bCWk2fGNHvbepj0j4Q05kDj8gud3B1cHWL3oPBFQIkOnv9uPDGW-D_-pZ70zL/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>Figure 4. Generated images with three TensorFlow Serving endpoints</i></td></tr></tbody></table></div>

<strong><h2>Note on XLA compilation</h2></strong>

<p>We can obtain a speed-up of 17 - 25% by incorporating compiling the <code>SavedModel</code>s to be <a href=\"https://www.tensorflow.org/xla\" target=\"_blank\">XLA compatible</a>. Note that the individual sub-networks of the Stable Diffusion class are fully XLA compatible. But in our case, the <code>SavedModel</code>s also contain important operations that are in native TensorFlow, such as the reverse diffusion process. </p>

<p>For deployment purposes, this speed-up could be impactful. To know more, check out the following repository: <a href=\"https://github.com/sayakpaul/xla-benchmark-sd\" target=\"_blank\">https://github.com/sayakpaul/xla-benchmark-sd</a>. </p>
  
<strong><h2>Conclusion</h2></strong>

<p>In this blog post, we explored what Stable Diffusion is, how it could be decomposed into the Text Encoder, Diffusion Model, and Decoder, and why it might be beneficial for better resource utilization. Also, we touched upon the concrete demonstration about the deployment of the decomposed Stable Diffusion by creating <code>SavedModel</code>s, containerizing them in TensorFlow Serving, deploying them on the GKE cluster, and running image generations. We used the vanilla Stable Diffusion, but feel free to try out replacing the only Diffusion Model with <a href=\"https://github.com/deep-diver/keras-sd-serving/blob/main/notebooks/inpainting_without_endpoint.ipynb\" target=\"_blank\">in-painting</a> or <a href=\"https://github.com/sayakpaul/stable-diffusion-keras-ft\" target=\"_blank\">pokemon fine-tuned diffusion models</a>.</p>

<strong><h2>References</h2></strong>

<p>CLIP: Connecting text and images, OpenAI, <a href=\"https://openai.com/research/clip\" target=\"_blank\">https://openai.com/research/clip</a>. </p>

<p>The Illustrated Stable Diffusion, Jay Alammar, <a href=\"https://jalammar.github.io/illustrated-stable-diffusion/\" target=\"_blank\">https://jalammar.github.io/illustrated-stable-diffusion/</a>. </p>

<p>Stable Diffusion, Stability AI, <a href=\"https://stability.ai/stable-diffusion\" target=\"_blank\">https://stability.ai/stable-diffusion</a>. </p>

<strong><h2>Acknowledgements</h2></strong>

<p><em>We are grateful to the <a href=\"https://developers.google.com/community/experts\" target=\"_blank\">ML Developer Programs team</a> that provided Google Cloud credits to support our experiments. We thank <a href=\"https://www.linkedin.com/in/robert-crowe\" target=\"_blank\">Robert Crowe</a> for providing us with helpful feedback and guidance. </em></p>

<p><strong>___________</strong></p>
<small><em><sup><a id=\"fn-1-ref\">1</a></sup> Stable Diffusion is not owned or operated by Google. It is made available by Stability AI. Please see their site for more information: <a href=\"https://stability.ai/blog/stable-diffusion-public-release\" target=\"_blank\">https://stability.ai/blog/stable-diffusion-public-release.</a></em></small>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Fri, 28 Apr 2023 17:00:00 +0000"
2526,Get ready for Google I/O,https://blog.tensorflow.org/2023/04/get-ready-for-google-io.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEizjsHSPpRYoieEo3e820PnUGyL1A4AAAFlLNQDFhgPMoyjOP76apEK60exJ4Qu1IXqLfMvMmiEMVzuND8FnoE-8rVpi2_0K4AAERvnMgK2TRcbFYiyVosE2U6QtkiBcMLg3_wIHLvzbW8kCiicgwWkVQjhSb5ZB8gxlcfLa06ann-HKJ9rghUGZxz3/s1600/278944847__42532861__715727.png\" style=\"display: none;\" />

<p><em>Posted by Timothy Jordan, Director, Developer Relations & Open Source</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgFVMIlCP4As_DCgFpzemOv1Zs19s40uVLFgOV1n7k3UD7yxlit1lTDPaZLaTyJzf0Wrd9T4lx3KE09cM8bnVGkn0xvvR80KlyMe0Ri2ymrNYOWzmQmYnvegpiZIrPJ9vXH4ZeRvR-zz8-SIDQwz3D5DoVmbkv5pkzKzIr5aJgrRpsKmwF8Ohyi4745/s1600/278944847__42532860__715727.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgFVMIlCP4As_DCgFpzemOv1Zs19s40uVLFgOV1n7k3UD7yxlit1lTDPaZLaTyJzf0Wrd9T4lx3KE09cM8bnVGkn0xvvR80KlyMe0Ri2ymrNYOWzmQmYnvegpiZIrPJ9vXH4ZeRvR-zz8-SIDQwz3D5DoVmbkv5pkzKzIr5aJgrRpsKmwF8Ohyi4745/s1600/278944847__42532860__715727.png\" /></a>
  
</p><a name=\"more\"></a><p></p>

<p>I/O is just a few days away and we couldn’t be more excited to share the latest updates across Google’s developer products, solutions, and technologies. From keynotes to technical sessions and hands-on workshops, these announcements aim to help you build smarter and ship faster. </p>

<p>Here are some helpful tips to maximize your experience online.</p>

<h2>Start building your personal I/O agenda</h2>

<p>Starting now, you can save the Google and developer keynotes to your calendar and explore the <a href=\"https://io.google/2023/program/\" target=\"_blank\">program</a> to preview content. Here are just a few noteworthy examples of what you’ll find this year:</p>
<blockquote>

  <strong>What's new in Android</strong>
<div style=\"text-align: left;\">Get the latest news in Android development: Android 14, form factors, Jetpack + Compose libraries, Android Studio, and performance.</div></blockquote><blockquote>

 <strong>What’s new in Web</strong>
<div style=\"text-align: left;\">Explore new features and APIs that became stable across browsers on the Web Platform this year.</div></blockquote><blockquote>

 <strong>What’s new in Generative AI</strong>
<div style=\"text-align: left;\">Discover a new suite of tools that make it easy for developers to leverage and build on top of Google's  large language models.</div></blockquote><blockquote>

 <strong>What’s new in Google Cloud</strong>
<div style=\"text-align: left;\">Learn how Google Cloud and generative AI will help you develop faster and more efficiently.</div></blockquote>
  
<p>For the best experience, create or connect a <a href=\"https://developers.google.com/profile/u/me\" target=\"_blank\">developer profile</a> and start saving content to My I/O to build your personal agenda. With over 200 sessions and other learning material, there’s a lot to cover, so we hope this will help you get organized. </p>

<p>This year we’ve introduced development focus filters to help you navigate content faster across mobile, web, AI, and cloud technologies. You can also peruse content by topic, type, or experience level so you can find what you’re interested in, faster. </p>

<h2>Connect with the community</h2>

<p>After the keynotes, you can talk to Google experts and other developers online in I/O Adventure chat. Here you can ask questions about new releases and learn best practices from the global developer community. </p>

<p>If you’re craving community now, visit the <a href=\"https://io.google/2023/community/\" target=\"_blank\">Community page</a> to meet people with similar interests in your area or find a watch party to attend.</p>

<p>We hope these updates are useful, and we can’t wait to connect online in May! </p>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Thu, 27 Apr 2023 16:30:00 +0000"
2527,Training a recommendation model with dynamic embeddings,https://blog.tensorflow.org/2023/04/training-recommendation-model-with-dynamic-embeddings.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdc76CVXCePD_2qIelWfi3dw_4P4d8tq8X6er753xrvUUGEDYtAqZiPkU1v_RitRm8bxXevsE54jARVORGnTXuC29DWDPIiN9dBr3nEHHVHbDo40EUJnqDvSu2k2nhwMoNuwQ4EEPiWWXIKc12j59vaSp_e_e7V1XL2iAaVNk-seCsNe5NuxYpY-G-/s1600/social-TensorFlow%20-%20Training%20a%20recommendation%20model%20with%20dynamic%20embeddings.png\" style=\"display: none;\" />

<em>Posted by <a href=\"https://www.linkedin.com/in/thushanganegedara/\" target=\"_blank\">Thushan Ganegedara</a> (<a href=\"https://developers.google.com/community/experts\" target=\"_blank\">GDE</a>), Haidong Rong (Nvidia), Wei Wei (Google)</em>

<a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdW4kHBd4n_Tz0ygjDJqqwoKpxgpu5Q9l-OmgfvAbpTo8smw0uBemAHobAN7sYt3U7v5slXFNudpyzY7JF7rxLuDbRB_v2S8UPDZQoP_edPjXl_U3UFMOyIusJK_H_DcYTlXhow7SjDozxoKpWO9z87SfF7on4WTaQgMOWWwtz0BQ-crja1DTHfCge/s1600/header-TensorFlow%20-%20Training%20a%20recommendation%20model%20with%20dynamic%20embeddings.png\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdW4kHBd4n_Tz0ygjDJqqwoKpxgpu5Q9l-OmgfvAbpTo8smw0uBemAHobAN7sYt3U7v5slXFNudpyzY7JF7rxLuDbRB_v2S8UPDZQoP_edPjXl_U3UFMOyIusJK_H_DcYTlXhow7SjDozxoKpWO9z87SfF7on4WTaQgMOWWwtz0BQ-crja1DTHfCge/s1600/header-TensorFlow%20-%20Training%20a%20recommendation%20model%20with%20dynamic%20embeddings.png\" /></a>

<a name=\"more\"></a><p></p>

<p>Modern recommenders heavily leverage embeddings to create vector representations of each user and candidate item. These embedding can then be used to calculate the similarity between users and items, so that users are recommended candidate items that are more interesting and relevant. But when working with data at scale, particularly in an <a href=\"https://en.wikipedia.org/wiki/Online_machine_learning\" target=\"_blank\">online machine learning</a> setting, embedding tables can grow in size dramatically, accumulating millions (and sometimes billions) of items. At this scale, it becomes impossible to store these embedding tables in memory. Furthermore, a large portion of the items might be rarely seen, so it does not make sense to keep dedicated embeddings for such rarely occurring items. A better solution would be to represent those items with one common embedding. This can dramatically reduce the size of the embedding table at a very small fraction of the performance cost. This is the main motivation behind dynamic embedding tables.</p>

<p>TensorFlow's built-in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\" target=\"_blank\">tf.keras.layers.Embedding</a> layer has a fixed size at creation time, so we need another approach. Fortunately, there is a <a href=\"https://www.tensorflow.org/community/sig_playbook\" target=\"_blank\">TensorFlow SIG</a> project exactly for this purpose: <a href=\"https://github.com/tensorflow/recommenders-addons\" target=\"_blank\">TensorFlow Recommenders Addons</a> (TFRA). You can learn more from its repository, but at a high level TFRA leverages dynamic embedding technology to dynamically change embedding size and achieve better recommendation results than static embeddings. TFRA is fully TF2.0-compatible and works smoothly with the familiar Keras API interfaces, so it can be easily integrated with other TensorFlow products, such as <a href=\"https://www.tensorflow.org/recommenders\" target=\"_blank\">TensorFlow Recommenders</a> (TFRS). </p>

<p>In this tutorial we will build a movie recommender model by leveraging both TFRS and TFRA. We will use the <a href=\"https://grouplens.org/datasets/movielens/\" target=\"_blank\">MovieLens</a> dataset, which contains anonymized data showing ratings given to movies by users. Our primary focus is to show how the dynamic embeddings provided in the <a href=\"https://github.com/tensorflow/recommenders-addons\" target=\"_blank\">TensorFlow Recommenders Addons</a> library can be used to dynamically grow and shrink the size of the embedding tables in the recommendation setting. You can find the full implementation <a href=\"https://github.com/tensorflow/recommenders-addons/blob/master/demo/dynamic_embedding/movielens-1m-keras-notebook/movielens_dynamic_embedding_tutorial.ipynb\" target=\"_blank\">here</a> and a walkthrough <a href=\"https://docs.google.com/presentation/d/1Q8tPMK-zTTXW4nw5vbrZ8bhDKkBx0SQLLpZ61V_wqFo/edit?usp=sharing\" target=\"_blank\">here</a>.
  
    <strong></strong></p><h2><strong>Import Libraries</strong></h2>

<p>We will first import the required libraries.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">import</span> tensorflow <span class=\"hljs-keyword\">as</span> tf
<span class=\"hljs-keyword\">import</span> tensorflow_datasets <span class=\"hljs-keyword\">as</span> tfds

<span class=\"hljs-comment\">#TFRA does some patching on TensorFlow so it MUST be imported after importing TF</span>
<span class=\"hljs-keyword\">import</span> tensorflow_recommenders <span class=\"hljs-keyword\">as</span> tfrs
<span class=\"hljs-keyword\">import</span> tensorflow_recommenders_addons <span class=\"hljs-keyword\">as</span> tfra
<span class=\"hljs-keyword\">import</span> tensorflow_recommenders_addons.dynamic_embedding <span class=\"hljs-keyword\">as</span> de</span></code></td></tr></tbody></table>

<p>Note how we are importing the TFRA library after importing TensorFlow. It is recommended to follow this ordering as the TFRA library will be applying some patches on TensorFlow.</p>

  <strong></strong><h2><strong>Processing the data</strong></h2>

<p>Let’s first build a baseline model with TensorFlow Recommenders. We will follow the pattern of <a href=\"https://www.tensorflow.org/recommenders/examples/basic_retrieval\" target=\"_blank\">this TFRS retrieval tutorial</a> to build a two-tower retrieval model. The user tower will take the user ID as the input, but the item tower will use the tokenized movie title as the input. 

</p><p>To handle the movie titles, we define a helper function that converts the movie titles to lowercase, removes any punctuation in a given movie title, and splits using spaces to generate a list of tokens. Finally we take only the up to <code>max_token_length</code> tokens (from the start) from the movie title. If a movie title has fewer tokens, all the tokens will be taken. This number is chosen based on some analysis and represents the 90th percentile in the title lengths in the dataset.
  
  
</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">max_token_length = <span class=\"hljs-number\">6</span>
pad_token = <span class=\"hljs-string\">\"[PAD]\"</span>
punctuation_regex = <span class=\"hljs-string\">\"[\\!\\\"#\\$%&amp;\\(\\)\\*\\+,-\\.\\/\\:;\\&lt;\\=\\&gt;\\?@\\[\\]\\\\\\^_`\\{\\|\\}~\\\\t\\\\n]\"</span>

<span class=\"hljs-comment\">#First we’ll define a helper function that will process the movie titles for us.</span>

<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">process_text</span>(<span class=\"hljs-params\">x: tf.Tensor, max_token_length: <span class=\"hljs-built_in\">int</span>, punctuation_regex: <span class=\"hljs-built_in\">str</span></span>) -&gt; tf.Tensor:
    
	<span class=\"hljs-keyword\">return</span> tf.strings.split(
    		tf.strings.regex_replace(
        			tf.strings.lower(x[<span class=\"hljs-string\">\"movie_title\"</span>]), punctuation_regex, <span class=\"hljs-string\">\"\"</span>
    		)
	)[:max_token_length]</span></code></td></tr></tbody></table><p></p><p></p>

<p>We also pad the tokenized movie titles to a fixed length and split the dataset using the same random seed so that we get consistent validation results across training epochs. You can find detailed code in the ‘Processing datasets’ section of the <a href=\"https://github.com/tensorflow/recommenders-addons/blob/master/demo/dynamic_embedding/movielens-1m-keras-notebook/movielens_dynamic_embedding_tutorial.ipynb\" target=\"_blank\">notebook</a>.</p>

<strong><h2>Building the two tower model</h2></strong>

<p>Our user tower is pretty much the same as in the <a href=\"https://www.tensorflow.org/recommenders/examples/basic_retrieval\" target=\"_blank\">TFRS retrieval tutorial</a> (except it’s deeper), but for the movie tower there is a <code>GlobalAveragePooling1D</code> layer after the embedding lookup, which averages the embedding of movie title tokens to a single embedding. </p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_movie_title_lookup_layer</span>(<span class=\"hljs-params\">dataset: tf.data.Dataset</span>) -&gt; tf.keras.layers.Layer:
	movie_title_lookup_layer = tf.keras.layers.StringLookup(mask_token=pad_token)
	movie_title_lookup_layer.adapt(dataset.<span class=\"hljs-built_in\">map</span>(<span class=\"hljs-keyword\">lambda</span> x: x[<span class=\"hljs-string\">\"movie_title\"</span>]))
	<span class=\"hljs-keyword\">return</span> movie_title_lookup_layer

<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">build_item_model</span>(<span class=\"hljs-params\">movie_title_lookup_layer: tf.keras.layers.StringLookup</span>):
	vocab_size = movie_title_lookup_layer.vocabulary_size()
	<span class=\"hljs-keyword\">return</span> tf.keras.models.Sequential([
    	tf.keras.layers.InputLayer(input_shape=(max_token_length), dtype=tf.string),
    	movie_title_lookup_layer,
    	tf.keras.layers.Embedding(vocab_size, <span class=\"hljs-number\">64</span>),
    	tf.keras.layers.GlobalAveragePooling1D(),
    	tf.keras.layers.Dense(<span class=\"hljs-number\">64</span>, activation=<span class=\"hljs-string\">\"gelu\"</span>),
    	tf.keras.layers.Dense(<span class=\"hljs-number\">32</span>),
    	tf.keras.layers.Lambda(<span class=\"hljs-keyword\">lambda</span> x: tf.math.l2_normalize(x, axis=<span class=\"hljs-number\">1</span>))
	])</span></code></td></tr></tbody></table>

<p>Next we are going to train the model.</p>

<strong><h2>Training the model</h2></strong>

<p>Training the model is simply calling <code>fit()</code> on the model with the required arguments. We will be using our validation dataset <code>validation_ds</code> to measure the performance of our model.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">history = model.fit(datasets.training_datasets.train_ds, epochs=<span class=\"hljs-number\">3</span>, validation_data=datasets.training_datasets.validation_ds)</span></code></td></tr></tbody></table>

<p>At the end, the output looks like below:</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">Epoch 3/3
220/220 [==============================] - 146s 633ms/step  
......
val_factorized_top_k/top_10_categorical_accuracy: 0.0179 - val_factorized_top_k/top_50_categorical_accuracy: 0.0766 - val_factorized_top_k/top_100_categorical_accuracy: 0.1338 - val_loss: 12359.0557 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12359.0557</span></code></td></tr></tbody></table>

<p>We have achieved a top 100 categorical accuracy of 13.38% on the validation dataset. </p>

<strong><h2>Building the model with dynamic embeddings</h2></strong>
<h4 style=\"text-align: left;\">Overview</h4>
<p>We will now learn how we can use the dynamic embedding in the <a href=\"https://github.com/tensorflow/recommenders-addons\" target=\"_blank\">TensorFlow Recommenders Addons</a> (TFRA) library, rather than a static embedding table. As the name suggests, as opposed to creating embeddings for all the items in the vocabulary up front, dynamic embedding would only grow the size of the embedding table on demand. This behavior really shines when dealing with millions and billions of items and users as some companies do. For these companies, it’s not surprising to find static embedding tables that would not fit in memory. Static embedding tables can grow up to hundreds of Gigabytes or even Terabytes, incapacitating even the highest memory instances available in cloud environments.</p>

<p>When you have an embedding table with large cardinality, the accessing weights will be quite sparse. Therefore, a hash-table based data structure is used to hold the weights and required weights for each iteration are retrieved from the underlying table structure. Here, to focus on the core functionality of the library, we will focus on a non-distributed setting. In this case, TFRA will choose cuckoo hashtable by default. But there are <a href=\"https://github.com/tensorflow/recommenders-addons#main-features\" target=\"_blank\">other solutions</a> such as Redis, nvhash available.</p>


<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"A chart showing the various embedding solutions across distruted and non-distributed settings in the TFRA library\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdLeEjNdYb4EiUhh3EvNOf9xpno3w87zdjNHKZjbTORI3Wf5FhNcLj6qTUt0eXKrlTT-ey1DXV7nkFRdy2V1W4EQBXyyuH8jNtbdt-FbyK4BXaHuaAaTasVJVzAa78xdlHajnM9mYPe1WKXo7i_L5e8d8nLNim3iXLoAymx2SMcJkWCyKD3uFbnW2Z/s1600/image2.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>When using the dynamic embedding, we initialize the table with some initial capacity and the table will grow in size on demand as it sees more IDs during model training. For more information about motivation and inner mechanics, please refer to the <a href=\"https://github.com/tensorflow/recommenders-addons/blob/master/rfcs/20200424-sparse-domain-isolation.md\" target=\"_blank\">RFC</a>.</p>

<h4 style=\"text-align: left;\">Types of embedding</h4>
<p>Currently in the TFRA <code>dynamic_embedding</code> module, there are three types of embedding available:</p>
<ul>
<li>Embedding - The most basic form of embeddings. This expects a 1D ([batch_size]) or 2D ([batch_size, time_steps]) tensor of IDs and outputs a [batch_size, embedding_dim] or [batch_size, time_steps, embedding_dim] sized tensor respectively.</li>
<li>SquashedEmbedding - This layer squashes the time step dimension based on some reduction operation (e.g. mean/sum) to transform a [batch_size, time_steps] sized  tensor of IDs to a [batch_size, embedding_dim] tensor.</li>
<li>FieldwiseEmbedding - This type can handle multiple features (i.e. fields) at once. The layer takes <code>n_slots</code> as an argument and IDs are mapped to a slot within the layer. The layer would return a tensor of size [batch_size, n_slots, embedding_dim]. </li>
</ul>

  <h4 style=\"text-align: left;\">Defining the embedding layers</h4>
<p>We will be using the <code>Embedding</code> to represent the user IDs and SquashedEmbedding to represent token IDs. Remember that each movie title has multiple tokens, therefore, we need a way to reduce the resulting token embeddings to a single representative embedding.</p>

<p><strong>Note:</strong> The behavior of Embedding has changed from version 0.5 to 0.6. Please make sure to use version 0.6 for this tutorial.</p>

<p>With that, we can define the two towers as we did in the standard model. However, this time we’ll be using the dynamic embedding layers instead of static embedding layers.</p>

<table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">build_de_user_model</span>(<span class=\"hljs-params\">user_id_lookup_layer: tf.keras.layers.StringLookup</span>) -&gt; tf.keras.layers.Layer:
	vocab_size = user_id_lookup_layer.vocabulary_size()
	<span class=\"hljs-keyword\">return</span> tf.keras.Sequential([
    	tf.keras.layers.InputLayer(input_shape=(), dtype=tf.string),
    	user_id_lookup_layer,
    	de.keras.layers.Embedding(
        	embedding_size=<span class=\"hljs-number\">64</span>,
        	initializer=tf.random_uniform_initializer(),
        	init_capacity=<span class=\"hljs-built_in\">int</span>(vocab_size*<span class=\"hljs-number\">0.8</span>),
        	restrict_policy=de.FrequencyRestrictPolicy,
        	name=<span class=\"hljs-string\">\"UserDynamicEmbeddingLayer\"</span>
    	),
    	tf.keras.layers.Dense(<span class=\"hljs-number\">64</span>, activation=<span class=\"hljs-string\">\"gelu\"</span>),
    	tf.keras.layers.Dense(<span class=\"hljs-number\">32</span>),
    	tf.keras.layers.Lambda(<span class=\"hljs-keyword\">lambda</span> x: tf.math.l2_normalize(x, axis=<span class=\"hljs-number\">1</span>))
	], name=<span class=\"hljs-string\">'user_model'</span>)

<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">build_de_item_model</span>(<span class=\"hljs-params\">movie_title_lookup_layer: tf.keras.layers.StringLookup</span>) -&gt; tf.keras.layers.Layer:
	vocab_size = movie_title_lookup_layer.vocabulary_size()
	<span class=\"hljs-keyword\">return</span> tf.keras.models.Sequential([
    		tf.keras.layers.InputLayer(input_shape=(max_token_length), dtype=tf.string),
    	movie_title_lookup_layer,
    	de.keras.layers.SquashedEmbedding(
        	embedding_size=<span class=\"hljs-number\">64</span>,
        	initializer=tf.random_uniform_initializer(),
        	init_capacity=<span class=\"hljs-built_in\">int</span>(vocab_size*<span class=\"hljs-number\">0.8</span>),
        	restrict_policy=de.FrequencyRestrictPolicy,
        	combiner=<span class=\"hljs-string\">\"mean\"</span>,
        	name=<span class=\"hljs-string\">\"ItemDynamicEmbeddingLayer\"</span>
    	),
    	tf.keras.layers.Dense(<span class=\"hljs-number\">64</span>, activation=<span class=\"hljs-string\">\"gelu\"</span>),
    	tf.keras.layers.Dense(<span class=\"hljs-number\">32</span>),
    	tf.keras.layers.Lambda(<span class=\"hljs-keyword\">lambda</span> x: tf.math.l2_normalize(x, axis=<span class=\"hljs-number\">1</span>))
	])</span></code></td></tr></tbody></table>

<p>With the user tower and movie tower models defined, we can define the retrieval model as usual.</p>

<h4 style=\"text-align: left;\">Creating and compiling the final model</h4>
<p>As a final step in model building, we’ll create the model and compile it.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">create_de_two_tower_model</span>(<span class=\"hljs-params\">dataset: tf.data.Dataset, candidate_dataset: tf.data.Dataset</span>) -&gt; tf.keras.Model:
    
	user_id_lookup_layer = get_user_id_lookup_layer(dataset)
	movie_title_lookup_layer = get_movie_title_lookup_layer(dataset)
	user_model = build_de_user_model(user_id_lookup_layer)
	item_model = build_de_item_model(movie_title_lookup_layer)
	task = tfrs.tasks.Retrieval(
    	metrics=tfrs.metrics.FactorizedTopK(
        	candidate_dataset.<span class=\"hljs-built_in\">map</span>(item_model)
    	),
	)

	model = DynamicEmbeddingTwoTowerModel(user_model, item_model, task)
	optimizer = de.DynamicEmbeddingOptimizer(tf.keras.optimizers.Adam())
	model.<span class=\"hljs-built_in\">compile</span>(optimizer=optimizer)
    
	<span class=\"hljs-keyword\">return</span> model

datasets = create_datasets()
de_model = create_de_two_tower_model(datasets.training_datasets.train_ds, datasets.candidate_dataset)</span></code></td></tr></tbody></table>

<p>Note the usage of the <code>DynamicEmbeddingOptimizer</code> wrapper around the standard TensorFlow optimizer. It is mandatory to wrap the standard optimizer in a <code>DynamicEmbeddingOpitmizer</code> as it will provide specialized functionality needed to train the weights stored in a hashtable. We can now train our model.</p>

<strong><h2>Training the model</h2></strong>
<p>Training the model is quite straightforward, but will involve a bit more extra effort as we’d like to log some extra information. We will perform the logging through a <code>tf.keras.callbacks.Callback</code> object. We’ll name this <code>DynamicEmbeddingCallback</code>.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">epochs = <span class=\"hljs-number\">3</span>
history_de = {}
history_de_size = {}
de_callback = DynamicEmbeddingCallback(de_model, steps_per_logging=<span class=\"hljs-number\">20</span>)

<span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(epochs):

	datasets = create_datasets()
	train_steps = <span class=\"hljs-built_in\">len</span>(datasets.training_datasets.train_ds)
    
	hist = de_model.fit(
    	datasets.training_datasets.train_ds,
    	epochs=<span class=\"hljs-number\">1</span>,
    	validation_data=datasets.training_datasets.validation_ds,
    	callbacks=[de_callback]
	)
    
	<span class=\"hljs-keyword\">for</span> k,v <span class=\"hljs-keyword\">in</span> de_model.dynamic_embedding_history.items():
    	<span class=\"hljs-keyword\">if</span> k==<span class=\"hljs-string\">\"step\"</span>:
        		v = [vv+(epoch*train_steps) <span class=\"hljs-keyword\">for</span> vv <span class=\"hljs-keyword\">in</span> v]
    	history_de_size.setdefault(k, []).extend(v)
   	 
	<span class=\"hljs-keyword\">for</span> k,v <span class=\"hljs-keyword\">in</span> hist.history.items():
    		history_de.setdefault(k, []).extend(v)</span></code></td></tr></tbody></table>

<p>We have taken the loop that goes through the epochs out of the <code>fit()</code> function. Then in every epoch we re-create the dataset, as that will provide a different shuffling of the training dataset. We will train the model for a single epoch within the loop. Finally we accumulate the logged embedding sizes in <code>history_de_size</code> (this is provided by our custom callback) and performance metrics in <code>history_de</code>.</p>

<p>The callback is implemented as follows.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DynamicEmbeddingCallback</span>(tf.keras.callbacks.Callback):
    
    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, model, steps_per_logging, steps_per_restrict=<span class=\"hljs-literal\">None</span>, restrict=<span class=\"hljs-literal\">False</span></span>):
        self.model = model
        self.steps_per_logging = steps_per_logging
        self.steps_per_restrict = steps_per_restrict
        self.restrict = restrict
    
    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_train_begin</span>(<span class=\"hljs-params\">self, logs=<span class=\"hljs-literal\">None</span></span>):
        self.model.dynamic_embedding_history = {}
        
    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_train_batch_end</span>(<span class=\"hljs-params\">self, batch, logs=<span class=\"hljs-literal\">None</span></span>):
                
        <span class=\"hljs-keyword\">if</span> self.restrict <span class=\"hljs-keyword\">and</span> self.steps_per_restrict <span class=\"hljs-keyword\">and</span> (batch+<span class=\"hljs-number\">1</span>) % self.steps_per_restrict == <span class=\"hljs-number\">0</span>:
            
            [
                self.model.embedding_layers[k].params.restrict(
                    num_reserved=<span class=\"hljs-built_in\">int</span>(self.model.lookup_vocab_sizes[k]*<span class=\"hljs-number\">0.8</span>), 
                    trigger=self.model.lookup_vocab_sizes[k]-<span class=\"hljs-number\">2</span> <span class=\"hljs-comment\"># UNK &amp; PAD tokens</span>
                ) <span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> self.model.embedding_layers.keys()
            ] 
        
        <span class=\"hljs-keyword\">if</span> (batch+<span class=\"hljs-number\">1</span>) % self.steps_per_logging == <span class=\"hljs-number\">0</span>:
            
            embedding_size_dict = {
                k:self.model.embedding_layers[k].params.size().numpy() 
                <span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> self.model.embedding_layers.keys()
            }

            <span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> embedding_size_dict.items():
                self.model.dynamic_embedding_history.setdefault(<span class=\"hljs-string\">f\"embedding_size_<span class=\"hljs-subst\">{k}</span>\"</span>, []).append(v)
            self.model.dynamic_embedding_history.setdefault(<span class=\"hljs-string\">f\"step\"</span>, []).append(batch+<span class=\"hljs-number\">1</span>)</span></code></td></tr></tbody></table><br /><div>

              <p>The callback does two things:</p>
<ul>
<li>Logs the sizes of the embedding layers every <code>steps_per_logging</code> iterations</li>
<li>Reduces the size of the embedding table to an 80% size of the total vocabulary size if <code>restrict=True</code>(This is set to <code>False</code> by default)</li>
</ul>

              <p>Let’s understand what reducing the size means and why it is important.</p>

<h4 style=\"text-align: left;\">Reducing the size of the embedding table</h4>
<p>An important topic we still haven’t discussed is how to reduce the size of the embedding table, should it grow over some predefined threshold. This is a powerful functionality as it allows us to define a threshold over which the embedding table should not grow. This will allow us to work with large vocabularies while keeping the memory requirement under the memory limitations we may have. We achieve this by calling <code>restrict()</code> on the underlying variables of the embedding layer as shown in the <code>DynamicEmbeddingCallback</code>. <code>restrict()</code> takes two arguments in: <code>num_reserved</code> (the size after the reduction) and <code>trigger</code> (size at which the reduction should be triggered). The policy that governs how the reduction is performed is defined using the <code>restrict_policy</code> argument in the layer construct. You can see that we are using the <code>FrequencyRestrictPolicy</code>. This means the least frequent items will be removed from the embedding table. The callback enables a user to set how frequently the reduction should get triggered by setting the <code>steps_per_restrict</code> and <code>restrict</code> arguments in the <code>DynamicEmbeddingCallback</code>.</p>

<p>Reducing the size of the embedding table makes more sense when you have streaming data. Think about an online learning setting, where you are training the model every day (or even every hour) on some incoming data. You can think of the outer for loop (i.e. epochs) representing days. Each day you receive a dataset (containing user interactions from the previous day for example) and you train the model from the previous checkpoint. In this case, you can use the <code>DynamicEmbeddingCallback</code> to trigger a restrict if the embedding table grows over the size defined in the trigger argument. 

  <strong></strong></p><h2><strong>Analyzing performance</strong></h2>
<p>Here we analyze the performance of three variants.</p>
<ul>
<li>The standard retrieval model (which uses a static embedding table)</li>
<li>Retrieval model using dynamic embedding but no restrict performed</li>
<li>Retrieval model using dynamic embedding with restrict performed</li>
              </ul> 
  <div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"A graph showing Model accuracy with and without dynamic embeddings\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEje2YQ6vDZwTnU2zZdELInx02rk28bCVFyZzJD_HwwmoyEwludk9wpikmB3JXgxtjoSVcgKknZgse0qkytkqTb_cS7-VEdE4i4tfQahblY4sbvWAR5WRkspleur7pYMULRcmsRh59bLKQKsbHkd4Y-RaBhAimi6pN6fzcCXPhSHVFBcqMnXSftGisfv/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>
  
<p>You can see that the model using dynamic embeddings (solid green line) has comparative validation performance to the baseline (solid red line). You can see a similar trend in the training accuracy as well. In practice, <strong>dynamic embeddings can often be seen to improve accuracy in a large-scale online learning setup. </strong></p>

<p>Finally, we can see that <code>restrict</code> has a somewhat detrimental effect on the validation accuracy, which is understandable. Since we’re working with a relatively small dataset with a small number of items, the reduction could be getting rid of embeddings that are best kept in the table. For example, you can increase the <code>num_reserved</code> argument (e.g. set it to <code>int(self.model.lookup_vocab_sizes[k]*0.95)</code>)  in the <code>restrict</code> function which would yield performance that improves towards the performance of without <code>restrict</code>.</p>

  <p>Next we look at how <code>dynamic</code> the embedding tables really are over time.</p>

  
  <div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"A graph showing changes in the embedding size over time\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjX6J6cCq6gc3DzlSKWdPUCz8vOo5IPFMhjdMUckDz2K3TwfSxlODzLX8vIcfDDQ_WjRxtSix4jsEAm71cQU27tFMyqXKeZgpiqk9OlFCRp76Vd39hovyqegVFpbHFEHk6Tne9UwVpKXSSw6JghuxkMZB2qVItCIIswpyfkLzTTsvEl4-tOePwLgRqe/s1600/image3.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>
  
<p>We can see that when restrict is not used, the embedding table grows to the full size of the vocabulary (dashed line) and stays there. However when <code>restrict</code> is triggered (dotted line), the size drops and grows in size again as it encounters new IDs.</p>

<p>It is also important to note that constructing a proper validation is not a trivial task. There are considerations such as out-of-sample validation, out-of-time validation, stratification, etc. that needs to be taken into account carefully. However for this exercise, we have not focused on such factors and created a validation set by sampling randomly from the existing dataset.</p>
  
  <strong><h2>Conclusion</h2></strong>
  
<p>Using dynamic embedding tables is a powerful way to perform representation learning when working with large sets of items containing millions or billions of entities. In this tutorial, we learnt how to use the <code>dynamic_embedding</code> module provided in the TensorFlow Recommender Addons library to achieve this. We first explored the data and constructed <code>tf.data.Dataset</code> objects by extracting the features we’ll be using for our model training and evaluation. Next we defined a model that uses static embedding tables to use as an evaluation baseline. We then created a model that uses dynamic embedding and trained it on the data. We saw that using dynamic embeddings, the embedding tables grow only on demand and still achieve comparable performance with the baseline. We also discussed how the <code>restrict</code> functionality can be used to shrink the embedding table if it grows past a pre-defined threshold.</p>

<p>We hope this tutorial gives you a good conceptual introduction to TFRA and dynamic embeddings, and helps you think about how you can leverage it to enhance your own recommenders. If you would like to have a more in-depth discussion, please visit the TFRA repository.</p></div>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Wed, 19 Apr 2023 17:00:00 +0000"
2528,Counterfactual Logit Pairing,https://blog.tensorflow.org/2023/04/counterfactual-logit-pairing.html,"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4JTW926mMONbwuuLuLfYR7Nug8wj5HBewNfjabbklWVBH2C0EaM87BTEl38yLdRahrvlkPnYw6ePjg6g1lEEBAqW2dKkSApQSEJkbEiOXuqu6VEr23YzUsdV-OQLUQIqUGIR3V6YweRAoDv1KsRfPkNJsQfGvWXVr1lrVZ8fTpGQC8Th1z4BSSD41/s1600/image2.png\" style=\"display: none;\" />

<p><em>Posted by Bhaktipriya Radharapu, Software Engineer</em></p><p>

</p><a name=\"more\"></a><p></p>

<p><a href=\"https://www.tensorflow.org/responsible_ai/model_remediation\" target=\"_blank\">TensorFlow Model Remediation</a> is an open source toolkit that showcases solutions to help mitigate unfair bias in Machine Learning models. The toolkit  offers resources to build fairer models for everyone  – in line with <a href=\"https://ai.google/principles/\" target=\"_blank\">Google’s AI Principles</a>. Today, we’re excited to announce a new technique within the TensorFlow Model Remediation Library called <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview\" target=\"_blank\">Counterfactual Logit Pairing</a> (CLP)  to address unintended bias in ML models.</p>

<p>ML models are prone to making incorrect predictions when a sensitive attribute in an input is removed or replaced, leading to unintended bias. For instance, the <a href=\"https://www.perspectiveapi.com/#/home\" target=\"_blank\">Perspective API</a>, used to identify offensive or toxic text in comments, revealed a positive correlation between identity terms referencing race or sexual orientation and the predicted toxicity score. For instance, the phrase \"I am a lesbian\" received a toxicity score of 0.51, while “I am a man” received a lower toxicity score of 0.2. This correlation resulted in higher toxicity scores for some identity terms, even when used non-pejoratively. For more information on the Perspective API, see the blog post on <a href=\"https://medium.com/jigsaw/unintended-bias-and-names-of-frequently-targeted-groups-8e0b81f80a23\" target=\"_blank\">unintended bias and identity terms</a>. </p>

<p>Counterfactual Logit Pairing (CLP) is a technique that addresses such issues to ensure that a model’s prediction doesn’t change when a sensitive attribute referenced in an example is either removed or replaced. It improves a model’s robustness to such perturbations, and can positively influence a model’s stability, fairness, and safety.</p> 


<p>CLP mitigates such counterfactual fairness issues at training time. It does so by adding an additional loss to the model’s training loss, which penalizes the difference in the model’s outputs between training examples and their counterfactuals.</p>

<p>Another advantage of using CLP is that you can use this even on unlabelled data. As long as the model treats the counterfactual examples similarly you can validate that your model is adhering to counterfactual fairness.</p>

<p>For an in-depth discussion on this topic, see research on <a href=\"https://arxiv.org/abs/1703.06856\" target=\"_blank\">counterfactual fairness</a>, <a href=\"https://arxiv.org/abs/1803.06373\" target=\"_blank\">adversarial logit pairing</a>, and <a href=\"https://arxiv.org/abs/1809.10610\" target=\"_blank\">counterfactual logit pairing</a>.</p>

<h3><strong>Counterfactual Logit Pairing Walkthrough:</strong></h3>

<p>The <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_keras\" target=\"_blank\">CLP with Keras</a> codelab provides an end-to-end example. In this overview, we'll emphasize key points from the notebook, while providing additional context.</p>

<p>The notebook trains a text classifier to identify toxic content. This type of model attempts to identify content that is rude, disrespectful or otherwise likely to make someone leave a discussion, and assigns the content a toxicity score. For this task, our baseline model will be a simple Keras sequential model pre-trained on the <a href=\"https://www.tensorflow.org/datasets/catalog/civil_comments\" target=\"_blank\">Civil Comments dataset</a>.</p>

<p>We will use CLP to avoid having identity terms unfairly skew what is classified as offensive. We consider a narrow class of counterfactuals that involves removing gender and sexual orientation related identity tokens in the input, such as removing “gay” in the input “I’m a gay person” to create the counterfactual example “I’m a person.”</p>

<p>The high-level steps will be to:</p>
<ol><blockquote>
<li>Calculate <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_usage_steps#measure_flip_count_and_flip_rate\" target=\"_blank\">flip rate and flip count</a> of the classifier on original and counterfactual examples. </li>
  <li>Build a counterfactual dataset using <code>CounterfactualPackedInputs</code> by performing a naive ablation based on term matching.</li> 
<li>Improve performance on flip rate and flip count by training with CLP.</li>
<li>Evaluate the new model’s performance on flip rate and flip count.</li>
  </blockquote></ol>

<p>Be aware that this is a minimal workflow to demonstrate usage of the CLP technique, and not a complete approach to fairness in machine learning. CLP addresses one specific challenge that may impact fairness in machine learning. See the <a href=\"https://www.tensorflow.org/responsible_ai\" target=\"_blank\">Responsible AI toolkit</a> for additional information on responsible AI and tools that can be used to complement CLP.</p>

<p>In a production setting, you would want to approach each of these steps with more rigor. For example:</p>
<ul><blockquote>
<li>Consider the fairness goals of your model. What qualifies as “fair” for your model? Which <a href=\"https://fairmlbook.org/tutorial2.html\" target=\"_blank\">definitions of fairness</a> are you trying to achieve?</li>
<li>Consider when counterfactual pairs should have the same prediction. Many syntactic counterfactuals generated by token substitution may not require identical output. Consider the application space and the potential societal impact of your model and understand <a href=\"https://arxiv.org/abs/2102.05085\" target=\"_blank\">when the outputs should be the same and when they shouldn’t be.</a></li>
<li>Consider using semantically and grammatically grounded counterfactuals instead of heuristic based ablations.</li>
<li>Experiment with the configuration of CLP by tuning hyperparameters to get optimal performance.</li>
  </blockquote></ul>

<p>Let’s begin by examining the flip count and flip rate of the original model on the counterfactual examples. The flip count measures the number of times the classifier gives a different decision if the identity term in a given example is changed. The flip rate measures the total number of times that the classifier incorrectly provides an incorrect decision over the total count. </p>

<p>Let’s use the \"Fairness Indicators widget\" in the notebook to measure the flip rate and counts. Select <code>flip_rate/overall</code> in the widget. Notice that the overall flip rate for females is about 13% and male is about 14%, which are both higher than the overall dataset of 8%. This means that the model is likely to change the classification based on the presence of gender related terms.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvQkzbndgfpbxHTvmQtc3AHpr_eg5gBTuc6K5-zBqnZGPGYjBpQ5cwEMi7uZbcvRERbvY0CO8N-QouyfrtrTJCs9pIphpPyt4YjA17HSc2ownJAKegDnTW1XmfhPhxSdQAstqZfaJHWZaYhCLC9gBro-a8Mn29KjXHl_uy9ExwSDawgS617_Lx4H-H/s1600/image1.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

We’ll now use CLP to try to reduce the model's flip rate and flip count for gender-related terms in our dataset. We start by creating an instance of <code>CounterfactualPackedInputs</code>, which packs the original_input and counterfactual_data. 


<p></p><p></p><div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\"><span class=\"hljs-built_in\">CounterfactualPackedInputs</span>(
  original_input=(x, y, sample_weight),
 counterfactual_data:(original_x, counterfactual_x,   
                 counterfactual_sample_weight)
)</span></code></td></tr></tbody></table></div>

We next remove instances of gender specific terms using the helper function, <code>build_counterfactual_data</code>. Note that we only include non-pejorative terms, as pejorative terms should have a different toxicity score. Requiring equal predictions across examples with pejorative terms would both weaken the model’s ability to perform its task and potentially increase harm to vulnerable groups.<div>&nbsp;
<div><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">sensitive_terms_to_remove = [
 <span class=\"hljs-string\">'aunt'</span>, <span class=\"hljs-string\">'boy'</span>, <span class=\"hljs-string\">'brother'</span>, <span class=\"hljs-string\">'dad'</span>, <span class=\"hljs-string\">'daughter'</span>, <span class=\"hljs-string\">'father'</span>, <span class=\"hljs-string\">'female'</span>, <span class=\"hljs-string\">'gay'</span>,
 <span class=\"hljs-string\">'girl'</span>, <span class=\"hljs-string\">'grandma'</span>, <span class=\"hljs-string\">'grandpa'</span>, <span class=\"hljs-string\">'grandson'</span>, <span class=\"hljs-string\">'grannie'</span>, <span class=\"hljs-string\">'granny'</span>, <span class=\"hljs-string\">'he'</span>,
 <span class=\"hljs-string\">'heir'</span>, <span class=\"hljs-string\">'her'</span>, <span class=\"hljs-string\">'him'</span>, <span class=\"hljs-string\">'his'</span>, <span class=\"hljs-string\">'hubbies'</span>, <span class=\"hljs-string\">'hubby'</span>, <span class=\"hljs-string\">'husband'</span>, <span class=\"hljs-string\">'king'</span>,
 <span class=\"hljs-string\">'knight'</span>, <span class=\"hljs-string\">'lad'</span>, <span class=\"hljs-string\">'ladies'</span>, <span class=\"hljs-string\">'lady'</span>, <span class=\"hljs-string\">'lesbian'</span>, <span class=\"hljs-string\">'lord'</span>, <span class=\"hljs-string\">'man'</span>, <span class=\"hljs-string\">'male'</span>,
 <span class=\"hljs-string\">'mom'</span>, <span class=\"hljs-string\">'mother'</span>, <span class=\"hljs-string\">'mum'</span>, <span class=\"hljs-string\">'nephew'</span>, <span class=\"hljs-string\">'niece'</span>, <span class=\"hljs-string\">'prince'</span>, <span class=\"hljs-string\">'princess'</span>,
 <span class=\"hljs-string\">'queen'</span>, <span class=\"hljs-string\">'queens'</span>, <span class=\"hljs-string\">'she'</span>, <span class=\"hljs-string\">'sister'</span>, <span class=\"hljs-string\">'son'</span>, <span class=\"hljs-string\">'uncle'</span>, <span class=\"hljs-string\">'waiter'</span>,
 <span class=\"hljs-string\">'waitress'</span>, <span class=\"hljs-string\">'wife'</span>, <span class=\"hljs-string\">'wives'</span>, <span class=\"hljs-string\">'woman'</span>, <span class=\"hljs-string\">'women'</span>
]


<span class=\"hljs-comment\"># Convert the Pandas DataFrame to a TF Dataset</span>
dataset_train_main = tf.data.Dataset.from_tensor_slices(
   (data_train[TEXT_FEATURE].values, labels_train)).batch(BATCH_SIZE)


counterfactual_data = counterfactual.keras.utils.build_counterfactual_dataset(
   original_dataset=dataset_train_main,
   sensitive_terms_to_remove=sensitive_terms_to_remove)


counterfactual_packed_input = counterfactual.keras.utils.pack_counterfactual_data(
 dataset_train_main,
 counterfactual_data)</span></code></td></tr></tbody></table></div></div>

<p>To train with a Counterfactual model, simply take the original model and wrap it in a <code>CounterfactualModel</code> with a corresponding <code>loss</code> and <code>loss_weight</code>. This will co-train the model on the main classification task and on the debiasing task using the CLP loss.</p>

<p>We are using 1.0 as the default <code>loss_weight</code>, but this is a parameter that can be tuned for your use case, since it depends on your model and product requirements.  You should experiment with changing the value to see how it impacts the model, noting that increasing it would cause the model to penalize the counterfactual examples more heavily. You can test a range of values to explore the trade off between the task performance and the flip rate.</p>

<p>Here, we use the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/api_docs/python/model_remediation/counterfactual/losses/PairwiseMSELoss\" target=\"_blank\">Pairwise Mean Squared Error Loss</a>. You can try experimenting with other metrics in the suite to know which options offer the best results.</p><table class=\"leading-snug\"><colgroup></colgroup><tbody><tr><td><code class=\"m-0 p-0 whitespace-pre-wrap font-monospace\" id=\"code-output\"><span style=\"font-family: courier;\">counterfactual_weight = 1.0

counterfactual_model = counterfactual.keras.CounterfactualModel(
    baseline_model,
    loss=counterfactual.losses.PairwiseMSELoss(),
    loss_weight=counterfactual_weight)

<span class=\"hljs-comment\"># Compile the model normally after wrapping the original model.</span>
<span class=\"hljs-comment\"># Note that this means we use the baseline's model's loss here.</span>
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
loss = tf.keras.losses.BinaryCrossentropy()
counterfactual_model.compile(optimizer=optimizer, loss=loss,
                             metrics=['accuracy'])

counterfactual_model.fit(counterfactual_packed_input,
                         epochs=1)</span></code></td></tr></tbody></table>

<p>Once again, we evaluate the results by looking at the flip count and flip rate. Select “flip_rate/overall” within Fairness Indicators and compare the results for female and male between the two models. You should notice that the flip rate for overall, female, and male have all decreased by about 90%, which leaves the final flip rate for female at approximately 1.3% and male at approximately 1.4%.</p>

<div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhegZBC4CDN7nr-osy1tvTMyciRBdCbvUcx3AhMv484xBMJV3iyvQKZSWuLytpQ-M24qzcWYL4qVX6DORs6ms3AjYqGa2J0dIvHe1hhebxAck74nwyBwRnAnWUig0zMuj_yFqsjphULBvmjqZnkYkbjX8fEKDwBowMyXi_g_bujiF37nb-2Tk5frRYP/s1600/image3.png\" style=\"width: 100%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i></i></td></tr></tbody></table></div>

<p>You can get started with Counterfactual by visiting <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview\" target=\"_blank\">TensorFlow Responsible AI</a> and learn more about evaluation fairness with <a href=\"https://www.tensorflow.org/responsible_ai/fairness_indicators/guide/guidance\" target=\"_blank\">Fairness Indicators</a>.</p>


<p></p><h4>Acknowledgements</h4><p></p>

<div style=\"text-align: left;\">The Counterfactual framework was developed in collaboration with
</div><ul><li>Amy Wang, Ben Packer, Bhaktipriya Radharapu, Christina Greer, Nick Blumm, Parker Barnes, Piyush Kumar, Sean O’Keefe, Shivam Jindal, Shivani Poddar, Summer Misherghi, Thomas Greenspan.</li></ul>

<div style=\"text-align: left;\">This research effort was jointly led by
</div><ul><li>Alex Beutel, Jilin Chen, Tulsee Doshi in collaboration with Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur Taly, Ed H. Chi.</li></ul>

<div style=\"text-align: left;\"><em>Further, this work was pursued in collaboration with</em></div><ul><li>Andrew Smart, Francois Chollet, Molly FitzMorris, Tomer Kaftan, Mark Daoust, Daniel 'Wolff' Dobson, Soo Sung.</li></ul>","[{'name': 'TensorFlow Blog', 'email': 'noreply@blogger.com'}]","Thu, 06 Apr 2023 17:00:00 +0000"
2529,How Many Days Would February Have if the Earth Rotated Backward?  Exploring Leap Years with Wolfram Language,https://blog.wolfram.com/2024/02/29/how-many-days-would-february-have-if-the-earth-rotated-backward-exploring-leap-years-with-wolfram-language/,"Happy Leap Day 2024! A leap day is an extra day (February 29) that is added to the Gregorian calendar (the calendar most of us use day to day) in leap years. While leap years most commonly come in four-year intervals, they sometimes come every eight years. This is because a traditional leap day every [&#8230;]",[{'name': 'José Martín-García'}],"Thu, 29 Feb 2024 15:59:09 +0000"
2530,Your Invitation to Take a Quantum Leap in Education,https://blog.wolfram.com/2024/02/27/your-invitation-to-take-a-quantum-leap-in-education/,"Learning quantum theory requires dedication and a willingness to challenge classical assumptions. Quantum interference, particularly for massive particles, is a pivotal example in this journey. The Schrödinger equation, inspired by de Broglie’s hypothesis, revolutionized our understanding by revealing the wavelike nature of even massive particles. This phenomenon not only deepens our grasp of nature but [&#8230;]",[{'name': 'Mads Bahrami'}],"Tue, 27 Feb 2024 23:02:19 +0000"
2531,Reduce Quantum Noise with Wolfram Language and Fire Opal,https://blog.wolfram.com/2024/02/27/reduce-quantum-noise-with-wolfram-language-and-fire-opal/,"Practical quantum computers have not entered the mainstream, but that has not stopped researchers and developers from innovating. Simulating quantum results on classical hardware and getting meaningful results from noisy quantum hardware are two important areas with lots of recent innovations. The Wolfram Quantum Framework is a toolkit for Wolfram Language that offers quantum simulations. [&#8230;]",[{'name': 'Mads Bahrami'}],"Tue, 27 Feb 2024 16:42:16 +0000"
2532,Hypergeometric Functions: From Euler to Appell and Beyond,https://blog.wolfram.com/2024/01/25/hypergeometric-functions-from-euler-to-appell-and-beyond/,"Hypergeometric series appeared in the mid-seventeenth century; since then, they have played an important role in the development of mathematical and physical theories. Most of the elementary and special functions are members of the large hypergeometric class. Hypergeometric functions have been a part of Wolfram Language since Version 1.0. The following plot shows the implementation [&#8230;]",[{'name': 'Tigran Ishkhanyan'}],"Thu, 25 Jan 2024 17:35:34 +0000"
2533,Leveling Up in Life Sciences: Unleashing the Power of Computational Biology with Wolfram Language,https://blog.wolfram.com/2024/01/18/leveling-up-in-life-sciences-unleashing-the-power-of-computational-biology-with-wolfram-language/,"In days past, life sciences was reserved for those who had access to the proper equipment to observe and experiment with the organisms of the physical world. For today’s scientist, exploration doesn’t end with access to physical encounters. Whether you’re classifying an animal for the first time or using a protein visualizer to develop medication, [&#8230;]",[{'name': 'Bailey Long'}],"Thu, 18 Jan 2024 19:40:37 +0000"
2534,The Story Continues: Announcing Version 14 of Wolfram Language and Mathematica,https://blog.wolfram.com/2024/01/09/the-story-continues-announcing-version-14-of-wolfram-language-and-mathematica/,<p>Today we celebrate a new waypoint on our journey of nearly four decades with the release of Version 14.0 of <a href=\"https://www.wolfram.com/language/\">Wolfram Language</a> and <a href=\"https://www.wolfram.com/mathematica/\">Mathematica</a>. Over the two years since we released <a href=\"https://reference.wolfram.com/legacy/language/v13/\">Version 13.0</a> we’ve been steadily delivering the fruits of our research and development in .1 releases every six months. Today we’re aggregating these—and more—into Version 14.0.</p>,[{'name': 'Stephen Wolfram'}],"Tue, 09 Jan 2024 22:42:48 +0000"
2535,Get Down to Business with Finite Mathematics in Wolfram Language,https://blog.wolfram.com/2023/12/22/get-down-to-business-with-finite-mathematics-in-wolfram-language/,"“There is every reason to expect that the various social sciences will serve as incentives for the development of great new branches of mathematics and that some day the theoretical social scientist will have to know more mathematics than the physicist needs to know today.” —John G. Kemeny, first author of the original textbook on [&#8230;]",[{'name': 'John McNally'}],"Fri, 22 Dec 2023 15:41:26 +0000"
2536,A Year in Review: New from Wolfram Media in 2023,https://blog.wolfram.com/2023/12/15/a-year-in-review-new-from-wolfram-media-in-2023/,"With seven newly published titles and deals penned for translations into 13 languages, 2023 has been Wolfram Media’s most productive year yet. As our list continues to grow, we are proud to cover more and more Wolfram Language functionality in conceptual and practical ways for our readers. As we near the end of the year, [&#8230;]",[{'name': 'Paige Vigliarolo'}],"Fri, 15 Dec 2023 15:29:53 +0000"
2537,Journey from the Wolfram Data Science Boot Camp to Creative Data Analytics,https://blog.wolfram.com/2023/12/06/journey-from-the-wolfram-data-science-boot-camp-to-creative-data-analytics/,"When I attended the 2019 Wolfram Data Science Boot Camp as an instructor, I had the pleasure of meeting Professor Fei Du and Davis Mo, the youngest Boot Camp alum to date. I don’t think any of us expected our conversations from the camp to grow into our collaboration on the book Creative Data Analytics: [&#8230;]",[{'name': 'Kelvin Mischo'}],"Wed, 06 Dec 2023 16:39:04 +0000"
2538,Mapping a 50-spin-qubit network through correlated sensing,https://www.nature.com/articles/s41467-024-46075-4,,[],"Tue, 5 Mar 2024 00:00:00 +0000"
2539,Robust parallel laser driving of quantum dots for multiplexing of quantum light sources,https://www.nature.com/articles/s41598-024-55634-0,,[],"Mon, 4 Mar 2024 00:00:00 +0000"
2540,Graph states of atomic ensembles engineered by photon-mediated entanglement,https://www.nature.com/articles/s41567-024-02407-1,,[],"Fri, 1 Mar 2024 00:00:00 +0000"
2541,QAL-BP: an augmented Lagrangian quantum approach for bin packing,https://www.nature.com/articles/s41598-023-50540-3,,[],"Fri, 1 Mar 2024 00:00:00 +0000"
2542,Deep learning the hierarchy of steering measurement settings of qubit-pair states,https://www.nature.com/articles/s42005-024-01563-3,,[],"Fri, 1 Mar 2024 00:00:00 +0000"
2543,Analyzing variational quantum landscapes with information content,https://www.nature.com/articles/s41534-024-00819-8,,[],"Thu, 29 Feb 2024 00:00:00 +0000"
2544,Deterministic generation of multidimensional photonic cluster states with a single quantum emitter,https://www.nature.com/articles/s41567-024-02408-0,,[],"Wed, 28 Feb 2024 00:00:00 +0000"
2545,A framework for demonstrating practical quantum advantage: comparing quantum against classical generative models,https://www.nature.com/articles/s42005-024-01552-6,,[],"Wed, 28 Feb 2024 00:00:00 +0000"
2546,Markovian noise modelling and parameter extraction framework for quantum devices,https://www.nature.com/articles/s41598-024-54598-5,,[],"Tue, 27 Feb 2024 00:00:00 +0000"
2547,Author Correction: Improved machine learning algorithm for predicting ground state properties,https://www.nature.com/articles/s41467-024-46164-4,,[],"Mon, 26 Feb 2024 00:00:00 +0000"
2548,Oscillating photonic Bell state from a semiconductor quantum dot for quantum key distribution,https://www.nature.com/articles/s42005-024-01547-3,,[],"Sat, 24 Feb 2024 00:00:00 +0000"
2549,Efficiency optimization in quantum computing: balancing thermodynamics and computational performance,https://www.nature.com/articles/s41598-024-55314-z,,[],"Sat, 24 Feb 2024 00:00:00 +0000"
2550,Practical high-dimensional quantum key distribution protocol over deployed multicore fiber,https://www.nature.com/articles/s41467-024-45876-x,,[],"Fri, 23 Feb 2024 00:00:00 +0000"
2551,Efficient bosonic nonlinear phase gates,https://www.nature.com/articles/s41534-024-00816-x,,[],"Fri, 23 Feb 2024 00:00:00 +0000"
2552,Autonomous error correction of a single logical qubit using two transmons,https://www.nature.com/articles/s41467-024-45858-z,,[],"Fri, 23 Feb 2024 00:00:00 +0000"
2553,Wide-field Fourier magnetic imaging with electron spins in diamond,https://www.nature.com/articles/s41534-024-00818-9,,[],"Wed, 21 Feb 2024 00:00:00 +0000"
2554,Better-than-classical Grover search via quantum error detection and suppression,https://www.nature.com/articles/s41534-023-00794-6,,[],"Tue, 20 Feb 2024 00:00:00 +0000"
2555,Enhancing detection of topological order by local error correction,https://www.nature.com/articles/s41467-024-45584-6,,[],"Tue, 20 Feb 2024 00:00:00 +0000"
2556,A series of fast-paced advances in Quantum Error Correction,https://www.nature.com/articles/s42254-024-00706-3,,[],"Fri, 16 Feb 2024 00:00:00 +0000"
2557,Topological matter created on a quantum chip produces quasiparticles with computing power,https://www.nature.com/articles/d41586-023-04126-8,,[],"Wed, 14 Feb 2024 00:00:00 +0000"
2558,Navigating the 16-dimensional Hilbert space of a high-spin donor qudit with electric and magnetic fields,https://www.nature.com/articles/s41467-024-45368-y,,[],"Wed, 14 Feb 2024 00:00:00 +0000"
2559,Non-Abelian topological order and anyons on a trapped-ion processor,https://www.nature.com/articles/s41586-023-06934-4,,[],"Wed, 14 Feb 2024 00:00:00 +0000"
2560,On the (relation between) efficiency and secret key rate of QKD,https://www.nature.com/articles/s41598-024-54246-y,,[],"Tue, 13 Feb 2024 00:00:00 +0000"
2561,Rapid single-shot parity spin readout in a silicon double quantum dot with fidelity exceeding 99%,https://www.nature.com/articles/s41534-024-00813-0,,[],"Tue, 13 Feb 2024 00:00:00 +0000"
2562,Spin-EPR-pair separation by conveyor-mode single electron shuttling in Si/SiGe,https://www.nature.com/articles/s41467-024-45583-7,,[],"Tue, 13 Feb 2024 00:00:00 +0000"
2563,Publisher Correction: The complexity of NISQ,https://www.nature.com/articles/s41467-024-45799-7,,[],"Mon, 12 Feb 2024 00:00:00 +0000"
2564,Author Correction: Tunable quantum simulation of spin models with a two-dimensional ion crystal,https://www.nature.com/articles/s41567-024-02432-0,,[],"Mon, 12 Feb 2024 00:00:00 +0000"
2565,Steady state engineering of a two-level system by the mixed-state inverse engineering scheme,https://www.nature.com/articles/s41598-024-53726-5,,[],"Sat, 10 Feb 2024 00:00:00 +0000"
2566,Quantum-parallel vectorized data encodings and computations on trapped-ion and transmon QPUs,https://www.nature.com/articles/s41598-024-53720-x,,[],"Sat, 10 Feb 2024 00:00:00 +0000"
2567,High-fidelity initialization and control of multiple nuclear spin qubits in silicon,https://www.nature.com/articles/s41565-024-01603-7,,[],"Fri, 9 Feb 2024 00:00:00 +0000"
2568,Explainable AI using expressive Boolean formulas,https://aws.amazon.com/blogs/quantum-computing/explainable-ai-using-expressive-boolean-formulas/,ML models driving high-stakes decisions need interpretability. See how the Amazon QSL and Fidelity FCAT developed interpretable models based on Boolean logic.,[{'name': 'Gili Rosenberg'}],"Wed, 21 Feb 2024 16:01:26 +0000"
2569,Citi and Classiq advance quantum solutions for portfolio optimization using Amazon Braket,https://aws.amazon.com/blogs/quantum-computing/citi-and-classiq-advance-quantum-solutions-for-portfolio-optimization/,Today we look at how Citi Innovation Labs is exploring quantum computing for portfolio optimization in partnership with Classiq and AWS. Their research examines how adjustments to the QAOA algorithm's penalty factor impact performance.,[{'name': 'Yoram Avidan'}],"Wed, 07 Feb 2024 15:38:57 +0000"
2570,Exploring industrial use cases in the Airbus-BMW Group Quantum Computing Challenge,https://aws.amazon.com/blogs/quantum-computing/exploring-industrial-use-cases-in-the-airbus-bmw-group-quantum-computing-challenge/,Discover how Airbus and BMW Group are harnessing quantum computing to tackle industry challenges. Join the Airbus-BMW Group Quantum Mobility Quest and help shape the future of transportation.,[{'name': 'Martin Schuetz'}],"Thu, 25 Jan 2024 14:54:04 +0000"
2571,Introducing the Amazon Braket Learning Plan and Digital Badge,https://aws.amazon.com/blogs/quantum-computing/introducing-the-amazon-braket-learning-plan-and-digital-badge/,"Available today, quantum computing developers, educators, and enthusiasts can&nbsp;learn the foundations of quantum computing on Amazon Web Services (AWS) with the Amazon Braket Digital Learning Plan and earn their own Digital badge – at no additional cost. You earn the badge after completing a series of learning courses and scoring at least 80% on an […]",[{'name': 'James Whitfield'}],"Mon, 27 Nov 2023 14:09:35 +0000"
2572,"A detailed, end-to-end assessment of a quantum algorithm for portfolio optimization, released by Goldman Sachs and AWS",https://aws.amazon.com/blogs/quantum-computing/a-detailed-end-to-end-assessment-of-a-quantum-algorithm-for-portfolio-optimization-released-by-goldman-sachs-and-aws/,In this post we’ll walk you through some key takeaways from a paper published today by scientists from Goldman Sachs and AWS describing a quantum algorithm for portfolio optimization.,[{'name': 'Alexander Dalzell'}],"Mon, 13 Nov 2023 19:43:37 +0000"
2573,Towards practical molecular electronic structure simulations on NISQ devices with Amazon Braket and Kvantify’s FAST-VQE algorithm,https://aws.amazon.com/blogs/quantum-computing/towards-practical-molecular-electronic-structure-simulations-on-nisq-devices-with-amazon-braket-and-kvantifys-fast-vqe-algorithm/,"Quantum computing's potential for computational chemistry is immense, but there are practical limitations. We show how Kvantify’s FAST-VQE algorithm can deliver great accuracy, performance, superior cost-effectiveness, driving us closer to transformative applications in drug discovery.",[{'name': 'Patrick Ettenhuber'}],"Wed, 08 Nov 2023 13:47:08 +0000"
2574,Analog Hamiltonian simulation with PennyLane,https://aws.amazon.com/blogs/quantum-computing/analog-hamiltonian-simulation-with-pennylane/,"In this post, we'll describe how the PennyLane-Braket SDK plugin to study the ground state of the anti-ferromagnetic Ising spin-chain on a 1D lattice on the Aquila quantum processor, a neutral-atom quantum computer available on-demand via the AWS Cloud.",[{'name': 'Mao Lin'}],"Wed, 01 Nov 2023 18:09:31 +0000"
2575,Explore quantum algorithms faster by running your local Python code as an Amazon Braket Hybrid Job with minimal code changes,https://aws.amazon.com/blogs/quantum-computing/explore-quantum-algorithms-faster-by-running-your-local-python-code-as-an-amazon-braket-hybrid-job-with-minimal-code-changes/,Today we'll show you how to use a new python decorator from the Amazon Braket SDK to help algorithm researchers seamlessly execute local Python functions as an Amazon Braket Hybrid Job with just one extra line of code.,[{'name': 'Stefan Natu'}],"Tue, 17 Oct 2023 14:58:22 +0000"
2576,Introducing a new temperature-resistant packaging technique for optical devices,https://aws.amazon.com/blogs/quantum-computing/introducing-a-new-temperature-resistant-packaging-technique-for-optical-devices/,"Today, we’re announcing a first-of-its-kind advancement in photonic interconnection - a fiber-device interface that can withstand multiple cycles of cooling to cryogenic temperatures - and back - without introducing additional losses.",[{'name': 'Denis Sukachev'}],"Mon, 16 Oct 2023 14:18:04 +0000"
2577,Speeding up hybrid quantum algorithms with parametric circuits on Amazon Braket,https://aws.amazon.com/blogs/quantum-computing/speeding-up-hybrid-quantum-algorithms-with-parametric-circuits-on-amazon-braket/,"Today, we're announcing improvements to the task-processing speed and our support for parametric compilation on QPUs from Rigetti Computing in Amazon Braket. This enables up to 10x faster runtime performance for algorithms that use Amazon Braket Hybrid Jobs.",[{'name': 'Tim Chen'}],"Wed, 11 Oct 2023 16:24:26 +0000"
